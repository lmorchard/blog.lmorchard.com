{
  "type": "aside",
  "title": "Quoting Max Woolf",
  "tags": [
    "ai",
    "llms",
    "ml"
  ],
  "time": "14:59:00-07:00",
  "attachments": [],
  "year": "2025",
  "month": "05",
  "day": "14",
  "isDir": false,
  "slug": "quoting-max-woolf",
  "date": "2025-05-14T21:59:00.000Z",
  "postName": "2025-05-14",
  "html": "<p>Max Woolf, \"<a href=\"https://minimaxir.com/2025/05/llm-use/\">As an Experienced LLM User, I Actually Don't Use Generative LLMs Often</a>\":</p>\n<blockquote>\n<p>Two things can be true simultaneously: (a) LLM provider cost economics are too negative to return positive ROI to investors, and (b) LLMs are useful for solving problems that are meaningful and high impact, albeit not to the AGI hype that would justify point (a). This particular combination creates a frustrating gray area that requires a nuance that an ideologically split social media can no longer support gracefully.</p>\n</blockquote>\n<p>I think this jibes well with what I <a href=\"https://blog.lmorchard.com/2025/05/13/thinking-about-llms/\">tried exporting from my head</a>, yesterday.</p>\n<blockquote>\n<p>There is one silly technique I discovered to allow a LLM to improve my writing without having it do my writing: feed it the text of my mostly-complete blog post, and ask the LLM to pretend to be a cynical Hacker News commenter and write five distinct comments based on the blog post. This not only identifies weaker arguments for potential criticism, but it also doesnâ€™t tell me what I should write in the post to preemptively address that negative feedback so I have to solve it organically.</p>\n</blockquote>\n<p>Oh, I might have to try that. ðŸ¤” I have used Claude to occasionally critique and brutally edit down some of the rambling texts that I've spewed into an editor. But this sounds like a whole 'nother level.</p>\n",
  "body": "\nMax Woolf, \"[As an Experienced LLM User, I Actually Don't Use Generative LLMs Often](https://minimaxir.com/2025/05/llm-use/)\":\n\n> Two things can be true simultaneously: (a) LLM provider cost economics are too negative to return positive ROI to investors, and (b) LLMs are useful for solving problems that are meaningful and high impact, albeit not to the AGI hype that would justify point (a). This particular combination creates a frustrating gray area that requires a nuance that an ideologically split social media can no longer support gracefully.\n\nI think this jibes well with what I [tried exporting from my head](https://blog.lmorchard.com/2025/05/13/thinking-about-llms/), yesterday.\n\n> There is one silly technique I discovered to allow a LLM to improve my writing without having it do my writing: feed it the text of my mostly-complete blog post, and ask the LLM to pretend to be a cynical Hacker News commenter and write five distinct comments based on the blog post. This not only identifies weaker arguments for potential criticism, but it also doesnâ€™t tell me what I should write in the post to preemptively address that negative feedback so I have to solve it organically.\n\nOh, I might have to try that. ðŸ¤” I have used Claude to occasionally critique and brutally edit down some of the rambling texts that I've spewed into an editor. But this sounds like a whole 'nother level.",
  "parentPath": "./content/posts/2025",
  "path": "2025/05/14/quoting-max-woolf",
  "prevPostPath": "2025/05/14/quoting-ashley-willis",
  "prevPostTitle": "Quoting Ashley Willis",
  "nextPostPath": "2025/05/14/quoting-david-gerard",
  "nextPostTitle": "Open Source contributions and AI annoyances"
}