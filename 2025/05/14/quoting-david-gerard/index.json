{
  "type": "aside",
  "title": "Open Source contributions and AI annoyances",
  "slug": "quoting-david-gerard",
  "tags": [
    "ai",
    "llms",
    "vibecoding"
  ],
  "time": "21:06:00-00:07",
  "attachments": [],
  "year": "2025",
  "month": "05",
  "day": "14",
  "isDir": false,
  "date": "2025-05-14T21:13:00.000Z",
  "postName": "2025-05-14",
  "html": "<p>David Gerard, \"<a href=\"https://pivot-to-ai.com/2025/05/13/if-ai-is-so-good-at-coding-where-are-the-open-source-contributions/\">If AI is so good at coding … where are the open source contributions?</a>\"</p>\n<blockquote>\n<p>You can hardly get online these days without hearing some AI booster talk about how AI coding is going to replace human programmers. AI code is absolutely up to production quality! Also, you’re all fired.</p>\n<p>But if AI is so obviously superior … show us the code. Where’s the receipts? Let’s say, where’s the open source code contributions using AI?</p>\n</blockquote>\n<p><a href=\"https://aider.chat/docs/faq.html#what-llms-do-you-use-to-build-aider\">The developer of Aider claims \"about 70% of new code in each release\" is written via Aider itself</a>. I haven't double checked it myself, but it seems like those metrics would be a lot of fuss to fake. Maybe that's the exception that proves the rule, though? Aider is, itself, an open source LLM-powered coding assistant. It works pretty well, though, IMO.</p>\n<blockquote>\n<p>It’s true that a lot of open source projects really hate AI code. There’s several objections, but the biggest one is that users who don’t understand their own lack of competence spam the projects with time-wasting AI garbage. The Curl project banned AI-generated security reports because they were getting flooded with automated AI-generated “bug bounty” requests.</p>\n<p>More broadly, the very hardest problem in open source is not code, it’s people — how to work with others. Some AI users just don’t understand the level they simply aren’t working at.</p>\n</blockquote>\n<p>Like Max Woolf wrote, \"<a href=\"https://minimaxir.com/2023/10/ai-sturgeons-law/\">The Greatest Threat to Generative AI is Humans Being Bad at Using it</a>\" - in other words, the jerks ruin it for everyone. </p>\n<p>I don't work so much in open source, these days, at least not during work hours. But, I don't miss when certain internship programs and college courses would require participants to provably open and get merged at least one Pull Request as a part of their programs. I think Wikipedia saw something similar. It would be a mess: just a flood of perfunctory, usually trivial little contributions aimed at checking off the box.</p>\n<p>Whether well meaning or not, it seems like a bunch of folks now seem to feel personally super-powered to dive into projects. But, alas, it's with similar or worse effect as the interns and students. Is the motivation for clout? Do they genuinely want to help? Either way, I can imagine why project leaders feel a bit surly about the whole thing.</p>\n",
  "body": "\nDavid Gerard, \"[If AI is so good at coding … where are the open source contributions?](https://pivot-to-ai.com/2025/05/13/if-ai-is-so-good-at-coding-where-are-the-open-source-contributions/)\"\n\n> You can hardly get online these days without hearing some AI booster talk about how AI coding is going to replace human programmers. AI code is absolutely up to production quality! Also, you’re all fired.\n> \n> But if AI is so obviously superior … show us the code. Where’s the receipts? Let’s say, where’s the open source code contributions using AI?\n\n[The developer of Aider claims \"about 70% of new code in each release\" is written via Aider itself](https://aider.chat/docs/faq.html#what-llms-do-you-use-to-build-aider). I haven't double checked it myself, but it seems like those metrics would be a lot of fuss to fake. Maybe that's the exception that proves the rule, though? Aider is, itself, an open source LLM-powered coding assistant. It works pretty well, though, IMO.\n\n> It’s true that a lot of open source projects really hate AI code. There’s several objections, but the biggest one is that users who don’t understand their own lack of competence spam the projects with time-wasting AI garbage. The Curl project banned AI-generated security reports because they were getting flooded with automated AI-generated “bug bounty” requests.\n> \n> More broadly, the very hardest problem in open source is not code, it’s people — how to work with others. Some AI users just don’t understand the level they simply aren’t working at.\n\nLike Max Woolf wrote, \"[The Greatest Threat to Generative AI is Humans Being Bad at Using it](https://minimaxir.com/2023/10/ai-sturgeons-law/)\" - in other words, the jerks ruin it for everyone. \n\nI don't work so much in open source, these days, at least not during work hours. But, I don't miss when certain internship programs and college courses would require participants to provably open and get merged at least one Pull Request as a part of their programs. I think Wikipedia saw something similar. It would be a mess: just a flood of perfunctory, usually trivial little contributions aimed at checking off the box.\n\nWhether well meaning or not, it seems like a bunch of folks now seem to feel personally super-powered to dive into projects. But, alas, it's with similar or worse effect as the interns and students. Is the motivation for clout? Do they genuinely want to help? Either way, I can imagine why project leaders feel a bit surly about the whole thing.",
  "parentPath": "./content/posts/2025",
  "path": "2025/05/14/quoting-david-gerard",
  "prevPostPath": "2025/05/14/quoting-max-woolf",
  "prevPostTitle": "Quoting Max Woolf",
  "nextPostPath": "2025/05/14/generating-documentation-for-my-easyblog-oven-with",
  "nextPostTitle": "Generating documentation for my Easy-Blog Oven with Claude"
}