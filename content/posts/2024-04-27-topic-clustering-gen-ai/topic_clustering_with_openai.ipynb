{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "xr748rctc4Ib",
      "metadata": {
        "id": "xr748rctc4Ib"
      },
      "outputs": [],
      "source": [
        "%pip install openai scikit-learn\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "config = {}\n",
        "\n",
        "# Copy some secrets into config\n",
        "config.update(dict((k, userdata.get(k)) for k in [\n",
        "    'openai_api_key'\n",
        "]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "40e592a9-ff26-4f94-a93b-9c59339c4653",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40e592a9-ff26-4f94-a93b-9c59339c4653",
        "outputId": "83247ae0-d9b2-41a0-c68f-3389a56068bf",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.23.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install openai scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f667fd54-3828-4b8f-84c4-8c549aa1f70d",
      "metadata": {
        "id": "f667fd54-3828-4b8f-84c4-8c549aa1f70d"
      },
      "source": [
        "Let's brainstorm a list of miscellaneous things:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "6e91a7c1-ee10-4b71-b7cc-5ee3ff5f38f1",
      "metadata": {
        "id": "6e91a7c1-ee10-4b71-b7cc-5ee3ff5f38f1"
      },
      "outputs": [],
      "source": [
        "items_text = \"\"\"\n",
        "- pasta\n",
        "- thomas dolby\n",
        "- alpha\n",
        "- apples\n",
        "- cats\n",
        "- pears\n",
        "- meters\n",
        "- brick\n",
        "- dogs\n",
        "- beta\n",
        "- howard jones\n",
        "- concrete\n",
        "- asphalt\n",
        "- milk\n",
        "- rebar\n",
        "- gillian gilbert\n",
        "- hamsters\n",
        "- bread\n",
        "- butter\n",
        "- wendy carlos\n",
        "- gamma\n",
        "- birds\n",
        "- bananas\n",
        "- rick wakeman\n",
        "- inches\n",
        "- glass\n",
        "- feet\n",
        "- gary numan\n",
        "- miles\n",
        "- lumber\n",
        "- kilometers\n",
        "- geoff downes\n",
        "\"\"\"\n",
        "\n",
        "# Split the text into non-empty lines...\n",
        "items = [x for x in items_text.split(\"\\n\") if x]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L9iFm_f9lXRn",
      "metadata": {
        "id": "L9iFm_f9lXRn"
      },
      "source": [
        "We're going to use OpenAI's services, so let's create a client with our API key:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "NV9kLwjeiKgh",
      "metadata": {
        "id": "NV9kLwjeiKgh"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "openai_client = OpenAI(api_key=config[\"openai_api_key\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be31fc26-fba7-43e1-9609-8f2138ac5090",
      "metadata": {
        "id": "be31fc26-fba7-43e1-9609-8f2138ac5090"
      },
      "source": [
        "Next, let's pick an embedding model and generate semantic vector representations for all our list items:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "qa6Z5_E1kBKR",
      "metadata": {
        "id": "qa6Z5_E1kBKR"
      },
      "outputs": [],
      "source": [
        "embeddings_response = openai_client.embeddings.create(\n",
        "  model=\"text-embedding-ada-002\",\n",
        "  input=items,\n",
        "  encoding_format=\"float\"\n",
        ")\n",
        "embeddings = [embedding_item.embedding for embedding_item in embeddings_response.data]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ca1f979-c48e-4abf-9234-ea18e5dc9279",
      "metadata": {
        "id": "0ca1f979-c48e-4abf-9234-ea18e5dc9279"
      },
      "source": [
        "Now that we have vectors, let's try clustering them within the semantic space of the model. This should be roughly analogous to grouping them by meaning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "a01789e5-0257-4227-a71a-666cc1160e98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a01789e5-0257-4227-a71a-666cc1160e98",
        "outputId": "4d307737-2693-4797-c54f-3e5916c3533b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['- lumber'],\n",
              " ['- apples', '- pears', '- milk', '- butter', '- bananas'],\n",
              " ['- meters', '- miles', '- kilometers'],\n",
              " ['- alpha', '- beta', '- gamma'],\n",
              " ['- howard jones', '- geoff downes'],\n",
              " ['- brick', '- concrete', '- asphalt', '- rebar', '- glass'],\n",
              " ['- pasta', '- bread'],\n",
              " ['- cats', '- dogs', '- hamsters', '- birds'],\n",
              " ['- thomas dolby'],\n",
              " ['- wendy carlos', '- rick wakeman'],\n",
              " ['- gillian gilbert', '- gary numan'],\n",
              " ['- inches', '- feet']]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from itertools import groupby\n",
        "\n",
        "# Let's say we want to organize the list into this many clusters\n",
        "n_clusters = 12\n",
        "\n",
        "# Use the k-means algorithm to come up with a cluster ID for each embedding\n",
        "cluster_ids = KMeans(n_clusters=n_clusters, n_init='auto').fit_predict(embeddings)\n",
        "\n",
        "# Associate each cluster ID with the corresponding item\n",
        "cluster_ids_with_items = zip(cluster_ids, items)\n",
        "\n",
        "# Group the pairs of (cluster_id, item) into lists based on cluster ID\n",
        "grouped_cluster_ids_with_items = groupby(\n",
        "    sorted(cluster_ids_with_items, key=lambda x: x[0]),\n",
        "    key=lambda x: x[0]\n",
        ")\n",
        "\n",
        "# Simplify that whole mess so we just have a list of clustered items\n",
        "clustered_items = [\n",
        "    [item for cluster_id, item in item_group]\n",
        "    for cluster_id, item_group\n",
        "    in grouped_cluster_ids_with_items\n",
        "]\n",
        "\n",
        "clustered_items"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f44e1d2-7179-4bce-8d0a-e716eecfcfb4",
      "metadata": {
        "id": "8f44e1d2-7179-4bce-8d0a-e716eecfcfb4"
      },
      "source": [
        "It's not perfect, but we've got our list roughly organized. Let's try coming up with a title for each cluster:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "XA7ElVJ-gIje",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA7ElVJ-gIje",
        "outputId": "74c36e14-8b96-4ce6-b2b9-8501525b2f00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Building materials\n",
            "\n",
            "- lumber\n",
            "\n",
            "# Groceries\n",
            "\n",
            "- apples\n",
            "- pears\n",
            "- milk\n",
            "- butter\n",
            "- bananas\n",
            "\n",
            "# Units of Length\n",
            "\n",
            "- meters\n",
            "- miles\n",
            "- kilometers\n",
            "\n",
            "# Greek letters\n",
            "\n",
            "- alpha\n",
            "- beta\n",
            "- gamma\n",
            "\n",
            "# Synthpop musicians\n",
            "\n",
            "- howard jones\n",
            "- geoff downes\n",
            "\n",
            "# Building materials\n",
            "\n",
            "- brick\n",
            "- concrete\n",
            "- asphalt\n",
            "- rebar\n",
            "- glass\n",
            "\n",
            "# Carbohydrate-rich foods\n",
            "\n",
            "- pasta\n",
            "- bread\n",
            "\n",
            "# Household pets\n",
            "\n",
            "- cats\n",
            "- dogs\n",
            "- hamsters\n",
            "- birds\n",
            "\n",
            "# Synthpop music artists\n",
            "\n",
            "- thomas dolby\n",
            "\n",
            "# Synthesizer music pioneers\n",
            "\n",
            "- wendy carlos\n",
            "- rick wakeman\n",
            "\n",
            "# Synthpop Pioneers\n",
            "\n",
            "- gillian gilbert\n",
            "- gary numan\n",
            "\n",
            "# Length measurements\n",
            "\n",
            "- inches\n",
            "- feet\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# for openai gpt-3.5-turbo\n",
        "topic_generation_prompt = \"\"\"\n",
        "Please consider a list of items, one item per line.\n",
        "From that list, produce a single concise label describing the entire list of items as a whole while avoiding the inclusion of the items.\n",
        "The label should consist of fewer than 7 words.\n",
        "Do not offer conversational preamble.\n",
        "Do not explain the result.\n",
        "Do not include any extraneous formatting or punctuation.\n",
        "Thank you!\n",
        "\"\"\"\n",
        "\n",
        "def generate_topic(items):\n",
        "    text = \"\\n\".join(items)\n",
        "    completion = openai_client.chat.completions.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=[\n",
        "        {\"role\": \"system\", \"content\": topic_generation_prompt},\n",
        "        {\"role\": \"user\", \"content\": text}\n",
        "      ]\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "for cluster in clustered_items:\n",
        "    topic = generate_topic(cluster)\n",
        "\n",
        "    print(f\"# {topic}\")\n",
        "    print()\n",
        "    for item in cluster:\n",
        "        print(f\"{item}\")\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
