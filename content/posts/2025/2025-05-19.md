8<--- { "title": "Miscellanea for 2025-05-19", "time": "23:59:00-07:00", "type": "miscellanea", "slug": "miscellanea", "tags": [ "miscellanea" ] }

- Hello world!
- "[Log Lady Look-Alike Contest Photos](https://www.portlandmercury.com/photo/2025/05/19/47791648/log-lady-look-alike-contest-photos-shes-got-the-look-and-the-log): Sheâ€™s Got the Look (and the Log)" 
	- I love this city.
- Interesting bugs here in my Rube Goldberg blogging machine involving Syncthing and Obsidian, where sync conflicts become clashing ghost entries ðŸ¤”
- I've been using Obsidian for about 5 years now for my daily notes. I've been tempted to take another swing at writing my own notebook, because I barely use any of Obsidian's fancier features. I mainly like that's it's a good cross-platform Markdown editor with a few plugins that I've settled on for regular use.
- I have a vague notion to make a USB or wifi interface for an old Atari 

8<--- { "title": "Foggy Blogging", "time": "12:58:20-07:00", "slug": "foggy-blogging", "tags": [ "metablogging", "covid", "brainfog" ] }

Baldur Bjarnason, "[Foggy feeds: the decline in my feed reader subscriptions](https://www.baldurbjarnason.com/notes/2025/foggy-feeds/)":

> ...I follow a lot of feeds in my feed reader, most of them only updating at most once a month, maybe weekly, and only a tiny handful update daily. About seven hundred (700) of the feeds I follow are active and Iâ€™ve been following some of them since the early 2000s.
> 
> Thatâ€™s a decent sample size both across fields â€“ tech, media, and academia â€“ and time â€“ Iâ€™ve been following most of these since before COVID â€“ and the decline in peopleâ€™s thinking across many of these feeds has been noticeable because itâ€™s incredibly fucking annoying.

My feeds suck, right now. My main excuse is I'm way out of the habit of blogging like I did 20 years ago. And I think part of that habit is thinking out loud, getting things out into words in front of me to clarify the thinking. Tweets and toots aren't really long enough to let a fully formed notion flop out of my head and thrash around on the desk for awhile.

I do know a lot of folks who got COVID, though. Gratefully, I seem to have avoided it so far. Is this like the notion that [the Roman Empire collapsed due to lead poisoning](https://arstechnica.com/science/2021/07/did-lead-poisoning-cause-downfall-of-roman-empire-the-jury-is-still-out/)? I do feel like there's a lot of stupidity out there right now, like more than I'd expect. I don't know if that's a conspiracy theory or just cynicism.

8<--- { "title": "AI winter, again", "time": "11:07:43-07:00", "slug": "llm-winter", "tags": [ "ai", "llms", "dev" ] }

carl svensson, [Is Winter Coming?](https://www.datagubbe.se/winter/):

> Even when it comes to something like LLM-assisted programming, where a highly skilled developer can maybe, sometimes, somewhat gain a performance boost, the most pertinent question isn't if it can be done at all - but rather if what can be done good enough can also be done profitably. The number of GPUs and the amount of increasingly expensive energy required remains as unclear as the time frame needed to accomplish it. 

I don't disagree that this is where things are right now. Personally, I'm getting utility from these tools - mainly for things that I could do myself, but the LLM lets me carve off a few rounds of googling and Stack Overflow browsing. That's valuable. Probably not as valuable as investors are hoping, though.

I see some glimmers of potential in letting the agents rip in full-auto. But, I do also find that ofttimes they're [developer slot machines](https://prototypr.io/note/vibe-coding-cursor-windsurf-slot-machine) that need careful tending to keep them from going off into the weeds, going into loops, and going off on quests for which I never asked.

I'm seeing the most value in these tools when they're given a lot of context and kept constrained to limited tasks in a tight loop with adult supervision. I've got a hunch this will improve over time, but who knows? We could hit a wall and see winter soon?

I'd really like it if this stuff would settle down and be [normal](https://www.fastly.com/blog/can-we-be-normal-about-ai-now-that-deepseek-happened). But, there's probably going to be a crash before that happens.

8<--- { "title": "Beyond Text-only AI", "time": "15:28:39-07:00", "slug": "beyond-text-only-ai", "tags": [ "ux", "llm", "ai" ] }

Fatih Kadir AkÄ±n, "[Beyond Text-Only AI: On-Demand UI Generation for Better Conversational Experience](https://blog.fka.dev/blog/2025-05-16-beyond-text-only-ai-on-demand-ui-generation-for-better-conversational-experiences/)":

> What if AI systems could generate precisely the right interface components when needed, without requiring developers to build every possible UI variation in advance? This post explores my work on a new prototype that enables LLMs to create dynamic, interactive UI components on demand, transforming how users interact with AI systems and MCP servers.

This is where LLMs are very interesting to me, where applications with them are most able to escape hype into practical building. A thing they're good at is taking some of the vague stuff we hand-wave at like "you know, that thing with the days in squares on it" and jumping to "you mean a calendar?" But then, skip straight from that to presenting a calendar for input as part of the workflow.

I'm finding LLMs most handy when they work in smaller universes. Give it a relatively small inventory of UI components, properly described with context, and they can be great at picking which one to use and when. Hard to hallucinate when there's not a wide range for wandering, easy to mitigate what hallucinations might occur when you can automatically kick it back into bounds. Meanwhile, the workflow can feel more smooth and demand less fiddly navigation from a user. That seems like a really promising glimmer to me.