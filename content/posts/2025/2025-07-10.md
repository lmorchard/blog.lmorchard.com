8<--- { "draft": false, "title": "Miscellanea for 2025-07-10", "time": "23:59:00-07:00", "type": "miscellanea", "slug": "miscellanea", "tags": [ "miscellanea" ] }

- Hello world!
- Trying to decide if this is a "[still alive](https://www.youtube.com/watch?v=Y6ljFaKRTrI)" or a "[beware, I live!](https://www.youtube.com/watch?v=CC2iqlvifSU)" kind of day?
- Either way, I've been down a hole of busy-ness for the past few weeks and been wanting to climb out to emit some reports here.
- Still trying to find a good balance while spinning plates across multiple projects. But, I've gotten a lot done without quite going entirely insane.
- Feel like I've suddenly become a cyborg over the past few weeks. Been working across multiple instances of Claude Code all day, every day.
- Also feels like I've picked a side in the war against Skynet in some folks' estimation. Except, to me, it feels like working with a concussed version of the main computer from the USS Enterprise (NCC-1701-D)â€”which is still pretty advanced for the 21st century.
- I've gotten well acquainted with Anthropic's usage limits, having managed to reliably burn through my Max plan allowances every 5 hours or so.
- I'm considering implementing [usage monitoring](https://docs.anthropic.com/en/docs/claude-code/monitoring-usage) to better understand my consumption patterns with Claude.
- Both Claude and I could probably use a brief vacation. I guess the kids call that a "[micro-retirement](https://www.fastcompany.com/91357784/what-is-a-micro-retirement-inside-the-latest-gen-z-trend)" these days?

8<--- { "draft": false, "title": "Do AI tools really slow me down by 20%?", "slug": "ai-tools-slowdown", "tags": [ "ai", "genai", "codegen", "llms", "cursor" ], "time": "16:26:50-07:00" }

[Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity - METR](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/):

  > We conduct a randomized controlled trial \(RCT\) to understand how early-2025 AI tools affect the productivity of experienced open-source developers working on their own repositories. Surprisingly, we find that when developers use AI tools, they take 19% longer than withoutâ€”AI makes them slower.

I'm seeing plenty of "I told you so" as this makes the rounds. But, having spent the past month deep in AI-assisted coding, it directly contradicts my experience. Maybe I've drunk too much Kool-Aid, but I don't think I'm entirely delusional. I want to head-scratch through this, though.

## Small sample, specific scenario

> we recruited 16 experienced developers from large open-source repositories (averaging 22k+ stars and 1M+ lines of code) that theyâ€™ve contributed to for multiple years.

That's a rather small sample and a very specific scenario, isn't it?

The researchers themselves acknowledge the limitations:

> We caution readers against overgeneralizing on the basis of our results. The slowdown we observe does not imply that current AI tools do not often improve developerâ€™s productivityâ€”we find evidence that the high developer familiarity with repositories and the size and maturity of the repositories both contribute to the observed slowdown, and these factors do not apply in many software development settings. For example, our results are consistent with small greenfield projects or development in unfamiliar codebases seeing substantial speedup from AI assistance.

Maybe this bit from the "Key Caveats" section basically jibes with my experience? My recent work (admittedly, a sample of 1) *has indeed* been largely with greenfield projects and relatively unfamiliar codebases.

## It does matter how you use it

The researchers hint at something important:

>We expect that AI systems that have higher fundamental reliability, lower latency, and/or are better elicited (e.g. via more inference compute/tokens, more skilled prompt-ing/scaffolding, or explicit fine-tuning on repositories) could speed up developers in our setting (i.e. experienced open-source developers on large repositories).

I think this rhymes with my experience, too. When I've just charged into a rambling chat & autocomplete session with Cursor, things steer into the ditch early and often.

But when I've worked with Claude Code through [a multi-step process](https://blog.lmorchard.com/2025/06/07/semi-automatic-coding/) of describing the problem, asking the agent to prompt _me_ with clarifying questions, reviewing the problem and considering a solution, breaking it down into parts, and then asking the agent to methodically executeâ€”that's yielded decently reliable success.

## Waiting, or lack thereof

The study notes:

> All else equal, faster AI generations would result in developers being slowed down less. Qualitatively, a minority of developers note that they spend significant time waiting on AI to generate code.

I rarely wait, because I'm juggling multiple projects. When one agent instance is working, I switch to another window. Sometimes it's [a separate git worktree of the same codebase](https://docs.anthropic.com/en/docs/claude-code/common-workflows#run-parallel-claude-code-sessions-with-git-worktrees). Yes, context switching is tiring, but it also seems to help me overcome ADHD-related activation energy barriers?

Over the years, there've been days when I just sit there staring at the IDE window, poking my brain with a stick saying "c'mon, do something" and nothing happens for an hour or more. I'm not planning my next move, I'm just dissociating. My executive function doesn't, like, function. Often. *My own brain* makes me wait long periods of time before it starts generating useful results. ðŸ˜…

Maybe it's the cycling novelty that keeps me going? I enjoy task switching between prosing and coding. I enjoy finding that the model appears to have "read" everythingâ€”evidenced by it echoing my intent back in code or follow-up questions. I enjoy discovering that while I was in another window, new things happened in the background for me to review.

I've also found that many agents are reliable at handling drudgery. Re-jiggering data structures, applying repeated refactorings, etc. Those tasks can seize me up for tens of minutes at a time with brain-killing waves of tedium. But usually, I can just tell the bot to do it, while I turn to more interesting stuff.

## Summing up

> Although the influence of experimental artifacts cannot be entirely ruled out, the robustness of the slowdown effect across our analyses suggests it is unlikely to primarily be a function of our experimental design.

This study provides one data point about one specific scenario: experienced developers using specific tools on massive, mature codebases. The researchers themselves caution against overgeneralization, noting that different contexts likely yield different results.

These tools aren't magic and they're not universally beneficial. But dismissing them based on this narrow study would be premature. The key is understanding when, how, and why to use themâ€”something that's still evolving rapidly as both tools and techniques improve.

8<--- { "draft": false, "title": "Building a Breakout clone with Claude", "slug": "breakout-with-claude", "tags": [ "codegen", "ai", "llms", "claude", "gamedev" ], "time": "11:11:01-07:00" }

To make steps toward showing and telling about my Claude Code workflow, I built a browser-based Breakout game with Phaser 3. The [repository](https://github.com/lmorchard/claude-breakout-clone) captures the full development process so farâ€”prompts, commands, and session transcripts.

Along with the basic game, [I added a multi-ball power-up](https://github.com/lmorchard/claude-breakout-clone/tree/main/docs/dev-sessions/2025-07-05-1336-multiball) to demonstrate iterative development. The game itself isn't particularly novel, but the documented development process might be useful for others exploring AI-assisted coding workflows.

At some point, this will turn into a show-and-tell presentation for co-workers and maybe a follow-up to last month's blog post on ["Baby steps into semi-automatic coding"](https://blog.lmorchard.com/2025/06/07/semi-automatic-coding/).

This took all of a couple hours on a Saturday afternoon on the couch watching TV, but I kind of want to keep going with it. It's rather addictive to just kind of riff on ideas and get them into the game with quick little iterations.

8<--- { "draft": false, "title": "Progress on Pebbling Club", "slug": "progress-on-pebbling-club", "tags": [ "pebblingclub", "codegen", "claude" ], "time": "11:54:03-07:00" }

I've been procrastinating getting back to it, but I finally threw some hours into a substantial overhaul of my [Pebbling Club](https://github.com/lmorchard/pebbling-club) web link sharing projectâ€”the first real efforts since December! Migrated [from SQLite to Postgres](https://github.com/lmorchard/pebbling-club/pull/239), [switched to uv](https://github.com/lmorchard/pebbling-club/pull/238) for dependency management, and moved deployment from fly.io to my basement machine running Docker Compose.

I built [my own git-push deployment post-receive hook](https://github.com/lmorchard/pebbling-club/blob/main/docker/compose/post-receive) because I'm a masochistâ€”er, I mean I wanted complete control over the deployment process. It's nice watching your own server rebuild containers when you push to main, even if cloud platforms would be more practical.

The development environment [became a hybrid](https://github.com/lmorchard/pebbling-club/pull/240): Docker Compose for stable services, Honcho + Procfile for active development. Added Flower for Celery monitoring and experimented with Prometheus and Grafana metrics. (But, then, I [reverted django-prometheus](https://github.com/lmorchard/pebbling-club/pull/255) because it doesn't work at all like I thought it did.)

I got several useful features working: [RSS feed reading](https://github.com/lmorchard/pebbling-club/commits/main/pebbling_apps/feeds), [duplicate URL detection through normalized hashing](https://github.com/lmorchard/pebbling-club/pull/249), ActivityStreams-inspired [import](https://github.com/lmorchard/pebbling-club/pull/250)/[export](https://github.com/lmorchard/pebbling-club/pull/248), and a [Netscape Bookmarks HTML export](https://github.com/lmorchard/pebbling-club/pull/247) (for fun). Built [a link inbox](https://github.com/lmorchard/pebbling-club/pull/250) that currently handles RSS feeds, with in-progress work to add [Mastodon timeline integration](https://github.com/lmorchard/pebbling-club/pull/254) and plans for Bluesky.

Along the way, I wanted to see how far I could get with Claude Code and make tweaks to my overall process. If nothing else, the bot helped me get past the barrier of activation energy to get some things done that I've put off for most of a year. The bot wrote a bunch of just-fine codeâ€”and where it was wrong, the wrongness motivated me to get it fixed and done myself.
