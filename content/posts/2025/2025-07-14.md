8<--- { "draft": false, "title": "Miscellanea for 2025-07-14", "time": "23:59:00-07:00", "type": "miscellanea", "slug": "miscellanea", "tags": [ "miscellanea" ] }

- Hello world!
- Spent a chunk Sunday doing [inadvisable things](https://switch.hacks.guide/) with my Nintendo Switch to back up all my downloaded games and game saves.
	- I think this risks getting the console banned from Nintendo's online services? But, the gist I've gotten from Reddit [and elsewhere](https://nx.eiphax.tech/ban.html) is that they seem to reserve that hammer for folks who actually pirate, hack, and cheat in multiplayer games.
	- Me, I just want to dump stuff to my NAS for later restoration if Something Bad happens. I did this with my 3DS, back when the eShop was on its way out. I've since been able to wipe and restore all my games on there without Nintendo's help. That makes me happy.
	- Since the Switch 2 is out, I figure the Switch 1 is on the verge of end-of-life. So, now seems like a good time to jailbreak the thing, even if I risk it getting cut off from the mothership.

8<--- { "draft": true, "title": "Quoting John Whiles on that METR paper", "slug": "mental-model-metr", "tags": [ "llms", "codegen", "ai" ], "time": "10:30:15-07:00" }

On that METR paper [on which I commented](https://blog.lmorchard.com/2025/07/10/ai-tools-slowdown/), last week, [John Whiles writes](https://johnwhiles.com/posts/mental-models-vs-ai-tools):

> We know that the programmers in Metr's study are all people with extremely well developed mental models of the projects they work on. And we also know that the LLMs they used had no real access to those mental models. The developers could provide chunks of that mental model to their AI tools - but doing so is a slow and lossy process that will never truly capture the theory of the program that exists in their minds. By offloading their software development work to an LLM they hampered their unique ability to work on their codebases effectively.

I think this goes back to what I think is the hot issue in AI-assisted coding tools right now - i.e. "[context management](https://docs.anthropic.com/en/docs/build-with-claude/context-windows)". These tools work best when they're given well-constructed context and 

> It's common for engineers to end up working on projects which they don't have an accurate mental model of. Projects built by people who have long since left the company for pastures new. It's equally common for developers to work in environments where little value is placed on understanding systems, but a lot of value is placed on quickly delivering changes that mostly work. In this context, I think that AI tools have more of an advantage. They can ingest the unfamiliar codebase faster than any human can, and can often generate changes that will essentially work.


> Okay, so if you don't have a mental model of a program, then maybe an LLM could improve your productivity. However, we agreed earlier that the main purpose of writing software is to build a mental model. If we outsource our work to the LLM are we still able to effectively build the mental model? I doubt it

