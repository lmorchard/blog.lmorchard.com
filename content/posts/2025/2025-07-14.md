8<--- { "draft": false, "title": "Miscellanea for 2025-07-14", "time": "23:59:00-07:00", "type": "miscellanea", "slug": "miscellanea", "tags": [ "miscellanea" ] }

- Hello world!
- Spent a chunk Sunday doing [inadvisable things](https://switch.hacks.guide/) with my Nintendo Switch to back up all my downloaded games and game saves.
	- I think this risks getting the console banned from Nintendo's online services? But, the gist I've gotten from Reddit [and elsewhere](https://nx.eiphax.tech/ban.html) is that they seem to reserve that hammer for folks who actually pirate, hack, and cheat in multiplayer games.
	- Me, I just want to dump stuff to my NAS for later restoration if Something Bad happens. I did this with my 3DS, back when the eShop was on its way out. I've since been able to wipe and restore all my games on there without Nintendo's help. That makes me happy.
	- Since the Switch 2 is out, I figure the Switch 1 is on the verge of end-of-life. So, now seems like a good time to jailbreak the thing, even if I risk it getting cut off from the mothership.

8<--- { "draft": true, "title": "On Mental Models vs LLM Context in Programming", "slug": "mental-model-metr", "tags": [ "llms", "codegen", "ai" ], "time": "10:30:15-07:00" }

Still thinking about that METR study and I saw [John Whiles write this](https://johnwhiles.com/posts/mental-models-vs-ai-tools):

> The developers could provide chunks of that mental model to their AI tools - but doing so is a slow and lossy process that will never truly capture the theory of the program that exists in their minds. By offloading their software development work to an LLM they hampered their unique ability to work on their codebases effectively.

I think this is a good take on why AI assistants slowed down developers in that study. A core challenge with AI coding assistants is context composition and management. But, creating that context takes time and effort that's often orthogonal to writing code.

For developers who can manage complex context in their heads as wordless thought-forms, just writing the code can be faster. AI agents aren't mind-readers, and LLM context windows don't match human headspace.

Here's the irony: AI tools help in situations where human mental models are weakest—and those situations often exist because expert programmers never tried to write down their mental models in the first place. When you're working on projects built by people who left years ago, onboarding engineers struggle to form accurate mental models because the veteran engineers who _had_ those models never documented them. New engineers have to start from scratch.

LLMs can ingest unfamiliar code faster than humans and generate changes that work because they resemble historic patterns. More importantly, they excel at transforming code symbols into readable explanations—roughly reverse-engineering a likely facsimile of documentation that should have existed.

If you expect to work on a project long-term and want to truly understand it, you need to do the homework: write the code yourself with maybe a little LLM advice and way-finding. At the very least, you should be reviewing LLM-generated code before merging it.

The best approach treats these tools as what they are: power tools for symbol transformation and pattern completion, grinding through boilerplate work that doesn't demand high creativity. They're not replacements for human thinking about architecture, requirements, and constraints.
