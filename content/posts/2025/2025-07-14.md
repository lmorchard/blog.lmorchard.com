8<--- { "draft": false, "title": "Miscellanea for 2025-07-14", "time": "23:59:00-07:00", "type": "miscellanea", "slug": "miscellanea", "tags": [ "miscellanea" ] }

- Hello world!
- Spent a chunk Sunday doing [inadvisable things](https://switch.hacks.guide/) with my Nintendo Switch to back up all my downloaded games and game saves.
	- I think this risks getting the console banned from Nintendo's online services? But, the gist I've gotten from Reddit [and elsewhere](https://nx.eiphax.tech/ban.html) is that they seem to reserve that hammer for folks who actually pirate, hack, and cheat in multiplayer games.
	- Me, I just want to dump stuff to my NAS for later restoration if Something Bad happens. I did this with my 3DS, back when the eShop was on its way out. I've since been able to wipe and restore all my games on there without Nintendo's help. That makes me happy.
	- Since the Switch 2 is out, I figure the Switch 1 is on the verge of end-of-life. So, now seems like a good time to jailbreak the thing, even if I risk it getting cut off from the mothership.

8<--- { "draft": true, "title": "On Mental Models vs LLM Context in Programming", "slug": "mental-model-metr", "tags": [ "llms", "codegen", "ai" ], "time": "10:30:15-07:00" }

The core challenge with AI coding assistants isn't their capability—it's context management. These tools work best when given well-constructed context and clear descriptions of the work to be done. But creating that context takes time and effort that's often orthogonal to actually writing code.

[John Whiles captured this well](https://johnwhiles.com/posts/mental-models-vs-ai-tools) in his analysis of the recent METR study:

> The developers could provide chunks of that mental model to their AI tools - but doing so is a slow and lossy process that will never truly capture the theory of the program that exists in their minds. By offloading their software development work to an LLM they hampered their unique ability to work on their codebases effectively.

For developers who can manage complex context in their heads as abstract notions, just writing the code is often faster. LLMs aren't mind-readers, and their context windows don't match human headspace.

## The Documentation Irony

Here's the irony: AI tools help most in situations where human mental models are weakest—and those situations often exist because expert programmers never wrote down their mental models in the first place.

When you're working on projects built by people who left years ago, onboarding engineers struggle to form accurate mental models because the veteran engineers who _had_ those models never documented them. New engineers have to start from scratch.

This is where LLMs shine. They can ingest unfamiliar code faster than humans and generate changes that mostly work. More importantly, they excel at transforming code symbols into readable explanations—roughly reverse-engineering the documentation that should have existed. They're doing the symbol transformation work that the original programmers never bothered to do.

## The Use Case Matters

If you're grinding through backlog tedium, exploring new territory, or working in environments where little value is placed on deep understanding, AI tools can be genuinely helpful. They can work like power tools, grinding through boilerplate work that doesn't demand high creativity.

If you expect to work on a project long-term and want to truly understand it, write the code yourself with maybe some LLM advice. Or, at least spend the time to review everything line-by-line before merging it. The main purpose of writing software is building mental models—outsourcing that work means losing that learning.

The best approach treats these tools as what they are: powerful assistants for symbol transformation and pattern completion, not replacements for human thinking about architecture, requirements, and constraints.