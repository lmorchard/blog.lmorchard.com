---
title: Large Language Mad Libs
tags:
  - ai
  - llm
  - writing
---

**TL;DR**: Might Large Langeuage Models (LLMs) be like Chinese Rooms that generate new completions of old Mad Libs?

<!--more-->

Here are some thoughts I'm entertaining while developing my practical understanding of LLMs:

Think about words and symbols. A symbol (or word) encapsulates a concept with great economy. We continually invent new symbols to encompass ever more complex conceptual patterns - most often composed, recursively, of previously invented symbols. Some symbols, if you could "double-click" to expand their full context, would result in entire library shelves of explanation.

Some conceptual patterns are too enormous to fit in the working memory of even the most brilliant human brains. Folks can still discover them and invent symbols to capture them - but the process drags as soon as we have to start using external memory prostheses like writing or social interaction. Sometimes, the invention of a new symbol takes multiple lifetimes.

What if we had a mechanical process that could tease out new nameless symbols from a given soup of symbolic representation? What if we could grant it super-human working memory and processing speed? And then, what if we let it rip on the largest corpus of human language we can assemble? Could such a process discover patterns and invent symbols that humans might never reasonably have the time or capacity to pursue?

This is how I'm thinking about Large Language Models - i.e. as something close to the process I just described. The frustrating thing is that, as far as I understand the current state of the art, LLMs stop just short of the whole deal. Patterns entrained into LLMs do not get encapsulated as symbols we can directly access. They're just weights in a neural network that we can't interpret.

The only way we can access the nascent symbols in LLMs is through the completion of text prompts that activate the neural network. Like, you ever talk to someone who can complete your sentences because they're so tuned into your wavelength? Someone who can already quote your conclusion, less than a paragraph into your TED Talk? What if a machine could do that at high-conceptual level? LLMs seem to be getting pretty good at doing that.

Now, it'd be great if, somehow, a future generation of machine learning could close the loop on symbol invention in a way that's legible to us. I don't even really know how that'd work - I'd imagine if I did, I'd be a billionaire.

Still, this capacity for text generation via LLM to finish the apparent trajectory of your thought is not entirely unhandy. When it's firing on all cylinders, it's like second best to having access to a head full of rich symbols.

We're currently wasting LLMs on things like the production of slop to maximize the saleable harvest of human attention. This, alongside cynical attempts to replace human effort & creativity. But, I can imagine a future where this stuff settles more into helping us think through problems faster. Maybe helping us get to conclusions more efficiently by clearing away intervening steps of thought that countless humans have already taken.

