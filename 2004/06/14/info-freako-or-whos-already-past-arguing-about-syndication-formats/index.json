{
  "comments_archived": true,
  "date": "2004-06-14T22:54:55.000Z",
  "excerpt": "Where's the state-of-the-art for feed aggregators, and what's next?  I'm tired of reverse-chronological versus three-pane; I'm tired of copying Usenet and email.  What needs to happen next to expand our Info Freako capacity by an order of magnitude or two?  The invention of aggregators has opened the door to the first few orders, but I need more.",
  "layout": "post",
  "tags": [
    "syndication"
  ],
  "title": "Info Freako, or who's already past arguing about syndication formats?",
  "wordpress_id": 528,
  "wordpress_slug": "info-freako-or-whos-already-past-arguing-about-syndication-formats",
  "wordpress_url": "http://www.decafbad.com/blog/?p=528",
  "year": "2004",
  "month": "06",
  "day": "14",
  "isDir": false,
  "slug": "info-freako-or-whos-already-past-arguing-about-syndication-formats",
  "postName": "2004-06-14-info-freako-or-whos-already-past-arguing-about-syndication-formats",
  "html": "<blockquote>\n<p>You know that sleep is getting hard to get<br />\n&#39;Cause you never know what you&#39;ll forget<br />\nAnd I&#39;ve got to know of all the news<br />\n&#39;Cause one day there&#39;ll be news for me<br />\n<br />\nI never let a headline by<br />\n&#39;Cause every one will catch my eye<br />\nAnd though it&#39;s tough to keep alert<br />\nYou never know what could hurt me<br /></p>\n</blockquote>\n<div class=\"credit\" align=\"right\"><small>Source: <cite><a href=\n\"http://www.jesusjonesarchive.com/lyrics.htm#Info%20Freako\">Jesus Jones, \"Info Freako\"</a></cite></small></div>\n\n<p>The Syndications Wars are over--at least, as far as I&#39;m concerned.  </p>\n<p>It&#39;s hard to resist <a href=\"http://www.reactuate.com/index.php?itemid=682\">jumping in</a> where I think someone&#39;s got it wrong or when my fingers compel me to feed trolls, but resisting that impulse is what needs to be done.  At this point, all that seems to happen is that the same old threads get recycled.  No one&#39;s got anything new to bring, except maybe ad hominem grousing or possibly a Yo Mama joke (though I&#39;ve yet to see that particular innovation).  Anyone who cares can do a bit of Googling to catch up on the story.</p>\n<p>The fact is, I no longer care about RSS versus Atom versus $foo.  Mark Pilgrim enables me to do so with his <a href=\"http://diveintomark.org/projects/feed_parser/\">feed parser</a>, and most other aggregators I might care about have also implemented support for both Atom and RSS.  And if they don&#39;t, I can <a href=\"http://www.decafbad.com/blog/2004/05/03/put_on_your_rsscolored_glasses_and_forget_about_atom\">route around the damage</a> just like I do when I <a href=\"http://www.decafbad.com/twiki/bin/view/Main/XslScraper\">scrape sites</a> devoid of any feeds.</p>\n<p>While I do prefer Atom over RSS, almost a year later I still say <a href=\"http://www.decafbad.com/blog/2003/07/07/syndications_formats\">the magic is in syndication, not the format</a>.  I&#39;ll let the tag-level grumblers foam on without comment and just thank them for their work when a good new spec  bubbles up or when something fun and useful comes out.  I&#39;m circling that whole area of concern and sticking a post-it on it that reads: <em>RSS and Atom both useful, neither perfect, neither going away.</em></p>\n<p>Whew.  That&#39;s a weight off my brain.  Now what is there left to talk about?</p>\n<p>Well, how about let&#39;s talk some more about what to do with the items we get, once we <em>do</em> manage to parse a feed?  (Sheesh, you mean we&#39;re not already fighting over that topic?)  </p>\n<p><a href=\"http://www.cadenhead.org/workbench/2004/06/10.html#a1802\">Rogers Cadenhead wants gluttonous RSS feeders</a>:</p>\n<blockquote>\n<p>With thousands of information sources producing RSS and Atom feeds, we need people like Thauvin [whose linkblog is <a href=\"http://www.thauvin.net/linkblog/\">here</a>] who have integrated weblogging into their daily news-gathering routine. Weblog links are like ant trails -- a lot of people have to link to something good in order to get noticed.</p>\n</blockquote>\n<p>I self-identify as such, since my feed list has topped 550 in count.  But I&#39;m happily surprised to find that I&#39;m not even in the <a href=\"http://feeds.scripting.com/prolificSubscribers\">top 10 of prolific subscribers</a>--at least I&#39;m not the biggest Info Freako.  (Yet.)  </p>\n<p>I&#39;m adding between 2-3 feeds to my list daily, so I can see myself approaching 1000 eventually.  But I&#39;m starting to hesitate at adding one more feed now.  Even with my current streamlined multi-pass skimming process, I&#39;m starting to see diminishing returns.  I breeze past screen loads of chaff that I&#39;ll never view, but it still bogs me down.  I can only think that people with twice the subscriptions as I either have more free time, or have a better mousetrap.</p>\n<p>The usual response I get toward my subscriptions is, &quot;Why don&#39;t you cut that list down to about 100 essentials?&quot;  And even that&#39;s said with a smirk, usually by someone with under 50 subscriptions and usually by someone who&#39;s not as obsessive an <a href=\"http://www.jesusjonesarchive.com/lyrics.htm#Info%20Freako\" title=\"Jesus Jones lyrics\">Info Freako</a> as I am.  Thing is, though, good stuff has at one point or another shown up on each and every feed I monitor.  I want to figure out how to scale <em>up</em> from 1 to 10 to 100 to 1000 to 10000 sources and beyond.</p>\n<p>(Singing interlude: &quot;Info Freako / There is no end to what I want to know&quot;)</p>\n<p>Besides, this is an area where I can tinker with and learn about another area I&#39;m interested in: machine intelligence and intelligence amplification.  Rogers says, &quot;I want a Bayesian filter that can guess which new headlines I&#39;m most likely to read&quot;  Though someone else might apply Bayes in a way that works for them, I didn&#39;t find <a href=\"http://www.decafbad.com/blog/2003/08/16/bayes_agg_one\">my experiments with SpamBayes</a> very satisfying.  I suspect it has something to do with the fact that SpamBayes is geared toward sorting out a quasi-binary world of spam-versus-ham, while I&#39;m interested in a spectrum between must-read and shrugs.</p>\n<p>But, the idea of introducing another pass through items at the head of the process, this one partially or completely automated, has great appeal.  Done right, this could be the bit that adds an order of magnitude to my capacity to monitor feeds.  I need to investigate other machine learning approaches.</p>\n<p>The idea is that, while I freakishly want to catch as much info as possible, I can only handle so much in a day.  For certain, I can&#39;t handle everything that might be interesting to me, so I need some prioritization and some pre-filtering before my attention gets applied to the flow.</p>\n<p>The way I picture this is trying to apply a sort of <a href=\"http://mtsu32.mtsu.edu:11178/171/pyramid.htm\">inverted pyramid</a> approach to the incoming flow of items.</p>\n<p>I started with a few primitive tools in <a href=\"http://www.decafbad.com/blog/2002/08/05/ooobbf\">AmphetaOutlines&#39; adaptivity to reading patterns</a>, limited mostly to just sorting channels by a count of items read historically.  I also introduced some information hiding and exploration aspects:  I tried to hide or de-emphasize older items by use of font size and weight; and I put items into a JavaScript-driven outline where item descriptions and more ancient items could be hidden or revealed via disclosure triangle.</p>\n<p>In my <a href=\"http://www.decafbad.com/cvs/dbagg2\">latest attempt</a>, I&#39;ve not yet implemented any adaptive sorting, but I&#39;ve kept and improved the outline display (see: <a href=\"http://www.decafbad.com/2004/06/dbagg2a.jpg\">screenshot #1</a>, <a href=\"http://www.decafbad.com/2004/06/dbagg2b.jpg\">screenshot #2</a>).  Also, I can now mark items as seen and/or flag them to be viewed in a queue for later.  I&#39;ve got some lame SpamBayes integration in there, but I&#39;ve let it atrophy in daily use due to a complete lack of usefulness.</p>\n<p>I&#39;m starting to think about next steps now toward a more advanced aggregator.  I&#39;ve still got my <a href=\"http://www.decafbad.com/twiki/bin/view/Main/AmphetaOutlinesWishList\">wishlist</a> for AmphetaOutlines, and I&#39;ve actually covered quite a few of the items with this new aggregator.  But, I&#39;m thinking things like the following would be useful to pursue:</p>\n<ul>\n<li><p><strong>What do you think is more important?</strong>  Do you value one group of feeds over another?  Personally, I want to see every single web comic that appears in my queue, most items from <a href=\"http://www.engadget.com/\">Engadget</a> and <a href=\"http://boingboing.net/\">Boing Boing</a>, and maybe only a few from some of the firehoses I&#39;ve hooked myself up to.  Also, there are <a href=\"http://interconnected.org/home/\">some</a> <a href=\"http://www.ecyrd.com/ButtUgly/Wiki.jsp?page=Main_blogentry_130604_1\">bloggers</a> who post somewhat infrequently, but I don&#39;t want to miss a thing when they <em>do</em> post.  I need to be able to group and prioritize manually.</p>\n</li>\n<li><p><strong>What do you <em>demonstrate</em> as important?</strong>  Which feeds&#39; items receive more of your attention, and within those feeds, what topics and phrases appear most frequently?  The machine should be able to make some observations about your history of behavior and give some input into the organization of items presented.  Also, it should give me some way to give feedback to its recommendations with a simple and lazy thumbs up and thumbs down.</p>\n</li>\n<li><p><strong>Republishing of interesting items to a linkblog is a must.</strong>  On the flip-side, it would be nice to somehow pull in others&#39; linkblogs in a more meaningful way than simply watching their feeds.  I should be able to triangulate some things and get some recommendations based on mutual links predicting future interest in items.  We need to start chasing ant trails unconsciously and automatically.</p>\n</li>\n<li><p><strong>Time-limited subscriptions which expire after a set time, or request renewal from the user.</strong>  Use these to track comment threads which offer RSS feeds.  (Like <a href=\"http://www.pycs.net/system/comments.py?u=0000001&#38;p=1802&#38;format=rss\">this one</a>.)</p>\n</li>\n<li><p><strong>More statistics and health monitoring of subscriptions.</strong>  How active are your feeds?  Which are dead &#38; gone, or merely just in hiatus?  Have any moved?</p>\n</li>\n</ul>\n<p>Now, I haven&#39;t done any sort of comprehensive survey of the aggregator landscape in a long time, so I&#39;d be very intrigued if any existing software implements these sorts of things.  I&#39;ve seen some progress toward monitoring feed health, but I&#39;ve seen next to nothing toward automatic filtering of items and recommendations based on past behavior.  I have seen manually constructed filters, but I&#39;m too lazy to try to figure out how to tell the computer what I want.   I want the machine to ride shotgun, watch and learn.</p>\n<p><a href=\"http://www.johnny-five.com/\"><img src=\"http://www.johnny-five.com/simplenet/Shortcircuit/Pics/Pictures/Misc/jfive.gif\" align=\"right\" alt=\"Need more input!\" hspace=\"10\" /></a> Where&#39;s the state-of-the-art for feed aggregators, and what&#39;s next?  I&#39;m tired of reverse-chronological versus three-pane; I&#39;m tired of copying Usenet and email.  What needs to happen next to expand our Info Freako capacity by an order of magnitude or two?  The invention of aggregators has opened the door to the first few orders, but I need more.   </p>\n<p>Exit singing (while twitching for more info):</p>\n<blockquote>\n<p>Info Freako, <br />\nThere is no end to what I want to know <br />\n<br />\nBut it means I&#39;ll have the edge over you<br />\nAnd it means I&#39;ll always have the edge over you<br />\nAnd you know there&#39;s nothing that you can do<br /></p>\n</blockquote>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221086587\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.majid.info/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8c5548eb0b2b80924f237953392df5e7&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.majid.info/\">Fazal Majid</a>\n</div>\n<a href=\"#comment-221086587\" class=\"permalink\"><time datetime=\"2004-06-14T21:52:14\">2004-06-14T21:52:14</time></a>\n</div>\n<div class=\"content\">I am trying to do this with my own home-made aggregator (www.temboz.com).\nI have serious doubts about software that could automatically determine whether an article is interesting or not, and would settle for a way to suppress duplicates as a meme propagates through the blogosphere, e.g. by finding posts that link to the same URLs.\nI did implement a simplistic kill-file style filtering system, that works reasonably well, no false positives and 204 out of 1701 items in the last 7 days caught.</div>\n</li>\n<li class=\"comment\" id=\"comment-221086588\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://wurldbook.blogspot.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=994697b1f98037fb294ca1679209aaa8&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://wurldbook.blogspot.com\">Olav</a>\n</div>\n<a href=\"#comment-221086588\" class=\"permalink\"><time datetime=\"2004-06-14T22:25:55\">2004-06-14T22:25:55</time></a>\n</div>\n<div class=\"content\">Anyone who subscribes to so many feeds has a mental illness. Like some kind of obsessive compulsive disorder. I bet they record all the channels on T.V. in case they miss something. I bet they don't throw away any newspapers either. I subscribe to about 144 feeds but that is only because I am testing an app. Most of it is garbage.</div>\n</li>\n<li class=\"comment\" id=\"comment-221086590\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://blogory.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8b702a775f458d5c2cf53f1021cb3ac6&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://blogory.com\">Greg Linden</a>\n</div>\n<a href=\"#comment-221086590\" class=\"permalink\"><time datetime=\"2004-06-14T22:49:58\">2004-06-14T22:49:58</time></a>\n</div>\n<div class=\"content\">You might check out Findory Blogory (http://blogory.com).  It's a personalized weblog reader that learns from the weblog articles you read and recommends other articles that appear to match your interests.\nIt's not a Bayesean filter like SpamBayes, but it does \"guess which new headlines you're most likely to read.\"  It is \"automatic filtering of items and recommendations based on past behavior.\"  You don't have to manually construct filters or \"tell the computer what you want.\"  Findory Blogory will \"ride shotgun, watch and learn.\"\nTake a look.  I'd love to hear your thoughts.</div>\n</li>\n<li class=\"comment\" id=\"comment-221086592\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8a5273f79cfe7579ad46023f93377aa8&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog/\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221086592\" class=\"permalink\"><time datetime=\"2004-06-14T23:03:38\">2004-06-14T23:03:38</time></a>\n</div>\n<div class=\"content\">Olav: See, for me, it isn't so much a compulsion as a challenge.  I don't read through my aggregator all day - I spend about an hour per day at lunch and maybe another at home skimming through items and maybe another hour or so reading longer stories.  \nThis isn't handwashing OCD behavior here - I don't read or even linger on more than a small fraction of what ends up on the screen.  It's a lot of quick glancing, page-down, and mass delete.  It's pretty much as much time as I used to spend just between a half-dozen sites like slashdot.org and cnet.com, only now my sources are so much more varied.\nThe challenge is that wanting to squeeze more coverage of more sources into my daily browsing has me wanting to learn more about certain technologies.  That, and just dealing with more volumes of data is kinda fun in a geeky sort of way.\nAnd, no, I don't record all the channels on the TV.  Besides watching 1 or 2 shows, and playing a few video games, this is what I do instead of sitting in front of the tube.</div>\n</li>\n<li class=\"comment\" id=\"comment-221086593\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.reactuate.com/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=43e4a9fa1d0e5d52a6979ddad94bc483&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.reactuate.com/\">Ron</a>\n</div>\n<a href=\"#comment-221086593\" class=\"permalink\"><time datetime=\"2004-06-16T19:52:44\">2004-06-16T19:52:44</time></a>\n</div>\n<div class=\"content\">When I wrote that story I wasn't expecting people to jump into a fight about RSS vs Atom. Should have known better. I just didn't like the original story and wanted to rant about it.\nOh well you learn something new everyday.</div>\n</li>\n<li class=\"comment\" id=\"comment-221086594\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://blog.ianbicking.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=cc8334869c9d2a9e603017f2da805eb3&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://blog.ianbicking.org\">Ian Bicking</a>\n</div>\n<a href=\"#comment-221086594\" class=\"permalink\"><time datetime=\"2004-06-17T00:36:51\">2004-06-17T00:36:51</time></a>\n</div>\n<div class=\"content\">You might want to look at Reverend: http://www.divmod.org/Home/Projects/Reverend/\nIt's a general-purpose Bayesian classifier.</div>\n</li>\n<li class=\"comment\" id=\"comment-221086595\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://quillio.com/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=b228325c24751d6a33a893fb8116d32f&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://quillio.com/\">Lou Quillio</a>\n</div>\n<a href=\"#comment-221086595\" class=\"permalink\"><time datetime=\"2004-06-17T05:01:13\">2004-06-17T05:01:13</time></a>\n</div>\n<div class=\"content\">There&#8217;s what we&#8217;d like to scan and what we&#8217;d like to read, yes?  Moving content to the must-read front burner will always be deliberate, but improving the content we scan can probably be improved mechanically.  I doubt Brother Orchard thinks there&#8217;s an algorithm for the A-list.  We&#8217;re just talking about making more productive use of the proximate cloud.\nScenario #1:  You Google for topics of interest.  The hits returned can&#8217;t be reliably filtered by creation date, and they consider (in general) the entire indexed Web.  It&#8217;s a good thing, if scatter-shot.  Queries can only be refined so much.\nScenario #2:  You amass and manage a list of syndicated feeds in which you have a passing interest.  The feed content is indexed (Bloglines does this; Google does or will, too).  You can query this universe discretely, using Google-like devices and maybe a few new ones.\nWhat&#8217;s different about these two?\nIn #2, you selected (and casually manage) the universe.  Its chunks &#8212; though perhaps truncated or paraphrased by the author &#8212; are reliably date-stamped.  A free-text query of such data would be very different from an identical Google query.\nAdd a few more discriminators and it gets better.  Suppose you could discriminate by\n1. Paragraph length.  That might get you recent topical hits of terse or essay length, as you choose.\n2. Link-text density.  Filter in or out those link-collection posts.\n3. Query-term density or semantic weight.  Is the topic being addressed directly or simply mentioned?\n4. Item weight or image density.  Helps filter noisy or glitzy corporate feeds (think Ziff-Davis).\nThere are plenty more.\nThe main differences, though, are date discrimination and the pre-filter of a confined universe.  Me, I&#8217;m down to thirty feeds and ignore half of those.  Better tools might change that.\nLQ</div>\n</li>\n<li class=\"comment\" id=\"comment-221086596\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://advogato.org/person/mbrubeck/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=85232f8499fd6ee91623408fc23835d1&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://advogato.org/person/mbrubeck/\">Matt Brubeck</a>\n</div>\n<a href=\"#comment-221086596\" class=\"permalink\"><time datetime=\"2004-06-19T21:06:49\">2004-06-19T21:06:49</time></a>\n</div>\n<div class=\"content\">I love the picture.  Need input!</div>\n</li>\n</ul>\n</div>\n",
  "body": "> You know that sleep is getting hard to get<br />\r\n> 'Cause you never know what you'll forget<br />\r\n> And I've got to know of all the news<br />\r\n> 'Cause one day there'll be news for me<br />\r\n> <br />\r\n> I never let a headline by<br />\r\n> 'Cause every one will catch my eye<br />\r\n> And though it's tough to keep alert<br />\r\n> You never know what could hurt me<br />\r\n\r\n<div class=\"credit\" align=\"right\"><small>Source: <cite><a href=\r\n\"http://www.jesusjonesarchive.com/lyrics.htm#Info%20Freako\">Jesus Jones, \"Info Freako\"</a></cite></small></div>\r\n\r\nThe Syndications Wars are over--at least, as far as I'm concerned.  \r\n\r\nIt's hard to resist [jumping in][jumping in] where I think someone's got it wrong or when my fingers compel me to feed trolls, but resisting that impulse is what needs to be done.  At this point, all that seems to happen is that the same old threads get recycled.  No one's got anything new to bring, except maybe ad hominem grousing or possibly a Yo Mama joke (though I've yet to see that particular innovation).  Anyone who cares can do a bit of Googling to catch up on the story.\r\n\r\nThe fact is, I no longer care about RSS versus Atom versus $foo.  Mark Pilgrim enables me to do so with his [feed parser][feedparser], and most other aggregators I might care about have also implemented support for both Atom and RSS.  And if they don't, I can [route around the damage][rss colored glasses] just like I do when I [scrape sites][scrape sites] devoid of any feeds.\r\n\r\nWhile I do prefer Atom over RSS, almost a year later I still say [the magic is in syndication, not the format][syndication magic].  I'll let the tag-level grumblers foam on without comment and just thank them for their work when a good new spec  bubbles up or when something fun and useful comes out.  I'm circling that whole area of concern and sticking a post-it on it that reads: *RSS and Atom both useful, neither perfect, neither going away.*\r\n\r\nWhew.  That's a weight off my brain.  Now what is there left to talk about?\r\n\r\nWell, how about let's talk some more about what to do with the items we get, once we *do* manage to parse a feed?  (Sheesh, you mean we're not already fighting over that topic?)  \r\n\r\n[Rogers Cadenhead wants gluttonous RSS feeders][cadenhead]:\r\n\r\n> With thousands of information sources producing RSS and Atom feeds, we need people like Thauvin [whose linkblog is [here][thauvin]] who have integrated weblogging into their daily news-gathering routine. Weblog links are like ant trails -- a lot of people have to link to something good in order to get noticed.\r\n\r\nI self-identify as such, since my feed list has topped 550 in count.  But I'm happily surprised to find that I'm not even in the [top 10 of prolific subscribers][prolific subs]--at least I'm not the biggest Info Freako.  (Yet.)  \r\n\r\nI'm adding between 2-3 feeds to my list daily, so I can see myself approaching 1000 eventually.  But I'm starting to hesitate at adding one more feed now.  Even with my current streamlined multi-pass skimming process, I'm starting to see diminishing returns.  I breeze past screen loads of chaff that I'll never view, but it still bogs me down.  I can only think that people with twice the subscriptions as I either have more free time, or have a better mousetrap.\r\n\r\nThe usual response I get toward my subscriptions is, \"Why don't you cut that list down to about 100 essentials?\"  And even that's said with a smirk, usually by someone with under 50 subscriptions and usually by someone who's not as obsessive an [Info Freako][info freako] as I am.  Thing is, though, good stuff has at one point or another shown up on each and every feed I monitor.  I want to figure out how to scale *up* from 1 to 10 to 100 to 1000 to 10000 sources and beyond.\r\n\r\n(Singing interlude: \"Info Freako / There is no end to what I want to know\")\r\n\r\nBesides, this is an area where I can tinker with and learn about another area I'm interested in: machine intelligence and intelligence amplification.  Rogers says, \"I want a Bayesian filter that can guess which new headlines I'm most likely to read\"  Though someone else might apply Bayes in a way that works for them, I didn't find [my experiments with SpamBayes][bayes] very satisfying.  I suspect it has something to do with the fact that SpamBayes is geared toward sorting out a quasi-binary world of spam-versus-ham, while I'm interested in a spectrum between must-read and shrugs.\r\n\r\nBut, the idea of introducing another pass through items at the head of the process, this one partially or completely automated, has great appeal.  Done right, this could be the bit that adds an order of magnitude to my capacity to monitor feeds.  I need to investigate other machine learning approaches.\r\n\r\nThe idea is that, while I freakishly want to catch as much info as possible, I can only handle so much in a day.  For certain, I can't handle everything that might be interesting to me, so I need some prioritization and some pre-filtering before my attention gets applied to the flow.\r\n\r\nThe way I picture this is trying to apply a sort of [inverted pyramid][inverted pyramid] approach to the incoming flow of items.\r\n\r\nI started with a few primitive tools in [AmphetaOutlines' adaptivity to reading patterns][amphetaoutlines], limited mostly to just sorting channels by a count of items read historically.  I also introduced some information hiding and exploration aspects:  I tried to hide or de-emphasize older items by use of font size and weight; and I put items into a JavaScript-driven outline where item descriptions and more ancient items could be hidden or revealed via disclosure triangle.\r\n\r\nIn my [latest attempt][dbagg2], I've not yet implemented any adaptive sorting, but I've kept and improved the outline display (see: [screenshot #1][dbagg2 screen1], [screenshot #2][dbagg2 screen2]).  Also, I can now mark items as seen and/or flag them to be viewed in a queue for later.  I've got some lame SpamBayes integration in there, but I've let it atrophy in daily use due to a complete lack of usefulness.\r\n\r\nI'm starting to think about next steps now toward a more advanced aggregator.  I've still got my [wishlist][wishlist] for AmphetaOutlines, and I've actually covered quite a few of the items with this new aggregator.  But, I'm thinking things like the following would be useful to pursue:\r\n\r\n* **What do you think is more important?**  Do you value one group of feeds over another?  Personally, I want to see every single web comic that appears in my queue, most items from [Engadget][engadget] and [Boing Boing][boing boing], and maybe only a few from some of the firehoses I've hooked myself up to.  Also, there are [some][blogger1] [bloggers][blogger2] who post somewhat infrequently, but I don't want to miss a thing when they *do* post.  I need to be able to group and prioritize manually.\r\n\r\n* **What do you *demonstrate* as important?**  Which feeds' items receive more of your attention, and within those feeds, what topics and phrases appear most frequently?  The machine should be able to make some observations about your history of behavior and give some input into the organization of items presented.  Also, it should give me some way to give feedback to its recommendations with a simple and lazy thumbs up and thumbs down.\r\n\r\n* **Republishing of interesting items to a linkblog is a must.**  On the flip-side, it would be nice to somehow pull in others' linkblogs in a more meaningful way than simply watching their feeds.  I should be able to triangulate some things and get some recommendations based on mutual links predicting future interest in items.  We need to start chasing ant trails unconsciously and automatically.\r\n\r\n* **Time-limited subscriptions which expire after a set time, or request renewal from the user.**  Use these to track comment threads which offer RSS feeds.  (Like [this one][comment feed].)\r\n\r\n* **More statistics and health monitoring of subscriptions.**  How active are your feeds?  Which are dead &#38; gone, or merely just in hiatus?  Have any moved?\r\n\r\nNow, I haven't done any sort of comprehensive survey of the aggregator landscape in a long time, so I'd be very intrigued if any existing software implements these sorts of things.  I've seen some progress toward monitoring feed health, but I've seen next to nothing toward automatic filtering of items and recommendations based on past behavior.  I have seen manually constructed filters, but I'm too lazy to try to figure out how to tell the computer what I want.   I want the machine to ride shotgun, watch and learn.\r\n\r\n<a href=\"http://www.johnny-five.com/\"><img src=\"http://www.johnny-five.com/simplenet/Shortcircuit/Pics/Pictures/Misc/jfive.gif\" align=\"right\" alt=\"Need more input!\" hspace=\"10\" /></a> Where's the state-of-the-art for feed aggregators, and what's next?  I'm tired of reverse-chronological versus three-pane; I'm tired of copying Usenet and email.  What needs to happen next to expand our Info Freako capacity by an order of magnitude or two?  The invention of aggregators has opened the door to the first few orders, but I need more.   \r\n\r\nExit singing (while twitching for more info):\r\n\r\n> Info Freako, <br />\r\n> There is no end to what I want to know <br />\r\n> <br />\r\n> But it means I'll have the edge over you<br />\r\n> And it means I'll always have the edge over you<br />\r\n> And you know there's nothing that you can do<br />\r\n\r\n[jumping in]: http://www.reactuate.com/index.php?itemid=682\r\n[blogger1]: http://interconnected.org/home/\r\n[blogger2]: http://www.ecyrd.com/ButtUgly/Wiki.jsp?page=Main_blogentry_130604_1\r\n[engadget]: http://www.engadget.com/\r\n[boing boing]: http://boingboing.net/\r\n[inverted pyramid]: http://mtsu32.mtsu.edu:11178/171/pyramid.htm\r\n[comment feed]: http://www.pycs.net/system/comments.py?u=0000001&#38;p=1802&#38;format=rss\r\n[wishlist]: http://www.decafbad.com/twiki/bin/view/Main/AmphetaOutlinesWishList\r\n[dbagg2 screen1]: http://www.decafbad.com/2004/06/dbagg2a.jpg\r\n[dbagg2 screen2]: http://www.decafbad.com/2004/06/dbagg2b.jpg\r\n[dbagg2]: http://www.decafbad.com/cvs/dbagg2\r\n[amphetaoutlines]: http://www.decafbad.com/blog/2002/08/05/ooobbf\r\n[bayes]: http://www.decafbad.com/blog/2003/08/16/bayes_agg_one\r\n[info freako]: http://www.jesusjonesarchive.com/lyrics.htm#Info%20Freako \"Jesus Jones lyrics\"\r\n[thauvin]: http://www.thauvin.net/linkblog/\r\n[prolific subs]: http://feeds.scripting.com/prolificSubscribers\r\n[cadenhead]: http://www.cadenhead.org/workbench/2004/06/10.html#a1802\r\n[syndication magic]: http://www.decafbad.com/blog/2003/07/07/syndications_formats\r\n[scrape sites]: http://www.decafbad.com/twiki/bin/view/Main/XslScraper\r\n[rss colored glasses]: http://www.decafbad.com/blog/2004/05/03/put_on_your_rsscolored_glasses_and_forget_about_atom\r\n[feedparser]: http://diveintomark.org/projects/feed_parser/\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221086587\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.majid.info/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8c5548eb0b2b80924f237953392df5e7&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.majid.info/\">Fazal Majid</a>\r\n                </div>\r\n                <a href=\"#comment-221086587\" class=\"permalink\"><time datetime=\"2004-06-14T21:52:14\">2004-06-14T21:52:14</time></a>\r\n            </div>\r\n            <div class=\"content\">I am trying to do this with my own home-made aggregator (www.temboz.com).\r\n\r\nI have serious doubts about software that could automatically determine whether an article is interesting or not, and would settle for a way to suppress duplicates as a meme propagates through the blogosphere, e.g. by finding posts that link to the same URLs.\r\n\r\nI did implement a simplistic kill-file style filtering system, that works reasonably well, no false positives and 204 out of 1701 items in the last 7 days caught.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221086588\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://wurldbook.blogspot.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=994697b1f98037fb294ca1679209aaa8&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://wurldbook.blogspot.com\">Olav</a>\r\n                </div>\r\n                <a href=\"#comment-221086588\" class=\"permalink\"><time datetime=\"2004-06-14T22:25:55\">2004-06-14T22:25:55</time></a>\r\n            </div>\r\n            <div class=\"content\">Anyone who subscribes to so many feeds has a mental illness. Like some kind of obsessive compulsive disorder. I bet they record all the channels on T.V. in case they miss something. I bet they don't throw away any newspapers either. I subscribe to about 144 feeds but that is only because I am testing an app. Most of it is garbage.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221086590\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://blogory.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8b702a775f458d5c2cf53f1021cb3ac6&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://blogory.com\">Greg Linden</a>\r\n                </div>\r\n                <a href=\"#comment-221086590\" class=\"permalink\"><time datetime=\"2004-06-14T22:49:58\">2004-06-14T22:49:58</time></a>\r\n            </div>\r\n            <div class=\"content\">You might check out Findory Blogory (http://blogory.com).  It's a personalized weblog reader that learns from the weblog articles you read and recommends other articles that appear to match your interests.\r\n\r\nIt's not a Bayesean filter like SpamBayes, but it does \"guess which new headlines you're most likely to read.\"  It is \"automatic filtering of items and recommendations based on past behavior.\"  You don't have to manually construct filters or \"tell the computer what you want.\"  Findory Blogory will \"ride shotgun, watch and learn.\"\r\n\r\nTake a look.  I'd love to hear your thoughts.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221086592\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8a5273f79cfe7579ad46023f93377aa8&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog/\">l.m.orchard</a>\r\n                </div>\r\n                <a href=\"#comment-221086592\" class=\"permalink\"><time datetime=\"2004-06-14T23:03:38\">2004-06-14T23:03:38</time></a>\r\n            </div>\r\n            <div class=\"content\">Olav: See, for me, it isn't so much a compulsion as a challenge.  I don't read through my aggregator all day - I spend about an hour per day at lunch and maybe another at home skimming through items and maybe another hour or so reading longer stories.  \r\n\r\nThis isn't handwashing OCD behavior here - I don't read or even linger on more than a small fraction of what ends up on the screen.  It's a lot of quick glancing, page-down, and mass delete.  It's pretty much as much time as I used to spend just between a half-dozen sites like slashdot.org and cnet.com, only now my sources are so much more varied.\r\n\r\nThe challenge is that wanting to squeeze more coverage of more sources into my daily browsing has me wanting to learn more about certain technologies.  That, and just dealing with more volumes of data is kinda fun in a geeky sort of way.\r\n\r\nAnd, no, I don't record all the channels on the TV.  Besides watching 1 or 2 shows, and playing a few video games, this is what I do instead of sitting in front of the tube.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221086593\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.reactuate.com/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=43e4a9fa1d0e5d52a6979ddad94bc483&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.reactuate.com/\">Ron</a>\r\n                </div>\r\n                <a href=\"#comment-221086593\" class=\"permalink\"><time datetime=\"2004-06-16T19:52:44\">2004-06-16T19:52:44</time></a>\r\n            </div>\r\n            <div class=\"content\">When I wrote that story I wasn't expecting people to jump into a fight about RSS vs Atom. Should have known better. I just didn't like the original story and wanted to rant about it.\r\n\r\nOh well you learn something new everyday.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221086594\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://blog.ianbicking.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=cc8334869c9d2a9e603017f2da805eb3&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://blog.ianbicking.org\">Ian Bicking</a>\r\n                </div>\r\n                <a href=\"#comment-221086594\" class=\"permalink\"><time datetime=\"2004-06-17T00:36:51\">2004-06-17T00:36:51</time></a>\r\n            </div>\r\n            <div class=\"content\">You might want to look at Reverend: http://www.divmod.org/Home/Projects/Reverend/\r\n\r\nIt's a general-purpose Bayesian classifier.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221086595\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://quillio.com/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=b228325c24751d6a33a893fb8116d32f&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://quillio.com/\">Lou Quillio</a>\r\n                </div>\r\n                <a href=\"#comment-221086595\" class=\"permalink\"><time datetime=\"2004-06-17T05:01:13\">2004-06-17T05:01:13</time></a>\r\n            </div>\r\n            <div class=\"content\">There&#8217;s what we&#8217;d like to scan and what we&#8217;d like to read, yes?  Moving content to the must-read front burner will always be deliberate, but improving the content we scan can probably be improved mechanically.  I doubt Brother Orchard thinks there&#8217;s an algorithm for the A-list.  We&#8217;re just talking about making more productive use of the proximate cloud.\r\n\r\nScenario #1:  You Google for topics of interest.  The hits returned can&#8217;t be reliably filtered by creation date, and they consider (in general) the entire indexed Web.  It&#8217;s a good thing, if scatter-shot.  Queries can only be refined so much.\r\n\r\nScenario #2:  You amass and manage a list of syndicated feeds in which you have a passing interest.  The feed content is indexed (Bloglines does this; Google does or will, too).  You can query this universe discretely, using Google-like devices and maybe a few new ones.\r\n\r\nWhat&#8217;s different about these two?\r\n\r\nIn #2, you selected (and casually manage) the universe.  Its chunks &#8212; though perhaps truncated or paraphrased by the author &#8212; are reliably date-stamped.  A free-text query of such data would be very different from an identical Google query.\r\n\r\nAdd a few more discriminators and it gets better.  Suppose you could discriminate by\r\n\r\n\r\n1. Paragraph length.  That might get you recent topical hits of terse or essay length, as you choose.\r\n\r\n2. Link-text density.  Filter in or out those link-collection posts.\r\n\r\n3. Query-term density or semantic weight.  Is the topic being addressed directly or simply mentioned?\r\n\r\n4. Item weight or image density.  Helps filter noisy or glitzy corporate feeds (think Ziff-Davis).\r\n\r\nThere are plenty more.\r\n\r\nThe main differences, though, are date discrimination and the pre-filter of a confined universe.  Me, I&#8217;m down to thirty feeds and ignore half of those.  Better tools might change that.\r\n\r\nLQ</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221086596\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://advogato.org/person/mbrubeck/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=85232f8499fd6ee91623408fc23835d1&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://advogato.org/person/mbrubeck/\">Matt Brubeck</a>\r\n                </div>\r\n                <a href=\"#comment-221086596\" class=\"permalink\"><time datetime=\"2004-06-19T21:06:49\">2004-06-19T21:06:49</time></a>\r\n            </div>\r\n            <div class=\"content\">I love the picture.  Need input!</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
  "parentPath": "../blog.lmorchard.com/posts/archives/2004",
  "path": "2004/06/14/info-freako-or-whos-already-past-arguing-about-syndication-formats",
  "thumbnail": "http://www.johnny-five.com/simplenet/Shortcircuit/Pics/Pictures/Misc/jfive.gif"
}