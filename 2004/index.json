[
  {
    "comments_archived": true,
    "date": "2004-12-23T05:58:41.000Z",
    "excerpt": "So, in the spirit of pico-projects, I've started building that address book application I mentioned awhile ago and I want to start writing about it as I go.",
    "layout": "post",
    "tags": [
      "hacks",
      "xml"
    ],
    "title": "Building an Address Book as a Modern Web App",
    "wordpress_id": 580,
    "wordpress_slug": "abook1",
    "wordpress_url": "http://www.decafbad.com/blog/?p=580",
    "year": "2004",
    "month": "12",
    "day": "23",
    "isDir": false,
    "slug": "abook1",
    "postName": "2004-12-23-abook1",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/12/23/abook1",
    "thumbnail": "http://www.decafbad.com/2004/12/abook-architecture.jpg",
    "summary": "So, in the spirit of pico-projects, I've started building that address book application I mentioned awhile ago and I want to start writing about it as I go.\nFirst off, hopefully you'll notice the quick diagram I threw together in OmniGraffle.  This is a sort of rough sketch of the loosely-joined architecture I want to explore with this thing.  \n\nData: This is where address book entries live.\nModel: A set of objects encapsulating the data, this is how address book entries will be accessed.\nREST API: Model objects exposed as resources identified by URI, serialized and deserialized as XML, and manipulated by GET / PUT / POST / DELETE methods.\nXSLT Filter: XML data produced by REST API calls can be first passed through XSL at a given URL before being served up as a response.  \nHTML, CSS, JavaScript: Thanks to the XSLT filter layer, the XML vocabulary used to describe address book entries can be transformed into user interface presentation.\nHTTP: Everything happens via HTTP...\nWeb Browser Client: ...and everything is viewed in a web browser.\n\nNow, I call this a loosely-joined architecture because I want to stress that you should be able to swap out just about any part of this whenever you want.  \nWant the Data to be in MySQL?  Fine.  Want it to be in flat files?  Fine.  Just make sure the Model can cope while maintaining a consistent interface for the REST API.  Want to change the user interface in the browser?  Great-- ideally, all you have to do is change some XSLT files.  I'm writing everything from the XSLT Filter down to the Model in Python.  Don't like that?  Fine.  Rewrite it all in Perl, and hopefully everything from the XSLT up to the browser will still be useful to you.\nAt some point, you might even want to ditch the browser for a native desktop client.  Fabulous! Just ignore everything past the REST API and HTTP, don't use any XSLT in the Filter, and use the API and XML directly.\nI don't think any of this is particularly revolutionary-- although I thought it was when I first saw Amazon Web Services doing some of this, and I hope to throw a little GMail in as well.  I hope that this will all be useful as I muddle through explaining what I'm doing.  In the meantime, you can see me getting the stage set as I start checking things into my Subversion repository over here:\n\nhttp://www.decafbad.com/svn/trunk/hacks/abook/",
    "prevPostPath": "2005/01/07/belated-happy-new-year",
    "nextPostPath": "2004/12/16/synchronet"
  },
  {
    "comments_archived": true,
    "date": "2004-12-16T15:19:03.000Z",
    "excerpt": "At least Finland isn't a long distance call anymore.",
    "layout": "post",
    "tags": [
      "oldschool"
    ],
    "title": "Synchronet BBS Software, Tidal Pools, and On-Ramps",
    "wordpress_id": 579,
    "wordpress_slug": "synchronet",
    "wordpress_url": "http://www.decafbad.com/blog/?p=579",
    "year": "2004",
    "month": "12",
    "day": "16",
    "isDir": false,
    "slug": "synchronet",
    "postName": "2004-12-16-synchronet",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/12/16/synchronet",
    "summary": "Synchronet Bulletin Board System Software is a free software package that can turn your personal computer into your own custom online service supporting multiple simultaneous users with hierarchical message and file areas, multi-user chat, and the ever-popular BBS door games.\n\n...\n\nIn November of 1999, the author found a renewed interest in further developing Synchronet, specifically for the Internet community, embracing and integrating standard Internet protocols such as Telnet, FTP, SMTP, POP3, IRC, NNTP, and HTTP. Synchronet has since been substantially redesigned as an Internet-only BBS package for Win32 and Unix-x86 platforms and is an Open Source project under continuous development.\nSource: Synchronet BBS Software\n\nThis software deserves so much more attention.  It's like an old-school BBS, complete with ASCII/ANSI menu screens and everything, but it's been modernized:  It offers a slew of Internet protocols integrated with the message bases and file areas.  It's got an HTTP daemon with server-side JavaScript.  It works on Win32 and various Unix platforms.  Everything above is true.  And it's open source.\nIn the 90's, I would have expected software like this to be at the core of a startup company stuffed with superfluous and overpaid code monkeys.  It would have turned into an Enterprise Application Server or Intranet Knowledge Management Solution-- a mini Domino or Lotus Notes.  And, in fact, I seem to remember seeing a few old-school BBS packages get mutated and gigantified by the dot-com radiation in this way.\nI keep meaning to get a Synchronet BBS up and keep it up, and maybe get a few interested users logging in, if only for the retro-gaming experience for things like Trade Wars, Barrent Realms Elite, Legend of the Red Dragon, Global War, and anything else I can find.\nI really miss the tidal-pool effect BBSes had back in the day, when in my area they were the first and best gateways to the Internet.  Direct SLIP and PPP access to the net were rare things still and, before the web took off, Usenet and IRC were some of the best things around.  But, anyone who wanted to get the the net had to wander through the local BBS first.  \nIt was really neat to see the mish-mash of people all drawn together by geographic areas denoted by telco area codes.  The degree of Aspergers affliction and just plain dysfunctional nerdity gradually decreased as sisters and friends-of-sisters were introduced to terminal programs and teleconference.  It was sad to see all of this gradually die off as more and more callers came in via SLIP/PPP dialers and headed straight for the information superhighway on-ramps.  All the gift shops closed up and no one showed up in the caf√© anymore.\nSigh.\nBut, at least Finland isn't a long distance call these days.",
    "prevPostPath": "2004/12/23/abook1",
    "nextPostPath": "2004/12/13/miscellaneous-thoughts-about-exploded-pcs"
  },
  {
    "comments_archived": true,
    "date": "2004-12-13T21:31:30.000Z",
    "excerpt": "So, I think I'm almost out of steam for now on this weekend's thoughts.",
    "layout": "post",
    "title": "Miscellaneous Thoughts about Exploded PCs",
    "wordpress_id": 578,
    "wordpress_slug": "miscellaneous-thoughts-about-exploded-pcs",
    "wordpress_url": "http://www.decafbad.com/blog/?p=578",
    "year": "2004",
    "month": "12",
    "day": "13",
    "isDir": false,
    "slug": "miscellaneous-thoughts-about-exploded-pcs",
    "postName": "2004-12-13-miscellaneous-thoughts-about-exploded-pcs",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/12/13/miscellaneous-thoughts-about-exploded-pcs",
    "prevPostPath": "2004/12/16/synchronet",
    "nextPostPath": "2004/12/13/on-exploding-pcs-and-appliance-relationships"
  },
  {
    "comments_archived": true,
    "date": "2004-12-13T20:28:56.000Z",
    "excerpt": "I've already ditched a central desktop computer, and sometimes this makes me feel like I'm living in the future.",
    "layout": "post",
    "title": "On Exploding PCs and Appliance Relationships",
    "wordpress_id": 577,
    "wordpress_slug": "on-exploding-pcs-and-appliance-relationships",
    "wordpress_url": "http://www.decafbad.com/blog/?p=577",
    "year": "2004",
    "month": "12",
    "day": "13",
    "isDir": false,
    "slug": "on-exploding-pcs-and-appliance-relationships",
    "postName": "2004-12-13-on-exploding-pcs-and-appliance-relationships",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/12/13/on-exploding-pcs-and-appliance-relationships",
    "prevPostPath": "2004/12/13/miscellaneous-thoughts-about-exploded-pcs",
    "nextPostPath": "2004/12/13/the-meta-lathe"
  },
  {
    "comments_archived": true,
    "date": "2004-12-13T18:26:45.000Z",
    "excerpt": "You don't want to use a metal lathe in your living room, and you wouldn't want to let just anyone loose on the thing unless they knew what they were doing.  As shop in junior high taught me, a lathe is powerful tool capable of doing quite a variety of things.  Some of those things leave you with jewelry and maybe more tools, and other (mis-)uses leave you with nasty injuries.",
    "layout": "post",
    "title": "The Meta Lathe",
    "wordpress_id": 576,
    "wordpress_slug": "the-meta-lathe",
    "wordpress_url": "http://www.decafbad.com/blog/?p=576",
    "year": "2004",
    "month": "12",
    "day": "13",
    "isDir": false,
    "slug": "the-meta-lathe",
    "postName": "2004-12-13-the-meta-lathe",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/12/13/the-meta-lathe",
    "prevPostPath": "2004/12/13/on-exploding-pcs-and-appliance-relationships",
    "nextPostPath": "2004/12/13/security-and-the-state-of-the-computer"
  },
  {
    "comments_archived": true,
    "date": "2004-12-13T18:23:46.000Z",
    "excerpt": "I don't see a bright future for any brand of general-purpose PC, at least not continuing as the main consumer computing product.",
    "layout": "post",
    "title": "Security and the State of the Computer",
    "wordpress_id": 575,
    "wordpress_slug": "security-and-the-state-of-the-computer",
    "wordpress_url": "http://www.decafbad.com/blog/?p=575",
    "year": "2004",
    "month": "12",
    "day": "13",
    "isDir": false,
    "slug": "security-and-the-state-of-the-computer",
    "postName": "2004-12-13-security-and-the-state-of-the-computer",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/12/13/security-and-the-state-of-the-computer",
    "prevPostPath": "2004/12/13/the-meta-lathe",
    "nextPostPath": "2004/12/08/mr-gruff"
  },
  {
    "comments_archived": true,
    "date": "2004-12-08T03:08:46.000Z",
    "layout": "post",
    "title": "Mr. Gruff",
    "wordpress_id": 574,
    "wordpress_slug": "mr-gruff",
    "wordpress_url": "http://www.decafbad.com/blog/?p=574",
    "year": "2004",
    "month": "12",
    "day": "07",
    "isDir": false,
    "slug": "mr-gruff",
    "postName": "2004-12-07-mr-gruff",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/12/08/mr-gruff",
    "thumbnail": "http://zoom.cafepress.com/9/5724969_zoom.jpg",
    "prevPostPath": "2004/12/13/security-and-the-state-of-the-computer",
    "nextPostPath": "2004/12/07/further-smart-aggregator-musings"
  },
  {
    "comments_archived": true,
    "date": "2004-12-07T21:37:08.000Z",
    "excerpt": "It seems like the magic Bayesian pixie dust works well for spam-vs-ham in my email box, so why shouldn't the magic for interesting-vs-yawn work for my aggregator firehose?",
    "layout": "post",
    "tags": [
      "syndication"
    ],
    "title": "Further musings toward smarter aggregators",
    "wordpress_id": 573,
    "wordpress_slug": "further-smart-aggregator-musings",
    "wordpress_url": "http://www.decafbad.com/blog/?p=573",
    "year": "2004",
    "month": "12",
    "day": "07",
    "isDir": false,
    "slug": "further-smart-aggregator-musings",
    "postName": "2004-12-07-further-smart-aggregator-musings",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/12/07/further-smart-aggregator-musings",
    "summary": "I'm a complete neophyte when it comes to machine learning, but I'd like to get into learning more about the field in general.  In particular, I'd like to make my news aggregator smarter.  I've already tried using SpamBayes, but that didn't make me happy.  Whether it was my approach or whether it was that Bayes itself is not suited toward this task, I'm not sure, though I suspect it's a little of both.\nIt seems like the magic Bayesian pixie dust works well for spam-vs-ham in my email box, so why shouldn't the magic for interesting-vs-yawn work for my aggregator firehose?    Well, here are the issues I'm guessing at:\nIn the case of spam-vs-ham, you want to classify things into this or that-- that which is kept, and that which is tossed away.  But in the case of items in my aggregator, I want a relative sort order or a score.  I want a fuzzy guess toward my interest with which to inform presentation of items.  Interesting-vs-yawn is more of a continuum than a pair of buckets.\nAnd then, there's the passive gathering of behavioral data from my interactions with the aggregator, because I'm sure as hell not going to click ratings or thumbs-up/down all day.  In spam-vs-ham, I could build up two clean mailboxes for training the categorizer, with one containing all spam and the other all ham.  But, in the case of my aggregator, the only thing I'm tracking are items in which I showed interest by revealing more information or by clicking through.  \nSo, I can say that a particular pile of items are all interesting.  But, my interest level for the rest of the items received is a complete unknown-- maybe I'm vehemently disinterested in those 50 items, but maybe I just never got around to looking at those other 20 and just let them fall off my date range for display.  Thus, I have a pile of ham, and a pile of undifferentiated unknown.  I'm not bothering to provide any cues as to whether I don't like something, because that'd be boring work-- I mean, I am disinterested in those items, after all.  So, I'd like to leverage what the system knows from what I care to provide, but not jump to any conclusions about the items in the unknown pile.  There is no spam, only various flavors of ham.\nGiven all this, then, is there anyone out there who knows more about machine learning than me who could maybe point me toward a better approach or algorithm that fits this profile?",
    "prevPostPath": "2004/12/08/mr-gruff",
    "nextPostPath": "2004/12/05/unopened-apple-ipod-20gb-for-sale"
  },
  {
    "comments_archived": true,
    "date": "2004-12-05T05:13:36.000Z",
    "layout": "post",
    "title": "Unopened Apple iPod 20GB for sale",
    "wordpress_id": 572,
    "wordpress_slug": "unopened-apple-ipod-20gb-for-sale",
    "wordpress_url": "http://www.decafbad.com/blog/?p=572",
    "year": "2004",
    "month": "12",
    "day": "05",
    "isDir": false,
    "slug": "unopened-apple-ipod-20gb-for-sale",
    "postName": "2004-12-05-unopened-apple-ipod-20gb-for-sale",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/12/05/unopened-apple-ipod-20gb-for-sale",
    "thumbnail": "http://www.decafbad.com/photos/2004/12/alex-sells-an-ipod/thumbs/IMG_3191.jpg",
    "prevPostPath": "2004/12/07/further-smart-aggregator-musings",
    "nextPostPath": "2004/12/03/if-you-snore-get-tested-for-sleep-apnea-now"
  },
  {
    "comments_archived": true,
    "date": "2004-12-03T17:09:39.000Z",
    "excerpt": "I cannot overestimate the positive effect this CPAP machine has had on me.",
    "layout": "post",
    "title": "If you snore, get tested for sleep apnea.  Now.",
    "wordpress_id": 571,
    "wordpress_slug": "if-you-snore-get-tested-for-sleep-apnea-now",
    "wordpress_url": "http://www.decafbad.com/blog/?p=571",
    "year": "2004",
    "month": "12",
    "day": "03",
    "isDir": false,
    "slug": "if-you-snore-get-tested-for-sleep-apnea-now",
    "postName": "2004-12-03-if-you-snore-get-tested-for-sleep-apnea-now",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/12/03/if-you-snore-get-tested-for-sleep-apnea-now",
    "thumbnail": "http://www.respironicsremstar.com/images/exploded_humid.gif",
    "prevPostPath": "2004/12/05/unopened-apple-ipod-20gb-for-sale",
    "nextPostPath": "2004/12/03/crossbreedingxsltzpt"
  },
  {
    "comments_archived": true,
    "date": "2004-12-03T01:15:52.000Z",
    "excerpt": "Both ZPT and XSLT very different technologies, but they are often used in similar contexts.  More than once, I've wished that XSLT was as simple as ZPT (i.e. less verbose and intrusive, more document centered), and I've wished that ZPT had some of the features of XSLT (i.e. ability to be used as a transforming filter).",
    "layout": "post",
    "tags": [
      "xml",
      "python"
    ],
    "title": "Cross-breeding XSLT and ZPT",
    "wordpress_id": 570,
    "wordpress_slug": "crossbreedingxsltzpt",
    "wordpress_url": "http://www.decafbad.com/blog/?p=570",
    "year": "2004",
    "month": "12",
    "day": "02",
    "isDir": false,
    "slug": "crossbreedingxsltzpt",
    "postName": "2004-12-02-crossbreedingxsltzpt",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/12/03/crossbreedingxsltzpt",
    "summary": "I've recently been doing some side work involving Zope and, along with the rest of the suite of technologies it offers, I've been happy to be working with Zope Page Templates again.  I dabbled with them a bit when they first came out, and a Zope-free implementation named SimpleTAL was one of the core components of the iteration of my news aggregator which came before FeedReactor.\nOut of all the templating and content generation approaches I've used, Zope Page Templates are my favorite yet.  Pretty expressive, yet unobtrusive; nicely powerful, yet not quite something with which you'd want to write an entire application (and that's a feature, not a bug).  \nI've yet to be in a work-a-day team that uses ZPT-- but I can see where a lot of production, delegation, and integration issues would have gone much smoother had I used ZPT instead of Template Toolkit for the web app framework I created at a previous company.  (Though I do have to say TT2 is very nicely done!)  And where I am now, I spend most of my days trying to pummel ASP 3.0 pages into some semblance of logic/presentation separation-- I would certainly dive at the chance to dump VBScript and <% cruft %> for a bit of Python and ZPT.  (But, you know, it's a living.)\nA close second favorite is XSLT.  I've really been hot on it lately, having worked it into the core of FeedReactor in place of SimpleTAL.  And in other hacks, I've really come to appreciate it's role as a filter segment in pipelines between REST web services and URL-as-command-line invocations.\nGranted, both ZPT and XSLT very different technologies, but they are often used in similar contexts.  More than once, I've wished that XSLT was as simple as ZPT (i.e. less verbose and intrusive, more document centered), and I've wished that ZPT had some of the features of XSLT (i.e. ability to be used as a transforming filter).\nReading Ryan Tomayko's description of Kid got me thinking, and googling.  One thing I turned up from a mailing list archive asked about an ‚ÄúXSL implementation of TAL?‚Äù  It struck me as a tad nutty at first, but then I started having inklings that just maybe it could be done.  (Whether it should be done, well...)  But the kernel of the idea grabbed me: Instead of using TALES path expressions to look up values in Pythonic space, why not use XPath expressions to look up values from a supplied XML document?\nThis strikes me as such an obvious idea that someone has to already have done it and possibly rejected it for good reason.  On the other hand, maybe this is the sort of thing Ryan's thinking about-- I wonder how hard it would be to hack this into Kid?  It would give only a subset of XSLT's capabilities in trade for simplicity, and would only offer the ‚Äúpull‚Äù approach, but it would give XML-pipelining to a ZPT-ish technology.\nI think this is something I want to look into a bit further at some point.",
    "prevPostPath": "2004/12/03/if-you-snore-get-tested-for-sleep-apnea-now",
    "nextPostPath": "2004/12/02/nofroogleapi"
  },
  {
    "comments_archived": true,
    "date": "2004-12-02T14:48:38.000Z",
    "excerpt": "You know what I was just thinking?  Why doesn't Froogle have an API like Amazon?",
    "layout": "post",
    "title": "Where's the Froogle API?",
    "wordpress_id": 569,
    "wordpress_slug": "nofroogleapi",
    "wordpress_url": "http://www.decafbad.com/blog/?p=569",
    "year": "2004",
    "month": "12",
    "day": "02",
    "isDir": false,
    "slug": "nofroogleapi",
    "postName": "2004-12-02-nofroogleapi",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/12/02/nofroogleapi",
    "summary": "You know what I was just thinking?  Why doesn't Froogle have an API like Amazon?  It's nearing Christmas again, and other than my occasional hacking activities, now is when my Amazon wishlist gets the most play.  Well, that and on my birthday.\nBut, since my mind's been on shopping a bit, I've been checking out Froogle.  Did you know that Froogle has wishlists?  Man.  I knew that back in the mid-90's I should have gone with that great business idea I had for making a site devoted to wishlists and aggregated shopping, maybe make some cash off affiliate fees.  But anyway, now that I see Froogle's doing it, I have the notion to migrate my eight pages of wishlist items over to Froogle.\nBut, no!  There's no API, and I'm feeling too lazy to hack any screen scraper web robots together.  So.  I'm probably weird for this being the deciding factor, but for now, Amazon retains my patronage.  Funny thing is, although it's a mild form of data lock-in, Amazon does have an API and I can scoop up my wishlist items whenever I feel like it.  It's just that there'd be no convenient place to put them right now.",
    "prevPostPath": "2004/12/03/crossbreedingxsltzpt",
    "nextPostPath": "2004/11/30/nextgenwebapps"
  },
  {
    "comments_archived": true,
    "date": "2004-11-30T21:53:35.000Z",
    "excerpt": "This has been where most of my private hacking sessions have been taking me over the past year or so:  combining HTML, CSS, DOM, JavaScript, XML, XSLT, and REST to build what I consider to be a next-generation web app.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "Next generation web apps using REST, XML, XSLT, and XmlHTTPRequest",
    "wordpress_id": 568,
    "wordpress_slug": "nextgenwebapps",
    "wordpress_url": "http://www.decafbad.com/blog/?p=568",
    "year": "2004",
    "month": "11",
    "day": "30",
    "isDir": false,
    "slug": "nextgenwebapps",
    "postName": "2004-11-30-nextgenwebapps",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/11/30/nextgenwebapps",
    "summary": "So, like I was saying:  I've been working on FeedReactor and have been doing some things with it that I find rather interesting, independent of news aggregation.  \nOne of the core goals I have for FeedReactor is to explore what it takes to build a web app that exploits principles of REST architecture.  Having already sung the praises of XML-RPC, I wanted to get immersed in REST and see what all the hubbub was about.  I've got some ways to go, but I think I understand the major concepts now, and it's a pretty nifty frame within which to work.\nBut, two other things I've added to my mix have really made things interesting for me:  \n\nXSLT filtering\nThe XmlHTTPRequest object\n\nXSLT and REST make a really good pair, as Amazon Web Services already demonstrate.  Inspired by that API (and earlier experiments), I use XML for all the input and output formats in my API and accept a query string parameter that contains the path to an XSLT file.  When this parameter is supplied, the XML output by the API is first processed using the given XSLT.  (Think of it like piping API output through xsltproc.)\nSo, with a properly constructed collection of XSLT, I can present a browser-viewable HTML user interface served up directly from REST API calls.  Links, frame sets, and iframes present in the HTML lead the user from that call to the next XSLT-wrapped REST API call. \nBut, once the initial HTML-and-JavaScript payload reaches the browser, it gets better (ala Gmail):  \nOn older browsers (if I happen to care about them), I can make new HTTP requests back to the server from JavaScript using iframes.  In this case, XSLT filtering lets me retrofit the API's responses to the HTML-and-JavaScript crud I need to serve up to make things happen back in the browser client.  Unfortunately, passing data to the API (which expects XML, not form submissions) is still a bit wonky and requires some hacks and exceptions involving hidden forms and such.\nHowever, on the newer browsers, it's all about the XmlHTTPRequest object.  With this facility, I can make clean asynchronous requests back to the REST API, including XML data in the request body if I feel like it.  Responses are handled by JavaScript callbacks, which twiddle the browser DOM to update the user interface in response.  \nSo, after the major initial contact with the API to supply the browser with HTML by way of XSLT, most future interactions take place in the form of direct calls to the REST API using XML.  Although for some things, it's easier to just reload a page of HTML, it's nicer for most interactions to be handled via DOM manipulations in-place.  I've been amazed at the Gmail-like responsiveness I get from FeedReactor when I'm skimming through news items, marking some as seen or flagged, and popping open the descriptions on others.  \nI suppose I shouldn't be amazed at the responsiveness, since I'm using some of the same techniques as Gmail.  However, my daily-use installation of FeedReactor is presently running on an old 300Mhz Debian Linux PC at home, and it's taking me through the daily produce of 600 subscribed feeds faster than any desktop aggregator has yet.  Of course, this is partly a product of my familiarity with the UI I've cobbled together, but... the server's running on a 300Mhz PC with 256MB of RAM!  And the client is my 867Mhz G4 PowerBook, running Firefox or Safari, depending on my mood.\nAlthough I can't see when I'll have time for it, I really want to explore this approach further using desktop apps on OS X and accessing the API from Flash movies (maybe using Laszlo).  I'd also like to see how far I can go toward adapting the interface toward mobile devices like my Treo 600.\nSo anyway, this has been where most of my private hacking sessions have been taking me over the past year or so:  combining HTML, CSS, DOM, JavaScript, XML, XSLT, and REST to build what I consider to be a next-generation web app.  \nNow, although I use FeedReactor on a daily basis to keep up with all my feeds, it's nowhere near any state suitable for public consumption.  I add new subscriptions from a command-line script and still fiddle with the database directly for some operations.  I'd like to have a personal-server version of it ready for use by some alpha geeks before or not long into the new year, but I'd like to share some of the things I've been doing with it before then.\nWith that in mind, I think I'll wrap up this entry and think about putting together a quick tutorial pico-project to demonstrate some of the concepts.  Maybe an address book, or something equally simple-yet-useful.  \nStay tuned.",
    "prevPostPath": "2004/12/02/nofroogleapi",
    "nextPostPath": "2004/11/30/pico-projects-and-trepanation"
  },
  {
    "comments_archived": true,
    "date": "2004-11-30T18:41:06.000Z",
    "excerpt": "See, in abstract, I understand how all this is supposed to work.  I just have to drum it into my mad-scientist skull.  (I wonder if trepanation would help with that?)",
    "layout": "post",
    "title": "Pico-projects and Trepanation",
    "wordpress_id": 567,
    "wordpress_slug": "pico-projects-and-trepanation",
    "wordpress_url": "http://www.decafbad.com/blog/?p=567",
    "year": "2004",
    "month": "11",
    "day": "30",
    "isDir": false,
    "slug": "pico-projects-and-trepanation",
    "postName": "2004-11-30-pico-projects-and-trepanation",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/11/30/pico-projects-and-trepanation",
    "prevPostPath": "2004/11/30/nextgenwebapps",
    "nextPostPath": "2004/11/30/earlyresolution"
  },
  {
    "comments_archived": true,
    "date": "2004-11-30T17:41:41.000Z",
    "excerpt": "It's the last month of 2004 tomorrow, and it's occurred to me that I haven't spent much time around here.",
    "layout": "post",
    "title": "Early New Years' Resolution",
    "wordpress_id": 566,
    "wordpress_slug": "earlyresolution",
    "wordpress_url": "http://www.decafbad.com/blog/?p=566",
    "year": "2004",
    "month": "11",
    "day": "30",
    "isDir": false,
    "slug": "earlyresolution",
    "postName": "2004-11-30-earlyresolution",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/11/30/earlyresolution",
    "summary": "It's the last month of 2004 tomorrow, and it's occurred to me that I haven't spent much time around here.  \nDoing a quick check, it looks like I've written a little over 50 posts this year, down from around 170 last year.  And the year before that was around 340.  Mainly, my activity around here has progressed toward much more link blogging using my own tools and, more recently, del.icio.us.  When I actually have written something of my own lately, I've tended toward sweating over longer entries or nothing at all.\nDoes all this mean I'm an ex-blogger?  Or was I ever?  On the other hand, who really cares?  Funny thing is, I'm sure I can find a few dozen entries I've written, self-flagellating about not writing more often.  \nIf I were to let you read from my handwritten journals, you'd find the same thing every few entries.  It seems I suffer from a strange complex of guilt and pedestal building: I feel guilty for not writing more, but then when I have something quick I could write, I feel guilty for not having something grander to offer.\nOf course, there's also the fact that I had a really busy streak in my work-a-day life for awhile there, but for the past month or so I've mostly been lying fallow.  Now, I'm getting antsy to produce some Worthwhile Things again.\nBah.  How about an early New Years' Resolution to follow my own advice and let my brain dribble barely-worthy crap here on a more regular basis.  \nAnd, how about I make this the last entry I write about not writing entries?  I'm sure I can come up with other topics about which to write when I can't think of what to write.",
    "prevPostPath": "2004/11/30/pico-projects-and-trepanation",
    "nextPostPath": "2004/11/02/ipodcostume"
  },
  {
    "comments_archived": true,
    "date": "2004-11-02T20:18:48.000Z",
    "excerpt": "Hey, Pete?  This one's for you.",
    "layout": "post",
    "title": "I ran out of costume ideas",
    "wordpress_id": 565,
    "wordpress_slug": "ipodcostume",
    "wordpress_url": "http://www.decafbad.com/blog/?p=565",
    "year": "2004",
    "month": "11",
    "day": "02",
    "isDir": false,
    "slug": "ipodcostume",
    "postName": "2004-11-02-ipodcostume",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/11/02/ipodcostume",
    "thumbnail": "http://www.decafbad.com/2004/11/02/ipod-halloween.jpg",
    "summary": "Hey, Pete?  Where do I send the candy?  This one's for you:",
    "prevPostPath": "2004/11/30/earlyresolution",
    "nextPostPath": "2004/10/27/ipodtickles"
  },
  {
    "comments_archived": true,
    "date": "2004-10-27T21:18:19.000Z",
    "excerpt": "What occurred to me as I rounded the last stretch of I-75 into Detroit this morning is that this metadata and these Smart Playlists on shuffle amount to an attempt to tickle myself.",
    "layout": "post",
    "tags": [
      "apple"
    ],
    "title": "My iPod experience is all about tickling myself.",
    "wordpress_id": 564,
    "wordpress_slug": "ipodtickles",
    "wordpress_url": "http://www.decafbad.com/blog/?p=564",
    "year": "2004",
    "month": "10",
    "day": "27",
    "isDir": false,
    "slug": "ipodtickles",
    "postName": "2004-10-27-ipodtickles",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/10/27/ipodtickles",
    "summary": "I've had an iPod for a little over a week now, and I've been working pretty diligently to rate every song I hear and trying to make sure all the metadata is correct.  I've even started tinkering with tagging songs using things like :dreamy, :goofy, :energy, :calm in the comments field for use with Smart Playlists.  (Yeah, I know about TuneTags, but the psuedo-XML in song comments bugs me, as does the somewhat buggy behavior of the last version of the program I tried.)\nBy this point, I've managed to cram about 3400 songs from our CD collection into it.  (So much for the marketing!)  With my efforts so far, a ‚ÄúGood Music‚Äù Smart Playlist selecting for 3-stars and above gives me around 415 songs.  This doesn't count the songs I've rated with 1-star, which get deleted from the iPod periodically.  Also, I've yet to get a significant proportion tagged with special comments, so mood-based and concept-based playlists are far off until I get a better tool for letting me quickly and lazily tag songs.\nSo, this morning on the way into work I fired up my ‚ÄúGood Music‚Äù playlist on random for the first time, and I was amazed at how good the selection was.  Yes, I rated these songs, so I should know they're good--but so far, I've had all 3400 songs on shuffle and have been alternating between listening and rating, skipping songs I wasn't in the mood for, and canning songs right off the bat with a 1-star rating.  So up until now, my rotation has been an okay experience.\nHowever, hearing that mix of consistently high rated songs was an unexpectedly good experience.  What occurred to me as I rounded the last stretch of I-75 into Detroit this morning is that this metadata and these Smart Playlists on shuffle amount to an attempt to tickle myself.  Ever try that?  For the most part, it doesn't work.  Sure, you know where you're ticklish--but if it's your hand trying to do it, you're expecting it and the tickle doesn't happen.  \nI'm probably stepping too far into breathless pretentiousness with this, but it makes me want to think further about machine learning and intelligence.  Yeah, Smart Playlists are a very, very rudimentary form of intelligence, but it's good enough to tickle me with a music mix--which is a very real bit of value added to my life.  \nI wonder how much further this tickling-myself metaphor can be taken?  That is: take a machine endowed with information I produced, apply some simple or slightly complex logic with a bit of random shuffle, and feed it back to me to see if it makes me experience it with some novelty.  Someone's got to already be on top of this as a research project.  That, or it's an idea obvious or dumb enough only to appeal to me.",
    "prevPostPath": "2004/11/02/ipodcostume",
    "nextPostPath": "2004/10/19/ipodismine"
  },
  {
    "comments_archived": true,
    "date": "2004-10-19T19:15:49.000Z",
    "excerpt": "So I finally got myself an iPod, thanks to The Girl.",
    "layout": "post",
    "tags": [
      "apple"
    ],
    "title": "I'm one of the iPod generation now",
    "wordpress_id": 563,
    "wordpress_slug": "ipodismine",
    "wordpress_url": "http://www.decafbad.com/blog/?p=563",
    "year": "2004",
    "month": "10",
    "day": "19",
    "isDir": false,
    "slug": "ipodismine",
    "postName": "2004-10-19-ipodismine",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/10/19/ipodismine",
    "summary": "So I finally got myself an iPod, thanks to The Girl.  \nThrough various twists of replacement policy and iBook promotional antics, somehow she ended up with two 20GB 4G iPods, both of which she's been planning to sell off on eBay to end up with some cash and an iPod Mini.  Well, it finally occurred to me this weekend that I needed to buy one of those iPods.\nLately, I've been only been listening to streaming radio at work, since I don't really have the hard drive space on my PowerBook for music, and loading up the work PC with MP3s is pretty unpalatable.  I miss the days when I had a 40GB library at work, but between company policy where I am now and having lost that whole library in a hard drive crash back then, I'm hesitant to go there again.\nEnter the iPod.  I was reminded of its presence in The Girl's office, still boxed up and shrink-wrapped, at a moment when I was thinking about podcasting and thinking about my lack of hard drive space.  So, I gave in and snapped it up.  \nThus far, I'm pretty happy.  Sure, I'd been looking at the larger capacity models that came with a dock and remote, but this one was the right price at the right place and the right time.  I was also lucky that she had an iTrip she was selling that just happened to work satisfactorily for playing MP3s in my car - something that's been a bit of a quest of mine for years.  While it's true I do have an in-dash Blaupunkt MP3 CD player in my Ford Focus now, it's also true that 20GB certainly outweighs 700MB.\nThe few snags I've run into so far mostly have to do with the fact that it seems like my desired usage pattern of the iPod isn't quite supported.  See, I don't want to have a massive library on my PowerBook, to be synched in part onto my iPod.  I have a library on a file server at home, and I want to use the iPod alternately as a music store away from home for iTunes on my PowerBook and as an MP3 player while I'm driving.  I don't want any music at all on my PowerBook.  Problem is, though, the iPod isn't quite a first-class citizen in iTunes.  Party Shuffle doesn't work, and I had a few problems with making sure metadata (like ratings and last played date) made it into iTunes.\nOh yeah, and I wish they'd turn down the wheel sensitivity way down when setting a song's rating.  At present, it's just a bare millimeter of a finger's twitch to leap from 1 to 5 stars.  Might just be me.\nBut, for the most part, I'm very happy to have my own music at work again, and the potential of tinkering with smart playlists and podcasts are exciting to me.  That, and the fourth-generation iPod is just an elegant, slick joy to hold.",
    "prevPostPath": "2004/10/27/ipodtickles",
    "nextPostPath": "2004/10/11/allgrowedup"
  },
  {
    "comments_archived": true,
    "date": "2004-10-11T14:22:51.000Z",
    "excerpt": "When I was in high school, around about the time Ross Perot was getting into the presidential race, I remember putting a little item on my to-do list in my brand new day planner:\n\n* Read the newspaper, watch the news.",
    "layout": "post",
    "tags": [
      "syndication"
    ],
    "title": "All Growed Up as an Info Freako",
    "wordpress_id": 562,
    "wordpress_slug": "allgrowedup",
    "wordpress_url": "http://www.decafbad.com/blog/?p=562",
    "year": "2004",
    "month": "10",
    "day": "11",
    "isDir": false,
    "slug": "allgrowedup",
    "postName": "2004-10-11-allgrowedup",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/10/11/allgrowedup",
    "summary": "The future of syndication that folks at Web2.0 are professing is really structured around information organization and access. It's about people who are addicted to content, people who want to be peripherally aware of some discussions that are happening. It is not about people who use these tools to maintain an always-on intimate community. There is a huge cultural divide occurring between generations, even as they use the same tools. Yet, i fear that many of the toolmakers aren't aware of this usage divide and they're only accounting for one segment of the population.\nSource: apophenia\n - a culture of feeds: syndication and youth culture\n\nAs I was writing about falling for the podcasting hype, I'd mentally queued up some ideas for something further relating to my growing addiction to NPR and news in general.  Danah's writing about youth and feeds and intimate communication versus institutional communication resonates well with what I've been tossing around in my head.\nWhen I was in high school, around about the time Ross Perot was getting into the presidential race, I remember putting a little item on my to-do list in my brand new day planner:\n\nRead the newspaper, watch the news.\n\nI must've been, what, 16 years old?  I suppose that would have made me one of the youths Danah's talking about, albeit of an earlier generation of online communicators.  At the time, the bulk of my disposable income earned as a grocery store bagger was spent on music CDs, gas, and the occasional upgrade to my Commodore Amiga.  I didn't even know was NPR was, though I knew there was this thing they did with news on the radio.  But newspapers and talk on the radio were things that my grandparents paid attention to, if anything.  \nThe only reason I put that item on my to-do list--in fact, the only reason I even had a day planner with a to-do list in the first place--was because, according to the teachers trying to prepare me for college, this was what grownups did.  Planning your days and reading the news were things that adults did, and if I wanted to be an adult, I should get with the program.  And I wanted to get with the program, but I really didn't see the point yet.\nHowever, I did live most of my social life online.  Now, that needs a bit of qualification:  Of course, I am a big geek and many of my kind spend their days living in Mom's basement talking to men pretending to be 14-year-old girls.  But, back when I was first getting online, the main gateway for access was the dial-up BBS, preferably one that was a local call to your area code and prefix.  What that meant is that most of the people I was chatting with online were within a 16-year-old's parentally condoned driving radius.\nSo, I never lived in the basement, and I did actually get out quite a bit.  The only real strange bit was that very few of my social group went to school together--and actually, most of us were misfits in school, some counting the minutes till we could get back to each other.  Having just finished Cory Doctorow's Eastern Standard Tribe (read on my Treo 600, my comm, no less), I can totally grok the tribes.  Mine was as small as an area code or two, rather than a time zone, but I had a tribe.  Still do, even though we've since dispersed across many, many area codes.  Now there's LiveJournal and Xanga, among other tribe-building technologies.\nBut lately, in the past few years, I've been changing.  I'm only 29 now, but I've learned what a day planner is for and my to-do list is crucial; I know enough about the news on TV not to watch it much, yet I pull in enormous volumes of news from online sources and magazines.  And, as I wrote earlier, NPR is now the only station on my radio dial.\nWhen I was 16, the presidential race was a curiosity about which I felt vague guilt for not knowing more. But, this time around I'm giving it an attention and range of emotion akin to a rabid sports fan during playoffs.  I lost sleep over whether or not my voter registration was up to date with my correct address.  I do realize that for many, many reasons this particular presidential race is historic.  But I'm a johnny-come-lately--there've been historic presidential races before: history didn't start because I started paying attention.\nWhat's happened is that I've changed.  If I could time-travel and stop by to say hello, my high-school-self would probably admire who I am now, but wouldn't quite understand me.  He'd get the half-dozen IRC windows I have open, and the handful of IM windows I'm floating at any particular moment, but I doubt he'd get the lure of my news aggregator in the background.  I loved Jesus Jones at the time, but I didn't really know what it meant to be an Info Freako.\nWhat changed in me?  I'm not quite sure.  I'm sure there's something going on with hormones and the few grey hairs I have now.  But I think it has something to do with actually starting to become a grownup.  That is, I'm paying taxes, I'm acting in the world, I have responsibilities, and I've left the shelter of my parents' house.  All the way from elementary school through college, I was on rails, and there wasn't much I needed to know other than what they were teaching to get by.  Now, though, I'm off the rails, and I feel I need all the information I can get, just to figure out how to navigate.  \nMaybe it's become obsessive, but I don't want to miss any vital data that will help lead me toward my bliss, to grow up without growing old.  And I know that, however small, my actions have consequence in the world, so I want to understand.  I am a member of a civilization.  I think I get that now.\n\nSo, anyway, if anything I'm just underscoring with my own experience that usage divide between youth and older info freako adults Danah wrote about.  I've been on both sides of it now, I think.  \nWhere I think I disagree a bit is about trends: she asks if this Info Freako style of massive feed consumption will be relevant beyond the Web 2.0 crowd of today.  As an early adopter of a technologically-driven social life, I would have to guess that the current generation will produce some even more obsessive Info Freakos than the oldsters around today.  \nBecause, if my own experience is any guide, we start off using the technology to talk to each other in tribes.  However, as (or, I guess, if) we grow up and become fully acting members of our civilization, we turn to the same sorts of tech to converse with the civilization itself.  Whether that will take the form of massive feed consumption, I don't know, because I have to assume the tech will be very much changed by then.  I can see the intimate communication habits progressing to civic and national and global communication habits, even in myself.  \nThe problem, though, is that once you start making ventures out of your tribe, you start running into the limits of your neocortex.  Communication must necessarily lose its intimacy and give way to group-to-group and one-to-many conversations.  That's where I see feeds coming in to supplement IM and email--though I certainly hope by then that there's a lot more intelligence behind feeds and microcontent routing and user interface, a lot of the principles will be the same.  \nBut, in any case, I think we're in for some interesting history coming up, as more youths used to texting each other take up roles as members of civilization.",
    "prevPostPath": "2004/10/19/ipodismine",
    "nextPostPath": "2004/10/08/itunesxslt"
  },
  {
    "comments_archived": true,
    "date": "2004-10-08T17:07:49.000Z",
    "excerpt": "So I had an idea for a quick podcasting listening hack on the way into work this morning.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "Using iTunes as a podcast aggregator, with a little help from XSLT",
    "wordpress_id": 561,
    "wordpress_slug": "itunesxslt",
    "wordpress_url": "http://www.decafbad.com/blog/?p=561",
    "year": "2004",
    "month": "10",
    "day": "08",
    "isDir": false,
    "slug": "itunesxslt",
    "postName": "2004-10-08-itunesxslt",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/10/08/itunesxslt",
    "summary": "So I had an idea for a quick podcasting listening hack on the way into work this morning. Check it out:\n\nTake one list of RSS feeds in OPML.\nThrow in a bit of XSLT.\nCombine using xsltproc to make a playlist that works in iTunes.\n\nAnd, oh yeah, I just happen to have an xsltproc web service laying around, so:\n\nSupply a URL to your OPML in this form.\nGet a freshly-built playlist.\n\nNow, this has been barely tested and is the product of a ten-minute hacking session.  There are likely an enormous number of things wrong with this.  That said, iTunes does seem to open the playlist happily, and it looks like only new streams are added with repeated openings of the playlist.\nYou will want to be careful to ensure that your OPML is valid XML (mine wasn't, on initial export from iPodderX - escape those freaking ampersands in URLs already!), and I have no idea what would happen if any of the RSS feeds in your subscriptions turn up invalid.  \nHave I mentioned that, despite their unforgiving and sometimes fragile nature, I love XML technologies?\nIf this looks useful, maybe I'll work it over a bit more and pair it up with some python to handle actually downloading the MP3s and torrents.\nUpdate: Oh yeah, and I'm expecting this will be useful with an iTunes smart playlist crafted along these lines:\n\nDate Added in the last 1 days\nPlay Count is less than 1\n\nUpdate #2: Another use I just found for this playlist, is on my Xbox Media Center.  I generate this playlist via cronjob every few hours, and store it on an SMB share accessible to the XBMC.  Voila!  Listening to podcasts on my stereo system via the Xbox.  Yeah, nothing big, just kind of nifty.",
    "prevPostPath": "2004/10/11/allgrowedup",
    "nextPostPath": "2004/10/07/podcastinghype"
  },
  {
    "comments_archived": true,
    "date": "2004-10-07T15:02:49.000Z",
    "excerpt": "So, over the last day or so, I've found myself falling for the Podcasting hype.",
    "layout": "post",
    "tags": [
      "syndication"
    ],
    "title": "Falling for the Podcasting Hype",
    "wordpress_id": 560,
    "wordpress_slug": "podcastinghype",
    "wordpress_url": "http://www.decafbad.com/blog/?p=560",
    "year": "2004",
    "month": "10",
    "day": "07",
    "isDir": false,
    "slug": "podcastinghype",
    "postName": "2004-10-07-podcastinghype",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/10/07/podcastinghype",
    "summary": "So, over the last day or so, I've found myself falling for the Podcasting hype.  \nYeah, yeah, I know -- I listened to and read Maciej's audioblogging manifesto (and, yes, that's a link to the text version, which kind of helps support the argument therein) but I think the addition of portable digital audio players and RSS feeds with enclosures to the mix changes things.  \nThe whole audioblogging thing has seemed incredibly stupid and annoying to me, since my experience of it so far has mostly consisted of this:  I navigate first to a text blog entry, click on a link to an MP3, then stare at the screen as the thing plays.  Being a high-bandwidth Info Freako, a feeling of time wasted comes upon me pretty quickly.  I can speed read and I want to get through this quickly, but I can't speed listen.  I want to throw a bookmark at del.icio.us if I like it, but I can't select any text.  Getting a bit bored, I start thinking about how maybe I might want to remix this crap, make a funky beat out of all the utterances of ‚Äúum‚Äù, ‚Äúahh‚Äù, and ‚Äúerr‚Äù.\nSo, yeah, this sucks.  Not picking on any particular audio blogger or post -- because they're almost all like this -- but I want that 4 minutes of my life back.\nBut the thing is, I'm a news radio junkie.  I abandoned listening to music over the air almost seven years ago, so when I'm not listening to MP3 CDRs, my car tuner is almost perpetually locked on NPR.  I listen to people jabbering at me at almost all times while I'm driving.  And at work, I mix listening to my MP3s with streaming talk, news, and old sci-fi radio stations.\nThe difference here is that radio doesn't demand much of my attention.  I'm usually doing something else while I'm listening, like driving or working.  I don't have to navigate to anything, I don't have to provide any feedback or make any decisions--I just have to let it stream into my head.  The lower mental demands of audio and a lack of necessary interaction dovetail nicely with multitasking.\nSo, in come iPodderX and friends.  They're feed aggregators specifically built to slurp down audio enclosures and sync them up to audio players like the iPod.  The idea is that, when you leave home, you take the digital audio player with you, loaded up with your own personal radio programming.  Not having an iPod, I've been queuing these aggregated audio posts up in iTunes at work, and I've been playing around with burning CDRW's for use in my car's in-dash MP3 player.  Once I get a headphone adapter for my Treo 600, maybe I'll start listening to them on there.\nWith this switch of perspective, I think I'm falling for the hype.  The key is to get out of the way: aggregate, queue, and play in the background.  Yeah, there's going to be a lot of awful crap out there, and lots of dorks eating breakfast and lipsmacking into the microphone as they blab (this is me, shuddering)--but as the number of podcasters expand, we will start to hear some blissful hams showing up with things worth listening to.\nI'd like to do something, but I doubt I have the time or insight to produce something worth listening to on a regular basis.  Adam Curry suggested doing things like a daily quote, jokes, or skits--short, good things have value.  (Pete's encounter with frozen pizza instructions on Rasterweb Audio made me snort a bit.)\nThe first thing that comes to my mind are these old sci-fi radio broacasts to which I'm addicted.  While I have written stories of my own, I wonder how much public-domain or Creative Commons licensed content is out there available?  Could be fun to do some readings and a maybe do a little low-budget foley work.  Of course, there's the hosting and bandwidth to worry about, though I suppose BitTorrent could help if the aggregators support it (and they should!)\nIn any case, I think the podcasters are on to something here.  I'll be listening.",
    "prevPostPath": "2004/10/08/itunesxslt",
    "nextPostPath": "2004/09/29/testing-treo-600-avant-go"
  },
  {
    "comments_archived": true,
    "date": "2004-09-29T22:55:58.000Z",
    "layout": "post",
    "title": "testing treo 600 + avant go",
    "wordpress_id": 559,
    "wordpress_slug": "testing-treo-600-avant-go",
    "wordpress_url": "http://www.decafbad.com/blog/?p=559",
    "year": "2004",
    "month": "09",
    "day": "29",
    "isDir": false,
    "slug": "testing-treo-600-avant-go",
    "postName": "2004-09-29-testing-treo-600-avant-go",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/29/testing-treo-600-avant-go",
    "prevPostPath": "2004/10/07/podcastinghype",
    "nextPostPath": "2004/09/22/bloggingyourbliss"
  },
  {
    "comments_archived": true,
    "date": "2004-09-22T13:54:49.000Z",
    "excerpt": "Maybe I'm a bit too optimistic about noospheric homesteading, but I expect that the pressures of this space will eventually leave only two kinds of bloggers: the ones who get paid enough, and the ones who have to be here because their bliss won't let them do anything else.",
    "layout": "post",
    "title": "Blogging your bliss, or blog like no one's watching.",
    "wordpress_id": 557,
    "wordpress_slug": "bloggingyourbliss",
    "wordpress_url": "http://www.decafbad.com/blog/?p=557",
    "year": "2004",
    "month": "09",
    "day": "22",
    "isDir": false,
    "slug": "bloggingyourbliss",
    "postName": "2004-09-22-bloggingyourbliss",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/22/bloggingyourbliss",
    "summary": "You, who ever you are, do what you want; but if you‚Äôre only here to be the next Kottke, or Scoble, or Stone, quit now. You‚Äôll never get to their position aping their behavior or their rules; you‚Äôll just end up miserable because you‚Äôre not writing the way you want, and for the joy of the act. Fuck me, too many sheep in this environment. How can your ‚Äòba-ah-ahh‚Äô be heard when you‚Äôre surrounding by people bleating the same thing?\n\nSomeone let in the wolves ‚Äì it‚Äôs feeding time.\n\nOf course, you have to take what I write with a grain of salt. Domestic, refined, mined salt. I‚Äôm not as popular as Robert Scoble or Biz Stone, so one can assume that their suggestions work, while my ‚Äòlong form diatribe‚Äô won‚Äôt do you a bit of good if all you want is to be known.\n\n Or as a friend (someone who I actually like and respect as a person, regardless of how many hits he could send me) says: do what you want, anyway, because we‚Äôre all just making this stuff up.\nSource: Burningbird: This is Wrong on Oh So Many Levels\n\nI haven't been writing a lot here, but things have been percolating in my head.  I've gone through phases of wanting this place to be a bit of a techie zine, I've been in a funk, and lately I've been telling myself that I should blog like no one's watching.\nFunny thing is, between those thoughts and my recent activity on a project, I've been posting quite a bit more than I have in a long time.  If I were to critique recent posts, I'd beat myself up for being either far too nerdy and obscure, or being inane.  Yet, oddly enough, I'd gotten comments and emails that demonstrate obvious interest.\nBut, it's not a thing to manipulate like search engine listings.  When I've written something that I expected to get a lot of comments, it didn't at first.  When I posted something that I expected to float by without much comment, it got eight right away.  I suppose one could carefully monitor and analyze trendy topics in blogs and try to post only things with high buzz factor, but the best thing is just to write like no one's watching and be pleasantly surprised when you do get attention.\nThe way I perceive this whole blogosphere working, long term, is for bloggers to read some Joseph Campbell and ‚ÄúFollow Your Bliss‚Äù.  You could serve the whims of ‚Äútraffic‚Äù for awhile, but if it's not following your bliss, you'll get tired of keeping up.  But if you hook into your bliss, there's bound to be traffic-a-plenty coming just to watch you do your own funky breakdance on that piece of cardboard you threw down on your domain name.\nMaybe I'm a bit too optimistic about noospheric homesteading, but I expect that the pressures of this space will eventually leave only two kinds of bloggers: the ones who get paid enough, and the ones who have to be here because their bliss won't let them do anything else.\n(And I expect the economics to slant in favor of bliss.)",
    "prevPostPath": "2004/09/29/testing-treo-600-avant-go",
    "nextPostPath": "2004/09/21/this-is-a-test-of"
  },
  {
    "comments_archived": true,
    "date": "2004-09-21T13:44:41.000Z",
    "layout": "post",
    "title": "This is a test of",
    "wordpress_id": 556,
    "wordpress_slug": "this-is-a-test-of",
    "wordpress_url": "http://www.decafbad.com/blog/?p=556",
    "year": "2004",
    "month": "09",
    "day": "21",
    "isDir": false,
    "slug": "this-is-a-test-of",
    "postName": "2004-09-21-this-is-a-test-of",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/21/this-is-a-test-of",
    "prevPostPath": "2004/09/22/bloggingyourbliss",
    "nextPostPath": "2004/09/20/bootstrapping-out-into-open-space"
  },
  {
    "comments_archived": true,
    "date": "2004-09-20T20:19:30.000Z",
    "excerpt": "So all I'm left with is that I *think* I have the occasional good idea, but with no way of know how to run with it.  And all these internet entrepreneurs apparently bootstrapping out into open space don't make sense to me either.\n\nAnyway...  It all seems like magic to me.  Maybe one day I'll figure it out.",
    "layout": "post",
    "title": "Bootstrapping out into open space",
    "wordpress_id": 555,
    "wordpress_slug": "bootstrapping-out-into-open-space",
    "wordpress_url": "http://www.decafbad.com/blog/?p=555",
    "year": "2004",
    "month": "09",
    "day": "20",
    "isDir": false,
    "slug": "bootstrapping-out-into-open-space",
    "postName": "2004-09-20-bootstrapping-out-into-open-space",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/20/bootstrapping-out-into-open-space",
    "prevPostPath": "2004/09/21/this-is-a-test-of",
    "nextPostPath": "2004/09/20/hosting-advice"
  },
  {
    "comments_archived": true,
    "date": "2004-09-20T19:47:46.000Z",
    "layout": "post",
    "title": "Hosting advice?",
    "wordpress_id": 554,
    "wordpress_slug": "hosting-advice",
    "wordpress_url": "http://www.decafbad.com/blog/?p=554",
    "year": "2004",
    "month": "09",
    "day": "20",
    "isDir": false,
    "slug": "hosting-advice",
    "postName": "2004-09-20-hosting-advice",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/20/hosting-advice",
    "prevPostPath": "2004/09/20/bootstrapping-out-into-open-space",
    "nextPostPath": "2004/09/19/feedreactor-dbagg3-notes"
  },
  {
    "comments_archived": true,
    "date": "2004-09-19T03:47:07.000Z",
    "excerpt": "While the girl does her Calculus and Statistics homework, I'm availing myself of this coffee shop wi-fi to make an initial brain-dump of FeedReactor details into Kwiki.",
    "layout": "post",
    "tags": [
      "syndication"
    ],
    "title": "Initial dbagg3 / feedReactor notes in Kwiki",
    "wordpress_id": 553,
    "wordpress_slug": "feedreactor-dbagg3-notes",
    "wordpress_url": "http://www.decafbad.com/blog/?p=553",
    "year": "2004",
    "month": "09",
    "day": "18",
    "isDir": false,
    "slug": "feedreactor-dbagg3-notes",
    "postName": "2004-09-18-feedreactor-dbagg3-notes",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/19/feedreactor-dbagg3-notes",
    "summary": "While the girl does her Calculus and Statistics homework, I'm availing myself of this coffee shop wi-fi to make an initial brain-dump of FeedReactor details into Kwiki:\n\nInstallation\nQuick Start\nUsage profiles\n\n\nConsole feed manipulation\nStatic blog publishing\nDesktop aggregator\nPersonal server aggregator\nPersonal dynamic blog publishing\nMulti-user dynamic blog publishing\nMulti-user aggregator\n\nArchitecture\nData model\nREST API\nCurrent TODO\nFuture / Blue Sky",
    "prevPostPath": "2004/09/20/hosting-advice",
    "nextPostPath": "2004/09/18/markdown-formatting-for-kwiki"
  },
  {
    "comments_archived": true,
    "date": "2004-09-18T23:20:41.000Z",
    "excerpt": "I just made my first Kwiki formatting plugin, making Markdown formatting available.",
    "layout": "post",
    "tags": [
      "wiki"
    ],
    "title": "Markdown formatting for Kwiki",
    "wordpress_id": 552,
    "wordpress_slug": "markdown-formatting-for-kwiki",
    "wordpress_url": "http://www.decafbad.com/blog/?p=552",
    "year": "2004",
    "month": "09",
    "day": "18",
    "isDir": false,
    "slug": "markdown-formatting-for-kwiki",
    "postName": "2004-09-18-markdown-formatting-for-kwiki",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/18/markdown-formatting-for-kwiki",
    "prevPostPath": "2004/09/19/feedreactor-dbagg3-notes",
    "nextPostPath": "2004/09/18/moving-toward-kwiki-away-from-twiki"
  },
  {
    "comments_archived": true,
    "date": "2004-09-18T17:51:32.000Z",
    "excerpt": "So, I'm going to try out Kwiki.",
    "layout": "post",
    "title": "Moving toward Kwiki, away from TWiki",
    "wordpress_id": 551,
    "wordpress_slug": "moving-toward-kwiki-away-from-twiki",
    "wordpress_url": "http://www.decafbad.com/blog/?p=551",
    "year": "2004",
    "month": "09",
    "day": "18",
    "isDir": false,
    "slug": "moving-toward-kwiki-away-from-twiki",
    "postName": "2004-09-18-moving-toward-kwiki-away-from-twiki",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/18/moving-toward-kwiki-away-from-twiki",
    "prevPostPath": "2004/09/18/markdown-formatting-for-kwiki",
    "nextPostPath": "2004/09/18/are-powerbook-hard-drives-supposed-to-sound-like-amiga-floppy-drives"
  },
  {
    "comments_archived": true,
    "date": "2004-09-18T01:37:14.000Z",
    "excerpt": "Ugh.  PowerBook hard drive is going click... click... click... click... and all the while, the system is frozen.  I think I may have accidentally banged the left corner of the thing one too many times.",
    "layout": "post",
    "title": "Are PowerBook hard drives supposed to sound like Amiga floppy drives?",
    "wordpress_id": 550,
    "wordpress_slug": "are-powerbook-hard-drives-supposed-to-sound-like-amiga-floppy-drives",
    "wordpress_url": "http://www.decafbad.com/blog/?p=550",
    "year": "2004",
    "month": "09",
    "day": "17",
    "isDir": false,
    "slug": "are-powerbook-hard-drives-supposed-to-sound-like-amiga-floppy-drives",
    "postName": "2004-09-17-are-powerbook-hard-drives-supposed-to-sound-like-amiga-floppy-drives",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/18/are-powerbook-hard-drives-supposed-to-sound-like-amiga-floppy-drives",
    "prevPostPath": "2004/09/18/moving-toward-kwiki-away-from-twiki",
    "nextPostPath": "2004/09/17/dbagg3mess"
  },
  {
    "comments_archived": true,
    "date": "2004-09-17T13:32:30.000Z",
    "excerpt": "Wow.  So it looks like there are some people starting to follow to what I'm doing with dbagg3, and they're showing me how woefully prepared I am for the attention from tinkerers who are actually trying to, you know, run my code.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "dbagg3: Please excuse the mess",
    "wordpress_id": 549,
    "wordpress_slug": "dbagg3mess",
    "wordpress_url": "http://www.decafbad.com/blog/?p=549",
    "year": "2004",
    "month": "09",
    "day": "17",
    "isDir": false,
    "slug": "dbagg3mess",
    "postName": "2004-09-17-dbagg3mess",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/17/dbagg3mess",
    "summary": "Wow.  So it looks like there are some people starting to follow to what I'm doing with dbagg3, and they're showing me how woefully prepared I am for the attention from tinkerers who are actually trying to, you know, run my code.  Things have been crazy busy for me at work, so I haven't been getting done what I've planned.  But, I do need to pull a few things together and clean a few things up.  I'll soon be answering the smattering of email I've gotten so far, but until then, a few quick thoughts:\n\nMy source control is a bit of a mess at the moment.  Not only have I switched from CVS to SVN-- but even if you followed me in that migration, I've not kept committed code in working order.  I already know that this is a horrible habit, but since no one's really been looking, I haven't been called on it until now.  (Heh, heh--d'oh.)  Planning this weekend (but hopefully today) to resolve this, so that moving forward, svn trunk will be (as far as possible) in a working state at any given moment.\n\nI've hacked one of my dependencies, SQLObject, by applying a patch to support SELECT DISTINCT queries.  This has understandably caused problems for some people who have no idea what I did.  This patch has turned out to be essential, though I don't know if/when it will or would be included in a release of SQLObject.  So...  I wonder if I should dump my working copy of SQLObject into source control?  Otherwise, applying the DISTINCT patch to your SQLObject install should work.\n\nAt some point very soon, I want to change the name of this thing to feedReactor.  Yes, I know there's already a feedparser, and a feeddemon, and a feedburner, and someone's probably got a feedkitchensink in the works, but I like this name and want to run with it.\n\n\nSo, in the meantime while I straighten some things out, please excuse the mess and thanks for bearing with me!",
    "prevPostPath": "2004/09/18/are-powerbook-hard-drives-supposed-to-sound-like-amiga-floppy-drives",
    "nextPostPath": "2004/09/16/moving-time-from-cvs-to-subversion"
  },
  {
    "comments_archived": true,
    "date": "2004-09-16T15:29:04.000Z",
    "excerpt": "So, I'm waiting for the other shoe to drop.  After making sure things seemed reasonably stable post-server-move, I migrated my CVS repository here to Subversion.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "Moving time: From CVS to Subversion",
    "wordpress_id": 548,
    "wordpress_slug": "moving-time-from-cvs-to-subversion",
    "wordpress_url": "http://www.decafbad.com/blog/?p=548",
    "year": "2004",
    "month": "09",
    "day": "16",
    "isDir": false,
    "slug": "moving-time-from-cvs-to-subversion",
    "postName": "2004-09-16-moving-time-from-cvs-to-subversion",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/16/moving-time-from-cvs-to-subversion",
    "prevPostPath": "2004/09/17/dbagg3mess",
    "nextPostPath": "2004/09/15/manipulating-aggregate-resources-in-a-rest-api"
  },
  {
    "comments_archived": true,
    "date": "2004-09-15T18:48:53.000Z",
    "excerpt": "So... am I missing a more elegant RESTful way of doing this which doesn't result in a quadrillion HTTP requests?",
    "layout": "post",
    "tags": [
      "xml"
    ],
    "title": "Manipulating aggregate resources in a REST API?",
    "wordpress_id": 547,
    "wordpress_slug": "manipulating-aggregate-resources-in-a-rest-api",
    "wordpress_url": "http://www.decafbad.com/blog/?p=547",
    "year": "2004",
    "month": "09",
    "day": "15",
    "isDir": false,
    "slug": "manipulating-aggregate-resources-in-a-rest-api",
    "postName": "2004-09-15-manipulating-aggregate-resources-in-a-rest-api",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/15/manipulating-aggregate-resources-in-a-rest-api",
    "prevPostPath": "2004/09/16/moving-time-from-cvs-to-subversion",
    "nextPostPath": "2004/09/13/dbagg3alive"
  },
  {
    "comments_archived": true,
    "date": "2004-09-13T22:11:41.000Z",
    "excerpt": "So at this point, it's all URLs and barely working HTML, but it's exciting to me at least.  And it's dogfood for me, since I'm using this crud to get my daily (hourly?) fix.  Pretty soon, I'll be diving into wrapping more of a proper usable web app around this, with user management and stuff that works in MSIE.  Until then, maybe someone else will see this and catch a buzz from it.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "Early dbagg3 demo is alive and kicking",
    "wordpress_id": 546,
    "wordpress_slug": "dbagg3alive",
    "wordpress_url": "http://www.decafbad.com/blog/?p=546",
    "year": "2004",
    "month": "09",
    "day": "13",
    "isDir": false,
    "slug": "dbagg3alive",
    "postName": "2004-09-13-dbagg3alive",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/13/dbagg3alive",
    "summary": "Got some very good work in this weekend on switching servers and getting dbagg3 in some semblance of working order somewhere other than on my overworked and decidedly non-publicly-demonstrable laptop.\nThis stuff is so this side of premature, that I'm probably about to cause JohnCompanies to send hit-men out to cancel me, along with my hosting account (have I said that I really appreciate the help so far?).  But I just have to get this out: I'm easily excited by shiny code and gadgets, but it's so much easier to get excited when I can see something in working condition before taking a screwdriver to it.  So... remember when I mentioned all those URLs?  They're working out nicely.\nFirst, check out a simple two-pane view of news items, ala Bloglines:\n\nhttp://feeds.decafbad.com/api/users/demo.xml?xsl=xsl/two-pane/index.xsl&content-type=text/html\n\nTaking this apart, you can see:\n\nA user account: http://feeds.decafbad.com/api/users/demo.xml\nSome XSL: http://feeds.decafbad.com/xsl/two-pane/index.xsl\n... and a specified content type (text/html)\n\nIf your curiosity is piqued by this, view source and pay attention to link URLs.  It's more of the same:  XML produced by a REST API, passed through XSL, delivered as HTML.\nHere, take a look at another view on this demo user's aggregated items:\n\nhttp://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/outliner/index.xsl&content-type=text/html\n\nUnfortunately, this only seems to be working decently with Firefox and Safari.  MSIE seems to be balking at the dynamic stuff, though I've had it working there in a previous incarnation of this code.  So hopefully this will be fixed soon.\nAt any rate, what you should see is a single-pane outliner-style display of feed entries.  This is the style of aggregator UI I've been using for almost 3 years now.  Disclosure triangles open entries up to show summaries and further content.  ‚Äú[seen]‚Äù links hide the entries, while ‚Äú[queue]‚Äù hides an entry while tossing it into a queue for viewing later.\nSpeaking of that, you can see what's in the queue right now:\n\nhttp://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&content-type=text/html&show_queued=1\n\nHere is a display of queued entries, with another stylesheet applied that shows everything in a flat and open blog-like template.  It's not reverse-chronological, but that's not hard to accomplish with a flag or a tweak to an <xsl:sort> tag.  \nSo that's just the start of things.  Remember when I was rambling on about XML storage and query?  A URL like this is one product of that:\n\nhttp://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&content-type=text/html&entry_xpath=//entry/title[contains(text(),'OS%20X')]\n\nThis should show you a flat listing of all entries whose titles contain ‚ÄúOS X‚Äù.  This is far from perfect, but it's very exciting to me-- it's got a lot of promise, stuff that first caught my eye when I saw Jon Udell playing awhile back.\nNow, something that you might not notice until doing a bit more digging, is that all these attributes like ‚Äúseen‚Äù and ‚Äúquery‚Äù are annotations made by the user on entries.  If you take a peek at some of the Javascript under the hood, you might notice some XmlHTTPRequest code going on.  To mark something as ‚Äúseen‚Äù or ‚Äúqueued‚Äù, I POST XML to a URL like this:\n\nhttp://feeds.decafbad.com/api/users/demo/subscriptions/638/entries/60567/notes/\n\nThe upshot of this is that these attributes are not limited to ‚Äúseen‚Äù or ‚Äúqueued‚Äù flags-- in fact, these annotations can (well, in theory) be any pairing of arbitrary XML and a name.  This annotation then gets injected into the entry, when viewed by the user who owns the annotation, like so:\n\nhttp://feeds.decafbad.com/api/users/demo/subscriptions/638/entries/60567.xml\n\nIn fact, you could invent a new annotation called 'tags' and filter for entries with this annotation with a URL like this:\n\nhttp://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&content-type=text/html&entry\\_notes\\_xpath=//dbagg3:note[@name='tags' and contains(text(),'#food#') and contains(text(),'#odd#')]\n\nEventually, what I'd really like to see this start doing is something akin to del.icio.us-style tagging while you're reading.  Then, you can have public queries that pull feeds based on your (and others') tags and spit things back out as feeds again with the proper XSL stylings.\nSo at this point, it's all URLs and barely working HTML, but it's exciting to me at least.  And it's dogfood for me, since I'm using this crud to get my daily (hourly?) fix.  Pretty soon, I'll be diving into wrapping more of a proper usable web app around this, with user management and stuff that works in MSIE.  Until then, maybe someone else will see this and catch a buzz from it.\nStay tuned.",
    "prevPostPath": "2004/09/15/manipulating-aggregate-resources-in-a-rest-api",
    "nextPostPath": "2004/09/12/moving-time-again"
  },
  {
    "comments_archived": true,
    "date": "2004-09-12T23:54:27.000Z",
    "excerpt": "If you're reading this, it means I've thrown the switch on the new server and hopefully haven't broken too much.  (Crossing fingers... now.)",
    "layout": "post",
    "title": "Moving time again",
    "wordpress_id": 545,
    "wordpress_slug": "moving-time-again",
    "wordpress_url": "http://www.decafbad.com/blog/?p=545",
    "year": "2004",
    "month": "09",
    "day": "12",
    "isDir": false,
    "slug": "moving-time-again",
    "postName": "2004-09-12-moving-time-again",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/12/moving-time-again",
    "prevPostPath": "2004/09/13/dbagg3alive",
    "nextPostPath": "2004/09/01/xpath-based-python-dictionaries-on-loan"
  },
  {
    "comments_archived": true,
    "date": "2004-09-01T10:47:41.000Z",
    "excerpt": "But, while I'm in the process of wheel reinvention, how about I borrow Kimbro's idea?  I just threw together a quick class called XPathDict, based on libxml2.",
    "layout": "post",
    "tags": [
      "hacks",
      "xml"
    ],
    "title": "XPath based Python dictionaries, on loan",
    "wordpress_id": 544,
    "wordpress_slug": "xpath-based-python-dictionaries-on-loan",
    "wordpress_url": "http://www.decafbad.com/blog/?p=544",
    "year": "2004",
    "month": "09",
    "day": "01",
    "isDir": false,
    "slug": "xpath-based-python-dictionaries-on-loan",
    "postName": "2004-09-01-xpath-based-python-dictionaries-on-loan",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/01/xpath-based-python-dictionaries-on-loan",
    "prevPostPath": "2004/09/12/moving-time-again",
    "nextPostPath": "2004/08/31/dbagg3-makingprogress"
  },
  {
    "comments_archived": true,
    "date": "2004-08-31T01:37:42.000Z",
    "excerpt": "Work has been insanely busy lately, but I have made some more progress with [`dbagg3`][dbagg3].  The code is all in CVS, so feel free to take a gander-- I don't have a ton of time for a proper write up, but I do want to spew a little bit.",
    "layout": "post",
    "tags": [
      "hacks",
      "syndication",
      "xml"
    ],
    "title": "Making progress on dbagg3",
    "wordpress_id": 543,
    "wordpress_slug": "dbagg3-makingprogress",
    "wordpress_url": "http://www.decafbad.com/blog/?p=543",
    "year": "2004",
    "month": "08",
    "day": "30",
    "isDir": false,
    "slug": "dbagg3-makingprogress",
    "postName": "2004-08-30-dbagg3-makingprogress",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/08/31/dbagg3-makingprogress",
    "summary": "Work has been insanely busy lately, but I have made some more progress with dbagg3.  The code is all in CVS, so feel free to take a gander-- I don't have a ton of time for a proper write up, but I do want to spew a little bit. \nAs per my previous musings on XML in a SQL database, I revamped the database.  Now things are sliced up by feed and entry tables, rows in each containing a few metadata columns and then one big column for an XML dump.  This lets me index on  date and parent feed and such, meanwhile punting on the issue of dicing things like authors or content up further.  And, as extension elements start to show up, this handling is dumb enough to simply store things it doesn't know about without mangling them.  This is a very good thing and one of my big goals for this beast.\nThe other thing that I'm getting excited about is the REST API built atop the Atom store.  Rather than spend time on proper documentation, here's a quick dump from the appropriate module:\nURL: GET /feeds/\nURL: GET /feeds/{id}.xml\nURL: GET /feeds/{id}/{yyyy}/{mm}/{dd}/{hstart}-{hend}.xml\nURL: GET /feeds/{id}/{yyyy}/{mm}/{dd}/{hh}.xml\nURL: GET /feeds/{id}/{yyyy}/{mm}/{dd}.xml\nURL: GET /feeds/{id}/{yyyy}/{mm}.xml\nURL: GET /feeds/{id}/now-{nowoff}.xml\nURL: GET /feeds/{fid}/entries/{eid}.xml\nURL: GET /users/\nURL: GET /users/{uname}.xml\nURL: POST /users/\nURL: DELETE /users/{uname}.xml\nURL: PUT /users/{uname}.xml\nURL: GET /users/{uname}/prefs.xml\nURL: GET /users/{uname}/prefs/\nURL: POST /users/{uname}/prefs/{pname}.{type}\nURL: PUT /users/{uname}/prefs/{pname}.{type}\nURL: GET /users/{uname}/prefs/{pname}.{type}\nURL: DELETE /users/{uname}/prefs/{pname}.{type}\nURL: GET /users/{uname}/subscriptions.{type}\nURL: GET /users/{uname}/subscriptions/\nURL: POST /users/{uname}/subscriptions/\nURL: DELETE /users/{uname}/subscriptions/{id}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}/{dd}/{hstart}-{hend}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}/{dd}/{hh}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}/{dd}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/now-{hours}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/now.xml\nURL: GET /users/{uname}/subscriptions/{yyyy}/{mm}/{dd}/{hstart}-{hend}.xml\nURL: GET /users/{uname}/subscriptions/{yyyy}/{mm}/{dd}/{hh}.xml\nURL: GET /users/{uname}/subscriptions/{yyyy}/{mm}/{dd}.xml\nURL: GET /users/{uname}/subscriptions/{yyyy}/{mm}.xml\nURL: GET /users/{uname}/subscriptions/now-{hours}.xml\nURL: GET /users/{uname}/subscriptions/now.xml\nURL: GET /users/{uname}/subscriptions/{sid}/entries/{eid}.xml\n\nHopefully, the structure of these URL patterns make a little bit of sense.  The too-clever thing about these is that they're both documentation in the module's docstrings, and parsed out to register methods with automagically-generated regexes applied to incoming URL requests.  (I may eventually realize just how stupid an idea this is, but not yet.)  \nThis list is nowhere near complete or final or even all that well thought out yet.  But, it seems to be working out pretty well so far, and it's so easy to tinker with the API to sketch out ideas in working code.  Eating my own dogfood, my first browser window of the day tends to open on this URL:\nhttp://localhost/~deusx/dbagg3.5/api/users/default/subscriptions/\nnow-12.xml?xsl=xsl/full.xsl&#38;content-type=text/html\n\nThis grabs the last 12 hours' worth of items from default's subscriptions, passing them through the XSL at xsl/full.xsl on the way to my browser with a content type of text/html.  This tends to produce about 1000-1500 entries in about 15 seconds on my PowerBook, which is better than I'd expected.  \nPretty soon, I'll be implementing the ability to post metadata onto feed entries under subscriptions.  Then, I can mark items as seen, attach categories, tags, and notes.  From there, I can exclude seen items from queries, produce new aggregate feeds based on my tagging or notes, among a few other ideas I've got stewing.\nA little more work, and I think I'll be able to throw together the beginnings of a Bloglines-style three-pane browser interface, as well as improving the functionality of my own outliner-style display with XmlHTTPRequest-based calls to the API to enable refresh-free interaction.  From there, I have some ideas for desktop apps and maybe even some tinkering in Flash.  (Wow... has it really been over a year since I was writing about Flash & REST?)\nAnd then, I want to implement the Atom API and allow users to create feeds to which they can post their own items and share read-only with others (or share writing with a group).  From there, this thing can turn into a read/write Atom storage tank, serving both as an aggregator and a blog publishing engine, given the appropriate XSL work.\nLots of ideas stewing.  Now I just have to get the time and possibly a new web server, since I'd like to eventually open up an installation of this to fellow tinkerers, but this poor little box can barely take what it's tasked with at present...\nOh yeah, and one other thing:  I've been thinking about names better than dbagg3.  The one that's sticking around in my head so far is feedReactor.  What do you think?",
    "prevPostPath": "2004/09/01/xpath-based-python-dictionaries-on-loan",
    "nextPostPath": "2004/08/30/crappyvideogames"
  },
  {
    "comments_archived": true,
    "date": "2004-08-30T02:52:48.000Z",
    "excerpt": "It all makes me almost wish for a kink in Moore's Law that stalls the progress of dazzling hardware and forces developers back to being clever with their resources and game ideas.",
    "layout": "post",
    "tags": [
      "gaming"
    ],
    "title": "Crappy video games to get more expensive to produce",
    "wordpress_id": 542,
    "wordpress_slug": "crappyvideogames",
    "wordpress_url": "http://www.decafbad.com/blog/?p=542",
    "year": "2004",
    "month": "08",
    "day": "29",
    "isDir": false,
    "slug": "crappyvideogames",
    "postName": "2004-08-29-crappyvideogames",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/08/30/crappyvideogames",
    "summary": "According to calculations, it may cost up to 200% more to develop games for the PS3 or Xbox 2 than it does for current systems.\n\nSource: EA expresses ‚Äòconcern‚Äô about next-gen technology\n\nHere's some blogging for you.  This article brings two thoughts to mind for me...\nFirst is this:  Of course, if you're striving for some semblance of realism in games, the costs will likely approach and exceed the cost to produce movies.  It'll approach the cost because, eventually, you'll need either movie-grade animators or real actors.  And then it'll exceed the cost, because who wants a game that's as linear as a 2-hour movie?  If you want any replay value out of the thing, you're going to have to produce the equivalent of a 4-hour movie at least, if not a 20- to 40-hour movie.  And then, you're going to have to be satisfied that many players will miss most of it.  Once things reach this point, I think in some sense video games will have arrived as a \"successor\" to movies, as movies were a \"successor\" to radio plays.\nThis brings me to my second thought:  Right now, I'm listening to a streaming radio station that's playing old sci-fi and drama radio plays, like X Minus One and The Shadow.  These shows are great, and I'm thinking of buying a few box sets of them.  These old radio shows get quite a bit of mileage out of their less technologically advanced medium.  In contrast to this, my consumption of contemporary and popular television, movies, and music has been dropping off from year to year as I get more tired of supremely well-produced yet worthless content.\nMusic gets sold on anything but a good tune, movies sold on special effects over plot, and video games head toward technological supremacy over a fun hook or even an engaging story line.  But, I don't want anything to do with any of these.\nA few days ago, a friend of mine remarked that many \"retro\" video games were just as horrible as modern video games, but I have to disagree a bit.  There were a lot of horrible games.  But, for games to be successful back when the dazzle factor of the hardware was low, you needed the fun trick or clever twist that addicted players.  The constraints called for ingenuity.  Sometimes this meant pushing the hardware, and sometimes this meant coming up with a brilliant yet simple-to-implement idea.  (Tetris, I'm looking at you.)\nAs the hardware platforms progress, we'll see more and more absolutely dazzling demos of the hardware sold as games that completely fail at being fun.  But they'll have insane budgets and probably sell very well just because people want to see the pretty sparklies and foobar shaders.  The increased capabilities will offer more expressive ability to interactive storytellers, but I bet it will just give even more excuse for game makers to be distracted from that and keep pumping out stories that suck carried by game play that reeks.\nIt all makes me almost wish for a kink in Moore's Law that stalls the progress of dazzling hardware and forces developers back to being clever with their resources and game ideas.  Maybe we'll see more and more of an indie games community rise, producing genuinely fun and amusingly ingenious games.  (Gish, I'm looking at you.)\nMeanwhile, my girlfriend and I will be playing massive amounts of Magical Drop III.",
    "prevPostPath": "2004/08/31/dbagg3-makingprogress",
    "nextPostPath": "2004/08/29/blogging-without-thought"
  },
  {
    "comments_archived": true,
    "date": "2004-08-29T23:14:04.000Z",
    "excerpt": "One should never put blogging on a pedestal, really.",
    "layout": "post",
    "title": "\"One should never think before one posts.\"",
    "wordpress_id": 541,
    "wordpress_slug": "blogging-without-thought",
    "wordpress_url": "http://www.decafbad.com/blog/?p=541",
    "year": "2004",
    "month": "08",
    "day": "29",
    "isDir": false,
    "slug": "blogging-without-thought",
    "postName": "2004-08-29-blogging-without-thought",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/08/29/blogging-without-thought",
    "summary": "One should never think before one posts. That's been my big blunder. And one should never ever ever rewrite, fine-tune, or God forbid edit the post, either. As a blogger, you should form a picture in your mind of a man drinking a cup of coffee. Then imagine that he suddenly feels a dead fly on his tongue and here you'll see your role model. Let your words spew forth with speed and velocity, out of reflex and not reflection. Let them fly without any possibility of ever taking them back. And when challenged, insist that the challenger is lucky that you don't sue somebody, and if he or she thinks you're going to help clean that up, they're crazy.\n\nSource: yellowtext: Oh...Hi! I didn't see you standing there! \n\nAmen, blog brother (with thanks to Quirk Blog for the pointer).  I wonder if I need to go on a Month of Blogging, complete with t-shirts, spewing here daily like a sort of NaBlogWriMo?  \nOne should never put blogging on a pedestal, really.  I mean, while I do aspire to doing some real writing (when I'm not so busy with work, as I have been of late), my blog-a-day writing shouldn't be all that painful.  It looks like my server's on its last legs and the act of posting itself takes forever, so belaboring the actual content so much just puts the last straw on the shaven yak's back.\nSo, here goes... posty posty post, as they say on LiveJournal.  (Well, I seem to remember someone saying that anyway.)",
    "prevPostPath": "2004/08/30/crappyvideogames",
    "nextPostPath": "2004/08/24/more-cooks-in-the-feed-stew-kitchen"
  },
  {
    "comments_archived": true,
    "date": "2004-08-24T03:14:40.000Z",
    "excerpt": "I tell ya, this is an idea that's catching.  Feeds go into a searchable stew, come back out as new synthetic feeds.  What comes out looks like what goes in, and there's a well-defined spec behind it.  Sprinkle in the elegance of loosely coupled UNIX pipelines and filters, REST interfaces, and XML tech like XSLT for munging, and you've got the makings of the next generation of syndication and XML feeds.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "More Cooks in the Feed Stew Kitchen",
    "wordpress_id": 540,
    "wordpress_slug": "more-cooks-in-the-feed-stew-kitchen",
    "wordpress_url": "http://www.decafbad.com/blog/?p=540",
    "year": "2004",
    "month": "08",
    "day": "23",
    "isDir": false,
    "slug": "more-cooks-in-the-feed-stew-kitchen",
    "postName": "2004-08-23-more-cooks-in-the-feed-stew-kitchen",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/08/24/more-cooks-in-the-feed-stew-kitchen",
    "prevPostPath": "2004/08/29/blogging-without-thought",
    "nextPostPath": "2004/08/23/slicing-and-dicing-to-make-atom-soup-in-dbagg3"
  },
  {
    "comments_archived": true,
    "date": "2004-08-23T22:52:06.000Z",
    "excerpt": "I've been putting more work into dbagg3, but I'm getting hung up on the database.  Well, actually I'm getting hung up on the subject of XML storage, query, and retrieval in general-- but at present, I'm trying to cram all this data into MySQL and SQLite databases.  But, my tendencies as an abstraction astronaut and my lack of database savvy are tying me (and my data) in knots.  I kept meaning to write a bit Atom (and XML in general) with regard to database storage and query, so maybe now's the time.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "Slicing and Dicing to Make Atom Soup in dbagg3",
    "wordpress_id": 539,
    "wordpress_slug": "slicing-and-dicing-to-make-atom-soup-in-dbagg3",
    "wordpress_url": "http://www.decafbad.com/blog/?p=539",
    "year": "2004",
    "month": "08",
    "day": "23",
    "isDir": false,
    "slug": "slicing-and-dicing-to-make-atom-soup-in-dbagg3",
    "postName": "2004-08-23-slicing-and-dicing-to-make-atom-soup-in-dbagg3",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/08/23/slicing-and-dicing-to-make-atom-soup-in-dbagg3",
    "prevPostPath": "2004/08/24/more-cooks-in-the-feed-stew-kitchen",
    "nextPostPath": "2004/08/23/mysql-and-xml-output"
  },
  {
    "comments_archived": true,
    "date": "2004-08-23T05:09:51.000Z",
    "excerpt": "So...  How many of you have ever used mysql -X?",
    "layout": "post",
    "tags": [
      "hacks",
      "xml"
    ],
    "title": "mysql and XML output",
    "wordpress_id": 538,
    "wordpress_slug": "mysql-and-xml-output",
    "wordpress_url": "http://www.decafbad.com/blog/?p=538",
    "year": "2004",
    "month": "08",
    "day": "23",
    "isDir": false,
    "slug": "mysql-and-xml-output",
    "postName": "2004-08-23-mysql-and-xml-output",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/08/23/mysql-and-xml-output",
    "prevPostPath": "2004/08/23/slicing-and-dicing-to-make-atom-soup-in-dbagg3",
    "nextPostPath": "2004/08/05/dbagg3cvs"
  },
  {
    "comments_archived": true,
    "date": "2004-08-05T23:53:34.000Z",
    "excerpt": "I've just dumped what code I have into my CVS repository.  So, go ahead and poke fun at it.",
    "layout": "post",
    "tags": [
      "syndication",
      "python"
    ],
    "title": "dbagg3 code in CVS",
    "wordpress_id": 537,
    "wordpress_slug": "dbagg3cvs",
    "wordpress_url": "http://www.decafbad.com/blog/?p=537",
    "year": "2004",
    "month": "08",
    "day": "05",
    "isDir": false,
    "slug": "dbagg3cvs",
    "postName": "2004-08-05-dbagg3cvs",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/08/05/dbagg3cvs",
    "summary": "I've just dumped what code I have into my CVS repository.  So, go ahead and poke fun at it:\n\nhttp://www.decafbad.com/cvs/dbagg3/\n\nOr, fetch it from CVS:\n$ cvs -d:pserver:anoncvs@www.decafbad.com:/cvsroot login\n(Logging in to anoncvs@www.decafbad.com)\nCVS password: anoncvs\n$ cvs -d:pserver:anoncvs@www.decafbad.com:/cvsroot co dbagg3",
    "prevPostPath": "2004/08/23/mysql-and-xml-output",
    "nextPostPath": "2004/08/05/introducing-dbagg3-an-atom-powered-clientserver-aggregator"
  },
  {
    "comments_archived": true,
    "date": "2004-08-05T13:04:56.000Z",
    "excerpt": "It's a new feed aggregator, my third attempt at such.  Everything is clunky and command-line driven at present--but I've got further plans, like a REST API for feed queries and manipulation of various things such as feed subscriptions and the read/unread state of items.  Pair this with an XSLT-driven browser UI, and the possibility of other clients (not the least of include other Atom-consuming aggregators).\n\nThe goal is to make a Client/Server Aggregator.",
    "layout": "post",
    "tags": [
      "syndication",
      "python"
    ],
    "title": "Introducing dbagg3, an Atom-powered client/server aggregator",
    "wordpress_id": 536,
    "wordpress_slug": "introducing-dbagg3-an-atom-powered-clientserver-aggregator",
    "wordpress_url": "http://www.decafbad.com/blog/?p=536",
    "year": "2004",
    "month": "08",
    "day": "05",
    "isDir": false,
    "slug": "introducing-dbagg3-an-atom-powered-clientserver-aggregator",
    "postName": "2004-08-05-introducing-dbagg3-an-atom-powered-clientserver-aggregator",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/08/05/introducing-dbagg3-an-atom-powered-clientserver-aggregator",
    "thumbnail": "http://www.decafbad.com/2004/08/dbagg3-demo/dbagg3-phase1.jpg",
    "prevPostPath": "2004/08/05/dbagg3cvs",
    "nextPostPath": "2004/07/30/kibo-kibo-kibo"
  },
  {
    "comments_archived": true,
    "date": "2004-07-30T03:22:32.000Z",
    "layout": "post",
    "title": "Kibo Kibo Kibo",
    "wordpress_id": 535,
    "wordpress_slug": "kibo-kibo-kibo",
    "wordpress_url": "http://www.decafbad.com/blog/?p=535",
    "year": "2004",
    "month": "07",
    "day": "29",
    "isDir": false,
    "slug": "kibo-kibo-kibo",
    "postName": "2004-07-29-kibo-kibo-kibo",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/07/30/kibo-kibo-kibo",
    "prevPostPath": "2004/08/05/introducing-dbagg3-an-atom-powered-clientserver-aggregator",
    "nextPostPath": "2004/07/22/use-control-click-for-button3-in-apples-x11"
  },
  {
    "comments_archived": true,
    "date": "2004-07-22T05:03:27.000Z",
    "excerpt": "Something that has annoyed me for awhile is that Cmd-Click is what my X11 on OS X has been using by default to simulate a right-click.",
    "layout": "post",
    "title": "Use Control-Click for button3 in Apple's X11",
    "wordpress_id": 534,
    "wordpress_slug": "use-control-click-for-button3-in-apples-x11",
    "wordpress_url": "http://www.decafbad.com/blog/?p=534",
    "year": "2004",
    "month": "07",
    "day": "22",
    "isDir": false,
    "slug": "use-control-click-for-button3-in-apples-x11",
    "postName": "2004-07-22-use-control-click-for-button3-in-apples-x11",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/07/22/use-control-click-for-button3-in-apples-x11",
    "prevPostPath": "2004/07/30/kibo-kibo-kibo",
    "nextPostPath": "2004/07/15/dork-funk"
  },
  {
    "comments_archived": true,
    "date": "2004-07-15T02:32:55.000Z",
    "excerpt": "Mostly I think I'm just in a funk.",
    "layout": "post",
    "title": "Dork Funk",
    "wordpress_id": 533,
    "wordpress_slug": "dork-funk",
    "wordpress_url": "http://www.decafbad.com/blog/?p=533",
    "year": "2004",
    "month": "07",
    "day": "14",
    "isDir": false,
    "slug": "dork-funk",
    "postName": "2004-07-14-dork-funk",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/07/15/dork-funk",
    "prevPostPath": "2004/07/22/use-control-click-for-button3-in-apples-x11",
    "nextPostPath": "2004/07/06/wishofthemonthclub3"
  },
  {
    "comments_archived": true,
    "date": "2004-07-06T21:05:45.000Z",
    "excerpt": "This is the exciting conclusion of the Wish-of-the-Month Club.  Before continuing on, you may want to catch up with parts one and two.",
    "layout": "post",
    "tags": [
      "hacks",
      "xml"
    ],
    "title": "Wish-of-the-Month Club, Part 3 of 3",
    "wordpress_id": 532,
    "wordpress_slug": "wishofthemonthclub3",
    "wordpress_url": "http://www.decafbad.com/blog/?p=532",
    "year": "2004",
    "month": "07",
    "day": "06",
    "isDir": false,
    "slug": "wishofthemonthclub3",
    "postName": "2004-07-06-wishofthemonthclub3",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/07/06/wishofthemonthclub3",
    "thumbnail": "http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.jpg",
    "summary": "This is the exciting conclusion of the Wish-of-the-Month Club.  Before continuing on, you may want to catch up with parts one and two.\nPresenting the Results\nSome ready-made files are available for this section:\n\nwishes-ex5.xsl: The fifth iteration of the stylesheet in development.\nwishes.html: Sample output in HTML\n\nWe've finally gotten together all the bits of information we need--wishlists have been queried; random items have been selected; and a shopping cart has been prepared.  Now we just have to present the selections and a link to check out with the shopping cart.\nFirst, locate the following line toward the end of the stylesheet as we left it in the last section:\n    <xsl:copy-of select=\"$shopping_cart\" />\n\nDelete this, and let's replace it by building some HTML:\n    <xsl:variable name=\"shopping_cart_purchase_url\" \n                  select=\"exsl:node-set($shopping_cart)//PurchaseUrl\" />\n    \n    <html xmlns=\"http://www.w3.org/1999/xhtml\">\n      <head><title>Wishlist Shopping Cart</title>\\</head>\n      <body>\n        <p class=\"title\">\n          Here are your wishlist items\n          <a href=\"{$shopping_cart_purchase_url}\">\n            <img src=\"http://g-images.amazon.com/images/G/01/detail/shoppingcart-header-02.gif\" />\n          </a> \n          items:\n        </p>\n\nWe're using the exsl:note-set function again to access the contents of $shopping_cart with an XPath expression.  We pluck out the value of the PurchaseUrl in the shopping cart and place it in the variable shopping_cart_purchase_url.  Then, after a bit of HTML preamble, we borrow a shopping cart icon from Amazon itself to construct a link to which we can browse later to purchase the selected items.  This HTML is very simple so far; it's likely too simple, so eventually you may like to toss some CSS in here to improve the looks of things.  But, I'll leave that as an exercise for the reader.  \nNext, let's build a display of the items selected by iterating first through the wishlists:\n        <xsl:for-each select=\"exsl:node-set($random_products)/wishes:wishitem\">\n          <div class=\"Detail\">\n\n            <p class=\"wishlistLabel\">\n              <xsl:value-of select=\"wishes:wishlist/@label\" />\n            </p>\n\nThis begins a block for each wishlist, starting off with a paragraph containing the label we gave each wishlist.  Next, let's include a few details about the product chosen.  Again, all of the bits of data included for each product are described in the AWS documentation in the Overview under Amazon Web Services Data Model.  Checking that out, we can see that the data includes a URL to images of several sizes representing the product.  Let's include the medium-sized image as a link to the product's detail page:\n            <p class=\"Product\">\n              <a href=\"{Details/@url}\">\n                <img src=\"{Details/ImageUrlMedium}\" />\n              </a>\n              <br />\n\nWe can also include the product's name as a link:\n              <span class=\"ProductName\">\n                <a href=\"{Details/@url}\">\n                  <xsl:value-of select=\"Details/ProductName\" />\n                </a>\n              </span>\n              <br />\n\nAnd, it would be nice to provide a listing of people involved in creating the product (ie. the artists and/or authors):\n          <xsl:for-each select=\"./Details/Artists/Artist | \n                                ./Details/Authors/Author\">\n            <span class=\"Author\">by <xsl:value-of select=\".\" /></span><br />\n          </xsl:for-each>\n\nNote that here, the XPath selecting the data is just a bit more involved, since this information can be found in both Artist and Author elements.  In another case, we might care to make a distinction, but it really isn't all that important for this project.  The data model also provides an indication of from which catalog this product came, as well as its date of release.  Let's include that for good measure:\n          (\n          <xsl:value-of select=\"Details/Catalog\" /> -\n          <span class=\"ReleaseDate\">\n            <xsl:value-of select=\"Details/ReleaseDate\" />\n          </span>\n          )\n          <br />\n        </p>\n\nAnother thing that would be nice to know is how much this thing costs--we've got this information provided in the XML data as well, so let's include it:\n        <p>\n          <span class=\"PriceLabel\">List Price:</span> \n          <span class=\"ListPrice\">\n            <xsl:value-of select=\"Details/ListPrice\" />\n          </span>\n          <br />\n          \n          <span class=\"PriceLabel\">Our Price:</span>\n          <span class=\"OurPrice\">\n            <xsl:value-of select=\"Details/OurPrice\" />\n          </span>\n          <br />\n\n          <span class=\"PriceLabel\">Used Price:</span> \n          <span class=\"UsedPrice\">\n            <xsl:value-of select=\"Details/UsedPrice\" />\n          </span>\n          <br />\n        </p>\n\nSomething to note about these prices, too, is that although the used price is listed, the shopping cart will contain new items from Amazon's shelves.  You might want to compare these prices though, and make a change to the shopping cart when you get there, if a used item is acceptable.  (Another good reason for manual intervention in our Wish-of-the-Month club.)\nOh yeah, and we should include one other bit of information:\n        <p>(<xsl:value-of select=\"Details/Availability\" />)</p>\n\nThis tells us whether or not this item can actually be bought, at present.  Although we used this data earlier to try to filter out unavailable items, we should still display this information just in case we missed something.\nFinally, let's clean up and finish the HTML:\n      </div>\n    </xsl:for-each>\n    \n  </body>\n</html>\n\nRunning this stylesheet (wishes-ex5.xsl) should give you a page that looks something like this in a browser:\n\nScheduling Monthly Emails\nSome ready-made files are available for this section:\n\nwishes-ex6.xsl: The sixth (and final) iteration of the stylesheet in development.\n\nThat HTML we're producing is fine, but what we really want to do is get it delivered to us.  We could set up a scheduled run that would periodically generate a page for us to visit, but the whole point of this is laziness.  How about firing off an email with this content?  There are two things to help us with this: RFC 1521 shows us how to construct email messages with a variety of content types; and sendmail will let us send these messages out.  And then, with the help of cron, we can fire up this process every month.\nAlong with producing XML, XSLT can also construct plain text output--which is just what we need to create MIME email messages.  RFC 1521 doesn't make for the most thrilling reading, but there are a few articles to be found that summarize things (such as this article and this article).   To make a long story short, a basic shell for an email message using MIME to include an HTML part and a plain text part looks something like this:\nTo: someone@example.org\nSubject: Some useful email subject\nMIME-Version: 1.0\nContent-Type: multipart/alternative; boundary=\"theBoundaryString\"\n\n--theBoundaryString\nContent-Type: text/plain\n\nSome plain text representation goes here...\n\n--theBoundaryString\nContent-Type: text/html\nContent-Transfer-Encoding: 7bit\nContent-Disposition: inline\nContent-Base: \"http://www.decafbad.com/\"\n\n<html xmlns=\"http://www.w3.org/1999/xhtml\">\n    <p>Some HTML representation goes here...</p>\n</html>\n\n--theBoundaryString--\n\nI've snuck in the idea of providing both an HTML version (which we've already done) and a new plain text version.  Depending on your email program and your preferences, one type might be more useful than the other.  In any case, it's not all that hard to offer both here.  To start sending these email messages, though, we'll need an email address.  So, add that as an element in wishes.xml:\n<wishes xmlns=\"http://www.decafbad.com/2004/05/wishes\">\n  <email>deus_x@pobox.com</email>\n  <maxprice>15.00</maxprice>\n  <associate>0xdecafbad-20</associate>\n  <devtoken>D8HVH869XA0NP</devtoken>\n  <wishlists>\n    <wishlist label=\"Me\">1QWYI6P2JF3Q5</wishlist>\n    <wishlist label=\"The Girl\">35OIOYWQ9XQAE</wishlist>\n  </wishlists>\n</wishes>\n\nLet's extract this data into a global variable near the start of the stylesheet:\n  <xsl:variable name=\"email_to\"  select=\"/wishes:wishes/wishes:email\" />\n\nStart editing the final template of the stylesheet, inserting before the start of HTML content:\n    <!-- Eat all the line breaks generated so far -->\n    <xsl:text>To: </xsl:text><xsl:value-of select=\"$email_to\" />   \nSubject: 0xDECAFBAD's Amazon Wish-of-the-Month Club\nMIME-Version: 1.0\nContent-Type: multipart/alternative; boundary=\"theBoundaryString\"\n\nThis is the header for the email.  Up until now, we've been generating XML with the stylesheet and haven't cared very much about any extra whitespace or line breaks which might sneak into the output.  However, in an email header, whitespace is important since a blank line is what's used to separate the headers from the body of the email message.  So, any stray blank lines will cause what we might have meant to be headers to be interpreted as part of the message instead.  Producing the first header in the email with xsl:text tags causes the XSL processor to throw away any leading whitespace which would have appeared before the first header.\nOther than this little twist, the email header looks pretty much like the shell.  We fill in the To address from the global variable $email_to and define a Subject line.  The MIME-Version and Content-Type headers are what enable us to include both text and HTML versions in one email.\nNow we can start into one of the parts:\n--theBoundaryString\nContent-Type: text/plain\n\nThis begins the plain text section of the email, using the boundary string as defined in the headers to delinieate the section's beginning.  The section can also have its own set of headers, of which we use only one: Content-Type.  Moving along, let's work on the text content itself.\nHere are your wishlist items:\n\n<xsl:value-of select=\"$shopping_cart_purchase_url\" /><xsl:text>\n</xsl:text>\n\nNo shopping cart image here, but this includes the human-viewable URL which leads to a shopping cart on Amazon.com.  The usage of xsl:text here forces a line break where there otherwise wouldn't have been one with the usage of xsl:value-of.  Now, let's iterate through each of the wishlists and list out the product details:\n<xsl:for-each select=\"exsl:node-set($random_products)/wishes:wishitem\">\n---------------------------------------------------------------------------\n<xsl:value-of select=\"wishes:wishlist/@label\" \n       disable-output-escaping=\"yes\" />\n---------------------------------------------------------------------------\n\n<xsl:value-of select=\"Details/ProductName\" \n       disable-output-escaping=\"yes\" />\n\n<xsl:for-each select=\"./Details/Artists/Artist | \n                      ./Details/Authors/Author\">\nby <xsl:value-of select=\".\"  \n   disable-output-escaping=\"yes\"/>\n</xsl:for-each>\n\nCatalog:      <xsl:value-of select=\"Details/Catalog\" \n   disable-output-escaping=\"yes\" />\nReleased:     <xsl:value-of select=\"Details/ReleaseDate\" \n   disable-output-escaping=\"yes\" />\n\nList Price:   <xsl:value-of select=\"Details/ListPrice\"  \n     disable-output-escaping=\"yes\"/> \nOur  Price:   <xsl:value-of select=\"Details/UsedPrice\"  \n     disable-output-escaping=\"yes\"/> \nUsed Price:   <xsl:value-of select=\"Details/OurPrice\"  \n     disable-output-escaping=\"yes\"/> \n        \nAvailability: <xsl:value-of select=\"Details/Availability\"  \n       disable-output-escaping=\"yes\"/>\n<xsl:text>\n\n</xsl:text>\n<xsl:value-of select=\"Details/@url\"  \n       disable-output-escaping=\"yes\"/>\n<xsl:text>\n</xsl:text>\n\n</xsl:for-each>\n\nMost everything in this stretch should look very similar to the HTML version we just finished.  The biggest difference is that every bit of information pulled in using xsl:value-of is done using the disable-output-escaping option.  When this is yes, things like ampersands are no longer escaped for valid XML output.  Since this bit of the email is plain text, we don't want to see &amp; in album titles, so this will cause ampersands to appear unmolested.\nThat's the plain text version finished.  Now let's create the HTML version:\n--theBoundaryString\nContent-Type: text/html\nContent-Transfer-Encoding: 7bit\nContent-Disposition: inline\nContent-Base: \"http://www.decafbad.com/2004/05/wishes\"\n\nThe boundary string appears again, signifying the end of the plain text section and the start of the HTML section.  Headers appear here which specify that what follows is HTML; that it's encoded in 7-bit characters; that it should be included in the message display itself (rather than presented as an attachment to be saved); and that all relative URLs which might appear in the HTML should be treated as having a base URL as specified.  This last part allows HTML in email to refer to images and other pages on another site without making all the URLs absolute.\nWe don't need to make any modifications to the HTML as we built it in the last iteration of the stylesheet, so we can just include it unchanged:\n<html xmlns=\"http://www.w3.org/1999/xhtml\">\n...\n</html>\n\n--theBoundaryString--\n\nThis final appearance of the boundary string is bracketed on both sides by dashes, which indicates the end of the final section of the document.  We should be ready to try this in combination with sendmail in a shell:\n$ xsltproc wishes-ex6.xsl wishes.xml | sendmail -it\n\nIf everything has worked correctly, there should be an email arriving in your mailbox sometime soon.  (Or in my inbox, if you followed the directions literally and didn't supply your own email address.)  The options supplied to sendmail are fairly basic: \n\n-i causes lines consisting solely of . not to be treated as an end-of-input signal.\n-t causes sendmail to look in the message headers (ie. To:) for a list of recipients.\n\nIf you don't happen to have have sendmail available, you might want to look into what local mail programs you have available which can accept the output from the stylesheet.\nOnce you have this working, the final task is to schedule its monthly execution with your local cron installation.  If you haven't played with cron before, there are many resources and tutorials available (here's one and here's another).  You should add something like the following to your user account's crontab:\n0 0 * 1 *  (cd /your/working/path; xsltproc wishes.xsl wishes.xml | sendmail -it)\n\nThe \"0 0 * 1 *\" indicates to cron that this set of commands should be run at midnight on the first of every months.  Note also that /your/working/path should be replaced by the path to where you've been working during this project.  And finally, I've renamed the final iteration of the stylesheet file to simply wishes.xsl.\nConclusion\nSo that's it--we have an XSL stylesheet which queries Amazon Web Services for products contained in multiple wishlists; selects a random item from each; prepares a shopping cart containing those items; and finally generates an email message containing both plain text and HTML presentations of the shopping cart and selected items.\nThough this implementation serves the purpose I wrote about at the start of this article, there are definitely many areas where this can be improved upon or expanded:\n\nMany people think Amazon is an evil company for their use of patents.  I can't say that I'm entirely happy with them for this myself, but their AWS offering is just too nice to resist tinkering with.  It might be interesting to investigate other retailers' wishlist offerings, where they exist, and to see how this idea might be made to work with other (or even multiple) retailers.  Even better, come up with your own wishlist system, and a cross-retailer shopping cart.\n\nI chose XSLT as the implementation technology because I thought it would be more natural to deal with Amazon's XML this way.  There are, admittedly, a few awkward parts in the resulting stylesheet however.  Sometimes it's good to see a project like this through, just to get a sense for where things do go awkward with a technology or my understanding of it.  It could be interesting to transliterate this into a scripting language like Python or Perl, perhaps using the libxml bindings to do so.\n\nThe error and failure handling in this implementation are all but non-existent.  Should anything unexpected happen while dealing with Amazon Web Services, the results aren't likely to be very pretty.  You may want to consider improving in this area.  One instance I identified was to report when the sanity limit was hit in looping through wishlist pages, versus an actual end of pages.\n\nIf you play around with making more wishlist queries using the techniques here, you might want to consider caching the full set of data pulled in by the multiple-page calls to AWS, in order to prevent hammering Amazon's servers with repeated requests for the same data, likely unchanged.\n\nI still don't know why exsl:random doesn't work for me.  Although I thought using a web service for random numbers was intereting, it would be very nice if I didn't have to use it.\n\nThe HTML presentation could certainly use some good CSS to make it more attractive.\n\n\nFeel free to send me any suggestions, criticisms, or complaints related to this article!",
    "prevPostPath": "2004/07/15/dork-funk",
    "nextPostPath": "2004/06/28/radioiorock-scraper"
  },
  {
    "comments_archived": true,
    "date": "2004-06-28T23:17:36.000Z",
    "excerpt": "Lately, my iTunes has been playing radioio Rock almost exclusively lately, but one thing that peeves me is that I don't seem to see the current song while the stream's playing.  Instead, the radioio site offers a pop-up window that displays the last few songs in the playlist.  However, I'm usually somewhere off in another window or a shell and don't really feel like popping over to a browser and navigating to the playlist just to see what this song is.  So, I wrote myself a little mini-scraper script...",
    "layout": "post",
    "tags": [
      "hacks"
    ],
    "title": "A mini-scraper for the playlist at radioio Rock",
    "wordpress_id": 531,
    "wordpress_slug": "radioiorock-scraper",
    "wordpress_url": "http://www.decafbad.com/blog/?p=531",
    "year": "2004",
    "month": "06",
    "day": "28",
    "isDir": false,
    "slug": "radioiorock-scraper",
    "postName": "2004-06-28-radioiorock-scraper",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/06/28/radioiorock-scraper",
    "summary": "Lately, my iTunes has been playing radioio Rock almost exclusively lately, but one thing that peeves me is that I don't seem to see the current song while the stream's playing.  Instead, the radioio site offers a pop-up window that displays the last few songs in the playlist.  However, I'm usually somewhere off in another window or a shell and don't really feel like popping over to a browser and navigating to the playlist just to see what this song is.\nSo, I wrote myself a little mini-scraper script:\n#!/bin/sh\n\ncurl -s 'http://player.radioio.com/player.php?b=614&#38;stream=radioioRock' | \\\n    tidy -asxml --wrap 300 -q -f /dev/null | \\\n    xml sel -t -m \"//*[@class='leadrock']\" -v '.' -n \\\n        -o '    [http://www.radioio.com' -v '../@href' -o ']' -n \n\nThe output looks something like this:\n[06/29 11:01:08] deusx@Caffeina2:~ % radioio\n\nVast - I Need To Say Goodbye\n    [http://www.radioio.com...]\nCure - The End Of The World\n    [http://www.radioio.com...]\nSeachange - Avs Co 10\n    [http://www.radioio.com...]\nPixies - Bam Thwok\n    [http://www.radioio.com...]\nDeath Cab For Cutie - The New Year\n    [http://www.radioio.com...]\nLovethugs - Drawing The Curtains\n    [http://www.radioio.com...]\n\nOh yeah, and to run this script, you will need these tools:\n\ncurl\nHTML Tidy \nXMLStarlet\n\nPersonally, I like the included URLs (which I edited here for length) since they launch a search for CDs by the artist.  However, you can cut the output down to just the artist/title by removing the final line of the script and the backslash at the end of the line before.\nIf you like a different radioio station, say radioio Eclectic, you can change stream=radioioRock to stream=radioioEclectic in the URL above and change class='leadrock' to class='leadeclectic'.  I could have parameterized these, but I'm lazy, and that was the whole point!\nShareAndEnjoy!",
    "prevPostPath": "2004/07/06/wishofthemonthclub3",
    "nextPostPath": "2004/06/28/wishofthemonthclub2"
  },
  {
    "comments_archived": true,
    "date": "2004-06-28T01:44:51.000Z",
    "excerpt": "Here's the next installment of the Wish-of-the-Month Club.  You can revisit the first part, too, if you've missed it.  I'd meant to post it within a week of the first part, so apologies all around to anyone who has been tapping a foot waiting for it.  Enjoy!",
    "layout": "post",
    "tags": [
      "hacks",
      "xml"
    ],
    "title": "Wish-of-the-Month Club, Part 2 of 3",
    "wordpress_id": 530,
    "wordpress_slug": "wishofthemonthclub2",
    "wordpress_url": "http://www.decafbad.com/blog/?p=530",
    "year": "2004",
    "month": "06",
    "day": "27",
    "isDir": false,
    "slug": "wishofthemonthclub2",
    "postName": "2004-06-27-wishofthemonthclub2",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/06/28/wishofthemonthclub2",
    "summary": "Here's the next installment of the Wish-of-the-Month Club.  You can revisit the first part, too, if you've missed it.  I'd meant to post it within a week of the first part, so apologies all around to anyone who has been tapping a foot waiting for it.  Enjoy!\nPaging Through Wishes\nSome ready-made files are available for this section:\n\nwishes-ex2.xsl: The second iteration of the stylesheet in development.\n\nNow we've got a way to make queries against Amazon Web Services, not entirely unlike what you might be used to if you tinker with MySQL databases on a regular basis.  At this point, though, we still have a bit of refining to make to this query.  If you take a look at the data produced by the query in its current state, and compare that to what you see on wishlists in your browser, you should notice some things missing.\nIf you look at my wishlist, you'll notice that items span several pages when visited by browser.  As it turns out, AWS queries work in a similar fashion--each query returns only a limited number of items (about 10), and an additional parameter supplied to further queries is required to step through further pages of results.  So, using what we've built so far will only get us to the first page of wishlist items; to get all of the items, we'll need a way to step through all of the pages.\nIn playing with this, I experienced a bit of hairpulling frustration:  The AWS documentation, under \"Generating Additional Product Results\", claims that XML returned by the service will supply a count of the total pages available for a given query.  And although I see this element present in other types of searches, the TotalPages element is absent when querying on wishlists.  This may be a bug, or it may be an undocumented change in the service--either way, it was a surprise and leaves me with no official way to know how many pages I need to ask for in order to have a complete set of data.  \nWith some further tinkering, though, I figured out a workaround: If a query is made for a page number beyond the final page, the XML returned will be a duplicate of the final page.  Once I see a duplicate item appear, I know it's time to stop paging through results.  This is completely undocumented behavior, and could break at any time (ie. if Amazon decided to start issuing an error for a page index out of bounds), but it'll work for now.\nThis calls for reworking the processWishlist template.  For a given wishlist, it will need to iterate through a sequence of page numbers, requesting XML from AWS for each, stopping when the first duplicate page is found.  Since XSLT is heavily steeped in functional programming concepts, this sort of iteration in XSLT is best done with recursion:\n  <xsl:template name=\"processWishlist\">\n\n    <xsl:param name=\"wishlist\" />              <!-- Wishlist ID -->\n    <xsl:param name=\"max\"   select=\"50\" />     <!-- Arbitrary upper loop limit -->\n    <xsl:param name=\"curr_page\" select=\"1\" />  <!-- Curr page # -->\n    <xsl:param name=\"prev_first_asin\" />       <!-- Keeping track of repeats -->\n\nThe first modification to this template is the addition of three parameters:\n\nmax provides an arbitrary upper limit to the number of pages through which this template will iterate.\ncurr_page contains the number of the page to be requested in this iteration.\nprev_first_asin will contain the ASIN number of the first item from the previous iteration's page of results.\n\nNext, we modify the URL used to query for wishlist data:\n    <!-- Fetch the wishlist products -->\n    <xsl:variable name=\"details\" select=\"document(concat(\n                  'http://xml.amazon.com/onca/xml3?',\n                  't=',$associate,'&amp;',\n                  'dev-t=',$devtoken,'&amp;',\n                  'WishlistSearch=',$wishlist,'&amp;',\n                  'type=lite&amp;f=xml&amp;',\n                  'page=',$curr_page))//Details\" />\n\nThe only addition here beyond the previous version is the page parameter in the URL.  Not much mystery here--this parameter specifies which page of results we want.  Now, let's build the loop:\n    <!-- Snag the first item Asin -->\n    <xsl:variable name=\"curr_first_asin\" select=\"$details/Asin/text()\" />\n\n    <!-- If we haven't exceeded the loop limit, and this first Asin isn't -->\n    <!-- a repeat of the previous loop (indicating we've run out of new   -->\n    <!-- pages), then go ahead...                                         -->\n    <xsl:if test=\"(($curr_page+1) &lt; $max) and\n                  (string-length($curr_first_asin) &gt; 0) and\n                  not($curr_first_asin = $prev_first_asin)\">\n  \n\nWe capture the ASIN of the first item in this page of results and check to see if we should continue.  This if conditional first ensures that we're not past the sanity guard for loop iterations, makes sure that we actually got a non-empty current first ASIN, then checks our current first product's ASIN against what was passed in as the previous iteration's first product's ASIN.  If this was the first time through the loop, this value should be empty and therefore wouldn't match the current ASIN.  But, if we've gone past the end of results, the previous and current ASIN values should match, and the conditional will fail.\nMoving along into the body of the conditional, we copy in wishlist products filtered on a price maximum, just as before:\n      <!-- Copy products, filtering on a maximum price -->\n      <xsl:copy-of select=\"$details/OurPrice[number(substring(\n                   text(),2)) &lt; $maxprice]/..\" />\n\nHaving done that, we move onto the recursive end of this template:\n      <!-- Loop by recursion to get the next page -->\n      <xsl:call-template name=\"processWishlist\">\n        <xsl:with-param name=\"wishlist\"        select=\"$wishlist\" />\n        <xsl:with-param name=\"max\"             select=\"$max\" />\n        <xsl:with-param name=\"curr_page\"       select=\"$curr_page + 1\" />\n        <xsl:with-param name=\"prev_first_asin\" select=\"$curr_first_asin\" />\n      </xsl:call-template>\n\n    </xsl:if>    \n  </xsl:template>\n\nHere, the template makes a recursive call back to itself, passing through the wishlist ID and the maximum iteration count.  Since variables in XSLT are immutable, meaning that their values can't be changed once they've been set, we can't increment $curr_page in-place like a loop counter in other languages--so, the current page count value is incremented and passed to the recursive call as a parameter.  Finally, the current first item's ASIN is passed along, to become the previous ASIN for the next iteration.\nNote that when the conditional fails--that is, if the loop limit is passed or a duplicate page is detected--the loop ends.  In other words, nothing further happens and execution pops back up out of all the levels of recursion and the top-level template ends.  \nI wrote \"when the conditional fails\".  This is a key point: for the loop to eventually end, this conditional must fail (or be made to fail) at some point, else this loop will happily progress through page requests forever.  This is the reason for the $max parameter limiting the number of iterations, in case something goes haywire--like, oh say, a failure of our duplicate-page detection hack as a loop ending condition.  A useful exercise for the reader might be to add some additional diagnostic code to report that the limit was hit versus a natural end to results.\nRandom Numbers\nSome ready-made files are available for this section:\n\nwishes-ex3.xsl: The third iteration of the stylesheet in development.\nrandom-xml: A Perl CGI script used as a web service to generate random numbers.\n\nArmed with a template that will query against the full set of items in a wishlist, we're ready to look into making a random selection from a list of products.  \nBut first, we need to pick a random number.  Unfortunately, there doesn't appear to be any random() function in the XPath or XSLT standards.  There is a math:random() from EXSLT implemented in libxslt, but I seem to be having a bit of a problem getting it to produce anything other than the same sequence of numbers.  I suspect there's a problem in seeding the random number generator, but I've yet to work out how to fix it.  (Suggestions welcome.)\nSo, I cheated and made another workaround with a CGI script on my web server that generates random numbers in a simple XML document.  Currently, it's hosted here:\nhttp://www.decafbad.com/2004/05/random-xml\n\nAnd this is what the script looks like:\n#!/usr/bin/perl\n\nuse strict;\nuse CGI;\n\nmy $q = new CGI();\n\nmy $min = $q->param('min') or 0;\nmy $max = $q->param('max') or 1;\nmy $int = $q->param('int');\n\nmy $num = $min + ( rand() * ($max - $min));\nif ($int) { $num = int($num); }\n\nprint $q->header('text/xml');\nprint \"<rand>$num</rand>\\n\";\n\nThis is a very simple CGI.  It accepts the parameters max, min, and int.  The values of these parameters determine the maximum and minimum value for the random number returned, and whether or not it should be an integer.  For example, the following URL should return an integer between 10 and 20:\nhttp://www.decafbad.com/2004/05/random-xml?\nint=1&#38;min=10&#38;max=20\n\nUsing this as a web service in the stylesheet with the document() function, we can get a random number.  If you've got web space where you can host CGI scripts, I suggest you host a copy of this script yourself, since I can't guarantee how long mine will stick around.  But, for as long at works, feel free to use the service from my server.\nMoving along, let's add a new named template to the stylesheet, called randomWishlistProduct:\n  <xsl:template name=\"randomWishlistProduct\">\n\n    <xsl:param name=\"wishlist\" /> <!-- Wishlist ID -->\n    \n    <!-- Gather all the products for the current wishlist -->\n    <xsl:variable name=\"products\">\n      <xsl:call-template name=\"processWishlist\">\n        <xsl:with-param name=\"wishlist\" select=\"$wishlist\" />\n      </xsl:call-template>\n    </xsl:variable>\n\nJust like the processWishlist template, we start by defining the parameter wishlist to accept a wishlist ID.  Using this ID, we call the processWishlist template itself and store the complete list of products queried from the wishlist into the variable $products.\n    <!-- Count the products in the wishlist -->\n    <xsl:variable name=\"max_products\"\n                  select=\"count(exsl:node-set($products)/Details)\" />\n\nThis next step counts the number of products found in the wishlist.  The one tricky bit here is the use of the EXSLT function exsl:node-set(): The $products variable contains what's called a result tree fragment, which is a kind of cross between XML data nodes and a plain old string.  This type of data does not normally allow the full set of XPath operators to be used on it, so first we need to use exsl:node-set() to turn it into a full-fledged node set.  Then we can look up the Details element nodes and count them.  \n    <!-- Conjure up a random index within the list of products -->\n    <xsl:variable name=\"rand_product_num\"\n                  select=\"document(concat(\n                  'http://www.decafbad.com/2004/05/random-xml?',\n                  'int=1&amp;',\n                  'min=1&amp;',\n                  'max=',$max_products))/rand\" />\n\nHere is where the random number service comes in handy.  The concat() function is used to build the URL to the service, with parameters specifying that the number should be an integer, and should fall between 1 and the number of products in the wishlist.  The document() function grabs the XML document from the service, and the value is extracted from the single element the document contains.\nThere is an alternative to this last bit, should you happen to have a properly working math:random() function in your XSLT processor:\n    <xsl:variable name=\"rand_product_num\" select=\"round( math:random() *\n                  $max_products ) + 1\" />\n\nIf you can use this instead, you'll have no need for the random number web service.  This version is obviously more concise, and doesn't require another trip out to a web service.  You might want to try it--but if you find that you keep getting the same wishlist items selected, then you've run into the problem I found with the random number generator.\nNow, let's wrap this template up by selecting an item:\n    <!-- Copy the product as indexed by the random number -->\n    <xsl:copy-of select=\"exsl:node-set($products)/Details[\n                 position()=$rand_product_num]\" />\n       \n  </xsl:template>\n\nAgain, we need to use the exsl:node-set() function to turn the result tree fragment in the $products variable into a node set, from which we select and copy the Details element whose position in the data is indexed by the random number we just selected.  Just one last tweak needed to wrap up this iteration of our stylesheet.  We need to swap out the call to the processWishlist function at the end and replace it with a call to randomWishlistProduct:\n  <xsl:template match=\"/wishes:wishes\">\n\n    <xsl:for-each select=\"//wishes:wishlist\">\n      <wishes:wishitem>\n        <xsl:copy-of select=\".\" />\n        <xsl:call-template name=\"randomWishlistProduct\">\n          <xsl:with-param name=\"wishlist\" select=\".\" />\n        </xsl:call-template>\n      </wishes:wishitem>\n    </xsl:for-each>\n\n  </xsl:template>\n\nAfter these changes, you should be able to run the stylesheet ([wishes-ex3.xsl][wishes_ex3]) and get something like the following:\n<wishes:wishitem xmlns:wishes=\"http://www.decafbad.com/2004/05/wishes\">\n    <wishes:wishlist label=\"The Girl\">35OIOYWQ9XQAE</wishes:wishlist>\n    <Details ...>...</Details>\n</wishes:wishitem>\n<wishes:wishitem xmlns:wishes=\"http://www.decafbad.com/2004/05/wishes\">\n    <wishes:wishlist label=\"Me\">1QWYI6P2JF3Q5</wishes:wishlist>\n    <Details ...>...</Details>\n</wishes:wishitem>\n\nThis is similar to the output of the previous iteration of the stylesheet, but this time there's only one product selected at random for each wishlist.  \nShopping Carts\nSome ready-made files are available for this section:\n\nwishes-ex4.xsl: The fourth iteration of the stylesheet in development.\n\nBy this point, we've been able to query and filter products in Amazon wishlists, and we've selected an item at random from each wishlist we've queried.  Now, let's enable some purchases.\nThe AWS provides for Remote Shopping Cart functionality, whereby items can be added to an Amazon.com shopping cart programmatically.  This is about as close as we can get to automating the purchase of items selected from the wishlists--there is no API functionality for actually completing the ordering of items.  If you really think about it, this really is a good thing and should demand human intervention; we certainly wouldn't want this script going crazy and accidentally buying up everything on a wishlist.\nDocumentation for the AWS Remote Shopping Cart explains that a shopping cart can be created and items added with a URL like the following:\nhttp://xml.amazon.com/onca/xml3?\nShoppingCart=add&#38;\nf=xml&#38;\ndev-t=[Developer Token goes here]&#38;\nt=[Associates ID goes here]&#38;\nAsin.[ASIN goes here]=[quantity goes here]&#38;\nsims=true\n\nPart of this should look familiar, so we already know what to do with the developer token and the associates ID.  The last part, specifying product ASIN and quantity, can be filled out with information contained in the product records selected at random from the wishlists.  \nSo, let's start by revising the template at the end of the stylesheet:\n<xsl:template match=\"/wishes:wishes\">\n\n    <xsl:variable name=\"random_products\">      \n      <xsl:for-each select=\"//wishes:wishlist\">\n        <wishes:wishitem>\n          <xsl:copy-of select=\".\" />\n          <xsl:call-template name=\"randomWishlistProduct\">\n            <xsl:with-param name=\"wishlist\" select=\".\" />\n          </xsl:call-template>\n        </wishes:wishitem>\n      </xsl:for-each>\n    </xsl:variable>\n\nHere, we've taken what was the output of the previous iteration of the stylesheet and stuffed it into the variable $random_products.  Next, let's fill in the blanks and build a Remote Shopping Cart URL:\n    <xsl:variable name=\"shopping_cart_create_url\">\n      <!-- Standard AWS URL -->\n      <xsl:text>http://xml.amazon.com/onca/xml3?</xsl:text>\n\n      <!-- Add in the selected items -->\n      <xsl:for-each select=\"exsl:node-set($random_products)\n                            /wishes:wishitem/Details\">\n        <xsl:text>Asin.</xsl:text><xsl:value-of select=\"Asin\" />\n        <xsl:text>=1&amp;</xsl:text>\n      </xsl:for-each>\n\n      <!-- Wrap up with the shopping cart function and required tokens -->\n      <xsl:text>ShoppingCart=add&amp;</xsl:text>\n      <xsl:text>f=xml&amp;</xsl:text>\n      <xsl:text>dev-t=</xsl:text><xsl:value-of select=\"$devtoken\" />\n      <xsl:text>&amp;</xsl:text>\n      <xsl:text>t=</xsl:text><xsl:value-of select=\"$associate\" />\n    </xsl:variable>\n\nSince simple XPath doesn't allow for the looping needed for multiple items, we can't just concatenate this URL together in a select expression like we did with the wishlist item query.  So, we use xslt:foreach to build this with blocks of text using the xsl:text element.  We iterate though the random products chosen from wishlists and add an ASIN for each to the URL with a quantity of 1. Then, we use the $devtoken and $associate variables to fill in their respective spots.\nNote that this could have been written without using the xsl:text elements like so:\n    <xsl:variable name=\"shopping_cart_create_url\">http://xml.amazon.\n    com/onca/xml3?ShoppingCart=add&amp;f=xml&amp;dev-t=<xsl:value-of \n    select=\"$devtoken\" />&amp;t=<xsl:value-of select=\"$associate\" />\n    &amp;<xsl:for-each select=\"exsl:node-set($random_products)/\n    wishes:wishitem/Details\">Asin.<xsl:value-of select=\"Asin\" />=1\n    &amp;</xsl:for-each></xsl:variable>\n\nThis removes the clutter of all the xsl:text elements, but it would need to be piled all on one line in order to keep undesired whitespace from getting into the URL.  I made a small attempt at wrapping this line here, but line breaks and spaces would leave us with a non-functioning shopping cart URL.  It's up to you to decide which to use--personally, I prefer the xsl:text clutter for the ability to add in comments and clarify things a bit.\nFinally, having built the shopping cart URL, let's use it to get a shopping cart and wrap things up:\n    <xsl:variable name=\"shopping_cart\"\n                  select=\"document($shopping_cart_create_url)\" />\n\n    <xsl:copy-of select=\"$shopping_cart\" />\n\n</xsl:template>  \n\nAs an aside, this part is pushing the concept of a REST web service a bit: In the REST philosophy, requests using the GET method (which is what document() uses) should only return existing resources and not create new resources or cause modifications to happen.  Instead, these sorts of actions should use a POST request.  But, since we've already accepted a few rough edges and workarounds in this project so far, we won't let a point of esoterica like that stop us.  (That and, well, this is the way Amazon designed their web service, so we'll take what we can get.)\nOnce you run this iteration of the stylesheet ([wishes-ex4.xsl][wishes_ex4]), you should get something like this XML as output:\n<ShoppingCartResponse ...>\n  ...\n  <ShoppingCart>\n   <CartId>...</CartId>\n   <HMAC>...</HMAC>\n   <PurchaseUrl>...</PurchaseUrl>\n   <Items>\n    <Item>...</item>\n    <Item>...</item>\n   </Items>\n  </ShoppingCart>\n  ...\n</ShoppingCartResponse>\n\nThe AWS documentation describes the vital elements here like so:\n\nCartId - The Cart ID is the unique identifier for a given shopping cart.\nHMAC - The HMAC is a security token that must be passed back to Amazon Web Services for using an existing cart.\nPurchaseUrl - Use the purchase URL to transfer the remote shopping cart from your application to Amazon so that your application's users may complete their purchases.¬† The purchase URL merges the remote shopping cart with the Amazon.com shopping cart.\n\nSo, in short, whenever we want to do any sort of manipulation on this Remote Shopping Cart via AWS, we'll need to remember and later supply both the CartId and HMAC found in the XML returned at its creation.  And, once we're all ready to check out, the PurchaseUrl points to where we'll need to browse in person.\nStay Tuned!\nThis concludes Part 2 of the Wish-of-the-Month Club.  Following this will be the final part, where we tie everything together and start firing off monthly emails!",
    "prevPostPath": "2004/06/28/radioiorock-scraper",
    "nextPostPath": "2004/06/16/wishofthemonthclub1"
  },
  {
    "comments_archived": true,
    "date": "2004-06-16T11:42:48.000Z",
    "excerpt": "For some time now, my girlfriend and I have been accumulating things we want in wishlists on Amazon.com.  Though they have come in handy with relatives at Christmas and on birthdays, neither of us really expects to see a regular flow of gifts from them.  For the most part, they've just become holding tanks for things we intend to buy for each other or ourselves.  On one particular visit, though, the notion of a Wish-of-the-Month club popped into my head.",
    "layout": "post",
    "tags": [
      "hacks",
      "xml"
    ],
    "title": "Wish-of-the-Month Club, Part 1 of 3",
    "wordpress_id": 529,
    "wordpress_slug": "wishofthemonthclub1",
    "wordpress_url": "http://www.decafbad.com/blog/?p=529",
    "year": "2004",
    "month": "06",
    "day": "16",
    "isDir": false,
    "slug": "wishofthemonthclub1",
    "postName": "2004-06-16-wishofthemonthclub1",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/06/16/wishofthemonthclub1",
    "summary": "Remember that I wrote a little while ago about wanting to publish some articles here that I'd want to read?  Well, I've been hard at work since then to turn out the first set and I think I've finally got something for you.  I mentioned earlier this week that I was taking this seriously, so I hope it shows.  So, with many thanks to my girlfriend's kind editorial help, and with some measure of anxiety, here goes...\nIntroduction\nFor some time now, my girlfriend and I have been accumulating things we want in wishlists on Amazon.com.  Here's mine and here's hers - if you visit them, you can see we've both got quite a few things listed.  Though they have come in handy with relatives at Christmas and on birthdays, neither of us really expects to see a regular flow of gifts from them.  For the most part, they've just become holding tanks for things we intend to buy for each other or ourselves.  \nHowever, I tend to forget we have these lists except for occasional visit to Amazon when I think, \"Oh yeah, wishlists.  I should pick up a thing or two, there's some good stuff piled up in them.\"  On one particular visit, though, the notion of a Wish-of-the-Month club popped into my head: We could afford to grab at least one item for each of us from our wishlists on a monthly basis, provided that we remembered to place an order.  It'd be better than signing up for a book or music club, driven by someone else's idea of what we wanted.  Unfortunately, there's that problem for busy, absentminded, and people like us: remembering to place an order.\nBut wait, isn't this the sort of thing computers are for?  I should be able to cobble something together that would peruse our wishlists and--given some criteria like a price maximum--select an item at random for each of us and send them on their way.  With this, I could schedule a monthly run and start whittling down those lists.\nGathering Tools\nBefore I start working through the project itself, let's establish some assumptions and then gather some tools and materials:\nI'm going to assume that you're using a UN*X operating system (ie. Linux, Mac OS X, etc.) and that you're reasonably familiar with getting around in a shell and editing files.  Things presented here could be adapted for Windows fairly easily, but I'll leave that as an exercise to the reader.  Also, you may need to build and install a package or two, so know-how in that regard will serve as well.  And finally: some familiarity with XML and XSLT would be useful, but you won't need to be a guru with either.\nOh, and all the files I'll be introducing in this project can be downloaded from my website as a tarball:  wishes.tar.gz.  If you feel like browsing, you can see these files in my CVS repository.  And if you feel like checking out a copy via anonymous CVS, the username is anoncvs and the password is blank--email me for help, if you need it.\nSo, how do we get a look at these wishlists?  Lately, I've been tinkering a bit with scraping information from and automating access to websites.  It's a bit like a puzzle game, with all the accompanying frustrations and happy breakthroughs.  However, where most puzzle games are designed with a solution in mind, this game isn't even necessarily meant to be played depending on the intentions of website owners.\nFortunately, the folks at Amazon.com have made things very friendly to tinkerers by providing an API, called Amazon Web Services (or AWS).  You'll want to download the AWS developer's kit, which contains a wealth of documentation and examples.  After downloading these materials, you should apply for a developer's token for use with the service.  AWS provides both SOAP and REST interfaces to functionality and data at their site; personally, I prefer the HTTP-and-XML approach taken by the REST interface, so that's what we'll be using here. \nTo handle the XML produced by AWS, we'll be using the xsltproc command from the XML C parser and toolkit of Gnome.  There are other XSLT processors--such as Xalan, Sablotron, and Saxon--but I've found libxslt easiest to feed and care for on the various platforms with which I tinker.  It also seems to support a very large swath of EXSLT extensions, all of which come in very handy, yet seem to receive uneven support in other XSLT processors.  We'll be pulling a trick or two out of that bag, so its support is key.\nYou may or may not already have libsxlt installed.  Depending on your variant of Linux, it might be as simple as a single package-management command or it might be a bit more complex if you need to compile from source.  For Mac OS X, I recommend using Fink for your packaging needs.  Although, DarwinPorts is nice as well, if you're used to The BSD Way.\nA bonus for OS X users: Marc Liyanage has provided a great Open Source tool named TestXSLT that embeds libxslt, among other XSLT processors, in a slick GUI for easier use.  This might come in handy for you as things develop.\nWishlists in XML\nOkay, we've got a working environment, a head start on accessing Amazon wishlists as XML, and a way to manipulate that XML using xsltproc.  Let's start playing.  First things first, we need to gain access to Amazon wishlists in XML form.  Reading through the AWS documentation reveals that wish list searches are available via a URL constructed like so:\nhttp://xml.amazon.com/onca/xml3?\nt=[Associates ID goes here]&#38;\ndev-t=[Developer Token goes here]&#38;\nWishlistSearch=[wishlist ID goes here]&#38;\ntype=[lite or heavy]&#38;\nf=xml\n\nI received an ID of 0xdecafbad-20 when I signed up to be an associate a few years ago.  This will ensure that I get credited for sales made via the API--which isn't as important for the present project, since I'll be buying items myself, but it'll come in handy in later projects.  Also, when I signed up for a developer's token, this is what I was given: D8HVH869XA0NP  I'm disclosing my own here for the sake of example, but you should sign up and get your own.\nSo, that fills in the first two parts of the URL.  For the purposes of this project, let's just go with the lite option for type.  As for the wishlist ID, let's take a look the wishlist URLs to which I linked earlier:\nhttp://www.amazon.com/exec/obidos/registry/35OIOYWQ9XQAE\nhttp://www.amazon.com/exec/obidos/registry/1QWYI6P2JF3Q5\n\nYou can discover these wishlist URLs using Amazon's Wish List Search feature, in which case a wishlist URL might appear like so:\nhttp://www.amazon.com/gp/registry/registry.html/\n002-7899886-3676027?%5Fencoding=UTF8&#38;\nid=35OIOYWQ9XQAE\n\nIn either case, there is a 13-character ID in each variety of wish list URL: this string is the wish list ID.  So, the ID for my girlfriend's wishlist is  35OIOYWQ9XQAE and mine is 1QWYI6P2JF3Q5.  Given this piece of the puzzle, we can fill in the blanks to come up with the following URL for my girlfriend's wish list:\nhttp://xml.amazon.com/onca/xml3?\nt=0xdecafbad-20&#38;\ndev-t=D8HVH869XA0NP&#38;\ntype=lite&#38;\nWishlistSearch=35OIOYWQ9XQAE&#38;\nf=xml\n\nCheck out the XML resulting from this URL--you may want to use a tool such as curl or wget instead of viewing this directly in your browser.  You'll see some XML that looks something like this:\n<ProductInfo>\n...\n<Details url=\"(some long URL)\">\n  <Asin>0262133601</Asin>\n  <ProductName>Foundations of Statistical Natural Language Processing</ProductName>\n  <Catalog>Book</Catalog>\n  <Authors>\n     <Author>Christopher D. Manning</Author>\n     <Author>Hinrich Sch&#252;tze</Author>\n  </Authors>\n  <ReleaseDate>18 June, 1999</ReleaseDate>\n  <Manufacturer>MIT Press</Manufacturer>\n  <ImageUrlSmall>(another long url)</ImageUrlSmall>\n  <ImageUrlMedium>(yet another long url)</ImageUrlMedium>\n  <ImageUrlLarge>(one last long url)</ImageUrlLarge>\n  <Availability>Usually ships within 24 hours</Availability>\n  <ListPrice>$75.00</ListPrice>\n  <OurPrice>$63.75</OurPrice>\n  <UsedPrice>$49.99</UsedPrice>\n</Details>\n...\n</ProductInfo>\n\nNote that the long URL in the Detail element's url attribute links to the human-viewable product detail page at Amazon.  I've also left a few other things out, such as the URLs to product images; I just thought I'd edit it a bit to be friendlier to your browser at home.  There's a schema for this XML data, and the ins-and-outs are explained in the AWS documentation under \"Amazon Web Services Data Model\".\nQuerying The Wishes\nSome ready-made files are available for this section:\n\nwishes-ex1.xsl: The first iteration of the stylesheet in development.\nwishes.xml: An XML document used as input with the stylesheet.\n\nNow that we've got some XML from Amazon to play with, let's start tinkering with an XSLT stylesheet to process it.  In the interests of flexibility and reusability, we can parameterize a few things in XML before starting in on the stylesheet:\n<wishes xmlns=\"http://www.decafbad.com/2004/05/wishes\">\n  <maxprice>15.00</maxprice>\n  <associate>0xdecafbad-20</associate>\n  <devtoken>D8HVH869XA0NP</devtoken>\n  <email>deus_x@pobox.com</email>\n  <wishlists>\n    <wishlist label=\"The Girl\">35OIOYWQ9XQAE</wishlist>\n    <wishlist label=\"Me\">1QWYI6P2JF3Q5</wishlist>\n  </wishlists>\n</wishes>\n\nHopefully, the data here is fairly self-explanatory:  I've established a maximum price for item selection; provided my associate ID and developer token; there's an email address to which I eventually want to send the results of all this work; and I've made a list of wishlist IDs, each with a readable label. Given this, let's start out simple and  use this to get some data from Amazon:\n<?xml version=\"1.0\"?>\n<xsl:stylesheet version=\"1.0\"\n            xmlns:wishes=\"http://www.decafbad.com/2004/05/wishes\"\n            xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\">\n  <xsl:output indent=\"yes\" />\n\n  <!-- Grab our global settings -->\n  <xsl:variable name=\"maxprice\"  select=\"/wishes:wishes/wishes:maxprice\" />  \n  <xsl:variable name=\"associate\" select=\"/wishes:wishes/wishes:associate\" />\n  <xsl:variable name=\"devtoken\"  select=\"/wishes:wishes/wishes:devtoken\" />\n\nSo far so good--things start off by pulling in some of the parameters into variables.  Next, let's dig into actually querying wishlist data with a reusable template:\n  <xsl:template name=\"processWishlist\">\n    <xsl:param name=\"wishlist\" />\n\n    <xsl:variable name=\"details\" select=\"document(concat(\n        'http://xml.amazon.com/onca/xml3?',\n        't=',$associate,'&amp;',\n        'dev-t=',$devtoken,'&amp;',\n        'WishlistSearch=',$wishlist,'&amp;',\n        'type=lite&amp;f=xml'))//Details\" />\n\nFirst thing into this template, we accept a parameter named wishlist which is expected to contain a wishlist ID string.  Next, we build an AWS URL by concatenating together the pieces we have in variables (associate ID, developer's token, and wishlist ID) using the XPath function concat().  Once we have this URL, we use the function document() to make a request and fetch the XML data for that URL.  From this, we select all the Details elements.  \nThen with that data, we can do some filtering on the price and availability.  We want to make sure that not only will we select items that are within our budget, but that they are available to buy in the first place:\n    <xsl:copy-of select=\"$details[\n      number(substring(OurPrice/text(),2)) &lt; $maxprice\n      and\n      contains(Availability, 'Usually ships within')\n      ]\" />\n\n  </xsl:template>\n\nThis code is just a little bit funky, since the price data given by Amazon contains a dollar sign, and we want to make a numerical comparison.  So, we chop the dollar sign off and convert to a number before making the comparison.  Also, there's an assumption here about what will show up in the Availability element: \"Usually ships within\"  Other things that might show up will declare that the item is out of stock, discontinued, or otherwise not shipping.  This might need some tweaking someday, but it seems to work for now.\nTaken all together, this template has the effect of a SQL SELECT statement somewhat like this:\nSELECT * \nFROM Amazon.WishlistItems \nWHERE WishlistID = $wishlist AND \n      OurPrice < $maxprice AND\n      Availability like '%Usually ships within%';\n\ndocument() is a very useful XPath function.  It allows us to pull in XML from external files and, in our case, from external URLs via HTTP requests.  This gives us the ability to make queries against REST web services like AWS--which, among many other reasons, is why I prefer REST web services over SOAP.  (I don't even want to think about trying to access a SOAP service from XSLT.)\nNow, let's wrap up this first iteration of the stylesheet by trying out the query template on each of the wishlist IDs:\n  <xsl:template match=\"/wishes:wishes\">\n    <xsl:for-each select=\"//wishes:wishlist\">\n      <wishes:wishitem>\n        <xsl:copy-of select=\".\" />\n        <xsl:call-template name=\"processWishlist\">\n              <xsl:with-param name=\"wishlist\" \n                              select=\".\" />\n        </xsl:call-template>\n      </wishes:wishitem>\n    </xsl:for-each>\n  </xsl:template>\n\n</xsl:stylesheet>\n\nYou can get a completed version of this stylesheet, along with the input XML, in case you haven't been cutting and pasting together a copy of your own along the way.  Try it out in a shell with:\n$ xsltproc wishes_ex1.xsl wishes.xml\n\nAlternately, you could check it out using TestXSLT under OS X.  You should get something like the following:\n<wishes:wishitem xmlns:wishes=\"http://www.decafbad.com/2004/05/wishes\">\n    <wishes:wishlist label=\"The Girl\">35OIOYWQ9XQAE</wishes:wishlist>\n    <Details ...>...</Details>\n    <Details ...>...</Details>\n    ...\n</wishes:wishitem>\n<wishes:wishitem xmlns:wishes=\"http://www.decafbad.com/2004/05/wishes\">\n    <wishes:wishlist label=\"Me\">1QWYI6P2JF3Q5</wishes:wishlist>\n    <Details ...>...</Details>\n    <Details ...>...</Details>\n    ...\n</wishes:wishitem>\n\nObviously, this example XML is much abridged, but hopefully you can get the gist:  For each wishlist ID, there is a containing wishitem element.  It contains a copy of the wishlist element from the input XML, followed by all the Details elements filtered and copied from the Amazon XML with the help of the processWishlist template.\nThat's All for Now!\nAnd that's the end of Part 1.  Next up, we'll be delving into a few more wrinkles in the wishlist querying process, selecting random items in XSLT, and the Remote Shopping Cart interface in Amazon Web Services.  Stay tuned!",
    "prevPostPath": "2004/06/28/wishofthemonthclub2",
    "nextPostPath": "2004/06/14/info-freako-or-whos-already-past-arguing-about-syndication-formats"
  },
  {
    "comments_archived": true,
    "date": "2004-06-14T22:54:55.000Z",
    "excerpt": "Where's the state-of-the-art for feed aggregators, and what's next?  I'm tired of reverse-chronological versus three-pane; I'm tired of copying Usenet and email.  What needs to happen next to expand our Info Freako capacity by an order of magnitude or two?  The invention of aggregators has opened the door to the first few orders, but I need more.",
    "layout": "post",
    "tags": [
      "syndication"
    ],
    "title": "Info Freako, or who's already past arguing about syndication formats?",
    "wordpress_id": 528,
    "wordpress_slug": "info-freako-or-whos-already-past-arguing-about-syndication-formats",
    "wordpress_url": "http://www.decafbad.com/blog/?p=528",
    "year": "2004",
    "month": "06",
    "day": "14",
    "isDir": false,
    "slug": "info-freako-or-whos-already-past-arguing-about-syndication-formats",
    "postName": "2004-06-14-info-freako-or-whos-already-past-arguing-about-syndication-formats",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/06/14/info-freako-or-whos-already-past-arguing-about-syndication-formats",
    "thumbnail": "http://www.johnny-five.com/simplenet/Shortcircuit/Pics/Pictures/Misc/jfive.gif",
    "prevPostPath": "2004/06/16/wishofthemonthclub1",
    "nextPostPath": "2004/06/13/i-will-do-the-fandango"
  },
  {
    "comments_archived": true,
    "date": "2004-06-13T11:07:46.000Z",
    "layout": "post",
    "title": "I will do the Fandango.",
    "wordpress_id": 527,
    "wordpress_slug": "i-will-do-the-fandango",
    "wordpress_url": "http://www.decafbad.com/blog/?p=527",
    "year": "2004",
    "month": "06",
    "day": "13",
    "isDir": false,
    "slug": "i-will-do-the-fandango",
    "postName": "2004-06-13-i-will-do-the-fandango",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/06/13/i-will-do-the-fandango",
    "thumbnail": "http://www.decafbad.com/2004/06/les.jpg",
    "prevPostPath": "2004/06/14/info-freako-or-whos-already-past-arguing-about-syndication-formats",
    "nextPostPath": "2004/05/25/i-was-a-pre-teen-transactor-author-wannabe-and-still-am"
  },
  {
    "comments_archived": true,
    "date": "2004-05-25T05:03:57.000Z",
    "excerpt": "I've always wanted to be the kind of hacker who did clever things and wrote about them for other kids like me to read and try.",
    "layout": "post",
    "title": "I was a pre-teen Transactor author wannabe (and still am!)",
    "wordpress_id": 526,
    "wordpress_slug": "i-was-a-pre-teen-transactor-author-wannabe-and-still-am",
    "wordpress_url": "http://www.decafbad.com/blog/?p=526",
    "year": "2004",
    "month": "05",
    "day": "25",
    "isDir": false,
    "slug": "i-was-a-pre-teen-transactor-author-wannabe-and-still-am",
    "postName": "2004-05-25-i-was-a-pre-teen-transactor-author-wannabe-and-still-am",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/05/25/i-was-a-pre-teen-transactor-author-wannabe-and-still-am",
    "prevPostPath": "2004/06/13/i-will-do-the-fandango",
    "nextPostPath": "2004/05/19/surprising-feature-at-amazoncom"
  },
  {
    "comments_archived": true,
    "date": "2004-05-19T22:12:51.000Z",
    "excerpt": "Here's a mini rant about Amazon.com:  Apparently, user accounts there are identified by some combination of email address and password.  That is, you can login with the same email address, give three different passwords, and get three different sets of user data.  Different wishlists, different shopping carts, the works.",
    "layout": "post",
    "title": "Surprising \"feature\" at Amazon.com",
    "wordpress_id": 525,
    "wordpress_slug": "surprising-feature-at-amazoncom",
    "wordpress_url": "http://www.decafbad.com/blog/?p=525",
    "year": "2004",
    "month": "05",
    "day": "19",
    "isDir": false,
    "slug": "surprising-feature-at-amazoncom",
    "postName": "2004-05-19-surprising-feature-at-amazoncom",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/05/19/surprising-feature-at-amazoncom",
    "prevPostPath": "2004/05/25/i-was-a-pre-teen-transactor-author-wannabe-and-still-am",
    "nextPostPath": "2004/05/17/use-atom-for-a-universal-blog-transfer-protocol"
  },
  {
    "comments_archived": true,
    "date": "2004-05-17T23:28:48.000Z",
    "excerpt": "You could use some mashup of RSS and XML-RPC for a Universal Blog Transfer Protocol, but I&#8217;d suggest using Atom. It&#8217;s a data model and an API, where the data model represents blog content quite well and the API complements it for the purposes of shuffling things around. With a mix of XML-RPC and RSS, I could only imagine lots of fiddling going on to transliterate between RSS and metaWeblog API structs or whatnot.",
    "layout": "post",
    "tags": [
      "syndication"
    ],
    "title": "Use Atom for a Universal Blog Transfer Protocol",
    "wordpress_id": 524,
    "wordpress_slug": "use-atom-for-a-universal-blog-transfer-protocol",
    "wordpress_url": "http://www.decafbad.com/blog/?p=524",
    "year": "2004",
    "month": "05",
    "day": "17",
    "isDir": false,
    "slug": "use-atom-for-a-universal-blog-transfer-protocol",
    "postName": "2004-05-17-use-atom-for-a-universal-blog-transfer-protocol",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/05/17/use-atom-for-a-universal-blog-transfer-protocol",
    "prevPostPath": "2004/05/19/surprising-feature-at-amazoncom",
    "nextPostPath": "2004/05/15/birthday-party-for-bob"
  },
  {
    "comments_archived": true,
    "date": "2004-05-15T02:23:22.000Z",
    "excerpt": "So last night my buddy Bob, aka Macross, aka director / producer / host / tech / janitor of IPM Radio, turned 30 last night. Lots of music, drinks, and monkeys. Can&#8217;t believe I&#8217;ve known this guy for like 14 years. Come take a look at some photos of the party that was broadcast live from his basement.",
    "layout": "post",
    "title": "Birthday party for Bob!",
    "wordpress_id": 523,
    "wordpress_slug": "birthday-party-for-bob",
    "wordpress_url": "http://www.decafbad.com/blog/?p=523",
    "year": "2004",
    "month": "05",
    "day": "14",
    "isDir": false,
    "slug": "birthday-party-for-bob",
    "postName": "2004-05-14-birthday-party-for-bob",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/05/15/birthday-party-for-bob",
    "thumbnail": "http://www.decafbad.com/photos/bob-turns-30/Images/IMG_2640_JPG.jpg",
    "prevPostPath": "2004/05/17/use-atom-for-a-universal-blog-transfer-protocol",
    "nextPostPath": "2004/05/12/just-what-does-one-use-a-windows-pc-for-anyway"
  },
  {
    "comments_archived": true,
    "date": "2004-05-12T11:52:02.000Z",
    "excerpt": "Wherein I try making a Windows box do things it's probably not supposed to do, and am frustrated when it doesn't quite do what I want it to do.",
    "layout": "post",
    "title": "Just what does one use a Windows PC for anyway?",
    "wordpress_id": 522,
    "wordpress_slug": "just-what-does-one-use-a-windows-pc-for-anyway",
    "wordpress_url": "http://www.decafbad.com/blog/?p=522",
    "year": "2004",
    "month": "05",
    "day": "12",
    "isDir": false,
    "slug": "just-what-does-one-use-a-windows-pc-for-anyway",
    "postName": "2004-05-12-just-what-does-one-use-a-windows-pc-for-anyway",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/05/12/just-what-does-one-use-a-windows-pc-for-anyway",
    "prevPostPath": "2004/05/15/birthday-party-for-bob",
    "nextPostPath": "2004/05/11/nintendo-ds-returning-to-game-watch-roots"
  },
  {
    "comments_archived": true,
    "date": "2004-05-11T22:31:17.000Z",
    "layout": "post",
    "tags": [
      "gaming"
    ],
    "title": "Nintendo DS returning to Game &#38; Watch roots",
    "wordpress_id": 521,
    "wordpress_slug": "nintendo-ds-returning-to-game-watch-roots",
    "wordpress_url": "http://www.decafbad.com/blog/?p=521",
    "year": "2004",
    "month": "05",
    "day": "11",
    "isDir": false,
    "slug": "nintendo-ds-returning-to-game-watch-roots",
    "postName": "2004-05-11-nintendo-ds-returning-to-game-watch-roots",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/05/11/nintendo-ds-returning-to-game-watch-roots",
    "thumbnail": "http://images.usatoday.com/life/_photos/2004/2004-05/11-nintendo-inside.jpg",
    "prevPostPath": "2004/05/12/just-what-does-one-use-a-windows-pc-for-anyway",
    "nextPostPath": "2004/05/11/homebrew-entertainment-appliances-cheap-open-and-embattled"
  },
  {
    "comments_archived": true,
    "date": "2004-05-11T01:58:15.000Z",
    "excerpt": "I've been tinkering for years now with TiVO-zing my PC, with varying degrees of success.  But, that's not what I really want.  Lately, I've been reading The Invisible Computer by Donald A. Norman, and it's gotten me thinking: What I really want is a family of entertainment appliances.  I want to make them myself, I want to do it on the cheap, and I don't want to go to jail.",
    "layout": "post",
    "title": "Homebrew entertainment appliances - cheap, open, and embattled",
    "wordpress_id": 520,
    "wordpress_slug": "homebrew-entertainment-appliances-cheap-open-and-embattled",
    "wordpress_url": "http://www.decafbad.com/blog/?p=520",
    "year": "2004",
    "month": "05",
    "day": "10",
    "isDir": false,
    "slug": "homebrew-entertainment-appliances-cheap-open-and-embattled",
    "postName": "2004-05-10-homebrew-entertainment-appliances-cheap-open-and-embattled",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/05/11/homebrew-entertainment-appliances-cheap-open-and-embattled",
    "prevPostPath": "2004/05/11/nintendo-ds-returning-to-game-watch-roots",
    "nextPostPath": "2004/05/03/put-on-your-rss-colored-glasses-and-forget-about-atom"
  },
  {
    "comments_archived": true,
    "date": "2004-05-03T10:39:05.000Z",
    "excerpt": "Well, it did seem quiet, but it's comforting in an odd way that RSS Wars are still raging as I wander back into the blogosphere.  I suggest that all that Atom haters out there put on some RSS-colored glasses and forget there ever was an Atom.  XSLT and URL-as-command-line to the rescue!",
    "layout": "post",
    "title": "Put on your RSS-colored glasses and forget about Atom",
    "wordpress_id": 519,
    "wordpress_slug": "put-on-your-rss-colored-glasses-and-forget-about-atom",
    "wordpress_url": "http://www.decafbad.com/blog/?p=519",
    "year": "2004",
    "month": "05",
    "day": "03",
    "isDir": false,
    "slug": "put-on-your-rss-colored-glasses-and-forget-about-atom",
    "postName": "2004-05-03-put-on-your-rss-colored-glasses-and-forget-about-atom",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/05/03/put-on-your-rss-colored-glasses-and-forget-about-atom",
    "prevPostPath": "2004/05/11/homebrew-entertainment-appliances-cheap-open-and-embattled",
    "nextPostPath": "2004/05/02/feed-validation-confusion"
  },
  {
    "comments_archived": true,
    "date": "2004-05-02T23:27:23.000Z",
    "excerpt": "Feed validators are confusing me, but it looks like there's been a fix.",
    "layout": "post",
    "title": "Feed validation confusion",
    "wordpress_id": 518,
    "wordpress_slug": "feed-validation-confusion",
    "wordpress_url": "http://www.decafbad.com/blog/?p=518",
    "year": "2004",
    "month": "05",
    "day": "02",
    "isDir": false,
    "slug": "feed-validation-confusion",
    "postName": "2004-05-02-feed-validation-confusion",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/05/02/feed-validation-confusion",
    "prevPostPath": "2004/05/03/put-on-your-rss-colored-glasses-and-forget-about-atom",
    "nextPostPath": "2004/04/30/fun-with-shell-scripting"
  },
  {
    "comments_archived": true,
    "date": "2004-04-30T13:06:11.000Z",
    "excerpt": "I went a little nuts tonight with shell scripting.",
    "layout": "post",
    "tags": [
      "colophon"
    ],
    "title": "Fun with shell scripting",
    "wordpress_id": 517,
    "wordpress_slug": "fun-with-shell-scripting",
    "wordpress_url": "http://www.decafbad.com/blog/?p=517",
    "year": "2004",
    "month": "04",
    "day": "30",
    "isDir": false,
    "slug": "fun-with-shell-scripting",
    "postName": "2004-04-30-fun-with-shell-scripting",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/04/30/fun-with-shell-scripting",
    "prevPostPath": "2004/05/02/feed-validation-confusion",
    "nextPostPath": "2004/04/30/has-it-been-quiet"
  },
  {
    "comments_archived": true,
    "date": "2004-04-30T03:36:28.000Z",
    "excerpt": "I know I've been Rip-van-Winkeling it in the blogosphere, but has it been getting quieter around here?",
    "layout": "post",
    "title": "Has it been quiet?",
    "wordpress_id": 516,
    "wordpress_slug": "has-it-been-quiet",
    "wordpress_url": "http://www.decafbad.com/blog/?p=516",
    "year": "2004",
    "month": "04",
    "day": "29",
    "isDir": false,
    "slug": "has-it-been-quiet",
    "postName": "2004-04-29-has-it-been-quiet",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/04/30/has-it-been-quiet",
    "prevPostPath": "2004/04/30/fun-with-shell-scripting",
    "nextPostPath": "2004/04/29/look-its-a-post-about-not-posting"
  },
  {
    "comments_archived": true,
    "date": "2004-04-29T05:06:57.000Z",
    "excerpt": "Yeah, so this blog thing.  I finally switched it over to the stuff I've been fiddling with in silence for months - and then I proceeded to immediately shut back up.",
    "layout": "post",
    "title": "Look, it's a post about not posting!",
    "wordpress_id": 515,
    "wordpress_slug": "look-its-a-post-about-not-posting",
    "wordpress_url": "http://www.decafbad.com/blog/?p=515",
    "year": "2004",
    "month": "04",
    "day": "29",
    "isDir": false,
    "slug": "look-its-a-post-about-not-posting",
    "postName": "2004-04-29-look-its-a-post-about-not-posting",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/04/29/look-its-a-post-about-not-posting",
    "prevPostPath": "2004/04/30/has-it-been-quiet",
    "nextPostPath": "2004/04/26/this-is-not-my-beautiful-blog"
  },
  {
    "comments_archived": true,
    "date": "2004-04-26T05:28:13.000Z",
    "excerpt": "There've been numerous reasons for my semi-disappearance, but I think I'd finally like to come back now.",
    "layout": "post",
    "tags": [
      "colophon"
    ],
    "title": "This is not my beautiful blog",
    "wordpress_id": 514,
    "wordpress_slug": "this-is-not-my-beautiful-blog",
    "wordpress_url": "http://www.decafbad.com/blog/?p=514",
    "year": "2004",
    "month": "04",
    "day": "26",
    "isDir": false,
    "slug": "this-is-not-my-beautiful-blog",
    "postName": "2004-04-26-this-is-not-my-beautiful-blog",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/04/26/this-is-not-my-beautiful-blog",
    "prevPostPath": "2004/04/29/look-its-a-post-about-not-posting",
    "nextPostPath": "2004/02/13/colloquy-irc"
  },
  {
    "comments_archived": true,
    "date": "2004-02-13T02:50:53.000Z",
    "layout": "post",
    "title": "Colloquy, an insane IRC client for OS X",
    "wordpress_id": 513,
    "wordpress_slug": "colloquy-irc",
    "wordpress_url": "http://www.decafbad.com/blog/?p=513",
    "year": "2004",
    "month": "02",
    "day": "12",
    "isDir": false,
    "slug": "colloquy-irc",
    "postName": "2004-02-12-colloquy-irc",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/02/13/colloquy-irc",
    "summary": "WebKit is so insanely easy to use that I'm amazed every OS X application doesn't do it somewhere, just for the fun of it. Maybe they do.\nSource:The Fishbowl: A Confluence GUI Client in 200 Lines of Code\n\nA new major feature of Colloquy 2 are the extensible conversation styles. Styles are simple OS X bundles wraped around a CSS file (at minimum) or a CSS file and a XSL file. Knowing this, the fact that Colloquy uses XML to store chat messages that come in over the network is no surprise to some. Pairing these three technologies gives us great flexibility when processing and displaying a message on screen.\n\nThe process of formatting a message follows these steps, start to finish. First, wrap the message in a simple XML envelope, encoding any special characters and representing IRC styling as XHTML. This XML envelope gets transformed with the curent style's XSL file (or a built-in default XSL file). The resulting transformation from the XSL on the XML should be XHTML that can then be rendered with help from the style's CSS file. Rendering is done via Apple's Safari (WebKit) engine -- so the possibilities are endless (evidenced by the built-in iChat like Bubbles style).\nSource:Colloquy: Developers\n\n\nColloquy is an IRC client for OS X that I just discovered this week,\nvia an article posted on MacSlash.\nI've been looking for a decent Cocoa-based app as an alternative\nto my use of X-Chat Aqua,\nConversation, and\nirssi.  Having never heard of Colloquy before,\nI figured I'd check it out.\n\n\n\nColloquy is a Cocoa app, and the source is available.  It's the first OS X\nIRC client I've played with yet that most resembles what I expect out of a modern\nCocoa app.  Conversation is right there, too, but I don't see any source (no\noffence to the author) and it doesn't yet support multiple servers or AppleScript\n(although those are on the planned features list).\n\n\n\nBeyond all that, though, what has sucked me into Colloquy is the way IRC messages are\npresented and styled.  In case the introductory quotes haven't given you the idea, this\nthing pipelines XML, XSL, CSS, HTML, Javascript, and WebKit to provide\nan immensely flexible user-customizable, modular display style system.\nThere aren't that many styles yet, but conceivably anything one could\ndo with the pile of technologies above can be employed in presenting IRC\nmessages.\n\n\n\nYes, you could make the case that this is an insane example of overkill.\nIf so, Conversation or a shell-based program is likely more your speed.\nAdmittedly, Colloquy is not a featherweight IRC client.\nBut I've been thinking about this sort of inversion of web tech for awhile.\nInstead of the browser hosting the app, the app hosts the browser.  I've been\ndoing a ton of tinkery UI work with HTML and JavaScript in my\nnews aggregator and have come\nto appreciate the DOM and various things JavaScript makes possible in modern\nbrowsers.\n\n\n\nThis has lately lead me to consider how a browser canvas\ncould be used as a sort of universal widget inside a native app... not at\nall unlike the way Colloquy uses it.  Apple's WebKit encapsulation makes it\njust about dead simple\nto drop it into an app and integrate it.  In fact,\nfrom a shallow glance at the docs for WebKit, it seems even simpler to use than\nsome other GUI widgets in the Cocoa arsenal.\n\n\n\nSo...  is this the start of more Cocoa apps embedding WebKit views, \"just for the\nfun of it\"?  Who knows, but it really appeals to my propensity for mixing and\nmatching different tech within the same project.  I suppose it's a sort of sick\naddiction I've picked up from the Tower of Babel web development I've been doing\nfor years, but it looks like fun to me!",
    "prevPostPath": "2004/04/26/this-is-not-my-beautiful-blog",
    "nextPostPath": "2003/12/05/hacking-infinite-and-cognition"
  }
]