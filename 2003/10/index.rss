<?xml version="1.0" encoding="UTF-8"?>
  <rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
      <title>blog.lmorchard.com</title>
      <description>It&#39;s all spinning wheels &amp; self-doubt until the first pot of coffee.</description>
      <link>https://lmorchard.github.io/blog.lmorchard.com</link>
      <atom:link href="https://lmorchard.github.io/blog.lmorchard.com/index.rss" rel="self" type="application/rss+xml" />      
      <item>
          <title>Panther, forgotten connections, and no more lockups</title>
          <description>Oh yeah, and, just noticed this upon arriving at work.  In the past 6 months, forgotten mounted shares and the subsequent filesystem-related lockups and beach-ball-spinnings in Jaguar have been my sole reason for reboot.


As it would happen, I forgot to disconnect from shares on my home LAN again, and awoke my PowerBook on the work LAN.  Before Panther, this would have lead to a reboot within 10 minutes.  This time, it did the Right Thing.  Yay hooray!


Oh, and the Grab application works for individual windows now-- something which seemed to always be greyed out before.</description>
          
          <pubDate>Wed, 29 Oct 2003 14:14:03 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2003/10/29/panther-and-forgotten-connections/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2003/10/29/panther-and-forgotten-connections/</guid>
        </item><item>
          <title>Late to the Panther party</title>
          <description>I know I&#39;m late to the blogosphere release party for Panther, but I just got it last night and, biting the bullet, installed it with only minimal effort toward backing things up.  I intend to eventually wipe this PowerBook completely and install fresh, but I couldn&#39;t wait.  :)


Mark Pilgrim published the most definitive coverage of the beastie I&#39;ve seen yet, with help of the denizens of #joiito to manage the onslaught of readers.  So, I won&#39;t make any attempt to catalog the new things.


A few impressions though:


Everything feels faster.  Windows slide around and resize like they&#39;ve been waxed underneath.  Things seem to launch faster.
A few small things have improved, like System Preferences quitting when I close the window, rather than hanging around waiting for me to open the window again or quit.
Some third-party extension I had installed threw Finder into a launch-and-crash loop for awhile.  So, if you&#39;ve yet to install, try to purge your system of extensions first.  This should be obvious, but is sometimes a surprise when it&#39;s actually a problem.
Expose looked like a neat feature when I first heard of it.  I fully expected it to be slow, stuttery, and &#39;cute&#39; when I finally played with it.  Now, having used it and slowly incorporating it into my usage habits, it&#39;s amazing.  Smooth and not stuttery at all, it looks like a computer interface feature from the movies.
Fast user switching, where desktops rotate in and out of view, also looks like you wish it would, and seems like it&#39;s from the movies.
I hate metal.
I hate metal.
I hate metal.


That is all.  For now.  Maybe.</description>
          
          <pubDate>Wed, 29 Oct 2003 13:38:46 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2003/10/29/late-to-the-panther-party/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2003/10/29/late-to-the-panther-party/</guid>
        </item><item>
          <title>A thought about the Nokia N-Gage</title>
          <description>After playing with an N-Gage, I think sidetalkin.com is freakin&#39; hillarious.  One thought on this sidetalking thing, though:


At least it keeps the screen from getting all schmutzed.  My Treo 300 screen gets absolutely filthy, due to me pressing the slab up against my head to talk.  Also, there seems to be a defect in the LCD developing, which seems to have something to do with, again, being pressed up against my face.


In most other ways, this thing looks to be a flop...  but the sidetalking thing might just not be such a bad idea.</description>
          
          <pubDate>Wed, 29 Oct 2003 13:06:02 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2003/10/29/nokia-ngage-schmutz/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2003/10/29/nokia-ngage-schmutz/</guid>
        </item><item>
          <title>Seeking Out Opposites</title>
          <description>For the past year or two, I&#39;ve been trying an experiment in my
personal research and learning.  I&#39;ve been seeking out tools and
technologies which are as different as possible from those with which
I already have experience.  I want to break up some prejudices and
habits I have, and expose myself to more ways of looking at things.
Now that I write this, it sounds like a great approach to life in
general, but for now I&#39;m focusing on computer science.  :)



My success 
with this has been entirely dependant on free time and brain cycles,
of which I&#39;ve had precious little.  But, I have managed to wean myself
away from Perl to learning Python, developing a few apps with it and
incorporating it into my problem solving kit.  I&#39;ve also managed to
get myself away from XEmacs for hours at a time in order to weave Vim
into my work-a-day life.  These two things haven&#39;t been easy for me,
since I&#39;ve been using both Perl and some variant of Emacs for almost
12 years now, and I&#39;ve done my share of sneering at that which is not
perl or emacs.  



And, although I&#39;ve yet to spring upon them, I&#39;ve also been making wary, 
narrowing circles around Lisp, Smalltalk, Prolog, and .NET.  There
been occasional forays into Java, as well as my daily attachment to
Flash and Actionscript lately.  And then, there&#39;ve been my hefting and
swinging of XSLT and XPath, as well as RDF, countered by a few feints
with plaintext shell tools and YAML.  There&#39;s been more, but most
investigations have been too tentative to mention.



If there&#39;s a &quot;holy war&quot; between two things, I want to explore them both.
I tend to see two apparently intelligent parties in an extended debate
over which of them has a hold on the One True Way.  In my
experience, though, there&#39;s a high likelyhood that such a phenomenon
points toward a real truth which lies somewhere inbetween.  (This, of
course, ignoring such cases where one party is correct, and the other
is WRONG, WRONG, WRONG!)  There tend to be very good reasons why smart
people on either side of a fence have taken up with what they have,
and I want to know both sides thoroughly.  I know full well that both
sides have at least some valid criticisms against the other, but I
want a synthesis of the two.



In this field of computer science, there
are as many ways of working with the dreamstuff as there
are ways of structuring thoughts.  And, rather than there ever being
One True Way to do things, there will always be another smart person
developing another powerfully expressive and insightful way of doing
things.  Someday, I&#39;d like to be one of those smart people, so I need
to have a sense for that truth in the middle that other One True Ways 
bracket and zero in on.  And then, I want to know enough to jump out
of the frame altogether, and in which ways I can invert and twist
things to encircle some new spark.



Someday in the next few years, I&#39;d like to get back into school so I
can get to even higher levels of growing up to be a computer scientist.
But for now, it&#39;s back to work for me.  And, if you happen to think of
any geeky holy wars, let me know.  I&#39;m collecting them for study.</description>
          
          <pubDate>Thu, 16 Oct 2003 17:19:17 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2003/10/16/seeing-out-opposites/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2003/10/16/seeing-out-opposites/</guid>
        </item><item>
          <title>When RSS Developers Attack</title>
          <description>I agree with Derek Balling [who criticized Foo Camp], and when you come back to earth, I bet you will too Jeremy.
Did I read that you guys had meetings about RSS? At a private invitation-only event? Do you realize how WRONG that is?

Source:Dave Winer in a comment on &quot;Some Foo Camp Links&quot;


One of the sessions on Sunday morning at FOO Camp was a brainstorming session on how a site could provide a list of feeds.
...A working name for this effort is &quot;FDML&quot;.  The stands for Feed (Discovery / Directory / Detailing) Markup Language, depending on who you ask. ;-)

Source:Sam Ruby: FDML


Just so it is absolutely clear: all I have done is listed a set of requirements, many if not most of which are directly from Jeremy himself.  The acronym was suggested by David Sifry.
People are welcome to question, refine, or add to the requirements, or present proposals on how these requirements can best be implemented.  Perhaps even with OPML.

Source:A later comment on Sam Ruby: FDML


For anyone who wonders why people talk about politics and animosity in
the tiny sphere of web syndication tech, here&#39;s a case in point.



You see, there was a private event over the weekend, called Foo Camp.
To this, many smart people were invited, and many more weren&#39;t.
Grousing about invitations, funding, and elitism aside, it sounded
like a great time and a cool change from your average conference.  I
hope it turns into a regular event, and hope that someday I&#39;m given
the opportunity to go to something like it.  I&#39;m sure a lot of us
out here would like to make it to something like that.



But, for what it was, you can only gather so many people before it
becomes a circus (or a conference).  Charging a price serves as a
limiter, while making the event invitation-only works as well.  The
difference is whether you&#39;re bringing in people who can afford it
versus people who are favored by the organizer.  Either way, someone&#39;s
going to be pissed about not going.  The difference is whether you&#39;re
pissed off at the organizer&#39;s economics or the organizer&#39;s
personality.  Oh well.



So anyway, around mid-September, Jeremy Zawodny had floated
an idea
involving publishing and discovery of lists of RSS feeds.
He was one of those invited to Foo Camp, and in one of their
huddles, he brought the idea up for a brainstorming session.
From the sounds of it, they tossed around a few ideas, but
didn&#39;t really come up with much other than that it was an idea
worth discussing.



No sooner than the camp breaks up, though, and the angry buzz
has already started.  How dare a bunch of geeks talk about
technology they&#39;re interested in while at a private gathering?
How dare they not invite all of us?  Conspiracy!  Elitism!
They didn&#39;t pick me for their kickball team!  By the way,
this isn&#39;t an attempt to put words in mouths.  This is my
off-the-cuff impression of what I read yesterday.  It all
seems repeatedly and unnecessarily childish to me, and it&#39;s
certainly not limited to one person.



So, by today, there&#39;s already
a wiki
devoted to exploring this idea, along with a scattering of blog
posts. This seems pretty speedy to me,
considering campers returning to the work-a-day world after
a geek retreat.  This doesn&#39;t seem at all the work of a sinister
cabal bent on wresting control and domination over a technology,
as what I saw implied in the first comment I quoted above.



Dave Winer&#39;s already posted a
first proposal
toward implementing the idea.  And, believe it or not, as Sam comments
on above, this approach has not been ruled out.  In fact,
Jeremy had suggested using OPML in his original posting of the idea.



Why couldn&#39;t we just have seen the collaboration without the
antagonism, in at least this case?  Yeah, there was a small, private
gathering at which discussions were had.  Sounds like what happens at
work, or with friends, or in classes.  Granted, I suppose an argument
could be made concerning the relative openness of these gatherings as
compared to Foo Camp.  But, this is mooted by the fact that the
people involved were already moving toward sharing the discussion.



For all the grousing about flame wars and personality clashes on
mailing lists and working groups, sometimes it&#39;s nice to work on an
idea in a smaller group with a good dynamic.  It helps to get
something together before throwing the doors open to have the thing
buffeted by opinions and criticism from all sides.  It&#39;s one way to
avoid &quot;stop
energy&quot; while trying to build some momentum.



As Dave himself wrote, &quot;I heard at a working group meeting that things
like SOAP can only happen when no one is paying attention.&quot;  So, it
sounds like a bunch of geeks tried to get something rolling before the
attentional heat lamps turned on it.  Had they wanted to be a sinister
cabal, we certainly wouldn&#39;t have heard about any of this until long,
long after the event.  It would have been kept behind closed corporate
doors until the day of embrace-and-extend.  Then, profit!  As it is, I
think they erred on the side of throwing open the discussion
too early.



So anyway, the reason I write at such length about this is that I
don&#39;t think that this should be let to pass without comment or
consideration.  This kind of thing is what&#39;s wrong.  We need to take
at least three deep breaths before reacting like this, whether
or not we&#39;ve taken 900 beep breaths in the past already.  It&#39;s the
nature of these things.  As an interested but outside observer, the
atmosphere created by such reactions makes me very sad.  And it&#39;s not
just one person doing this, either.



So, chill out.  It&#39;s just data.  In fact, the proposal at question
here is just a friggen outline of feeds!  It&#39;s just a list of
lists!  Most of the geeks out there just want to play, and are happy
to have more geeks to play with.  Can&#39;t we just get along and play the
game together, rather than gaming each other?</description>
          
          <pubDate>Tue, 14 Oct 2003 15:05:34 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2003/10/14/when-rss-attacks/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2003/10/14/when-rss-attacks/</guid>
        </item><item>
          <title>Microcontent and RSS-Data</title>
          <description>In response to the opposition to RSS-Data,
Marc asks,
&quot;Where are the Reviews, Resumes, Recipes, Topics and other cool new
forms of micro-content?&quot;


Well, I did a bit of Googling this morning, and this is what I found:



On the subject of reviews, A.M. Kuchling
has provided an
RDF namespace
for embedding book review metadata within XHTML documents.


For resumes,
Uldis Bojars
has been working on an
RDF schema for resumes and CV.


To offer up recipes, I found
this RDF schema
for recipes hosted on
donnafales.com.


As for topics, well, there&#39;s already a straight RSS 2.0 namespace
extension called Easy News Topics.


And, finally, for events there is
mod_event,
and RSS 1.0 module used for presenting calendar event information.



Yes, with the exception of ENT, these are RDF schema or namespaces.
But, any one of them could likely be adapted to straight XML and used as an RSS 2.0
namespace, thereby leveraging the work these people have already done
in modeling these kinds of content, as well as potentially providing
an easy transformation path to RDF for those who care.


What does RSS-Data provide out of the box which makes any of the
above obsolete?  There&#39;s no magic here, other than translating between
raw data sctructures.  You&#39;ll still need to do the same sort of
modeling and structure work that the authors of all the above have
done.  It&#39;s always nicer to have someone else do homework for you.


So, if all this new microcontent is so hot, why hasn&#39;t anything like
the above been put into use?  Would adding 5 new tags to an RSS
feed really be an insane burden to express calendar events?  Granted,
some of the other examples above are more complex, but then so are
the things they seek to represent.


What&#39;s the RSS-Data magic that improves on all the above?</description>
          
          <pubDate>Wed, 08 Oct 2003 12:30:52 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2003/10/08/microcontent-and-rss-data/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2003/10/08/microcontent-and-rss-data/</guid>
        </item><item>
          <title>Schemas, Freedom, and Control</title>
          <description>I&#39;ll be at the Enterprise Architect Summit in Palm Springs next week,
on a couple of panels. One&#39;s entitled Schemas in the wild: XML takes
on the vertical industries, and the panelists are Jon Bosak and Jean
Paoli. The single most important question I&#39;d like to ask these guys
is: how do we strike the proper balance between freedom and control?
By freedom I mean incremental and iterative evolution of data
structures in response to patterns of real-world use. By control I
mean the predictable regularity enforced by a DTD or XSD.

Source:Jon Udell&#39;s weblog, XML vocabularies: freedom and control

For quite awhile now, Jon Udell&#39;s been asking the same
sorts of questions as I did in my longwinded write-up yesterday.</description>
          
          <pubDate>Tue, 07 Oct 2003 15:12:49 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2003/10/07/schemas-freedom-and-control/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2003/10/07/schemas-freedom-and-control/</guid>
        </item><item>
          <title>RSS-Data and Schema: Thinking about structure and data</title>
          <description>Dare Obasanjo has provided some initial bullet points of what a vocabulary gets from having an XML Schema :

 * Usually provides a terse and concise description of
 the vocabulary [relative to the prose of the spec]

* Enables software to validate that XML documents
 being received from clients or servers actually
 conform to the vocabulary. This prevents issues like
 each application hacking up its own validator or
 &quot;liberal RSS parser&quot;. 

* Allows vocabulary to co-exist with technologies and
 tools that already support features specific to a
 schema language such as relational to XML mapping,
 object to XML mapping, directed editting, etc.

Source:Finally Atom: Why use schema?

Danny [Ayers]: &quot;...and the same can already be done using RSS 1.0 as it stands.&quot;

But are we talking about the same &quot;same&quot;?  The appeal of RSS-Data is that I don&#39;t need to work up a schema, get anyone to buy-in, or map anything to an external resource... I take an existing data structure, and plug it into a syndication feed. That&#39;s it.

Source:Roger Benningfield in a comment on his &quot;RSS-Data: A Working Demo&quot; 

Yes - we know that RDF can do many of the things RSS-Data was designed for.? But (believe it or not) it really has nothing to do with RSS 1.0 at all.? RSS-Data is about extending RSS 2.0.? OK?? Not RSS 1.0.

The point here being that the world is bi-forcated and what do we do?? Can&#39;t we all live together?? Can&#39;t we put our heads together and come up with solutions that BRIDGE between these two standards - which just happen to have almost the same dam name?

I gotta believe there&#39;s a way that once we &quot;structure&quot; something - like a Calendar Events, Resumes, Recipes or Reviews - we SHOULD be able to express and subscribe to these micro-content?formats - via EITHER RSS 1.0 or RSS 2.0.

OK - get it?? BRIDGE BETWEEN BOTH RSS 1.0 &amp; RSS 2.0.? That&#39;s what we want.? BOTH!
Source:Marc&#39;s Voice: We want BOTH RSS 1.0 &amp; RSS 2.0!

So, it looks like this RSS-Data thing is gaining momentum and demos, so I&#39;m guessing that it&#39;s going to become one of the thing us rock-bangers will have to contend with at some point or another in tinkering with things in syndication and interoperability.  I have my misgivings about it, which mostly center around the issue of schema.

See, the goal of RSS-Data, as I understand it, is to bridge raw data from one programming environment to another, and package it up to be syndicated within RSS feeds for which an existing infrastructure already exists.  So, it&#39;s &quot;easy&quot;.  Just throw your data structures at a library, which serializes them into some magic XML.  At the receiving end, another library, written possibly in a different language altogether, transliterates the magic XML into local idiomatic data structures.  You never think much about XML, nor does the consumer of your data.

But...  we&#39;re still talking about structures here.  Whether they&#39;re represented by XML tags, RDF triples, RDF/XML serialization, or hashtables and arrays-- there&#39;s still a structure involved.  From whence did it come?

About RSS-Data, Roger Benningfield writes, &quot;...I don&#39;t need to work up a schema...&quot;, which is literally true.  He goes on to write, &quot;I take an existing data structure, and plug it into a syndication feed. That&#39;s it.&quot;

From where did this &quot;existing data structure&quot; originate?  For my examples, I used an existing schema from the Amazon web services.  Where&#39;d you get yours?

I&#39;d guess that you got it from somewhere in the bowels of your scripts, a hash or rough structure once limited to intra- or inter- module data exchange, but now pressed into service as a unit of interoperation.  I wouldn&#39;t expect that you&#39;d put much specific effort toward making this data structure particularly concise or friendly for interoperation.  This might not be a big deal for now.  And anyway, why bother with it?  That&#39;s not the philosophy with this tech, as far as I understand it.  The idea, is that hopefully this data structure is already good enough for sharing.  And, luckily enough, this is sometimes the case.

On the other hand, maybe you&#39;re sitting down to come up with a new data structure for sharing, from scratch.  During this activity, I imagine that you&#39;ll be mulling over what goes where, what&#39;s contained by what, what this hash or dictionary key means versus that one.  You&#39;ll likely be deciding whether to use a string here, or a date time here, and you&#39;ll likely have some idea about ranges of values for various things.  This is a bit more abstract an activity than you may have gone through, were you simply creating an internal data structure for your app.  In this case, you&#39;d likely be thinking more about the data in and of itself, rather than the specific needs of your app and its API. In my opinion, this is a bit better for sharing.

But, how&#39;s your documentation?  Will I be able to reliably accept data from your application by just looking at a write-up or a rough spec?  Will I have to walk through your source code to reverse engineer general usage?  Will I have to examine RSS-Data dumps to come up with a rough approximation of what to expect from your data structure?  If this is a data structure plucked from the depths of your script, who knows?  If this structure was designed specifically for sharing, I hope that you&#39;ve documented as you go along.

What RSS-Data makes me worry about is an abundance of fuzzy, adhoc structures for interchange that no one ever quite documents well enough because they&#39;re too busy hacking along and pushing things out the door.  Maybe they&#39;ll be good enough, given discipline and thoughtfulness, but then maybe they&#39;ll end up in a mess.  But, just like many scripting languages, there are no facilities in RSS-Data currently to either require or even merely encourage clean and documented interchange structures.

This is a code-first-schema-later approach:  The schema stems, eventually, from general usage and tradition, and if we&#39;re lucky, from documentation.  If the people hacking on the project have discipline and are thoughtful, this documentation will be well maintained, and changes well communicated.  It can be a train-wreck, but it doesn&#39;t have to be.

On the other hand, we can circle back to that Amazon Web Services schema I used in my previous examples.  This technology, XML Schema, represents the opposite approach: schema-first-code-later.  In coming up with such a schema, I think still think about information and data structures just as I would while hacking on a script and thinking about a native data structure for sharing.  It&#39;s just that, with this approach, I&#39;m doing things in a different order and front-loading the thinking. 

But, there&#39;s more: if I build something like an XML Schema, I&#39;m creating something which is both documentation and a machine readable resource.  I&#39;m sure someone out there is working on or has released tools or stylesheets to convert XML Schema into HTML or RTF or something human readable.  Hell, you could even apply some transformation to the schema to generate code or data entry forms.

Once I have a schema, implementing code to produce and handle XML data conforming to it isn&#39;t really all that much harder than using straight RSS-Data.  This is an item for much dispute, but my gut and limited experience tells me that the difference in complexity will usually be more like a dozen lines of code or less in a decent environment rather than, say, an order of magnitude.  I think we&#39;ll find that things will tend to be consistent with Phillip Pearson&#39;s example implementations of an RSS namespace extension versus an RSS-Data example.

What we get for the added complexity, though, is certainty.  I can say, &quot;Here.  This is a URL to the schema for the XML data my application produces.&quot;  If I&#39;ve lived up to my end 
of the bargain, you won&#39;t even need to see my application&#39;s code or documentation.  You can implement with the schema, and our apps will interoperate.  We can treat the data formats as separate entities from applications.  In other words, we can treat interchange as neutral ground.

The problem, of course, is that this business with schema carries with it a bit of overhead, as well as a demand that you do some homework.  You&#39;ll need to know more than your immediate programming environment.  You&#39;ll need to think about XML and XML schemas, and you can&#39;t just stay in your comfortable favorite environment of programing language idiom.  This is off-putting to some, to say the least.

So...  how about Marc&#39;s question?  &quot;Can&#39;t we all live together?? Can&#39;t we put our heads together and come up with solutions that BRIDGE between these two standards - which just happen to have almost the same dam name?&quot;  On the one side, I see hackers who want to get down and code, and who consider themselves and each other thoughtful and disciplined enough to do the right thing and prevent trainwrecks.  On the other side, I see hackers who want to put discipline and thoughtfulness upfront and in writing (or typing?) before they code, because they don&#39;t really trust themselves or others to keep from wrecking the trains all the time.

Personally, I want to live somewhere in the middle.  Just enough distrust of myself and others to discourage sloppy problems, but not too much so that I have to trudge through careful molasses to get anywhere.

I don&#39;t think I&#39;m thrilled with RSS-Data.  But if you&#39;re going to use RSS-Data anyway, but here&#39;s one thought out of all this:  Is there some way we could come up with an RSS-Data-analogue for schema?  Forget about XML schema and standards groups and the like.  Think about some semi-universal way of translating meta-data-structures composed within one&#39;s favorite scripting language which forms documentation and a promise about what to expect over the wire?  If done right, maybe we could even generate an XML schema with this, and that could be a bridge between the two approaches.  On the surface, it sounds like a wonky idea to me, but hey...

Thanks for bearing with me through this much-longer-than-usual post.  :)</description>
          
          <pubDate>Mon, 06 Oct 2003 22:52:44 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2003/10/06/rss-data-and-schema/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2003/10/06/rss-data-and-schema/</guid>
        </item><item>
          <title>RDF representations of HTTP transactions?</title>
          <description>13:52:29 &lt;monkeyiq&gt; is there a notation for capturing browse
histories in rdf?

13:53:25 &lt;DanC&gt; good question, monkeyiq... I wanted something
like that a while ago...

13:53:30 &lt;DanC&gt; I didn&#39;t find anything in particular.
Source:#rdfig: hypertext histories and RDF schemas for HTTP

For what it&#39;s worth, I&#39;m looking for this too.  I&#39;ve done a little bit
of work in cobbling together some RDF representations of HTTP transactions,
in order to record browsing history in a rich way.  I&#39;ve
basically just been mapping from HTTP/1.1
header fields to RDF properties.  It&#39;s been a little while, but I seem to remember that both 
dbproxy&#39;s metaminer plugin
and
AgentFrank&#39;s MetaMiner plugin
have implementations toward this end.  Sooner or later, I&#39;ll get back to one project or
the other, and I&#39;d really like someone else to do my homework on this. :)</description>
          
          <pubDate>Mon, 06 Oct 2003 19:45:12 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2003/10/06/http-in-rdf/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2003/10/06/http-in-rdf/</guid>
        </item><item>
          <title>A quick SOAP primer via IRC (but not SOAP via IRC)</title>
          <description>After making those RSS namespace examples, I was thinking aloud about
SOAP on #joiito yesterday and how it compares to what I did with the Amazon
data.  Sam Ruby
happened to be in the room:

&lt;rubys&gt; deusx: want a quick primer?

&lt;deusx&gt; rubys: I&#39;d love one, though unfortunately at the moment,
I&#39;m about to be off to a meeting :(

f8dy would like a quick primer

&lt;rubys&gt; This is really quick.  Take some XML.  XML that doesn&#39;t
have a DTD or any PI&#39;s.  Put it in a soap:Body.  Put the soap:Body in
a soap:Envelope.  Voila&#39;, you have valid document literal SOAP.

That was a quick primer, and though I know there&#39;s more to
it, putting it like that makes me see SOAP a little differently.</description>
          
          <pubDate>Fri, 03 Oct 2003 13:28:17 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2003/10/03/a-quick-irc-soap-primer/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2003/10/03/a-quick-irc-soap-primer/</guid>
        </item><item>
          <title>RSS 2.0 namespace versus RSS-Data, Part 3: Electric Boogalee</title>
          <description>So, for the same of argument, yesterday I threw together
examples
of what a use of RSS-Data might look like alongside what
the same data in an RSS namespace extension might look like.
I promised code, but never got a chance to circle back around.
Fortunately, Phillip Pearson
connected the rest of the dots for me with two examples:


Parsing RSS-Data
Parsing an RSS namespace extension


I was just a little surprised by his results, since I expected
the code to handle an RSS namespace to be at least a bit more complex
than the RSS-Data example.  But,
as Phillip observed later,
the scripts were pretty much equivalent in length, complexity, and
ease of construction.


Then, this morning, I saw that Danny Ayers had posted an
example in RDF
of this same data.  It doesn&#39;t differ very much from my namespace
extension example, except that the few differences there are enables
his example to flow through RDF tools (as well as, usually, XML tools like
XPath and XSLT).


In a comment
on one of Phillip&#39;s posts, though, Roger Benningfield makes
the point that this example is a bit biased:


I agree that there won&#39;t be a ton of difference between a struct full
of strings and plain ol&#39; XML. But that&#39;s kind of a stacked example,
since SDL would allow a lot more than that... arrays, integers, and
arrays of integers inside structs.


What I did could be obscuring some work.  I just took an existing
schema from Amazon, which gave me some initial work already for free.
(Though, there&#39;s something to be said for that in and of itself.)
The structures were already established, and the schema was created
with XML representation already in mind.  This could have placed
RSS-Data at an example.  While I really don&#39;t think
that XML-RPC serialization offers more flexibility in expression than
XML itself, I could be wrong and I don&#39;t want to be tilting
at straw men.  


So, while I doubt that I&#39;ll have a whole lot of time today, I think
for the same of completeness, someone should go through the parallel
processes of going from problem statement up through data modeling and
on to production and consumption of RSS-Data and an RSS namespace
extension.  While doing this, capture the work involved in both.


I could see shortcuts taken on the RSS-Data side, since you don&#39;t have
to be concerened with various bits of XML tech like DTDs or schema
or whatnot.  You can jump right into coding up an example usage and
come up with your data model on the fly.  Whether this is a good thing
or not, I&#39;m sure many will disagree.  Also, I&#39;m sure others would
go through this differently than I would.  Again, your mojo may
exceed mine.


At this point, I can see the benefits of RSS-Data in rapidly cobbling
together scripts, but I lean toward having a decently defined data
model first.  You can do this in your scripts, but using the existing
XML tech forces you through some specific processes.  On the other
hand, I can see where some busy developers don&#39;t have time or spare
brain cycles to absorb all the XML tech.  It could be made easier
at that end of things, which is where I&#39;d rather spend my effort.


Anyway, I&#39;m really interested in seeing where this goes, because
this comparison of RSS-Data, RSS namespace extensions, and even
RDF seems like another very concrete, non-theoretical way to demonstrate
the benefits and drawbacks of these ways of thinking about data
and interoperability.</description>
          
          <pubDate>Fri, 03 Oct 2003 12:28:16 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2003/10/03/rss-data-versus-namespace-3/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2003/10/03/rss-data-versus-namespace-3/</guid>
        </item><item>
          <title>RSS 2.0 namespace versus RSS-Data, Part 2: First impressions</title>
          <description>Okay, I got
the example data out there.
Here&#39;s what&#39;s first on my mind about it:




Man, that RSS-Data is one verbose piece of XML.  The Amazon-specific
namespace version looks much more compact and readable; I&#39;d rather
View Source
on that one.




Python comes out of the box with
xmlrpclib,
and other languages have XML-RPC facilities available as well.  I can&#39;t imagine
it&#39;d be too hard to get a hold of the core of it and employ it in
unmarshalling the RSS-Data straight into idiomatic Python structures.
On the other hand, I&#39;ll need to write my own handlers for the Amazon XML
using the XML parser modules that come with Python.




With its clean, almost self-documenting structure, the Amazon XML is easily
handled with XPath and XSL.  If I had a pile of ProductInfo elements
in a document, I could yank out all their images with something like:
//az:ProductInfo/az:Details/az:ImageUrlSmall


Using the RSS-Data
example, it&#39;d probably be something more like:
//sdl:data/sdl:struct/sdl:member/sdl:name[@text=&#39;ImageUrlSmall&#39;]/../sdl:value,
and that&#39;s not considering if I have mixed kinds of RSS-Data schema represented in the
feed.


I suppose I could help this out by surrounding the struct with another
struct, containing one member named &#39;AzProductInfo&#39;, making the path something
like so:
//sdl:data/sdl:struct/sdl:member/sdl:name[@text=&#39;AzProductInfo&#39;]
/../sdl:value/sdl:struct/sdl:member/sdl:name[@text=&#39;ImageUrlSmall&#39;]/../sdl:value.





And these are the conclusions I&#39;m jumping to at the moment, before experimenting:




RSS-Data&#39;s convenience to script authors is at odds with the RSS 2.0
spirit of View Source.


Producing and consuming RSS-Data could be easier than handling
purpose-specific XML schema in scripts.


Since RSS-Data doesn&#39;t follow in the spirit of XML specs and schema,
using formal XML tools to handle this stuff will give you
nothing but headaches.  (Then again, it seems like some of the
stuff that&#39;s fully in the spirit of XML yields headaches just
the same.)


RSS-Data might catch on and spread nonetheless, because lots
of people don&#39;t read XML, don&#39;t use formal XML tools, and just
write scripts to get their jobs done.</description>
          
          <pubDate>Thu, 02 Oct 2003 16:26:02 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2003/10/02/rss-data-versus-namespace-2/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2003/10/02/rss-data-versus-namespace-2/</guid>
        </item><item>
          <title>An example of an RSS 2.0 namespace versus RSS-Data usage</title>
          <description>Okay, just for the sake of tinkering, I&#39;m poking at embedding data
from the
Amazon Web Services
into an RSS 2.0 feed.  On one hand, I just shoehorned the Amazon
XML schema into an RSS 2.0 namespace, and on the other, I tried
transliterating the Amazon XML data into
RSS-Data /
XML-RPC serialized data
structures.


To resolve my own love/hate of this RSS-Data idea,
I&#39;m planning to keep going from here and work up some simple Python
scripts to produce and consume data along the lines of both examples,
then to comment on the experience.  (This is assuming I don&#39;t run out
of round tuits.)  Some things to note:


Your XML mojo is probably stronger than mine,
so please feel free to correct me.

Although I created the RSS-Data example by hand, it would
otherwise be completely produced and consumed by machine.

Since it&#39;s at the root of a few things I&#39;m thinking,
it&#39;s worth restating:  RSS-Data is intended to be produced and
consumed by machine, not by humans.  This means that the XML
data needs not look pretty or elegant to you, but to your machine.





So, on with the XML.  First, I
requested data
from Amazon and got the following:


&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;ProductInfo
  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
  xsi:noNamespaceSchemaLocation=&quot;http://xml.amazon.com/schemas3/dev-lite.xsd&quot;&gt;
  &lt;Details url=&quot;http://www.amazon.com/exec/obidos/ASIN/0439139597/0xdecafbad-20&quot;&gt;
    &lt;Asin&gt;0439139597&lt;/Asin&gt;
    &lt;ProductName&gt;Harry Potter and the Goblet of Fire (Book 4)&lt;/ProductName&gt;
    &lt;Catalog&gt;Book&lt;/Catalog&gt;
    &lt;Authors&gt;
      &lt;Author&gt;J. K. Rowling&lt;/Author&gt;
      &lt;Author&gt;Mary GrandPr?&lt;/Author&gt;
    &lt;/Authors&gt;
    &lt;ReleaseDate&gt;08 July, 2000&lt;/ReleaseDate&gt;
    &lt;Manufacturer&gt;Scholastic&lt;/Manufacturer&gt;
    &lt;ImageUrlSmall&gt;http://images.amazon.com/images/P/0439139597.01.THUMBZZZ.jpg&lt;/ImageUrlSmall&gt;
    &lt;ImageUrlMedium&gt;http://images.amazon.com/images/P/0439139597.01.MZZZZZZZ.jpg&lt;/ImageUrlMedium&gt;
    &lt;ImageUrlLarge&gt;http://images.amazon.com/images/P/0439139597.01.LZZZZZZZ.jpg&lt;/ImageUrlLarge&gt;
    &lt;Availability&gt;Usually ships within 24 hours&lt;/Availability&gt;
    &lt;ListPrice&gt;$25.95&lt;/ListPrice&gt;
    &lt;OurPrice&gt;$18.16&lt;/OurPrice&gt;
    &lt;UsedPrice&gt;$3.97&lt;/UsedPrice&gt;
  &lt;/Details&gt;
&lt;/ProductInfo&gt;


From this, I cooked up an example RSS feed with Amazon&#39;s XML
schema shoehorned in as a namespace:

&lt;rss version=&quot;2.0&quot;
  xmlns=&quot;http://blogs.law.harvard.edu/tech/rss&quot;
  xmlns:az=&quot;http://www.amazon.com/gp/aws/landing.html&quot;
  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
  xsi:schemaLocation=&quot;http://www.amazon.com/gp/aws/landing.html
                      http://xml.amazon.com/schemas3/dev-lite.xsd&quot;&gt;
  &lt;channel&gt;
    &lt;title&gt;Testing Amazon Namespace&lt;/title&gt;   
    &lt;item&gt;
      &lt;title&gt;Harry Potter and the Goblet of Fire (Book 4)&lt;/title&gt;
      &lt;az:ProductInfo&gt;
        &lt;az:Details url=&quot;http://www.amazon.com/exec/obidos/ASIN/0439139597/0xdecafbad-20&quot;&gt;
          &lt;az:Asin&gt;0439139597&lt;/az:Asin&gt;
          &lt;az:ProductName&gt;Harry Potter and the Goblet of Fire (Book 4)&lt;/az:ProductName&gt;
          &lt;az:Catalog&gt;Book&lt;/az:Catalog&gt;
          &lt;az:Authors&gt;
            &lt;az:Author&gt;J. K. Rowling&lt;/az:Author&gt;
            &lt;az:Author&gt;Mary GrandPr?&lt;/az:Author&gt;
          &lt;/az:Authors&gt;
          &lt;az:ReleaseDate&gt;08 July, 2000&lt;/az:ReleaseDate&gt;
          &lt;az:Manufacturer&gt;Scholastic&lt;/az:Manufacturer&gt;
          &lt;az:ImageUrlSmall&gt;http://images.amazon.com/images/P/0439139597.01.THUMBZZZ.jpg&lt;/az:ImageUrlSmall&gt;
          &lt;az:ImageUrlMedium&gt;http://images.amazon.com/images/P/0439139597.01.MZZZZZZZ.jpg&lt;/az:ImageUrlMedium&gt;
          &lt;az:ImageUrlLarge&gt;http://images.amazon.com/images/P/0439139597.01.LZZZZZZZ.jpg&lt;/az:ImageUrlLarge&gt;
          &lt;az:Availability&gt;Usually ships within 24 hours&lt;/az:Availability&gt;
          &lt;az:ListPrice&gt;$25.95&lt;/az:ListPrice&gt;
          &lt;az:OurPrice&gt;$18.16&lt;/az:OurPrice&gt;
          &lt;az:UsedPrice&gt;$3.97&lt;/az:UsedPrice&gt;
        &lt;/az:Details&gt;
      &lt;/az:ProductInfo&gt;
    &lt;/item&gt;   
  &lt;/channel&gt;   
&lt;/rss&gt;


Then, I transliterated things into what I understand of RSS-Data:

&lt;rss version=&quot;2.0&quot;
  xmlns=&quot;http://blogs.law.harvard.edu/tech/rss&quot;
  xmlns:sdl=&quot;http://radio.weblogs.com/0113297/2003/10/01.html#a237&quot;&gt;
  &lt;channel&gt;
    &lt;title&gt;Testing Amazon Namespace&lt;/title&gt;   
    &lt;item&gt;   
      &lt;title&gt;A Sample Item&lt;/title&gt;
      &lt;sdl:data&gt;
        &lt;sdl:struct&gt;
          &lt;sdl:member&gt;
            &lt;sdl:name&gt;url&lt;/sdl:name&gt;
            &lt;sdl:value&gt;
              &lt;sdl:string&gt;http://www.amazon.com/exec/obidos/ASIN/0439139597/0xdecafbad-20&lt;/sdl:string&gt;
            &lt;/sdl:value&gt;
          &lt;/sdl:member&gt;
          &lt;sdl:member&gt;
            &lt;sdl:name&gt;Asin&lt;/sdl:name&gt;
            &lt;sdl:value&gt;&lt;sdl:string&gt;0439139597&lt;/sdl:string&gt;&lt;/sdl:value&gt;
          &lt;/sdl:member&gt;
          &lt;sdl:member&gt;
            &lt;sdl:name&gt;ProductName&lt;/sdl:name&gt;
            &lt;sdl:value&gt;
              &lt;sdl:string&gt;
                Harry Potter and the Goblet of Fire (Book 4)
              &lt;/sdl:string&gt;
            &lt;/sdl:value&gt;
          &lt;/sdl:member&gt;
          &lt;sdl:member&gt;
            &lt;sdl:name&gt;Catalog&lt;/sdl:name&gt;
            &lt;sdl:value&gt;&lt;sdl:string&gt;Book&lt;/sdl:string&gt;&lt;/sdl:value&gt;
          &lt;/sdl:member&gt;          
          &lt;sdl:member&gt;
            &lt;sdl:name&gt;Authors&lt;/sdl:name&gt;
            &lt;sdl:value&gt;
              &lt;sdl:array&gt;
                &lt;sdl:data&gt;
                  &lt;sdl:value&gt;J. K. Rowling&lt;/sdl:value&gt;
                  &lt;sdl:value&gt;Mary GrandPr&lt;/sdl:value&gt;
                &lt;/sdl:data&gt;
              &lt;/sdl:array&gt;
            &lt;/sdl:value&gt;            
          &lt;/sdl:member&gt;
          &lt;sdl:member&gt;
            &lt;sdl:name&gt;ReleaseDate&lt;/sdl:name&gt;
            &lt;sdl:value&gt;
              &lt;sdl:dateTime.iso8601&gt;2000-07-08T00:00:00&lt;/sdl:dateTime.iso8601&gt;
            &lt;/sdl:value&gt;
          &lt;/sdl:member&gt;          
          &lt;sdl:member&gt;
            &lt;sdl:name&gt;Manufacturer&lt;/sdl:name&gt;
            &lt;sdl:value&gt;&lt;sdl:string&gt;Scholastic&lt;/sdl:string&gt;&lt;/sdl:value&gt;
          &lt;/sdl:member&gt;
          &lt;sdl:member&gt;
            &lt;sdl:name&gt;ImageUrlSmall&lt;/sdl:name&gt;
            &lt;sdl:value&gt;
              &lt;sdl:string&gt;http://images.amazon.com/images/P/0439139597.01.THUMBZZZ.jpg&lt;/sdl:string&gt;
            &lt;/sdl:value&gt;
          &lt;/sdl:member&gt;          
          &lt;sdl:member&gt;
            &lt;sdl:name&gt;ImageUrlMedium&lt;/sdl:name&gt;
            &lt;sdl:value&gt;
              &lt;sdl:string&gt;http://images.amazon.com/images/P/0439139597.01.MZZZZZZZ.jpg&lt;/sdl:string&gt;
            &lt;/sdl:value&gt;
          &lt;/sdl:member&gt;          
          &lt;sdl:member&gt;
            &lt;sdl:name&gt;ImageUrlLarge&lt;/sdl:name&gt;
            &lt;sdl:value&gt;
              &lt;sdl:string&gt;http://images.amazon.com/images/P/0439139597.01.LZZZZZZZ.jpg&lt;/sdl:string&gt;
            &lt;/sdl:value&gt;
          &lt;/sdl:member&gt;          
          &lt;sdl:member&gt;
            &lt;sdl:name&gt;Availability&lt;/sdl:name&gt;
            &lt;sdl:value&gt;&lt;sdl:string&gt;Usually ships within 24 hours&lt;/sdl:string&gt;&lt;/sdl:value&gt;
          &lt;/sdl:member&gt;
          &lt;sdl:member&gt;
            &lt;sdl:name&gt;ListPrice&lt;/sdl:name&gt;
            &lt;sdl:value&gt;&lt;sdl:string&gt;$25.95&lt;/sdl:string&gt;&lt;/sdl:value&gt;
          &lt;/sdl:member&gt;
          &lt;sdl:member&gt;
            &lt;sdl:name&gt;OurPrice&lt;/sdl:name&gt;
            &lt;sdl:value&gt;&lt;sdl:string&gt;$18.16&lt;/sdl:string&gt;&lt;/sdl:value&gt;
          &lt;/sdl:member&gt;
          &lt;sdl:member&gt;
            &lt;sdl:name&gt;UsedPrice&lt;/sdl:name&gt;
            &lt;sdl:value&gt;&lt;sdl:string&gt;$3.97&lt;/sdl:string&gt;&lt;/sdl:value&gt;
          &lt;/sdl:member&gt;
        &lt;/sdl:struct&gt;
      &lt;/sdl:data&gt;
    &lt;/item&gt;   
  &lt;/channel&gt;   
&lt;/rss&gt;</description>
          
          <pubDate>Thu, 02 Oct 2003 15:52:00 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2003/10/02/rss-data-versus-namespace/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2003/10/02/rss-data-versus-namespace/</guid>
        </item><item>
          <title>RSS-Data: XML-RPC encoding in RSS 2.0</title>
          <description>A few months ago I approached Dave Winer and a few other people with a very simple idea.? Why not use XML-RPC&#39;s data serialization format to create a simple data language for object meta-data in RSS (and other!) applications.? Interestingly, if you subtract the message envelop from XML-RPC, add Unicode and time-zone support to the standard, you&#39;ve actually got WDDX, quite literally.? Dave really liked the idea, and we came up with the idea of RSS-Data.


Why use RSS-Data?? Pragmatism.? Because of the rapid growth of blogging software, XML-RPC parsers are already implemented in dozens of languages and platforms.? As a result, a simple data language based on XML-RPC&#39;s data model could emerge in a matter of days or weeks, as developers quickly refactor their parsers to simply provide data serialization/deserialization components.
Source: Jeremy Allaire&#39;s Radio  (via Silicon Valley - Dan Gillmor&#39;s eJournal - Expanding the Scope of RSS)	Grr. I can’t decide whether I hate this idea or can live with it.  On the one hand, I have benefitted from XML-RPC and it’s quick integration between disparate scripting environments.  But on the other hand, the tendency to use adhoc data structures in scripting has given me numerous headaches and plenty of inexplicable bugs.The further I get, the less I want quick and dirty, and the more I want thoughtful chaos and at least some documentation.  I’d like some schemas, rather than reverse engineering from example.  But sometimes it’s nice to short circuit over-designed processes and take expedient shortcuts, even if there lies the road to madness.  Sleep is good sometimes.</description>
          
          <pubDate>Wed, 01 Oct 2003 20:21:23 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2003/10/01/rss-data/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2003/10/01/rss-data/</guid>
        </item><item>
          <title>Comment Icons drawn from author&#39;s RSS or FOAF files</title>
          <description>This is an interesting thing over at
Life on Mars:
Comment Icons.


Post a comment, supply the URL to your blog, and if your
blog has a locatable RSS feed which points to an image,
that image will be displayed next to your comments.  As I&#39;ve
been known to have a mild obsession with LiveJournal, this reminds
me a lot of the usericons in use there, only distributed
across blogspace, which is what I&#39;ve wanted to see done for a
long time.


All the infrastructure of LiveJournal,
Friendster, and the like could be recast as distributed
feeds and metadata, with smarts on blog servers or
personal clients.  One piece at a time...</description>
          
          <pubDate>Wed, 01 Oct 2003 17:00:56 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2003/10/01/comment-icons/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2003/10/01/comment-icons/</guid>
        </item>
    </channel>
  </rss>