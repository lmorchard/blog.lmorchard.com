[
  {
    "comments_archived": true,
    "date": "2003-09-29T17:48:28.000Z",
    "layout": "post",
    "title": "Dynamic polling times for news aggregators, II",
    "wordpress_id": 484,
    "wordpress_slug": "dynamic-polling-freq-too",
    "wordpress_url": "http://www.decafbad.com/blog/?p=484",
    "year": "2003",
    "month": "09",
    "day": "29",
    "isDir": false,
    "slug": "dynamic-polling-freq-too",
    "postName": "2003-09-29-dynamic-polling-freq-too",
    "html": "<p>\nOkay, so that <a href=\"http://www.decafbad.com/blog/tech/dynamic_feed_scan_times.html\">thing with the SQL</a> I did Friday?\nI'm not exactly sure what I was thinking with it.  I was doing something\nthat seems really odd now, trying to collect counts of new items together\nby hour, then averaging those hourly counts across a week.  Instead, I'm\ntrying this now:\n</p>\n\n<pre>SELECT\n  source,\n  'update_period' AS name,\n  round(min(24,max(1,(max(1,(iso8601_to_epoch(max(created)) -\n    max(now() - (7*24*60*60), iso8601_to_epoch(min(created)))) /\n   (60*60))) / count(id))),2) AS value\nFROM\n  items\nWHERE\n  created >= epoch_to_iso8601(now() - (7*24*60*60)) \nGROUP BY\n  source</pre>\n\n<p>\nThis bit of SQL, though still ugly, is much simpler.  This leaves out\nthe subselect, which I think I might have been playing with in order\nto build a little graph display of new items over time by source.  What\nthe above does now is to get an average time between new items for the\npast week, with a minimum of an hour, and a maximum of a day.  This\nseems to be working much better.\n</p>\n\n<p>\nAn alternate algorithm I've been playing with was suggested in\n<a href=\"http://www.decafbad.com/comments/tech/dynamic_feed_scan_times/#comment-aofdehdefioofcb\">a comment</a>\nby <a href=\"http://24.102.209.201/weblogs/ben/\">Gnomon</a>,\ninspired by TCP/IP's Additive Increase / Multiplicative Decrease.\nWith this, I subtract an hour from the time between polls when a\npoll finds new items, and then multiply by 2 every time a poll\ncomes up with nothing new.\n</p>\n\n<p>\nUsing the average of new items over time lessens my pummeling\nof servers per hour, but the second approach is even lighter\non polling since it's biased toward large leaps backing off\nfrom polling when new items are not found.  I'll likely be trading\noff between the two to see which one seems to work best.\n</p>\n\n<p>\nHoping that, after playing a bit, I'll settle on one and my\naggregator will play much nicer with feeds, especially once\nI get the HTTP client usage to correctly use things like\nlast-modified headers and ETags.  There's absolutely no reason\nfor a news aggregator to poll a feed every single hour of a day,\nunless you're monitoring a feed that's mostly quiet, except\nfor emergencies.  In that case, well, a different polling\nalgorithm is needed, or maybe an instant messaging or pub/sub\narchitecture is required.\n</p>\n\n<p>\n<b>Update:</b> As <a href=\"http://24.102.209.201/weblogs/ben/\">Gnomon</a>\nhas corrected me in comments, I've got the AIMD algorithm mixed up.\nWhat I really should be doing is making quick jumps up in polling\nfrequency in response to new items (multiplicative decrease of\npolling period) and creeping away in response to no new items\n(additive increase of polling period).  As he notes, this approach\nshould make an aggregator jump to attention when clumps of new\nposts come in, and gradually get bored over periods of silence.\nI've adjusted my code and will be tinkering with it.\n</p>\n\n<p>\nAlso, although <a href=\"http://24.102.209.201/weblogs/ben/\">Gnomon</a> makes\na good point that bloggers and their posting habits are not easily\nsubject to statistical analysis,\nI've further refined my little SQL query to catch sources\nwhich haven't seen any updates during the week (or ever):\n</p>\n\n<pre>SELECT \n  id as source,\n  'update_period' AS name,\n  round(min(24,max(1,coalesce(update_period,24)))) AS value\nFROM sources\nLEFT JOIN (\n     SELECT\n      source AS source_id,\n            (iso8601_to_epoch(max(created)) -\n              max(\n                now()-(7*24*60*60),\n                iso8601_to_epoch(min(created))\n              )\n            ) / (60*60) / count(id)\n        AS update_period\n    FROM items\n    WHERE created >= epoch_to_iso8601(now() - (7*24*60*60)) \n    GROUP BY source\n) ON sources.id=source_id</pre>\n\n<p>\nAlso, in case anyone's interested, I've checked <a href=\"http://www.decafbad.com/cvs/dbagg/lib/dbagg/scan.py?rev=HEAD&content-type=text/vnd.viewcvs-markup\">all the above</a>\ninto CVS.  This beastie's far from ready for prime time, but it\nmight be interesting to someone.\n</p>\n<!--more-->\nshortname=dynamic_polling_freq_too\n\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221083781\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://webseitz.fluxent.com/wiki\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2e83224d92ed7f1148f4dd3cdb0e4548&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://webseitz.fluxent.com/wiki\">Bill Seitz</a>\n</div>\n<a href=\"#comment-221083781\" class=\"permalink\"><time datetime=\"2003-09-29T10:11:11\">2003-09-29T10:11:11</time></a>\n</div>\n<div class=\"content\">It might be good to step back and prioritize your goals. How important is quickly catching mid-day updates?\nI think looking at averages throws things off, considering how \"clumpy\" I'd guess most update frequencies are. Some thoughts:\n* probably makes sense to check each feed at least once per day\n* for each feed, look at the average time-of-day of its first-post-of-the-day. Actually, look at a distribution curve, and pick the time at which there's an 80% chance that the first post will have been made (if it's going to be made at all).\n* check at that time; if no posting then check 12 hours later?\n* if found posting at first check of day, then start that additive/multiplicative process\n* regardless of the state of that latter calculation, check the next morning at that time-of-first-post prediction\nParallel idea:\n* calc average time between posts like you're doing, but just over the window each day when posts are being made (e.g. 8am-11pm = 15 hrs, not 24 hrs).</div>\n</li>\n<li class=\"comment\" id=\"comment-221083784\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2ac2cffd36ada8c734b90e02a1e5c1ac&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221083784\" class=\"permalink\"><time datetime=\"2003-09-29T10:39:45\">2003-09-29T10:39:45</time></a>\n</div>\n<div class=\"content\">Ooh, good ideas!  I think a lot of this addresses some of the not-quite-yet thought out concerns I have with the simple averaging.  I'll have to poke around some more with this.</div>\n</li>\n<li class=\"comment\" id=\"comment-221083786\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://24.102.209.201/weblogs/ben/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=588bdfdda82be46c638d6956c55ebc38&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://24.102.209.201/weblogs/ben/\">Gnomon</a>\n</div>\n<a href=\"#comment-221083786\" class=\"permalink\"><time datetime=\"2003-09-29T11:18:28\">2003-09-29T11:18:28</time></a>\n</div>\n<div class=\"content\">I'm afraid that you've credited me with more politeness than I deserve! When I suggested AIMD, I meant that the time between polls should be subject to this scheduling system - that is, the poll interval should increase additively but decrease multiplicatively.\nThis is not as polite as your interpretation, which definitely backs off very quickly. My reasoning went like this: weblog posts tend to clump, so the best indicator of an upcoming post is a new post...:\n- If there aren't any new posts, lengthen the check interval by a little bit and check again later; keep lengthening the check interval up to a certain limit.\n- If there is a new post, then it's likely that another new post will follow soon, so substantially decrease the poll time (down to a certain limit) and check again soon.\nThis approach is less biased towards decreasing server load and more biased towards detecting quick clumps of updates, which seem to be the norm. I don't know any human webloggers who have such a predictable posting pattern that they are subject to statistical analysis  ;)</div>\n</li>\n<li class=\"comment\" id=\"comment-221083787\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2ac2cffd36ada8c734b90e02a1e5c1ac&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221083787\" class=\"permalink\"><time datetime=\"2003-09-29T11:53:46\">2003-09-29T11:53:46</time></a>\n</div>\n<div class=\"content\">Oh, duh.  Heh, I've got it in reverse then.  Seems like jumping up / creeping back, now that you've explained it to me again, would better suit the posting styles of bloggers for sure!\nThanks for correcting me!</div>\n</li>\n<li class=\"comment\" id=\"comment-221083789\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://bwinton.latte.ca/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=441f5529f1db69e1a18cefb090e2690a&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://bwinton.latte.ca/\">Blake Winton</a>\n</div>\n<a href=\"#comment-221083789\" class=\"permalink\"><time datetime=\"2003-09-29T14:00:39\">2003-09-29T14:00:39</time></a>\n</div>\n<div class=\"content\">I was thinking along the same lines as Bill, in that you know that most webloggers have to sleep and eat sometime, so if you  could take advantage of this knowledge, you'ld be ahead of the game.\nMy thoughts on how to do it would be to break the day into blocks of time (start with hours, say), and build a histogram of how many posts fit into each block.  Then, you could collapse the series of hours where nothing was posted into a big block, and split any hours where something was posted into two sections, to average out the number of posts per hour.  Then, if my theory is correct, you can poll once per block of time, and would have a reasonable chance of getting a new post.\nSome notable flaws with the algorithm:\n1. It fails to account for whole days where there's nothing posted.  This might be overcome by having your initial blocks of time be the days of the week.\n2. It fails to account for the relationship (or the average time) between posts.  So if someone posts a lot at 9:00 or 10:00, but never both at 9:00 and 10:00, my theory will still check the 10:00 time even if something was found at 9:00.  I can't think of a way to get around this, off the top of my head.\nAnother way of thinking of this idea is pre-calculating a guess at the fall-off, based on previous posts.</div>\n</li>\n</ul>\n</div>\n",
    "body": "<p>\r\nOkay, so that <a href=\"http://www.decafbad.com/blog/tech/dynamic_feed_scan_times.html\">thing with the SQL</a> I did Friday?\r\nI'm not exactly sure what I was thinking with it.  I was doing something\r\nthat seems really odd now, trying to collect counts of new items together\r\nby hour, then averaging those hourly counts across a week.  Instead, I'm\r\ntrying this now:\r\n</p>\r\n\r\n<pre>SELECT\r\n  source,\r\n  'update_period' AS name,\r\n  round(min(24,max(1,(max(1,(iso8601_to_epoch(max(created)) -\r\n    max(now() - (7*24*60*60), iso8601_to_epoch(min(created)))) /\r\n   (60*60))) / count(id))),2) AS value\r\nFROM\r\n  items\r\nWHERE\r\n  created >= epoch_to_iso8601(now() - (7*24*60*60)) \r\nGROUP BY\r\n  source</pre>\r\n\r\n<p>\r\nThis bit of SQL, though still ugly, is much simpler.  This leaves out\r\nthe subselect, which I think I might have been playing with in order\r\nto build a little graph display of new items over time by source.  What\r\nthe above does now is to get an average time between new items for the\r\npast week, with a minimum of an hour, and a maximum of a day.  This\r\nseems to be working much better.\r\n</p>\r\n\r\n<p>\r\nAn alternate algorithm I've been playing with was suggested in\r\n<a href=\"http://www.decafbad.com/comments/tech/dynamic_feed_scan_times/#comment-aofdehdefioofcb\">a comment</a>\r\nby <a href=\"http://24.102.209.201/weblogs/ben/\">Gnomon</a>,\r\ninspired by TCP/IP's Additive Increase / Multiplicative Decrease.\r\nWith this, I subtract an hour from the time between polls when a\r\npoll finds new items, and then multiply by 2 every time a poll\r\ncomes up with nothing new.\r\n</p>\r\n\r\n<p>\r\nUsing the average of new items over time lessens my pummeling\r\nof servers per hour, but the second approach is even lighter\r\non polling since it's biased toward large leaps backing off\r\nfrom polling when new items are not found.  I'll likely be trading\r\noff between the two to see which one seems to work best.\r\n</p>\r\n\r\n<p>\r\nHoping that, after playing a bit, I'll settle on one and my\r\naggregator will play much nicer with feeds, especially once\r\nI get the HTTP client usage to correctly use things like\r\nlast-modified headers and ETags.  There's absolutely no reason\r\nfor a news aggregator to poll a feed every single hour of a day,\r\nunless you're monitoring a feed that's mostly quiet, except\r\nfor emergencies.  In that case, well, a different polling\r\nalgorithm is needed, or maybe an instant messaging or pub/sub\r\narchitecture is required.\r\n</p>\r\n\r\n<p>\r\n<b>Update:</b> As <a href=\"http://24.102.209.201/weblogs/ben/\">Gnomon</a>\r\nhas corrected me in comments, I've got the AIMD algorithm mixed up.\r\nWhat I really should be doing is making quick jumps up in polling\r\nfrequency in response to new items (multiplicative decrease of\r\npolling period) and creeping away in response to no new items\r\n(additive increase of polling period).  As he notes, this approach\r\nshould make an aggregator jump to attention when clumps of new\r\nposts come in, and gradually get bored over periods of silence.\r\nI've adjusted my code and will be tinkering with it.\r\n</p>\r\n\r\n<p>\r\nAlso, although <a href=\"http://24.102.209.201/weblogs/ben/\">Gnomon</a> makes\r\na good point that bloggers and their posting habits are not easily\r\nsubject to statistical analysis,\r\nI've further refined my little SQL query to catch sources\r\nwhich haven't seen any updates during the week (or ever):\r\n</p>\r\n\r\n<pre>SELECT \r\n  id as source,\r\n  'update_period' AS name,\r\n  round(min(24,max(1,coalesce(update_period,24)))) AS value\r\nFROM sources\r\nLEFT JOIN (\r\n     SELECT\r\n      source AS source_id,\r\n            (iso8601_to_epoch(max(created)) -\r\n              max(\r\n                now()-(7*24*60*60),\r\n                iso8601_to_epoch(min(created))\r\n              )\r\n            ) / (60*60) / count(id)\r\n        AS update_period\r\n    FROM items\r\n    WHERE created >= epoch_to_iso8601(now() - (7*24*60*60)) \r\n    GROUP BY source\r\n) ON sources.id=source_id</pre>\r\n\r\n<p>\r\nAlso, in case anyone's interested, I've checked <a href=\"http://www.decafbad.com/cvs/dbagg/lib/dbagg/scan.py?rev=HEAD&content-type=text/vnd.viewcvs-markup\">all the above</a>\r\ninto CVS.  This beastie's far from ready for prime time, but it\r\nmight be interesting to someone.\r\n</p>\r\n<!--more-->\r\nshortname=dynamic_polling_freq_too\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221083781\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://webseitz.fluxent.com/wiki\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2e83224d92ed7f1148f4dd3cdb0e4548&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://webseitz.fluxent.com/wiki\">Bill Seitz</a>\r\n                </div>\r\n                <a href=\"#comment-221083781\" class=\"permalink\"><time datetime=\"2003-09-29T10:11:11\">2003-09-29T10:11:11</time></a>\r\n            </div>\r\n            <div class=\"content\">It might be good to step back and prioritize your goals. How important is quickly catching mid-day updates?\r\n\r\nI think looking at averages throws things off, considering how \"clumpy\" I'd guess most update frequencies are. Some thoughts:\r\n\r\n* probably makes sense to check each feed at least once per day\r\n\r\n* for each feed, look at the average time-of-day of its first-post-of-the-day. Actually, look at a distribution curve, and pick the time at which there's an 80% chance that the first post will have been made (if it's going to be made at all).\r\n\r\n* check at that time; if no posting then check 12 hours later?\r\n\r\n* if found posting at first check of day, then start that additive/multiplicative process\r\n\r\n* regardless of the state of that latter calculation, check the next morning at that time-of-first-post prediction\r\n\r\nParallel idea:\r\n\r\n* calc average time between posts like you're doing, but just over the window each day when posts are being made (e.g. 8am-11pm = 15 hrs, not 24 hrs).</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221083784\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2ac2cffd36ada8c734b90e02a1e5c1ac&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog\">l.m.orchard</a>\r\n                </div>\r\n                <a href=\"#comment-221083784\" class=\"permalink\"><time datetime=\"2003-09-29T10:39:45\">2003-09-29T10:39:45</time></a>\r\n            </div>\r\n            <div class=\"content\">Ooh, good ideas!  I think a lot of this addresses some of the not-quite-yet thought out concerns I have with the simple averaging.  I'll have to poke around some more with this.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221083786\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://24.102.209.201/weblogs/ben/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=588bdfdda82be46c638d6956c55ebc38&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://24.102.209.201/weblogs/ben/\">Gnomon</a>\r\n                </div>\r\n                <a href=\"#comment-221083786\" class=\"permalink\"><time datetime=\"2003-09-29T11:18:28\">2003-09-29T11:18:28</time></a>\r\n            </div>\r\n            <div class=\"content\">I'm afraid that you've credited me with more politeness than I deserve! When I suggested AIMD, I meant that the time between polls should be subject to this scheduling system - that is, the poll interval should increase additively but decrease multiplicatively.\r\n\r\nThis is not as polite as your interpretation, which definitely backs off very quickly. My reasoning went like this: weblog posts tend to clump, so the best indicator of an upcoming post is a new post...:\r\n\r\n - If there aren't any new posts, lengthen the check interval by a little bit and check again later; keep lengthening the check interval up to a certain limit.\r\n - If there is a new post, then it's likely that another new post will follow soon, so substantially decrease the poll time (down to a certain limit) and check again soon.\r\n\r\nThis approach is less biased towards decreasing server load and more biased towards detecting quick clumps of updates, which seem to be the norm. I don't know any human webloggers who have such a predictable posting pattern that they are subject to statistical analysis  ;)</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221083787\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2ac2cffd36ada8c734b90e02a1e5c1ac&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog\">l.m.orchard</a>\r\n                </div>\r\n                <a href=\"#comment-221083787\" class=\"permalink\"><time datetime=\"2003-09-29T11:53:46\">2003-09-29T11:53:46</time></a>\r\n            </div>\r\n            <div class=\"content\">Oh, duh.  Heh, I've got it in reverse then.  Seems like jumping up / creeping back, now that you've explained it to me again, would better suit the posting styles of bloggers for sure!\r\n\r\nThanks for correcting me!</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221083789\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://bwinton.latte.ca/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=441f5529f1db69e1a18cefb090e2690a&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://bwinton.latte.ca/\">Blake Winton</a>\r\n                </div>\r\n                <a href=\"#comment-221083789\" class=\"permalink\"><time datetime=\"2003-09-29T14:00:39\">2003-09-29T14:00:39</time></a>\r\n            </div>\r\n            <div class=\"content\">I was thinking along the same lines as Bill, in that you know that most webloggers have to sleep and eat sometime, so if you  could take advantage of this knowledge, you'ld be ahead of the game.\r\n\r\nMy thoughts on how to do it would be to break the day into blocks of time (start with hours, say), and build a histogram of how many posts fit into each block.  Then, you could collapse the series of hours where nothing was posted into a big block, and split any hours where something was posted into two sections, to average out the number of posts per hour.  Then, if my theory is correct, you can poll once per block of time, and would have a reasonable chance of getting a new post.\r\n\r\nSome notable flaws with the algorithm:\r\n1. It fails to account for whole days where there's nothing posted.  This might be overcome by having your initial blocks of time be the days of the week.\r\n2. It fails to account for the relationship (or the average time) between posts.  So if someone posts a lot at 9:00 or 10:00, but never both at 9:00 and 10:00, my theory will still check the 10:00 time even if something was found at 9:00.  I can't think of a way to get around this, off the top of my head.\r\n\r\nAnother way of thinking of this idea is pre-calculating a guess at the fall-off, based on previous posts.</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2003",
    "path": "2003/09/29/dynamic-polling-freq-too",
    "summary": "<p>\nOkay, so that <a href=\"http://www.decafbad.com/blog/tech/dynamic_feed_scan_times.html\">thing with the SQL</a> I did Friday?\nI&apos;m not exactly sure what I was thinking with it.  I was doing something\nthat seems really odd now, trying to collect counts of new items together\nby hour, then averaging those hourly counts across a week.  Instead, I&apos;m\ntrying this now:\n</p>\n\n<pre>SELECT\n  source,\n  &apos;update_period&apos; AS name,\n  round(min(24,max(1,(max(1,(iso8601_to_epoch(max(created)) -\n    max(now() - (7*24*60*60), iso8601_to_epoch(min(created)))) /\n   (60*60))) / count(id))),2) AS value\nFROM\n  items\nWHERE\n  created &gt;= epoch_to_iso8601(now() - (7*24*60*60)) \nGROUP BY\n  source</pre>\n\n<p>\nThis bit of SQL, though still ugly, is much simpler.  This leaves out\nthe subselect, which I think I might have been playing with in order\nto build a little graph display of new items over time by source.  What\nthe above does now is to get an average time between new items for the\npast week, with a minimum of an hour, and a maximum of a day.  This\nseems to be working much better.\n</p>\n\n<p>\nAn alternate algorithm I&apos;ve been playing with was suggested in\n<a href=\"http://www.decafbad.com/comments/tech/dynamic_feed_scan_times/#comment-aofdehdefioofcb\">a comment</a>\nby <a href=\"http://24.102.209.201/weblogs/ben/\">Gnomon</a>,\ninspired by TCP/IP&apos;s Additive Increase / Multiplicative Decrease.\nWith this, I subtract an hour from the time between polls when a\npoll finds new items, and then multiply by 2 every time a poll\ncomes up with nothing new.\n</p>\n\n<p>\nUsing the average of new items over time lessens my pummeling\nof servers per hour, but the second approach is even lighter\non polling since it&apos;s biased toward large leaps backing off\nfrom polling when new items are not found.  I&apos;ll likely be trading\noff between the two to see which one seems to work best.\n</p>\n\n<p>\nHoping that, after playing a bit, I&apos;ll settle on one and my\naggregator will play much nicer with feeds, especially once\nI get the HTTP client usage to correctly use things like\nlast-modified headers and ETags.  There&apos;s absolutely no reason\nfor a news aggregator to poll a feed every single hour of a day,\nunless you&apos;re monitoring a feed that&apos;s mostly quiet, except\nfor emergencies.  In that case, well, a different polling\nalgorithm is needed, or maybe an instant messaging or pub/sub\narchitecture is required.\n</p>\n\n<p>\n<b>Update:</b> As <a href=\"http://24.102.209.201/weblogs/ben/\">Gnomon</a>\nhas corrected me in comments, I&apos;ve got the AIMD algorithm mixed up.\nWhat I really should be doing is making quick jumps up in polling\nfrequency in response to new items (multiplicative decrease of\npolling period) and creeping away in response to no new items\n(additive increase of polling period).  As he notes, this approach\nshould make an aggregator jump to attention when clumps of new\nposts come in, and gradually get bored over periods of silence.\nI&apos;ve adjusted my code and will be tinkering with it.\n</p>\n\n<p>\nAlso, although <a href=\"http://24.102.209.201/weblogs/ben/\">Gnomon</a> makes\na good point that bloggers and their posting habits are not easily\nsubject to statistical analysis,\nI&apos;ve further refined my little SQL query to catch sources\nwhich haven&apos;t seen any updates during the week (or ever):\n</p>\n\n<pre>SELECT \n  id as source,\n  &apos;update_period&apos; AS name,\n  round(min(24,max(1,coalesce(update_period,24)))) AS value\nFROM sources\nLEFT JOIN (\n     SELECT\n      source AS source_id,\n            (iso8601_to_epoch(max(created)) -\n              max(\n                now()-(7*24*60*60),\n                iso8601_to_epoch(min(created))\n              )\n            ) / (60*60) / count(id)\n        AS update_period\n    FROM items\n    WHERE created &gt;= epoch_to_iso8601(now() - (7*24*60*60)) \n    GROUP BY source\n) ON sources.id=source_id</pre>\n\n<p>\nAlso, in case anyone&apos;s interested, I&apos;ve checked <a href=\"http://www.decafbad.com/cvs/dbagg/lib/dbagg/scan.py?rev=HEAD&amp;content-type=text/vnd.viewcvs-markup\">all the above</a>\ninto CVS.  This beastie&apos;s far from ready for prime time, but it\nmight be interesting to someone.\n</p>\n",
    "prevPostPath": "2003/10/01/mailbucket-feeds",
    "nextPostPath": "2003/09/26/dynamic-feed-scan-times"
  },
  {
    "comments_archived": true,
    "date": "2003-09-26T02:45:29.000Z",
    "layout": "post",
    "title": "Dynamic feed polling times for news aggregators",
    "wordpress_id": 483,
    "wordpress_slug": "dynamic-feed-scan-times",
    "wordpress_url": "http://www.decafbad.com/blog/?p=483",
    "year": "2003",
    "month": "09",
    "day": "25",
    "isDir": false,
    "slug": "dynamic-feed-scan-times",
    "postName": "2003-09-25-dynamic-feed-scan-times",
    "html": "<p>Today, <a href=http://www.decafbad.com/cvs/dbagg/\">my aggregator</a> got\nthe following SQL worked into its <a href=\"http://www.decafbad.com/cvs/dbagg/lib/dbagg/scan.py?rev=HEAD&content-type=text/vnd.viewcvs-markup\">feed poll scheduling machinery</a>:</p>\n\n<pre>SELECT id as source,\n       'update_period' as name,\n       max(1, 1/max((1.0/24.0),\n                    sum(update_count)/(7*24))) AS value \nFROM sources \nLEFT JOIN (\n    SELECT source AS count_id,\n                round(iso8601_to_epoch(created)/(60*60)) AS hour, \n                count(id) AS update_count \n    FROM items \n    WHERE created>epoch_to_iso8601(now()-(7*(24*60*60))) \n    GROUP BY hour\n) ON id=count_id\nGROUP BY source\nORDER BY value</pre>\n\n<p>\nIt's likely that this is really nasty, but I have only a street-level\nworking knowledge of SQL.  Also, a few of the date functions are\nspecific to how I've <a href=\"http://pysqlite.sourceforge.net/documentation/pysqlite/node10.html#SECTION004231000000000000000\">extended sqlite in Python</a>.  It works though, and\nwhat it does is this:\n</p>\n\n<p>\nFor each feed to which I'm subscribed, work out\nan average time between updates for the past week, with a maximum\nperiod of 24 hours and a minimum of 1 hour.\n</p>\n\n<p>\nMy aggregator does this daily, and uses the results to determine how\nfrequently to schedule scans.  In this way, it automatically backs off\non checking feeds which update infrequently, and ramps up its polling\nof more active feeds.  This shortens my feed downloading and scanning\ntime, and is kinder in general to everyone on my subscription list.\n</p>\n\n<p>\nNext, among other things, I have to look into making sure that the\nHTTP client parts of this beast pass all the\n<a href=\"http://diveintomark.org/tests/client/http/\">aggregator client\nHTTP tests</a> that <a href=\"http://diveintomark.org/\">Mark\nPilgrim</a> put together.\n</p>\n\n<p>\n<b>Update</b>: Well, it seemed like a good idea, anyway.  But, on\nfurther examination, it has flaws.  The most notable is that it\nassumes a polling frequency of once per hour.  This works right up\nuntil I start changing the polling frequency with the results of the\ncalculation.  I haven't poked at it yet, but maybe if I take this\ninto account, it'll be more accurate.\n</p>\n\n<p>\nOn the other hand, I've also been thinking about a much simpler\napproach to ramping polling frequency up and down:  Start out at\na poll every hour.  If, after a poll, no new items are found,\ndouble the time until the next poll.  If new items were found,\nhalve the time until the next poll.</p>\n\n<p>\nProvide lower and upper limits to this, say between 1 hour and 1\nweek.  Also, consider the ramp up and ramp down factor as a variable\nsetting too.  Instead of a factor of 2, maybe try 1.5 or even 1.25 for\na more gradual change.  To go even further, I wonder if it would be\nvaluable to dynamically alter this factor itself, to try to get the\npolling time zeroed in on a realistic polling time.\n</p>\n\n<p>\nOkay.  There the simpler approach leaves simplicity.  I'm sure there's\nsome decently elegant math that could be pulled in here.  :)\n</p>\n<!--more-->\nshortname=dynamic_feed_scan_times\n\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221087768\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://24.102.209.201/weblogs/ben/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=588bdfdda82be46c638d6956c55ebc38&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://24.102.209.201/weblogs/ben/\">Gnomon</a>\n</div>\n<a href=\"#comment-221087768\" class=\"permalink\"><time datetime=\"2003-09-26T09:56:09\">2003-09-26T09:56:09</time></a>\n</div>\n<div class=\"content\">Why not just go the TCP/IP route - Additive Increase / Multiplicative Decrease? Start by setting the check-interval to one hour (or whatever). For each feed, if a new post is found, cut the check-interval for that feed by half; if no new post is found, increase the check-interval by an hour.\nIt's not optimal, and it won't automagically zero in on the predicted post times of individual feeds, but it strikes a nice balance between bandwidth politeness, update rapidity and conceptual simplicity. The constant values (initial check-interval, check-interval increment, check-interval multiplier) can be tweaked for different behavioural styles.</div>\n</li>\n<li class=\"comment\" id=\"comment-221087769\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2ac2cffd36ada8c734b90e02a1e5c1ac&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221087769\" class=\"permalink\"><time datetime=\"2003-09-26T11:04:24\">2003-09-26T11:04:24</time></a>\n</div>\n<div class=\"content\">Hmm...  I knew that this was something that someone had already handled somewhere.  :)  I'm just not all that familiar with the details of TCP/IP, but this sounds pretty much like a workable approach I'd like to go with.</div>\n</li>\n<li class=\"comment\" id=\"comment-221087770\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2ac2cffd36ada8c734b90e02a1e5c1ac&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221087770\" class=\"permalink\"><time datetime=\"2003-09-26T11:07:00\">2003-09-26T11:07:00</time></a>\n</div>\n<div class=\"content\">Oh!  For a second I thought that what you're suggesting was basically what I was already working on with my multiplying/dividing by a factor...  But you're talking about something that ADDS to increase and MULTIPLIES to decrease, which is something much more biased to back off than ramp up, which seems very polite to me.  Yay!</div>\n</li>\n</ul>\n</div>\n",
    "body": "<p>Today, <a href=http://www.decafbad.com/cvs/dbagg/\">my aggregator</a> got\r\nthe following SQL worked into its <a href=\"http://www.decafbad.com/cvs/dbagg/lib/dbagg/scan.py?rev=HEAD&content-type=text/vnd.viewcvs-markup\">feed poll scheduling machinery</a>:</p>\r\n\r\n<pre>SELECT id as source,\r\n       'update_period' as name,\r\n       max(1, 1/max((1.0/24.0),\r\n                    sum(update_count)/(7*24))) AS value \r\nFROM sources \r\nLEFT JOIN (\r\n    SELECT source AS count_id,\r\n                round(iso8601_to_epoch(created)/(60*60)) AS hour, \r\n                count(id) AS update_count \r\n    FROM items \r\n    WHERE created>epoch_to_iso8601(now()-(7*(24*60*60))) \r\n    GROUP BY hour\r\n) ON id=count_id\r\nGROUP BY source\r\nORDER BY value</pre>\r\n\r\n<p>\r\nIt's likely that this is really nasty, but I have only a street-level\r\nworking knowledge of SQL.  Also, a few of the date functions are\r\nspecific to how I've <a href=\"http://pysqlite.sourceforge.net/documentation/pysqlite/node10.html#SECTION004231000000000000000\">extended sqlite in Python</a>.  It works though, and\r\nwhat it does is this:\r\n</p>\r\n\r\n<p>\r\nFor each feed to which I'm subscribed, work out\r\nan average time between updates for the past week, with a maximum\r\nperiod of 24 hours and a minimum of 1 hour.\r\n</p>\r\n\r\n<p>\r\nMy aggregator does this daily, and uses the results to determine how\r\nfrequently to schedule scans.  In this way, it automatically backs off\r\non checking feeds which update infrequently, and ramps up its polling\r\nof more active feeds.  This shortens my feed downloading and scanning\r\ntime, and is kinder in general to everyone on my subscription list.\r\n</p>\r\n\r\n<p>\r\nNext, among other things, I have to look into making sure that the\r\nHTTP client parts of this beast pass all the\r\n<a href=\"http://diveintomark.org/tests/client/http/\">aggregator client\r\nHTTP tests</a> that <a href=\"http://diveintomark.org/\">Mark\r\nPilgrim</a> put together.\r\n</p>\r\n\r\n<p>\r\n<b>Update</b>: Well, it seemed like a good idea, anyway.  But, on\r\nfurther examination, it has flaws.  The most notable is that it\r\nassumes a polling frequency of once per hour.  This works right up\r\nuntil I start changing the polling frequency with the results of the\r\ncalculation.  I haven't poked at it yet, but maybe if I take this\r\ninto account, it'll be more accurate.\r\n</p>\r\n\r\n<p>\r\nOn the other hand, I've also been thinking about a much simpler\r\napproach to ramping polling frequency up and down:  Start out at\r\na poll every hour.  If, after a poll, no new items are found,\r\ndouble the time until the next poll.  If new items were found,\r\nhalve the time until the next poll.</p>\r\n\r\n<p>\r\nProvide lower and upper limits to this, say between 1 hour and 1\r\nweek.  Also, consider the ramp up and ramp down factor as a variable\r\nsetting too.  Instead of a factor of 2, maybe try 1.5 or even 1.25 for\r\na more gradual change.  To go even further, I wonder if it would be\r\nvaluable to dynamically alter this factor itself, to try to get the\r\npolling time zeroed in on a realistic polling time.\r\n</p>\r\n\r\n<p>\r\nOkay.  There the simpler approach leaves simplicity.  I'm sure there's\r\nsome decently elegant math that could be pulled in here.  :)\r\n</p>\r\n<!--more-->\r\nshortname=dynamic_feed_scan_times\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221087768\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://24.102.209.201/weblogs/ben/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=588bdfdda82be46c638d6956c55ebc38&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://24.102.209.201/weblogs/ben/\">Gnomon</a>\r\n                </div>\r\n                <a href=\"#comment-221087768\" class=\"permalink\"><time datetime=\"2003-09-26T09:56:09\">2003-09-26T09:56:09</time></a>\r\n            </div>\r\n            <div class=\"content\">Why not just go the TCP/IP route - Additive Increase / Multiplicative Decrease? Start by setting the check-interval to one hour (or whatever). For each feed, if a new post is found, cut the check-interval for that feed by half; if no new post is found, increase the check-interval by an hour.\r\n\r\nIt's not optimal, and it won't automagically zero in on the predicted post times of individual feeds, but it strikes a nice balance between bandwidth politeness, update rapidity and conceptual simplicity. The constant values (initial check-interval, check-interval increment, check-interval multiplier) can be tweaked for different behavioural styles.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221087769\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2ac2cffd36ada8c734b90e02a1e5c1ac&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog\">l.m.orchard</a>\r\n                </div>\r\n                <a href=\"#comment-221087769\" class=\"permalink\"><time datetime=\"2003-09-26T11:04:24\">2003-09-26T11:04:24</time></a>\r\n            </div>\r\n            <div class=\"content\">Hmm...  I knew that this was something that someone had already handled somewhere.  :)  I'm just not all that familiar with the details of TCP/IP, but this sounds pretty much like a workable approach I'd like to go with.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221087770\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2ac2cffd36ada8c734b90e02a1e5c1ac&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog\">l.m.orchard</a>\r\n                </div>\r\n                <a href=\"#comment-221087770\" class=\"permalink\"><time datetime=\"2003-09-26T11:07:00\">2003-09-26T11:07:00</time></a>\r\n            </div>\r\n            <div class=\"content\">Oh!  For a second I thought that what you're suggesting was basically what I was already working on with my multiplying/dividing by a factor...  But you're talking about something that ADDS to increase and MULTIPLIES to decrease, which is something much more biased to back off than ramp up, which seems very polite to me.  Yay!</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2003",
    "path": "2003/09/26/dynamic-feed-scan-times",
    "summary": "<p>Today, <a href=\"http://www.decafbad.com/cvs/dbagg/&quot;\">my aggregator</a> got\nthe following SQL worked into its <a href=\"http://www.decafbad.com/cvs/dbagg/lib/dbagg/scan.py?rev=HEAD&amp;content-type=text/vnd.viewcvs-markup\">feed poll scheduling machinery</a>:</p>\n\n<pre>SELECT id as source,\n       &apos;update_period&apos; as name,\n       max(1, 1/max((1.0/24.0),\n                    sum(update_count)/(7*24))) AS value \nFROM sources \nLEFT JOIN (\n    SELECT source AS count_id,\n                round(iso8601_to_epoch(created)/(60*60)) AS hour, \n                count(id) AS update_count \n    FROM items \n    WHERE created&gt;epoch_to_iso8601(now()-(7*(24*60*60))) \n    GROUP BY hour\n) ON id=count_id\nGROUP BY source\nORDER BY value</pre>\n\n<p>\nIt&apos;s likely that this is really nasty, but I have only a street-level\nworking knowledge of SQL.  Also, a few of the date functions are\nspecific to how I&apos;ve <a href=\"http://pysqlite.sourceforge.net/documentation/pysqlite/node10.html#SECTION004231000000000000000\">extended sqlite in Python</a>.  It works though, and\nwhat it does is this:\n</p>\n\n<p>\nFor each feed to which I&apos;m subscribed, work out\nan average time between updates for the past week, with a maximum\nperiod of 24 hours and a minimum of 1 hour.\n</p>\n\n<p>\nMy aggregator does this daily, and uses the results to determine how\nfrequently to schedule scans.  In this way, it automatically backs off\non checking feeds which update infrequently, and ramps up its polling\nof more active feeds.  This shortens my feed downloading and scanning\ntime, and is kinder in general to everyone on my subscription list.\n</p>\n\n<p>\nNext, among other things, I have to look into making sure that the\nHTTP client parts of this beast pass all the\n<a href=\"http://diveintomark.org/tests/client/http/\">aggregator client\nHTTP tests</a> that <a href=\"http://diveintomark.org/\">Mark\nPilgrim</a> put together.\n</p>\n\n<p>\n<b>Update</b>: Well, it seemed like a good idea, anyway.  But, on\nfurther examination, it has flaws.  The most notable is that it\nassumes a polling frequency of once per hour.  This works right up\nuntil I start changing the polling frequency with the results of the\ncalculation.  I haven&apos;t poked at it yet, but maybe if I take this\ninto account, it&apos;ll be more accurate.\n</p>\n\n<p>\nOn the other hand, I&apos;ve also been thinking about a much simpler\napproach to ramping polling frequency up and down:  Start out at\na poll every hour.  If, after a poll, no new items are found,\ndouble the time until the next poll.  If new items were found,\nhalve the time until the next poll.</p>\n\n<p>\nProvide lower and upper limits to this, say between 1 hour and 1\nweek.  Also, consider the ramp up and ramp down factor as a variable\nsetting too.  Instead of a factor of 2, maybe try 1.5 or even 1.25 for\na more gradual change.  To go even further, I wonder if it would be\nvaluable to dynamically alter this factor itself, to try to get the\npolling time zeroed in on a realistic polling time.\n</p>\n\n<p>\nOkay.  There the simpler approach leaves simplicity.  I&apos;m sure there&apos;s\nsome decently elegant math that could be pulled in here.  :)\n</p>\n",
    "prevPostPath": "2003/09/29/dynamic-polling-freq-too",
    "nextPostPath": "2003/09/25/atom-is-its-name-o"
  },
  {
    "comments_archived": true,
    "date": "2003-09-25T13:31:01.000Z",
    "layout": "post",
    "title": "Atom is its Name-O?",
    "wordpress_id": 482,
    "wordpress_slug": "atom-is-its-name-o",
    "wordpress_url": "http://www.decafbad.com/blog/?p=482",
    "year": "2003",
    "month": "09",
    "day": "25",
    "isDir": false,
    "slug": "atom-is-its-name-o",
    "postName": "2003-09-25-atom-is-its-name-o",
    "html": "<blockquote cite=\"http://www.imc.org/atom-syntax/mail-archive/msg00571.html\">I would like to propose, nay, admonish, that the name of the format and spec\nshould be Atom, that the current naming vote should be killed, and we should\nmove on to grander things without the auspices of \"what's it called?!\" over\nour heads. This has been going on far too long.</blockquote>\n<div class=\"credit\" align=\"right\"><small>Source:<cite><a href=\"http://www.imc.org/atom-syntax/mail-archive/msg00571.html\">Morbus Iff: 'Atom' Should Be It's Name, and It's Name Was Atom</a></cite></small></div>\n\n<p>I haven't been anywhere near the epicenter of Atom/Pie/Echo much,\nso this is mostly a 'me too' kind of posting.  But, you know, as an\ninterested hacker waiting for dust to settle before I start paying\nmuch attention, the decision on a name, as superficial as it is,\nseems telling to me.</p>\n\n<p>On one hand, I could take it to be representative of what's going\non inside the project as a whole.  (If they can't settle on a name,\nhow can they settle on what's included in the spec?)  On the other hand,\nit could just be that naming the thing is the least interesting aspect\nof the project.  But I consider that because I'm a nerd, I've been\nthere, and I want to see the project thrive.  Others might not be so\ncharitable or patient. :)</p>\n\n<p><i>So just name the dang thing Atom already.</i></p>\n<!--more-->\nshortname=atom_is_its_name_o\n\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221089890\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.sungnyemun.org/weblog2/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=9c3933771376b7533860934128bfb989&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.sungnyemun.org/weblog2/\">dda</a>\n</div>\n<a href=\"#comment-221089890\" class=\"permalink\"><time datetime=\"2003-09-25T21:37:27\">2003-09-25T21:37:27</time></a>\n</div>\n<div class=\"content\">Right-o. It's like Koreans trying to decide these days whether Korea should be spelled in English with a K or with a C... Like they don't have more pressing stuff!\nHave been enjoying silently your blog for awhile now. Keep the good job.</div>\n</li>\n<li class=\"comment\" id=\"comment-221089892\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.curiousfrog.com/weblog/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=43f54f4e781c8374414d45c287474cac&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.curiousfrog.com/weblog/\">Mike</a>\n</div>\n<a href=\"#comment-221089892\" class=\"permalink\"><time datetime=\"2003-09-30T09:23:28\">2003-09-30T09:23:28</time></a>\n</div>\n<div class=\"content\">I propose calling it Just Some XML (JSX) and then calling it a day.</div>\n</li>\n</ul>\n</div>\n",
    "body": "<blockquote cite=\"http://www.imc.org/atom-syntax/mail-archive/msg00571.html\">I would like to propose, nay, admonish, that the name of the format and spec\r\nshould be Atom, that the current naming vote should be killed, and we should\r\nmove on to grander things without the auspices of \"what's it called?!\" over\r\nour heads. This has been going on far too long.</blockquote>\r\n<div class=\"credit\" align=\"right\"><small>Source:<cite><a href=\"http://www.imc.org/atom-syntax/mail-archive/msg00571.html\">Morbus Iff: 'Atom' Should Be It's Name, and It's Name Was Atom</a></cite></small></div>\r\n\r\n<p>I haven't been anywhere near the epicenter of Atom/Pie/Echo much,\r\nso this is mostly a 'me too' kind of posting.  But, you know, as an\r\ninterested hacker waiting for dust to settle before I start paying\r\nmuch attention, the decision on a name, as superficial as it is,\r\nseems telling to me.</p>\r\n\r\n<p>On one hand, I could take it to be representative of what's going\r\non inside the project as a whole.  (If they can't settle on a name,\r\nhow can they settle on what's included in the spec?)  On the other hand,\r\nit could just be that naming the thing is the least interesting aspect\r\nof the project.  But I consider that because I'm a nerd, I've been\r\nthere, and I want to see the project thrive.  Others might not be so\r\ncharitable or patient. :)</p>\r\n\r\n<p><i>So just name the dang thing Atom already.</i></p>\r\n<!--more-->\r\nshortname=atom_is_its_name_o\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221089890\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.sungnyemun.org/weblog2/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=9c3933771376b7533860934128bfb989&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.sungnyemun.org/weblog2/\">dda</a>\r\n                </div>\r\n                <a href=\"#comment-221089890\" class=\"permalink\"><time datetime=\"2003-09-25T21:37:27\">2003-09-25T21:37:27</time></a>\r\n            </div>\r\n            <div class=\"content\">Right-o. It's like Koreans trying to decide these days whether Korea should be spelled in English with a K or with a C... Like they don't have more pressing stuff!\r\n\r\nHave been enjoying silently your blog for awhile now. Keep the good job.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221089892\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.curiousfrog.com/weblog/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=43f54f4e781c8374414d45c287474cac&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.curiousfrog.com/weblog/\">Mike</a>\r\n                </div>\r\n                <a href=\"#comment-221089892\" class=\"permalink\"><time datetime=\"2003-09-30T09:23:28\">2003-09-30T09:23:28</time></a>\r\n            </div>\r\n            <div class=\"content\">I propose calling it Just Some XML (JSX) and then calling it a day.</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2003",
    "path": "2003/09/25/atom-is-its-name-o",
    "summary": "<blockquote cite=\"http://www.imc.org/atom-syntax/mail-archive/msg00571.html\">I would like to propose, nay, admonish, that the name of the format and spec\nshould be Atom, that the current naming vote should be killed, and we should\nmove on to grander things without the auspices of &quot;what&apos;s it called?!&quot; over\nour heads. This has been going on far too long.</blockquote>\n<div class=\"credit\" align=\"right\"><small>Source:<cite><a href=\"http://www.imc.org/atom-syntax/mail-archive/msg00571.html\">Morbus Iff: &apos;Atom&apos; Should Be It&apos;s Name, and It&apos;s Name Was Atom</a></cite></small></div>\n\n<p>I haven&apos;t been anywhere near the epicenter of Atom/Pie/Echo much,\nso this is mostly a &apos;me too&apos; kind of posting.  But, you know, as an\ninterested hacker waiting for dust to settle before I start paying\nmuch attention, the decision on a name, as superficial as it is,\nseems telling to me.</p>\n\n<p>On one hand, I could take it to be representative of what&apos;s going\non inside the project as a whole.  (If they can&apos;t settle on a name,\nhow can they settle on what&apos;s included in the spec?)  On the other hand,\nit could just be that naming the thing is the least interesting aspect\nof the project.  But I consider that because I&apos;m a nerd, I&apos;ve been\nthere, and I want to see the project thrive.  Others might not be so\ncharitable or patient. :)</p>\n\n<p><i>So just name the dang thing Atom already.</i></p>\n",
    "prevPostPath": "2003/09/26/dynamic-feed-scan-times",
    "nextPostPath": "2003/09/21/rss-feedback"
  },
  {
    "comments_archived": true,
    "date": "2003-09-21T19:54:42.000Z",
    "layout": "post",
    "title": "Feedback loops and syndication",
    "wordpress_id": 481,
    "wordpress_slug": "rss-feedback",
    "wordpress_url": "http://www.decafbad.com/blog/?p=481",
    "year": "2003",
    "month": "09",
    "day": "21",
    "isDir": false,
    "slug": "rss-feedback",
    "postName": "2003-09-21-rss-feedback",
    "html": "<blockquote cite=\"http://www.crn.com/weblogs/stevegillmor/2003/09/20/20.asp\"><i>Enter attention.xml. Of course it monitors my attention list, noting what feeds are in what order. Then it pays attention to what items I read, in what order, or if not, then what feeds I scan, and for how long. The results are packaged up in an attention.xml file and shipped via some transport (RSS, FTP, whatever) to Technorati. Dave has some ideas about what he will provide in return: \"If you liked these feeds and items, then here are some ones you don't know about that you may want to add to your list.\"\n\n<p>But the real power comes in a weighted return feed that works like this: OK, I see who you think is important and what posts are most relevant to your interests. Then we factor in their attention.xml lists weighted by their location on your list, average the newly weighted list based on this trusted group of &quot;advisors&quot;, and return it to your aggregator, which rewrites the list accordingly.</i></blockquote><div class=\"credit\" align=\"right\"><small>Source: <cite><a href=\"http://www.crn.com/weblogs/stevegillmor/2003/09/20/20.asp\">Steve Gillmor&#39;s Emerging Opps</a></cite></small></div>    <p><a href=\"http://scriptingnews.userland.com/2003/09/21#When:10:08:20AM\">Dave Winer says</a> this guy&#8217;s full of shit.  I&#8217;m not sure why, or it if&#8217;s sarcasm.  In a lot of ways, what Steve Gilmore wrote about sounds like <a href=\"http://www.decafbad.com/blog/geek/syndicated_whuffie.html\">syndicating whuffie</a> and what <a href=\"http://www.teledyn.com/mt/archives/001055.html\">Gary Lawrence Murphy of TeledyN wrote</a> about republishing <span class=\"caps\">RSS</span> items read and rated from one&#8217;s news aggregator.</p></p>\n<pre><code>&lt;p&gt;Sounds like the next one of the next steps this tech needs to take to hit a new level of intelligence, forming a minimum-effort feedback loop from writers to readers and between readers themselves.  What did I read today, and was it interesting? What did you read today, and was it interesting?  What did we both read and both find interesting?  What did you read, and find interesting, that I didn&amp;#8217;t read and &lt;strong&gt;might&lt;/strong&gt; find interesting?  And then, back around to the author again, what of your writings was found very interesting, and (maybe) by whom?&lt;/p&gt;</code></pre>\n<!--more-->\n<p>shortname=rss_feedback</p>\n",
    "body": "<blockquote cite=\"http://www.crn.com/weblogs/stevegillmor/2003/09/20/20.asp\"><i>Enter attention.xml. Of course it monitors my attention list, noting what feeds are in what order. Then it pays attention to what items I read, in what order, or if not, then what feeds I scan, and for how long. The results are packaged up in an attention.xml file and shipped via some transport (RSS, FTP, whatever) to Technorati. Dave has some ideas about what he will provide in return: \"If you liked these feeds and items, then here are some ones you don't know about that you may want to add to your list.\"\r\n\r\nBut the real power comes in a weighted return feed that works like this: OK, I see who you think is important and what posts are most relevant to your interests. Then we factor in their attention.xml lists weighted by their location on your list, average the newly weighted list based on this trusted group of \"advisors\", and return it to your aggregator, which rewrites the list accordingly.</i></blockquote><div class=\"credit\" align=\"right\"><small>Source: <cite><a href=\"http://www.crn.com/weblogs/stevegillmor/2003/09/20/20.asp\">Steve Gillmor's Emerging Opps</a></cite></small></div>\t<p><a href=\"http://scriptingnews.userland.com/2003/09/21#When:10:08:20AM\">Dave Winer says</a> this guy&#8217;s full of shit.  I&#8217;m not sure why, or it if&#8217;s sarcasm.  In a lot of ways, what Steve Gilmore wrote about sounds like <a href=\"http://www.decafbad.com/blog/geek/syndicated_whuffie.html\">syndicating whuffie</a> and what <a href=\"http://www.teledyn.com/mt/archives/001055.html\">Gary Lawrence Murphy of TeledyN wrote</a> about republishing <span class=\"caps\">RSS</span> items read and rated from one&#8217;s news aggregator.</p>\r\n\r\n\t<p>Sounds like the next one of the next steps this tech needs to take to hit a new level of intelligence, forming a minimum-effort feedback loop from writers to readers and between readers themselves.  What did I read today, and was it interesting? What did you read today, and was it interesting?  What did we both read and both find interesting?  What did you read, and find interesting, that I didn&#8217;t read and <strong>might</strong> find interesting?  And then, back around to the author again, what of your writings was found very interesting, and (maybe) by whom?</p>\r\n<!--more-->\r\nshortname=rss_feedback\r\n",
    "parentPath": "../blog.lmorchard.com/posts/archives/2003",
    "path": "2003/09/21/rss-feedback",
    "summary": "<blockquote cite=\"http://www.crn.com/weblogs/stevegillmor/2003/09/20/20.asp\"><i>Enter attention.xml. Of course it monitors my attention list, noting what feeds are in what order. Then it pays attention to what items I read, in what order, or if not, then what feeds I scan, and for how long. The results are packaged up in an attention.xml file and shipped via some transport (RSS, FTP, whatever) to Technorati. Dave has some ideas about what he will provide in return: &quot;If you liked these feeds and items, then here are some ones you don&apos;t know about that you may want to add to your list.&quot;\n\n</i><p><i>But the real power comes in a weighted return feed that works like this: OK, I see who you think is important and what posts are most relevant to your interests. Then we factor in their attention.xml lists weighted by their location on your list, average the newly weighted list based on this trusted group of &quot;advisors&quot;, and return it to your aggregator, which rewrites the list accordingly.</i></p></blockquote><div class=\"credit\" align=\"right\"><small>Source: <cite><a href=\"http://www.crn.com/weblogs/stevegillmor/2003/09/20/20.asp\">Steve Gillmor&apos;s Emerging Opps</a></cite></small></div>    <p><a href=\"http://scriptingnews.userland.com/2003/09/21#When:10:08:20AM\">Dave Winer says</a> this guy&#x2019;s full of shit.  I&#x2019;m not sure why, or it if&#x2019;s sarcasm.  In a lot of ways, what Steve Gilmore wrote about sounds like <a href=\"http://www.decafbad.com/blog/geek/syndicated_whuffie.html\">syndicating whuffie</a> and what <a href=\"http://www.teledyn.com/mt/archives/001055.html\">Gary Lawrence Murphy of TeledyN wrote</a> about republishing <span class=\"caps\">RSS</span> items read and rated from one&#x2019;s news aggregator.</p><p></p>\n<pre><code>&lt;p&gt;Sounds like the next one of the next steps this tech needs to take to hit a new level of intelligence, forming a minimum-effort feedback loop from writers to readers and between readers themselves.  What did I read today, and was it interesting? What did you read today, and was it interesting?  What did we both read and both find interesting?  What did you read, and find interesting, that I didn&amp;#8217;t read and &lt;strong&gt;might&lt;/strong&gt; find interesting?  And then, back around to the author again, what of your writings was found very interesting, and (maybe) by whom?&lt;/p&gt;</code></pre>\n",
    "prevPostPath": "2003/09/25/atom-is-its-name-o",
    "nextPostPath": "2003/09/19/flash-hates-progressive-jpeg"
  },
  {
    "comments_archived": true,
    "date": "2003-09-19T18:28:23.000Z",
    "layout": "post",
    "title": "Flash MX Hates Progressive JPEGs",
    "wordpress_id": 480,
    "wordpress_slug": "flash-hates-progressive-jpeg",
    "wordpress_url": "http://www.decafbad.com/blog/?p=480",
    "year": "2003",
    "month": "09",
    "day": "19",
    "isDir": false,
    "slug": "flash-hates-progressive-jpeg",
    "postName": "2003-09-19-flash-hates-progressive-jpeg",
    "html": "<p>\nOkay, I may be the last person fiddling with Flash to\ndiscover this, but here's what I've learned today:\n</p>\n<p>\n<a href=\"http://www.macromedia.com/support/flash/ts/documents/cant_load_jpg.htm\"><b>Flash MX hates progressive JPEGs.</b></a>\n</p>\n<p>\nFrom the above: \"<i>The Macromedia Flash Player does not have a\ndecompressor for progressive JPEG images, therefore files of this type\ncannot be loaded dynamically and will not display when using the\nloadMovie action.</i>\"\n</p>\n<p>\nThis would have been nice to know, hours ago.  Or maybe fixed in\nthe past year or so since the above linked tech note.  See, although\nI'm a Jack of a lot of Trades, I don't really pay attention much\nto things like JPEGs and their progressive natures.  It wasn't\nuntil I finally started randomly clicking buttons on and off in\nMacromedia Fireworks while exporting a test JPEG that I finally\nnarrowed down the problem.\n</p>\n<p>\nThis was after a day worth of examining ActionScript, XML data,\nHTTP headers, and a mess of other random dead ends.  And a lot of\nlast-ditch random and exhaustive twiddling of checkboxes and\noptions.\n</p>\n<p>\n<b>Then</b>, once I had the words I\nwouldn't have had unless I already knew what my problem was, a Google search for\n\"<a href=\"http://www.google.com/search?q=flash+progressive+jpeg&ie=UTF-8&oe=UTF-8\">flash progressive jpeg</a>\"\ngot me all kinds of info.\n</p>\n<p>\nProblem is, the JPEGs supplied to the particular Flash app on which\nI'm hacking come from a random assortment of people working through\na content management system on the backend.  They upload them\nwith a form in their browser, and this Flash app gets a URL to the\nimage via an XML doc it loads.  Me, I'm probably in bed when this\nhappens.  I'd love to have tested every one... er, rather, no I\nwouldn't.\n</p>\n<p>\nSo... Now I just have to figure out how to get all these people\nto start making sure that their JPEGs aren't progressive.  Hmph.\n</p>\n<p>\nI can only hope that this message gets indexed and maybe provides\nmore triangulation for some other poor sucker in the future.\n</p>\n<!--more-->\nshortname=flash_hates_progressive_jpeg\n\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221090485\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://aaronland.net\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=9b704dff33489e0ba50f7a6364a8bf5a&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://aaronland.net\">Aaron of Montreal</a>\n</div>\n<a href=\"#comment-221090485\" class=\"permalink\"><time datetime=\"2003-09-19T15:01:02\">2003-09-19T15:01:02</time></a>\n</div>\n<div class=\"content\">FYI : \nhttp://studio.imagemagick.org/pipermail/magick-users/2003-May/008922.html</div>\n</li>\n<li class=\"comment\" id=\"comment-221090486\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.m14m.net/bloglet.php\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=4a798b64b3d34d2377959729761f68b2&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.m14m.net/bloglet.php\">Moss Collum</a>\n</div>\n<a href=\"#comment-221090486\" class=\"permalink\"><time datetime=\"2003-09-19T16:02:38\">2003-09-19T16:02:38</time></a>\n</div>\n<div class=\"content\">Wow... and here's me just embarking on a project in Flash that's going to have to deal with JPEGs uploaded by random people on the web. Thank you, I think you've just saved me a lot of trouble.</div>\n</li>\n<li class=\"comment\" id=\"comment-221090488\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://dougal.gunters.org/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=9f2c8c704e6bf55bc51399157c5283a9&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://dougal.gunters.org/\">Dougal Campbell</a>\n</div>\n<a href=\"#comment-221090488\" class=\"permalink\"><time datetime=\"2003-09-19T16:43:43\">2003-09-19T16:43:43</time></a>\n</div>\n<div class=\"content\">And of course, there's always the GD library, too, which may or may not be easier to install than ImageMagick. Many PHP environments already have it, in case that helps. Yaarrr!\nJust gdImageCreateFromJpeg, gdImageInterlace, then gdImageJpeg, and you can get a non-interlaced version of your image.</div>\n</li>\n<li class=\"comment\" id=\"comment-221090489\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://admin.support.journurl.com/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=4df556273eae91df768e9af6e4efdfcc&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://admin.support.journurl.com/\">Roger Benningfield</a>\n</div>\n<a href=\"#comment-221090489\" class=\"permalink\"><time datetime=\"2003-09-20T13:21:31\">2003-09-20T13:21:31</time></a>\n</div>\n<div class=\"content\">Just another option I stumbled across:\nhttp://www.img2swf.com/about.htm</div>\n</li>\n</ul>\n</div>\n",
    "body": "<p>\r\nOkay, I may be the last person fiddling with Flash to\r\ndiscover this, but here's what I've learned today:\r\n</p>\r\n<p>\r\n<a href=\"http://www.macromedia.com/support/flash/ts/documents/cant_load_jpg.htm\"><b>Flash MX hates progressive JPEGs.</b></a>\r\n</p>\r\n<p>\r\nFrom the above: \"<i>The Macromedia Flash Player does not have a\r\ndecompressor for progressive JPEG images, therefore files of this type\r\ncannot be loaded dynamically and will not display when using the\r\nloadMovie action.</i>\"\r\n</p>\r\n<p>\r\nThis would have been nice to know, hours ago.  Or maybe fixed in\r\nthe past year or so since the above linked tech note.  See, although\r\nI'm a Jack of a lot of Trades, I don't really pay attention much\r\nto things like JPEGs and their progressive natures.  It wasn't\r\nuntil I finally started randomly clicking buttons on and off in\r\nMacromedia Fireworks while exporting a test JPEG that I finally\r\nnarrowed down the problem.\r\n</p>\r\n<p>\r\nThis was after a day worth of examining ActionScript, XML data,\r\nHTTP headers, and a mess of other random dead ends.  And a lot of\r\nlast-ditch random and exhaustive twiddling of checkboxes and\r\noptions.\r\n</p>\r\n<p>\r\n<b>Then</b>, once I had the words I\r\nwouldn't have had unless I already knew what my problem was, a Google search for\r\n\"<a href=\"http://www.google.com/search?q=flash+progressive+jpeg&ie=UTF-8&oe=UTF-8\">flash progressive jpeg</a>\"\r\ngot me all kinds of info.\r\n</p>\r\n<p>\r\nProblem is, the JPEGs supplied to the particular Flash app on which\r\nI'm hacking come from a random assortment of people working through\r\na content management system on the backend.  They upload them\r\nwith a form in their browser, and this Flash app gets a URL to the\r\nimage via an XML doc it loads.  Me, I'm probably in bed when this\r\nhappens.  I'd love to have tested every one... er, rather, no I\r\nwouldn't.\r\n</p>\r\n<p>\r\nSo... Now I just have to figure out how to get all these people\r\nto start making sure that their JPEGs aren't progressive.  Hmph.\r\n</p>\r\n<p>\r\nI can only hope that this message gets indexed and maybe provides\r\nmore triangulation for some other poor sucker in the future.\r\n</p>\r\n<!--more-->\r\nshortname=flash_hates_progressive_jpeg\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221090485\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://aaronland.net\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=9b704dff33489e0ba50f7a6364a8bf5a&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://aaronland.net\">Aaron of Montreal</a>\r\n                </div>\r\n                <a href=\"#comment-221090485\" class=\"permalink\"><time datetime=\"2003-09-19T15:01:02\">2003-09-19T15:01:02</time></a>\r\n            </div>\r\n            <div class=\"content\">FYI : \r\n\r\nhttp://studio.imagemagick.org/pipermail/magick-users/2003-May/008922.html</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221090486\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.m14m.net/bloglet.php\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=4a798b64b3d34d2377959729761f68b2&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.m14m.net/bloglet.php\">Moss Collum</a>\r\n                </div>\r\n                <a href=\"#comment-221090486\" class=\"permalink\"><time datetime=\"2003-09-19T16:02:38\">2003-09-19T16:02:38</time></a>\r\n            </div>\r\n            <div class=\"content\">Wow... and here's me just embarking on a project in Flash that's going to have to deal with JPEGs uploaded by random people on the web. Thank you, I think you've just saved me a lot of trouble.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221090488\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://dougal.gunters.org/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=9f2c8c704e6bf55bc51399157c5283a9&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://dougal.gunters.org/\">Dougal Campbell</a>\r\n                </div>\r\n                <a href=\"#comment-221090488\" class=\"permalink\"><time datetime=\"2003-09-19T16:43:43\">2003-09-19T16:43:43</time></a>\r\n            </div>\r\n            <div class=\"content\">And of course, there's always the GD library, too, which may or may not be easier to install than ImageMagick. Many PHP environments already have it, in case that helps. Yaarrr!\r\n\r\nJust gdImageCreateFromJpeg, gdImageInterlace, then gdImageJpeg, and you can get a non-interlaced version of your image.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221090489\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://admin.support.journurl.com/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=4df556273eae91df768e9af6e4efdfcc&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://admin.support.journurl.com/\">Roger Benningfield</a>\r\n                </div>\r\n                <a href=\"#comment-221090489\" class=\"permalink\"><time datetime=\"2003-09-20T13:21:31\">2003-09-20T13:21:31</time></a>\r\n            </div>\r\n            <div class=\"content\">Just another option I stumbled across:\r\n\r\nhttp://www.img2swf.com/about.htm</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2003",
    "path": "2003/09/19/flash-hates-progressive-jpeg",
    "summary": "<p>\nOkay, I may be the last person fiddling with Flash to\ndiscover this, but here&apos;s what I&apos;ve learned today:\n</p>\n<p>\n<a href=\"http://www.macromedia.com/support/flash/ts/documents/cant_load_jpg.htm\"><b>Flash MX hates progressive JPEGs.</b></a>\n</p>\n<p>\nFrom the above: &quot;<i>The Macromedia Flash Player does not have a\ndecompressor for progressive JPEG images, therefore files of this type\ncannot be loaded dynamically and will not display when using the\nloadMovie action.</i>&quot;\n</p>\n<p>\nThis would have been nice to know, hours ago.  Or maybe fixed in\nthe past year or so since the above linked tech note.  See, although\nI&apos;m a Jack of a lot of Trades, I don&apos;t really pay attention much\nto things like JPEGs and their progressive natures.  It wasn&apos;t\nuntil I finally started randomly clicking buttons on and off in\nMacromedia Fireworks while exporting a test JPEG that I finally\nnarrowed down the problem.\n</p>\n<p>\nThis was after a day worth of examining ActionScript, XML data,\nHTTP headers, and a mess of other random dead ends.  And a lot of\nlast-ditch random and exhaustive twiddling of checkboxes and\noptions.\n</p>\n<p>\n<b>Then</b>, once I had the words I\nwouldn&apos;t have had unless I already knew what my problem was, a Google search for\n&quot;<a href=\"http://www.google.com/search?q=flash+progressive+jpeg&amp;ie=UTF-8&amp;oe=UTF-8\">flash progressive jpeg</a>&quot;\ngot me all kinds of info.\n</p>\n<p>\nProblem is, the JPEGs supplied to the particular Flash app on which\nI&apos;m hacking come from a random assortment of people working through\na content management system on the backend.  They upload them\nwith a form in their browser, and this Flash app gets a URL to the\nimage via an XML doc it loads.  Me, I&apos;m probably in bed when this\nhappens.  I&apos;d love to have tested every one... er, rather, no I\nwouldn&apos;t.\n</p>\n<p>\nSo... Now I just have to figure out how to get all these people\nto start making sure that their JPEGs aren&apos;t progressive.  Hmph.\n</p>\n<p>\nI can only hope that this message gets indexed and maybe provides\nmore triangulation for some other poor sucker in the future.\n</p>\n",
    "prevPostPath": "2003/09/21/rss-feedback",
    "nextPostPath": "2003/09/12/dont-copy-software"
  },
  {
    "comments_archived": true,
    "date": "2003-09-12T19:35:25.000Z",
    "layout": "post",
    "title": "Don't copy that floppy, or cracked software strikes back",
    "wordpress_id": 479,
    "wordpress_slug": "dont-copy-software",
    "wordpress_url": "http://www.decafbad.com/blog/?p=479",
    "year": "2003",
    "month": "09",
    "day": "12",
    "isDir": false,
    "slug": "dont-copy-software",
    "postName": "2003-09-12-dont-copy-software",
    "html": "<pre>* Orangerobot uses cracked software.  I will respond to the following\ncommands: !ame &lt;msg&gt;, !amsg &lt;msg&gt;, !quit &lt;msg&gt;,\n!open_cd, !switch_my_mouse_buttons\n\n&lt;deusx&gt; Hmm.  If what Orangerobot just emoted is true, that's\nfunny as hell.\n\n&lt;deusx&gt; !amsg Wang!\n\n&lt;Orangerobot&gt; Wang!\n\n&lt;AnitaR&gt; and what's the purpose?\n\n&lt;deusx&gt; AnitaR: Of the message from Orangerobot?\n\n&lt;AnitaR&gt; yes\n\n&lt;AnitaR&gt; must be part of the joke I'm not getting\n\n&lt;AnitaR&gt; yet\n\n* Orangerobot uses cracked software.  I will respond to the following\ncommands: !ame &lt;msg&gt;, !amsg &lt;msg&gt;, !quit &lt;msg&gt;,\n!open_cd, !switch_my_mouse_buttons\n\n&lt;deusx&gt; AnitaR: Could be a joke, but it appears that this person\nis using pirated software that's detected its illegitimacy and is\nallowing us to manipulate that user's computer.\n\n&lt;adamhill&gt; or its a social experiment by the person behind OR :)\n\n&lt;deusx&gt; adamhill: Or that. :)  Either way, it's fun\n\n&lt;AnitaR&gt; I'm glad it isn't one of those experiments that tests\nhow strong a shock we'll give the owner\n\n&lt;Argyle&gt; ?def orangerobot\n\n&lt;deusx&gt; Some googling points to this software:\nhttp://www.klient.com\n\n&lt;deusx&gt; !switch_my_mouse_buttons\n\n&lt;deusx&gt; !ame likes cheddar cheese.\n\n* Orangerobot likes cheddar cheese.\n\n&lt;adamhill&gt; ?learn Orangerobot is either a person using cracked\nsoftware or a social experiment by a demented psych student\n\n&lt;jibot&gt; I understand now, Dr. Chandra; orangerobot is either a\nperson using cracked software or a social experiment by a demented\npsych student\n\n&lt;deusx&gt; !open_cd\n\n&lt;deusx&gt; okay, I'm done.\n\n* Orangerobot uses cracked software.  I will respond to the following\ncommands: !ame &lt;msg&gt;, !amsg &lt;msg&gt;, !quit &lt;msg&gt;,\n!open_cd, !switch_my_mouse_buttons\n\n&lt;deusx&gt; !quit hush.\n\n&lt;-- Orangerobot has quit (\"hush.\")</pre>\n<!--more-->\n<p>shortname=dont_copy_software</p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221082992\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.neuro-tech.net/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=245c88d2364dc668936f82556a7458b4&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.neuro-tech.net/\">Luke Reeves</a>\n</div>\n<a href=\"#comment-221082992\" class=\"permalink\"><time datetime=\"2003-09-12T16:40:14\">2003-09-12T16:40:14</time></a>\n</div>\n<div class=\"content\">Wow.  Privacy implications aside, that's a pure stroke of genius.</div>\n</li>\n<li class=\"comment\" id=\"comment-221082993\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.1stvamp.org/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=4eff559c7b49814a352a93fd3c6acc7c&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.1stvamp.org/\">Wesley Mason</a>\n</div>\n<a href=\"#comment-221082993\" class=\"permalink\"><time datetime=\"2003-09-12T18:54:34\">2003-09-12T18:54:34</time></a>\n</div>\n<div class=\"content\">Yup, that's an anti-piracy easter egg put in by Tom, the author of Klient (I'm a reg'd user of the great IRC client). He realises there isn't much he can do about pirating his software, and in most cases it doesn't really matter, but he definitely had a good time putting that joke into Klient. ;)</div>\n</li>\n</ul>\n</div>\n",
    "body": "<pre>* Orangerobot uses cracked software.  I will respond to the following\r\ncommands: !ame &lt;msg&gt;, !amsg &lt;msg&gt;, !quit &lt;msg&gt;,\r\n!open_cd, !switch_my_mouse_buttons\r\n\r\n&lt;deusx&gt; Hmm.  If what Orangerobot just emoted is true, that's\r\nfunny as hell.\r\n\r\n&lt;deusx&gt; !amsg Wang!\r\n\r\n&lt;Orangerobot&gt; Wang!\r\n\r\n&lt;AnitaR&gt; and what's the purpose?\r\n\r\n&lt;deusx&gt; AnitaR: Of the message from Orangerobot?\r\n\r\n&lt;AnitaR&gt; yes\r\n\r\n&lt;AnitaR&gt; must be part of the joke I'm not getting\r\n\r\n&lt;AnitaR&gt; yet\r\n\r\n* Orangerobot uses cracked software.  I will respond to the following\r\ncommands: !ame &lt;msg&gt;, !amsg &lt;msg&gt;, !quit &lt;msg&gt;,\r\n!open_cd, !switch_my_mouse_buttons\r\n\r\n&lt;deusx&gt; AnitaR: Could be a joke, but it appears that this person\r\nis using pirated software that's detected its illegitimacy and is\r\nallowing us to manipulate that user's computer.\r\n\r\n&lt;adamhill&gt; or its a social experiment by the person behind OR :)\r\n\r\n&lt;deusx&gt; adamhill: Or that. :)  Either way, it's fun\r\n\r\n&lt;AnitaR&gt; I'm glad it isn't one of those experiments that tests\r\nhow strong a shock we'll give the owner\r\n\r\n&lt;Argyle&gt; ?def orangerobot\r\n\r\n&lt;deusx&gt; Some googling points to this software:\r\nhttp://www.klient.com\r\n\r\n&lt;deusx&gt; !switch_my_mouse_buttons\r\n\r\n&lt;deusx&gt; !ame likes cheddar cheese.\r\n\r\n* Orangerobot likes cheddar cheese.\r\n\r\n&lt;adamhill&gt; ?learn Orangerobot is either a person using cracked\r\nsoftware or a social experiment by a demented psych student\r\n\r\n&lt;jibot&gt; I understand now, Dr. Chandra; orangerobot is either a\r\nperson using cracked software or a social experiment by a demented\r\npsych student\r\n\r\n&lt;deusx&gt; !open_cd\r\n\r\n&lt;deusx&gt; okay, I'm done.\r\n\r\n* Orangerobot uses cracked software.  I will respond to the following\r\ncommands: !ame &lt;msg&gt;, !amsg &lt;msg&gt;, !quit &lt;msg&gt;,\r\n!open_cd, !switch_my_mouse_buttons\r\n\r\n&lt;deusx&gt; !quit hush.\r\n\r\n&lt;-- Orangerobot has quit (\"hush.\")</pre>\r\n<!--more-->\r\nshortname=dont_copy_software\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221082992\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.neuro-tech.net/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=245c88d2364dc668936f82556a7458b4&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.neuro-tech.net/\">Luke Reeves</a>\r\n                </div>\r\n                <a href=\"#comment-221082992\" class=\"permalink\"><time datetime=\"2003-09-12T16:40:14\">2003-09-12T16:40:14</time></a>\r\n            </div>\r\n            <div class=\"content\">Wow.  Privacy implications aside, that's a pure stroke of genius.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221082993\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.1stvamp.org/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=4eff559c7b49814a352a93fd3c6acc7c&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.1stvamp.org/\">Wesley Mason</a>\r\n                </div>\r\n                <a href=\"#comment-221082993\" class=\"permalink\"><time datetime=\"2003-09-12T18:54:34\">2003-09-12T18:54:34</time></a>\r\n            </div>\r\n            <div class=\"content\">Yup, that's an anti-piracy easter egg put in by Tom, the author of Klient (I'm a reg'd user of the great IRC client). He realises there isn't much he can do about pirating his software, and in most cases it doesn't really matter, but he definitely had a good time putting that joke into Klient. ;)</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2003",
    "path": "2003/09/12/dont-copy-software",
    "summary": "<pre>* Orangerobot uses cracked software.  I will respond to the following\ncommands: !ame &lt;msg&gt;, !amsg &lt;msg&gt;, !quit &lt;msg&gt;,\n!open_cd, !switch_my_mouse_buttons\n\n&lt;deusx&gt; Hmm.  If what Orangerobot just emoted is true, that&apos;s\nfunny as hell.\n\n&lt;deusx&gt; !amsg Wang!\n\n&lt;Orangerobot&gt; Wang!\n\n&lt;AnitaR&gt; and what&apos;s the purpose?\n\n&lt;deusx&gt; AnitaR: Of the message from Orangerobot?\n\n&lt;AnitaR&gt; yes\n\n&lt;AnitaR&gt; must be part of the joke I&apos;m not getting\n\n&lt;AnitaR&gt; yet\n\n* Orangerobot uses cracked software.  I will respond to the following\ncommands: !ame &lt;msg&gt;, !amsg &lt;msg&gt;, !quit &lt;msg&gt;,\n!open_cd, !switch_my_mouse_buttons\n\n&lt;deusx&gt; AnitaR: Could be a joke, but it appears that this person\nis using pirated software that&apos;s detected its illegitimacy and is\nallowing us to manipulate that user&apos;s computer.\n\n&lt;adamhill&gt; or its a social experiment by the person behind OR :)\n\n&lt;deusx&gt; adamhill: Or that. :)  Either way, it&apos;s fun\n\n&lt;AnitaR&gt; I&apos;m glad it isn&apos;t one of those experiments that tests\nhow strong a shock we&apos;ll give the owner\n\n&lt;Argyle&gt; ?def orangerobot\n\n&lt;deusx&gt; Some googling points to this software:\nhttp://www.klient.com\n\n&lt;deusx&gt; !switch_my_mouse_buttons\n\n&lt;deusx&gt; !ame likes cheddar cheese.\n\n* Orangerobot likes cheddar cheese.\n\n&lt;adamhill&gt; ?learn Orangerobot is either a person using cracked\nsoftware or a social experiment by a demented psych student\n\n&lt;jibot&gt; I understand now, Dr. Chandra; orangerobot is either a\nperson using cracked software or a social experiment by a demented\npsych student\n\n&lt;deusx&gt; !open_cd\n\n&lt;deusx&gt; okay, I&apos;m done.\n\n* Orangerobot uses cracked software.  I will respond to the following\ncommands: !ame &lt;msg&gt;, !amsg &lt;msg&gt;, !quit &lt;msg&gt;,\n!open_cd, !switch_my_mouse_buttons\n\n&lt;deusx&gt; !quit hush.\n\n&lt;-- Orangerobot has quit (&quot;hush.&quot;)</pre>\n",
    "prevPostPath": "2003/09/19/flash-hates-progressive-jpeg",
    "nextPostPath": "2003/09/06/wiki-apis"
  },
  {
    "comments_archived": true,
    "date": "2003-09-06T17:50:45.000Z",
    "layout": "post",
    "title": "An API for Wikis?  Here's one.",
    "wordpress_id": 478,
    "wordpress_slug": "wiki-apis",
    "wordpress_url": "http://www.decafbad.com/blog/?p=478",
    "year": "2003",
    "month": "09",
    "day": "06",
    "isDir": false,
    "slug": "wiki-apis",
    "postName": "2003-09-06-wiki-apis",
    "html": "<p><br /><br /></p>\n<blockquote><i>Some folks are experimenting with using Wiki to build websites.  I particularly like what Matt Haughey did with PHPWiki and a bit of <a href=\"http://www.decafbad.com/twiki/bin/view/Main/CSS\">CSS</a> magic dust.  Looks nice, eh?  [Via Seb's Wikis are Ugly? post at Corante]\n<br /><br />\nJanne Jalkanen's Wiki-based Weblog is interesting too.  Hmm.  Maybe blog API(s) can be used for Wikis too.  That reminds me, shouldn't Wiki formatted text have their own MIME type?  Is there one?  \"text/wiki\"?  For now, different dialects of Wiki formatting rules will have to be accounted for like \"text/wiki+moinmoin\".</i></blockquote><div class=\"credit\" align=\"right\"><small>Source: <cite><a href=\"http://www.docuverse.com/blog/donpark/2003/09/05.html#a859\">Don Park's Daily Habit</s></cite></small></div>\n<br /><br />\nIt's been a while since I last worked on it, but I did implement an\nXML-RPC API on a few wikis, called <a href=\"http://www.decafbad.com/twiki/bin/view/Main/XmlRpcToWiki\">XmlRpcToWiki</a>.  Janne Jalkanen\ndid a lot of work toward the same interface with JSPWiki.  I use this API\nin the linkage between my blog and the wiki on this site.  Now that\nI've drifted away from <a href=\"http://www.decafbad.com/twiki/bin/view/Main/XmlRpc\">XmlRpc</a> a bit and am more in favor of simpler\n<a href=\"http://www.decafbad.com/twiki/bin/view/Main/REST\">REST</a>-ish web service APIs, I'd like to see something more toward that\nend.  Seems like a lot of people are discovering or rediscovering\nwikis since the introduction of Sam Ruby's wiki for Atom/Echo/Pie\nwork, so it's interesting to see a lot of things come up again like\ngrousing about APIs and mutant wiki-format offshoots and standards.\n<!--more-->\nshortname=wiki_apis\n\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221087123\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://bitsko.slc.ut.us/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=743ec87899694a206abd6bdca8fed5fc&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://bitsko.slc.ut.us/\">Ken MacLeod</a>\n</div>\n<a href=\"#comment-221087123\" class=\"permalink\"><time datetime=\"2003-09-06T16:46:13\">2003-09-06T16:46:13</time></a>\n</div>\n<div class=\"content\">Joe Gregorio recently posted today how the Atom API is great Wiki API too, http://bitworking.org/news/An_editable_web .</div>\n</li>\n<li class=\"comment\" id=\"comment-221087124\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://webseitz.fluxent.com/wiki\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=5a70d939a73fa73603f2a9255ab81d21&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://webseitz.fluxent.com/wiki\">BillSeitz</a>\n</div>\n<a href=\"#comment-221087124\" class=\"permalink\"><time datetime=\"2003-09-08T12:22:28\">2003-09-08T12:22:28</time></a>\n</div>\n<div class=\"content\">But it still leaves you the issue of the formatting of the contents, since different WikiEngines use different SmartAscii flavors.\nhttp://webseitz.fluxent.com/wiki/SmartAscii</div>\n</li>\n<li class=\"comment\" id=\"comment-221087125\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://thetinfoilhat.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=af907f0db68a77ac7aca277f19121470&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://thetinfoilhat.com\">Al Brown</a>\n</div>\n<a href=\"#comment-221087125\" class=\"permalink\"><time datetime=\"2003-09-08T15:48:40\">2003-09-08T15:48:40</time></a>\n</div>\n<div class=\"content\">You should give a look at TikiWiki http://tikiwiki.org the package has grown to become a full service CMS/Portal.\nNot exactly ugly either.\nAl</div>\n</li>\n<li class=\"comment\" id=\"comment-221087127\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://weblog.beruf-it.de/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=9c1b3189cb72c7b4a2f6cac236a24732&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://weblog.beruf-it.de/\">reinhard</a>\n</div>\n<a href=\"#comment-221087127\" class=\"permalink\"><time datetime=\"2003-09-09T10:09:35\">2003-09-09T10:09:35</time></a>\n</div>\n<div class=\"content\">look at http://www.decafbad.com/twiki/bin/search/Main/SearchResult?scope=text&regex=on&search=Xml%20*Rpc%20*To%20*Wiki%5B%5EA-Za-z%5D</div>\n</li>\n</ul>\n</div>\n",
    "body": "<br /><br />\r\n<blockquote><i>Some folks are experimenting with using Wiki to build websites.  I particularly like what Matt Haughey did with PHPWiki and a bit of <a href=\"http://www.decafbad.com/twiki/bin/view/Main/CSS\">CSS</a> magic dust.  Looks nice, eh?  [Via Seb's Wikis are Ugly? post at Corante]\r\n<br /><br />\r\nJanne Jalkanen's Wiki-based Weblog is interesting too.  Hmm.  Maybe blog API(s) can be used for Wikis too.  That reminds me, shouldn't Wiki formatted text have their own MIME type?  Is there one?  \"text/wiki\"?  For now, different dialects of Wiki formatting rules will have to be accounted for like \"text/wiki+moinmoin\".</i></blockquote><div class=\"credit\" align=\"right\"><small>Source: <cite><a href=\"http://www.docuverse.com/blog/donpark/2003/09/05.html#a859\">Don Park's Daily Habit</s></cite></small></div>\r\n<br /><br />\r\nIt's been a while since I last worked on it, but I did implement an\r\nXML-RPC API on a few wikis, called <a href=\"http://www.decafbad.com/twiki/bin/view/Main/XmlRpcToWiki\">XmlRpcToWiki</a>.  Janne Jalkanen\r\ndid a lot of work toward the same interface with JSPWiki.  I use this API\r\nin the linkage between my blog and the wiki on this site.  Now that\r\nI've drifted away from <a href=\"http://www.decafbad.com/twiki/bin/view/Main/XmlRpc\">XmlRpc</a> a bit and am more in favor of simpler\r\n<a href=\"http://www.decafbad.com/twiki/bin/view/Main/REST\">REST</a>-ish web service APIs, I'd like to see something more toward that\r\nend.  Seems like a lot of people are discovering or rediscovering\r\nwikis since the introduction of Sam Ruby's wiki for Atom/Echo/Pie\r\nwork, so it's interesting to see a lot of things come up again like\r\ngrousing about APIs and mutant wiki-format offshoots and standards.\r\n<!--more-->\r\nshortname=wiki_apis\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221087123\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://bitsko.slc.ut.us/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=743ec87899694a206abd6bdca8fed5fc&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://bitsko.slc.ut.us/\">Ken MacLeod</a>\r\n                </div>\r\n                <a href=\"#comment-221087123\" class=\"permalink\"><time datetime=\"2003-09-06T16:46:13\">2003-09-06T16:46:13</time></a>\r\n            </div>\r\n            <div class=\"content\">Joe Gregorio recently posted today how the Atom API is great Wiki API too, http://bitworking.org/news/An_editable_web .</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221087124\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://webseitz.fluxent.com/wiki\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=5a70d939a73fa73603f2a9255ab81d21&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://webseitz.fluxent.com/wiki\">BillSeitz</a>\r\n                </div>\r\n                <a href=\"#comment-221087124\" class=\"permalink\"><time datetime=\"2003-09-08T12:22:28\">2003-09-08T12:22:28</time></a>\r\n            </div>\r\n            <div class=\"content\">But it still leaves you the issue of the formatting of the contents, since different WikiEngines use different SmartAscii flavors.\r\n\r\nhttp://webseitz.fluxent.com/wiki/SmartAscii</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221087125\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://thetinfoilhat.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=af907f0db68a77ac7aca277f19121470&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://thetinfoilhat.com\">Al Brown</a>\r\n                </div>\r\n                <a href=\"#comment-221087125\" class=\"permalink\"><time datetime=\"2003-09-08T15:48:40\">2003-09-08T15:48:40</time></a>\r\n            </div>\r\n            <div class=\"content\">You should give a look at TikiWiki http://tikiwiki.org the package has grown to become a full service CMS/Portal.\r\n\r\nNot exactly ugly either.\r\n\r\nAl</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221087127\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://weblog.beruf-it.de/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=9c1b3189cb72c7b4a2f6cac236a24732&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://weblog.beruf-it.de/\">reinhard</a>\r\n                </div>\r\n                <a href=\"#comment-221087127\" class=\"permalink\"><time datetime=\"2003-09-09T10:09:35\">2003-09-09T10:09:35</time></a>\r\n            </div>\r\n            <div class=\"content\">look at http://www.decafbad.com/twiki/bin/search/Main/SearchResult?scope=text&regex=on&search=Xml%20*Rpc%20*To%20*Wiki%5B%5EA-Za-z%5D</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2003",
    "path": "2003/09/06/wiki-apis",
    "summary": "<p><br><br></p>\n<blockquote><i>Some folks are experimenting with using Wiki to build websites.  I particularly like what Matt Haughey did with PHPWiki and a bit of <a href=\"http://www.decafbad.com/twiki/bin/view/Main/CSS\">CSS</a> magic dust.  Looks nice, eh?  [Via Seb&apos;s Wikis are Ugly? post at Corante]\n<br><br>\nJanne Jalkanen&apos;s Wiki-based Weblog is interesting too.  Hmm.  Maybe blog API(s) can be used for Wikis too.  That reminds me, shouldn&apos;t Wiki formatted text have their own MIME type?  Is there one?  &quot;text/wiki&quot;?  For now, different dialects of Wiki formatting rules will have to be accounted for like &quot;text/wiki+moinmoin&quot;.</i></blockquote><div class=\"credit\" align=\"right\"><small>Source: <cite><a href=\"http://www.docuverse.com/blog/donpark/2003/09/05.html#a859\">Don Park&apos;s Daily Habit</a></cite></small></div><a href=\"http://www.docuverse.com/blog/donpark/2003/09/05.html#a859\">\n<br><br>\nIt&apos;s been a while since I last worked on it, but I did implement an\nXML-RPC API on a few wikis, called </a><a href=\"http://www.decafbad.com/twiki/bin/view/Main/XmlRpcToWiki\">XmlRpcToWiki</a>.  Janne Jalkanen\ndid a lot of work toward the same interface with JSPWiki.  I use this API\nin the linkage between my blog and the wiki on this site.  Now that\nI&apos;ve drifted away from <a href=\"http://www.decafbad.com/twiki/bin/view/Main/XmlRpc\">XmlRpc</a> a bit and am more in favor of simpler\n<a href=\"http://www.decafbad.com/twiki/bin/view/Main/REST\">REST</a>-ish web service APIs, I&apos;d like to see something more toward that\nend.  Seems like a lot of people are discovering or rediscovering\nwikis since the introduction of Sam Ruby&apos;s wiki for Atom/Echo/Pie\nwork, so it&apos;s interesting to see a lot of things come up again like\ngrousing about APIs and mutant wiki-format offshoots and standards.\n",
    "prevPostPath": "2003/09/12/dont-copy-software",
    "nextPostPath": "2003/09/05/superworm"
  },
  {
    "comments_archived": true,
    "date": "2003-09-05T15:10:53.000Z",
    "layout": "post",
    "title": "White Hat Worms and robots.txt?",
    "wordpress_id": 477,
    "wordpress_slug": "superworm",
    "wordpress_url": "http://www.decafbad.com/blog/?p=477",
    "year": "2003",
    "month": "09",
    "day": "05",
    "isDir": false,
    "slug": "superworm",
    "postName": "2003-09-05-superworm",
    "html": "<blockquote cite=\"http://www.gulufuture.com/superworm.htm\"><i>Or maybe it's time to release our own Defender.A worm which could invasively close down the relevant \"holes\" in Internet security. A defensive worm could use standard intrusion tactics for benign result. For example, it could worm it's way into Windows XP computers and get the owner's permission to turn their firewalls on. It could survey open TCP/IP ports and offer to close them.</i></blockquote><div class=\"credit\" align=\"right\"><small>Source: <cite><a href=\"http://www.gulufuture.com/superworm.htm\">Superworm To Storm The Net On 9/11</a></cite> (via <a href=\"http://www.kurzweilai.net/news/news_single.html?id=2398\">KurzweilAI</a>)</small></div>    <p>So, anger is my first reaction to the idea of any unwelcome visitors on any of my machines, well intentioned or not.  I&#8217;m sure that there aren&#8217;t many who wouldn&#8217;t feel the same way.  But, although a lot of us try to keep up on patches and maintain decent security, there&#8217;s the &#8220;great unwashed masses&#8221; who just want to &#8220;do email&#8220;.</p>\n\n<pre><code>&lt;p&gt;On one hand, it&amp;#8217;s easy to say, &amp;#8220;Tough.  Learn the care &amp;#38; feeding of your equipment.&amp;#8221;  Yeah, as if that will help or get any response from all the people who&amp;#8217;ve bought into &lt;span class=&quot;caps&quot;&gt;AOL&lt;/span&gt; and have been reassured for years that computers are friendly and easy beasts (despite their intuitions to the contrary).  Hell, I&amp;#8217;d bet that, more often than not, the same person who gets regular oil changes and tune-ups for the car has no idea how to do the equivalent for a computer (or that it even needs it).  Cars have been positioned differently than computers.  No one expects a Spanish Inquisition when they live in a virtual preschool of a user interface with large and colorful buttons and happy smiling faces.  They know there&amp;#8217;s some voodoo going on underneath, but the UI tells them that it&amp;#8217;s nothing to worry about (until &lt;a href=&quot;http://www.decafbad.com/blog/geek/not_working.html&quot;&gt;it isn&amp;#8217;t working&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;Now if the problem was just that stupid users ended up with broken computers, there&amp;#8217;d be no problem.  But, like cars with problems waiting to happen (like worn down tires), their users become a hazard to others.  Unlike cars, however, the problems of stupid users&amp;#8217; computers are contagious and self-replicating: every tire blowout becomes a 1000 car pileup.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#8217;s like everyone sits on their recliners watching TV in their houses; not even realizing that there are doors to lock; not even hearing the intruders rummaging through the fridge in the kitchen; and certainly not knowing that there&amp;#8217;s a guy sleeping on the sofa at night working by day to let his army of clones into the neighbor&amp;#8217;s houses.&lt;/p&gt;\n\n&lt;p&gt;So, about what about vigilante &amp;#8220;white hat&amp;#8221; worms?  Wouldn&amp;#8217;t it be nice if there was a guy wandering the neighborhood locking door for the ignorant?  Wouldn&amp;#8217;t it be nice if there was a truck driver on the road that forced cars with bald tires off to the side for free tire replacement?  Okay, maybe that&amp;#8217;s a bit whacky, but then again, people with bald tires aren&amp;#8217;t causing 1000 car pileups.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#8217;m thinking that &amp;#8220;white hat&amp;#8221; virii and worms are one of the only things that will work, since I&amp;#8217;m very pessimistic about the user culture changing to be more responsible.  Though, what about a compromise?  Install a service or some indicator on every network-connected machine, somewhat like &lt;a href=&quot;http://www.robotstxt.org/wc/robots.html&quot;&gt;robots.txt&lt;/a&gt; , which tells friendly robots where they&amp;#8216;re welcome and where they&amp;#8216;re not.  Set this to maximum permissiveness for white hat worms as a default.  The good guys infect, fix, and self-destruct unless this indicator tells them to stay out.  Then, all of us who want to take maintenance into our own hands can turn away the friendly assistance of white hat worms.  It&amp;#8217;s an honor system, but the white hats should be the honorable ones anyway.  The ones which ignore the no-worms-allowed indicator are hostile by definition.&lt;/p&gt;\n\n&lt;p&gt;So, then, the internet develops an immune system.  Anyone can release a white hat worm as soon as they find an exploit to be nullified, and I&amp;#8217;m sure there are lots of geeks out there who&amp;#8217;d jump at the chance to play with worms and virii in a constructive way.  And if you want to opt-out of the system, go for it.  Hell&amp;#8230;  think of this on a smaller scale as a next-gen anti-virus software.  Instead of internet-wide, just support &lt;span class=&quot;caps&quot;&gt;P2P&lt;/span&gt; networks between installations of your anti-virus product.  When it&amp;#8217;s time to close a hole, infect your network with a vaccinating update.  I doubt this would work as well as a fully open system, but might have less controversy.&lt;/p&gt;\n\n&lt;p&gt;Anyway, it&amp;#8217;s a whacky idea to a whacky problem that just might work.&lt;/p&gt;</code></pre>\n<!--more-->\n<p>shortname=superworm</p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221086264\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.dme.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=ba95ba57f948f9de1d4a101bb84cca3a&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.dme.org\">David Edmondson</a>\n</div>\n<a href=\"#comment-221086264\" class=\"permalink\"><time datetime=\"2003-09-05T11:23:25\">2003-09-05T11:23:25</time></a>\n</div>\n<div class=\"content\">How would a system tell the difference between white hat and black hat\nworms or virii when they arrive?  Distributed trust network?</div>\n</li>\n<li class=\"comment\" id=\"comment-221086265\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2ac2cffd36ada8c734b90e02a1e5c1ac&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221086265\" class=\"permalink\"><time datetime=\"2003-09-05T11:45:13\">2003-09-05T11:45:13</time></a>\n</div>\n<div class=\"content\">Well, my incredibly naive idea is this:  White hats knock (ie. contact a known local service), and go away if told to.  Black hats sneak in the back door as usual.</div>\n</li>\n<li class=\"comment\" id=\"comment-221086266\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://webseitz.fluxent.com/wiki\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=5a70d939a73fa73603f2a9255ab81d21&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://webseitz.fluxent.com/wiki\">BillSeitz</a>\n</div>\n<a href=\"#comment-221086266\" class=\"permalink\"><time datetime=\"2003-09-05T12:04:31\">2003-09-05T12:04:31</time></a>\n</div>\n<div class=\"content\">I think this is a bad line to cross. It's harder to argue against RIAA worms when you're supporting other \"good causes\" worms.\nUnfortunately I don't have any great alternative ideas.\nGet the OEMs to bundle ZoneAlarm lite? (Get ZoneAlarm to make a version that's tweaked to scare clueless users into paranoid fears?)</div>\n</li>\n<li class=\"comment\" id=\"comment-221086269\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2ac2cffd36ada8c734b90e02a1e5c1ac&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221086269\" class=\"permalink\"><time datetime=\"2003-09-05T13:45:05\">2003-09-05T13:45:05</time></a>\n</div>\n<div class=\"content\">Hmm, maybe.  Though I'd still say that, if worms sent out by the RIAA don't go away when told, they're rogue.  The only worms with white hats are the ones that stop other worms and virii.  Anything else is unwelcome, and subject to neutralization by other worms.\nHmm.  But yeah, lots of issues and it's a very naive idea</div>\n</li>\n<li class=\"comment\" id=\"comment-221086270\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://geocities.com/free_love98\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=91a4687b3f3c6a42953676d422fbc199&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://geocities.com/free_love98\">sunny</a>\n</div>\n<a href=\"#comment-221086270\" class=\"permalink\"><time datetime=\"2003-09-05T15:11:22\">2003-09-05T15:11:22</time></a>\n</div>\n<div class=\"content\">i actually thought your idea was awesome...just send out worms to fix security holes and they respect your no worms directive unless you specifically allow them in...\nnice site i'll come back later.</div>\n</li>\n<li class=\"comment\" id=\"comment-221086271\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://webseitz.fluxent.com/wiki\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=5a70d939a73fa73603f2a9255ab81d21&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://webseitz.fluxent.com/wiki\">BillSeitz</a>\n</div>\n<a href=\"#comment-221086271\" class=\"permalink\"><time datetime=\"2003-09-05T16:43:01\">2003-09-05T16:43:01</time></a>\n</div>\n<div class=\"content\">Another thought: have a site that tests the holes in your computer when you ask it to. Then you need someone like EFF to promote it. But at least it's a 1-stop-shop.</div>\n</li>\n<li class=\"comment\" id=\"comment-221086272\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://webseitz.fluxent.com/wiki\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=5a70d939a73fa73603f2a9255ab81d21&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://webseitz.fluxent.com/wiki\">BillSeitz</a>\n</div>\n<a href=\"#comment-221086272\" class=\"permalink\"><time datetime=\"2003-09-05T16:49:47\">2003-09-05T16:49:47</time></a>\n</div>\n<div class=\"content\">Another step back: aren't pretty much all the victims of these big worms users who click on email attachments?\n(Sorry if that's a stupid question, I haven't been playing close attention to the technical coverage of the latest infections...)</div>\n</li>\n<li class=\"comment\" id=\"comment-221086273\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=673077cfcaedce7b37ff753d6100560a&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"\">John Burton</a>\n</div>\n<a href=\"#comment-221086273\" class=\"permalink\"><time datetime=\"2003-09-06T11:57:52\">2003-09-06T11:57:52</time></a>\n</div>\n<div class=\"content\">What happens if I'm running some private protocol on a port and this comes along and tried to send some other random data and breaks things? Not a good idea</div>\n</li>\n</ul>\n</div>\n",
    "body": "<blockquote cite=\"http://www.gulufuture.com/superworm.htm\"><i>Or maybe it's time to release our own Defender.A worm which could invasively close down the relevant \"holes\" in Internet security. A defensive worm could use standard intrusion tactics for benign result. For example, it could worm it's way into Windows XP computers and get the owner's permission to turn their firewalls on. It could survey open TCP/IP ports and offer to close them.</i></blockquote><div class=\"credit\" align=\"right\"><small>Source: <cite><a href=\"http://www.gulufuture.com/superworm.htm\">Superworm To Storm The Net On 9/11</a></cite> (via <a href=\"http://www.kurzweilai.net/news/news_single.html?id=2398\">KurzweilAI</a>)</small></div>\t<p>So, anger is my first reaction to the idea of any unwelcome visitors on any of my machines, well intentioned or not.  I&#8217;m sure that there aren&#8217;t many who wouldn&#8217;t feel the same way.  But, although a lot of us try to keep up on patches and maintain decent security, there&#8217;s the &#8220;great unwashed masses&#8221; who just want to &#8220;do email&#8220;.</p>\r\n\r\n\t<p>On one hand, it&#8217;s easy to say, &#8220;Tough.  Learn the care &#38; feeding of your equipment.&#8221;  Yeah, as if that will help or get any response from all the people who&#8217;ve bought into <span class=\"caps\">AOL</span> and have been reassured for years that computers are friendly and easy beasts (despite their intuitions to the contrary).  Hell, I&#8217;d bet that, more often than not, the same person who gets regular oil changes and tune-ups for the car has no idea how to do the equivalent for a computer (or that it even needs it).  Cars have been positioned differently than computers.  No one expects a Spanish Inquisition when they live in a virtual preschool of a user interface with large and colorful buttons and happy smiling faces.  They know there&#8217;s some voodoo going on underneath, but the UI tells them that it&#8217;s nothing to worry about (until <a href=\"http://www.decafbad.com/blog/geek/not_working.html\">it isn&#8217;t working</a>).</p>\r\n\r\n\t<p>Now if the problem was just that stupid users ended up with broken computers, there&#8217;d be no problem.  But, like cars with problems waiting to happen (like worn down tires), their users become a hazard to others.  Unlike cars, however, the problems of stupid users&#8217; computers are contagious and self-replicating: every tire blowout becomes a 1000 car pileup.</p>\r\n\r\n\t<p>It&#8217;s like everyone sits on their recliners watching TV in their houses; not even realizing that there are doors to lock; not even hearing the intruders rummaging through the fridge in the kitchen; and certainly not knowing that there&#8217;s a guy sleeping on the sofa at night working by day to let his army of clones into the neighbor&#8217;s houses.</p>\r\n\r\n\t<p>So, about what about vigilante &#8220;white hat&#8221; worms?  Wouldn&#8217;t it be nice if there was a guy wandering the neighborhood locking door for the ignorant?  Wouldn&#8217;t it be nice if there was a truck driver on the road that forced cars with bald tires off to the side for free tire replacement?  Okay, maybe that&#8217;s a bit whacky, but then again, people with bald tires aren&#8217;t causing 1000 car pileups.</p>\r\n\r\n\t<p>I&#8217;m thinking that &#8220;white hat&#8221; virii and worms are one of the only things that will work, since I&#8217;m very pessimistic about the user culture changing to be more responsible.  Though, what about a compromise?  Install a service or some indicator on every network-connected machine, somewhat like <a href=\"http://www.robotstxt.org/wc/robots.html\">robots.txt</a> , which tells friendly robots where they&#8216;re welcome and where they&#8216;re not.  Set this to maximum permissiveness for white hat worms as a default.  The good guys infect, fix, and self-destruct unless this indicator tells them to stay out.  Then, all of us who want to take maintenance into our own hands can turn away the friendly assistance of white hat worms.  It&#8217;s an honor system, but the white hats should be the honorable ones anyway.  The ones which ignore the no-worms-allowed indicator are hostile by definition.</p>\r\n\r\n\t<p>So, then, the internet develops an immune system.  Anyone can release a white hat worm as soon as they find an exploit to be nullified, and I&#8217;m sure there are lots of geeks out there who&#8217;d jump at the chance to play with worms and virii in a constructive way.  And if you want to opt-out of the system, go for it.  Hell&#8230;  think of this on a smaller scale as a next-gen anti-virus software.  Instead of internet-wide, just support <span class=\"caps\">P2P</span> networks between installations of your anti-virus product.  When it&#8217;s time to close a hole, infect your network with a vaccinating update.  I doubt this would work as well as a fully open system, but might have less controversy.</p>\r\n\r\n\t<p>Anyway, it&#8217;s a whacky idea to a whacky problem that just might work.</p>\r\n<!--more-->\r\nshortname=superworm\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221086264\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.dme.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=ba95ba57f948f9de1d4a101bb84cca3a&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.dme.org\">David Edmondson</a>\r\n                </div>\r\n                <a href=\"#comment-221086264\" class=\"permalink\"><time datetime=\"2003-09-05T11:23:25\">2003-09-05T11:23:25</time></a>\r\n            </div>\r\n            <div class=\"content\">How would a system tell the difference between white hat and black hat\r\nworms or virii when they arrive?  Distributed trust network?</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221086265\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2ac2cffd36ada8c734b90e02a1e5c1ac&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog\">l.m.orchard</a>\r\n                </div>\r\n                <a href=\"#comment-221086265\" class=\"permalink\"><time datetime=\"2003-09-05T11:45:13\">2003-09-05T11:45:13</time></a>\r\n            </div>\r\n            <div class=\"content\">Well, my incredibly naive idea is this:  White hats knock (ie. contact a known local service), and go away if told to.  Black hats sneak in the back door as usual.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221086266\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://webseitz.fluxent.com/wiki\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=5a70d939a73fa73603f2a9255ab81d21&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://webseitz.fluxent.com/wiki\">BillSeitz</a>\r\n                </div>\r\n                <a href=\"#comment-221086266\" class=\"permalink\"><time datetime=\"2003-09-05T12:04:31\">2003-09-05T12:04:31</time></a>\r\n            </div>\r\n            <div class=\"content\">I think this is a bad line to cross. It's harder to argue against RIAA worms when you're supporting other \"good causes\" worms.\r\n\r\nUnfortunately I don't have any great alternative ideas.\r\n\r\nGet the OEMs to bundle ZoneAlarm lite? (Get ZoneAlarm to make a version that's tweaked to scare clueless users into paranoid fears?)</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221086269\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2ac2cffd36ada8c734b90e02a1e5c1ac&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog\">l.m.orchard</a>\r\n                </div>\r\n                <a href=\"#comment-221086269\" class=\"permalink\"><time datetime=\"2003-09-05T13:45:05\">2003-09-05T13:45:05</time></a>\r\n            </div>\r\n            <div class=\"content\">Hmm, maybe.  Though I'd still say that, if worms sent out by the RIAA don't go away when told, they're rogue.  The only worms with white hats are the ones that stop other worms and virii.  Anything else is unwelcome, and subject to neutralization by other worms.\r\n\r\nHmm.  But yeah, lots of issues and it's a very naive idea</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221086270\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://geocities.com/free_love98\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=91a4687b3f3c6a42953676d422fbc199&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://geocities.com/free_love98\">sunny</a>\r\n                </div>\r\n                <a href=\"#comment-221086270\" class=\"permalink\"><time datetime=\"2003-09-05T15:11:22\">2003-09-05T15:11:22</time></a>\r\n            </div>\r\n            <div class=\"content\">i actually thought your idea was awesome...just send out worms to fix security holes and they respect your no worms directive unless you specifically allow them in...\r\nnice site i'll come back later.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221086271\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://webseitz.fluxent.com/wiki\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=5a70d939a73fa73603f2a9255ab81d21&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://webseitz.fluxent.com/wiki\">BillSeitz</a>\r\n                </div>\r\n                <a href=\"#comment-221086271\" class=\"permalink\"><time datetime=\"2003-09-05T16:43:01\">2003-09-05T16:43:01</time></a>\r\n            </div>\r\n            <div class=\"content\">Another thought: have a site that tests the holes in your computer when you ask it to. Then you need someone like EFF to promote it. But at least it's a 1-stop-shop.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221086272\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://webseitz.fluxent.com/wiki\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=5a70d939a73fa73603f2a9255ab81d21&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://webseitz.fluxent.com/wiki\">BillSeitz</a>\r\n                </div>\r\n                <a href=\"#comment-221086272\" class=\"permalink\"><time datetime=\"2003-09-05T16:49:47\">2003-09-05T16:49:47</time></a>\r\n            </div>\r\n            <div class=\"content\">Another step back: aren't pretty much all the victims of these big worms users who click on email attachments?\r\n\r\n(Sorry if that's a stupid question, I haven't been playing close attention to the technical coverage of the latest infections...)</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221086273\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=673077cfcaedce7b37ff753d6100560a&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"\">John Burton</a>\r\n                </div>\r\n                <a href=\"#comment-221086273\" class=\"permalink\"><time datetime=\"2003-09-06T11:57:52\">2003-09-06T11:57:52</time></a>\r\n            </div>\r\n            <div class=\"content\">What happens if I'm running some private protocol on a port and this comes along and tried to send some other random data and breaks things? Not a good idea</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2003",
    "path": "2003/09/05/superworm",
    "summary": "<blockquote cite=\"http://www.gulufuture.com/superworm.htm\"><i>Or maybe it&apos;s time to release our own Defender.A worm which could invasively close down the relevant &quot;holes&quot; in Internet security. A defensive worm could use standard intrusion tactics for benign result. For example, it could worm it&apos;s way into Windows XP computers and get the owner&apos;s permission to turn their firewalls on. It could survey open TCP/IP ports and offer to close them.</i></blockquote><div class=\"credit\" align=\"right\"><small>Source: <cite><a href=\"http://www.gulufuture.com/superworm.htm\">Superworm To Storm The Net On 9/11</a></cite> (via <a href=\"http://www.kurzweilai.net/news/news_single.html?id=2398\">KurzweilAI</a>)</small></div>    <p>So, anger is my first reaction to the idea of any unwelcome visitors on any of my machines, well intentioned or not.  I&#x2019;m sure that there aren&#x2019;t many who wouldn&#x2019;t feel the same way.  But, although a lot of us try to keep up on patches and maintain decent security, there&#x2019;s the &#x201C;great unwashed masses&#x201D; who just want to &#x201C;do email&#x201C;.</p>\n\n<pre><code>&lt;p&gt;On one hand, it&amp;#8217;s easy to say, &amp;#8220;Tough.  Learn the care &amp;#38; feeding of your equipment.&amp;#8221;  Yeah, as if that will help or get any response from all the people who&amp;#8217;ve bought into &lt;span class=&quot;caps&quot;&gt;AOL&lt;/span&gt; and have been reassured for years that computers are friendly and easy beasts (despite their intuitions to the contrary).  Hell, I&amp;#8217;d bet that, more often than not, the same person who gets regular oil changes and tune-ups for the car has no idea how to do the equivalent for a computer (or that it even needs it).  Cars have been positioned differently than computers.  No one expects a Spanish Inquisition when they live in a virtual preschool of a user interface with large and colorful buttons and happy smiling faces.  They know there&amp;#8217;s some voodoo going on underneath, but the UI tells them that it&amp;#8217;s nothing to worry about (until &lt;a href=&quot;http://www.decafbad.com/blog/geek/not_working.html&quot;&gt;it isn&amp;#8217;t working&lt;/a&gt;).&lt;/p&gt;\n\n&lt;p&gt;Now if the problem was just that stupid users ended up with broken computers, there&amp;#8217;d be no problem.  But, like cars with problems waiting to happen (like worn down tires), their users become a hazard to others.  Unlike cars, however, the problems of stupid users&amp;#8217; computers are contagious and self-replicating: every tire blowout becomes a 1000 car pileup.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#8217;s like everyone sits on their recliners watching TV in their houses; not even realizing that there are doors to lock; not even hearing the intruders rummaging through the fridge in the kitchen; and certainly not knowing that there&amp;#8217;s a guy sleeping on the sofa at night working by day to let his army of clones into the neighbor&amp;#8217;s houses.&lt;/p&gt;\n\n&lt;p&gt;So, about what about vigilante &amp;#8220;white hat&amp;#8221; worms?  Wouldn&amp;#8217;t it be nice if there was a guy wandering the neighborhood locking door for the ignorant?  Wouldn&amp;#8217;t it be nice if there was a truck driver on the road that forced cars with bald tires off to the side for free tire replacement?  Okay, maybe that&amp;#8217;s a bit whacky, but then again, people with bald tires aren&amp;#8217;t causing 1000 car pileups.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#8217;m thinking that &amp;#8220;white hat&amp;#8221; virii and worms are one of the only things that will work, since I&amp;#8217;m very pessimistic about the user culture changing to be more responsible.  Though, what about a compromise?  Install a service or some indicator on every network-connected machine, somewhat like &lt;a href=&quot;http://www.robotstxt.org/wc/robots.html&quot;&gt;robots.txt&lt;/a&gt; , which tells friendly robots where they&amp;#8216;re welcome and where they&amp;#8216;re not.  Set this to maximum permissiveness for white hat worms as a default.  The good guys infect, fix, and self-destruct unless this indicator tells them to stay out.  Then, all of us who want to take maintenance into our own hands can turn away the friendly assistance of white hat worms.  It&amp;#8217;s an honor system, but the white hats should be the honorable ones anyway.  The ones which ignore the no-worms-allowed indicator are hostile by definition.&lt;/p&gt;\n\n&lt;p&gt;So, then, the internet develops an immune system.  Anyone can release a white hat worm as soon as they find an exploit to be nullified, and I&amp;#8217;m sure there are lots of geeks out there who&amp;#8217;d jump at the chance to play with worms and virii in a constructive way.  And if you want to opt-out of the system, go for it.  Hell&amp;#8230;  think of this on a smaller scale as a next-gen anti-virus software.  Instead of internet-wide, just support &lt;span class=&quot;caps&quot;&gt;P2P&lt;/span&gt; networks between installations of your anti-virus product.  When it&amp;#8217;s time to close a hole, infect your network with a vaccinating update.  I doubt this would work as well as a fully open system, but might have less controversy.&lt;/p&gt;\n\n&lt;p&gt;Anyway, it&amp;#8217;s a whacky idea to a whacky problem that just might work.&lt;/p&gt;</code></pre>\n",
    "prevPostPath": "2003/09/06/wiki-apis",
    "nextPostPath": "2003/09/04/litany-meetings"
  },
  {
    "comments_archived": true,
    "date": "2003-09-04T14:50:58.000Z",
    "layout": "post",
    "title": "Litany against meetings, courtesy of purl",
    "wordpress_id": 476,
    "wordpress_slug": "litany-meetings",
    "wordpress_url": "http://www.decafbad.com/blog/?p=476",
    "year": "2003",
    "month": "09",
    "day": "04",
    "isDir": false,
    "slug": "litany-meetings",
    "postName": "2003-09-04-litany-meetings",
    "html": "<p>Speaking of Infobots:</p>\n<pre><code>&lt;deusx&gt; litany against meetings?\n&lt;purl&gt; &quot;I must not attend meetings. Meetings are the mind killer.\nMeetings re the little-death that brings total obliteration. I will face \nmy meeting. I will permit it to pass over me and through me. And \nwhen it has gone past I will turn the inner eye to see its path. \nWhere the wasted time has gone there will be nothing. Only \nI will remain.&quot;</code></pre>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221087830\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=c7a3895376100fa2a20cabab927bf35b&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"\">David</a>\n</div>\n<a href=\"#comment-221087830\" class=\"permalink\"><time datetime=\"2003-09-05T09:45:42\">2003-09-05T09:45:42</time></a>\n</div>\n<div class=\"content\">It's surprising how many Frank Herbert fans are out there. Recently there was a Slashdot article (http://slashdot.org/articles/03/09/04/225242.shtml) where someone remarked all these Windows worm should at leat produce some spice.</div>\n</li>\n</ul>\n</div>\n",
    "body": "Speaking of Infobots:\r\n\r\n    <deusx> litany against meetings?\r\n    <purl> \"I must not attend meetings. Meetings are the mind killer.\r\n    Meetings re the little-death that brings total obliteration. I will face \r\n    my meeting. I will permit it to pass over me and through me. And \r\n    when it has gone past I will turn the inner eye to see its path. \r\n    Where the wasted time has gone there will be nothing. Only \r\n    I will remain.\"\r\n\n<div id=\"comments\" class=\"comments archived-comments\">\n            <h3>Archived Comments</h3>\n            \n        <ul class=\"comments\">\n            \n        <li class=\"comment\" id=\"comment-221087830\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=c7a3895376100fa2a20cabab927bf35b&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"\">David</a>\n                </div>\n                <a href=\"#comment-221087830\" class=\"permalink\"><time datetime=\"2003-09-05T09:45:42\">2003-09-05T09:45:42</time></a>\n            </div>\n            <div class=\"content\">It's surprising how many Frank Herbert fans are out there. Recently there was a Slashdot article (http://slashdot.org/articles/03/09/04/225242.shtml) where someone remarked all these Windows worm should at leat produce some spice.</div>\n            \n        </li>\n    \n        </ul>\n    \n        </div>\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2003",
    "path": "2003/09/04/litany-meetings",
    "prevPostPath": "2003/09/05/superworm",
    "nextPostPath": "2003/09/04/jibot-and-purl"
  },
  {
    "comments_archived": true,
    "date": "2003-09-04T12:57:55.000Z",
    "layout": "post",
    "title": "Jibot and purl, distant cousins?",
    "wordpress_id": 475,
    "wordpress_slug": "jibot-and-purl",
    "wordpress_url": "http://www.decafbad.com/blog/?p=475",
    "year": "2003",
    "month": "09",
    "day": "04",
    "isDir": false,
    "slug": "jibot-and-purl",
    "postName": "2003-09-04-jibot-and-purl",
    "html": "<blockquote cite=\"http://epeus.blogspot.com/2003_09_01_epeus_archive.html#106267649855792923\"><i><a href=\"http://jibot.joi.ito.com:8080/braindump.rpy\">What the #joiito bot knows.</a> I'm dumping it out dynamically with the Twisted webserver, which is all Python too.</i></blockquote><div class=\"credit\" align=\"right\"><small>Source: <cite><a href=\"http://epeus.blogspot.com/2003_09_01_epeus_archive.html#106267649855792923\">Epeus' epigone - Kevin Marks weblog</a></cite></small></div>    <p>While the <a href=\"irc://irc.freenode.org/%23joiito\">#joiito</a> bot is looking pretty keen, I keep wondering if anyone hacking on it has seen <a href=\"http://www.infobot.org/\">Infobot</a> ?  It&#8217;s the brains behind purl, the bot serving #perl channels on a few <span class=\"caps\">IRC</span> networks.  Jibot seems to have some funky punctuation-based commands, but purl accepts commands in formulatic english and even picks a few things up from normal channel chatter.  When I look at Kevin Marks&#8217; dump of Jibot&#8217;s brains, I can&#8217;t help but think of the gigantic <a href=\"http://www.infobot.org/factpacks/\">factoid packs</a> available for Infobot.</p>\n<!--more-->\nshortname=jibot_and_purl\n\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221089663\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://epeus.bogspot.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=e7b8f8b0a6e65759ab030afb0c9339e0&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://epeus.bogspot.com\">Kevin Marks</a>\n</div>\n<a href=\"#comment-221089663\" class=\"permalink\"><time datetime=\"2003-09-05T00:58:47\">2003-09-05T00:58:47</time></a>\n</div>\n<div class=\"content\">Jibot doesn't store facts, it stores opinions. It is a communal repository for gossip. When you enter #joiito it heralds you with your communal definition.</div>\n</li>\n<li class=\"comment\" id=\"comment-221089670\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2ac2cffd36ada8c734b90e02a1e5c1ac&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221089670\" class=\"permalink\"><time datetime=\"2003-09-05T01:30:33\">2003-09-05T01:30:33</time></a>\n</div>\n<div class=\"content\">Well, purl doesn't herald, but she does remember gossip and she does impressions of channel regulars.  Oh yeah, and she maintains a Swahilli Phrasebook.  :)</div>\n</li>\n</ul>\n</div>\n",
    "body": "<blockquote cite=\"http://epeus.blogspot.com/2003_09_01_epeus_archive.html#106267649855792923\"><i><a href=\"http://jibot.joi.ito.com:8080/braindump.rpy\">What the #joiito bot knows.</a> I'm dumping it out dynamically with the Twisted webserver, which is all Python too.</i></blockquote><div class=\"credit\" align=\"right\"><small>Source: <cite><a href=\"http://epeus.blogspot.com/2003_09_01_epeus_archive.html#106267649855792923\">Epeus' epigone - Kevin Marks weblog</a></cite></small></div>\t<p>While the <a href=\"irc://irc.freenode.org/%23joiito\">#joiito</a> bot is looking pretty keen, I keep wondering if anyone hacking on it has seen <a href=\"http://www.infobot.org/\">Infobot</a> ?  It&#8217;s the brains behind purl, the bot serving #perl channels on a few <span class=\"caps\">IRC</span> networks.  Jibot seems to have some funky punctuation-based commands, but purl accepts commands in formulatic english and even picks a few things up from normal channel chatter.  When I look at Kevin Marks&#8217; dump of Jibot&#8217;s brains, I can&#8217;t help but think of the gigantic <a href=\"http://www.infobot.org/factpacks/\">factoid packs</a> available for Infobot.</p>\r\n<!--more-->\r\nshortname=jibot_and_purl\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221089663\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://epeus.bogspot.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=e7b8f8b0a6e65759ab030afb0c9339e0&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://epeus.bogspot.com\">Kevin Marks</a>\r\n                </div>\r\n                <a href=\"#comment-221089663\" class=\"permalink\"><time datetime=\"2003-09-05T00:58:47\">2003-09-05T00:58:47</time></a>\r\n            </div>\r\n            <div class=\"content\">Jibot doesn't store facts, it stores opinions. It is a communal repository for gossip. When you enter #joiito it heralds you with your communal definition.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221089670\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2ac2cffd36ada8c734b90e02a1e5c1ac&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog\">l.m.orchard</a>\r\n                </div>\r\n                <a href=\"#comment-221089670\" class=\"permalink\"><time datetime=\"2003-09-05T01:30:33\">2003-09-05T01:30:33</time></a>\r\n            </div>\r\n            <div class=\"content\">Well, purl doesn't herald, but she does remember gossip and she does impressions of channel regulars.  Oh yeah, and she maintains a Swahilli Phrasebook.  :)</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2003",
    "path": "2003/09/04/jibot-and-purl",
    "summary": "<blockquote cite=\"http://epeus.blogspot.com/2003_09_01_epeus_archive.html#106267649855792923\"><i><a href=\"http://jibot.joi.ito.com:8080/braindump.rpy\">What the #joiito bot knows.</a> I&apos;m dumping it out dynamically with the Twisted webserver, which is all Python too.</i></blockquote><div class=\"credit\" align=\"right\"><small>Source: <cite><a href=\"http://epeus.blogspot.com/2003_09_01_epeus_archive.html#106267649855792923\">Epeus&apos; epigone - Kevin Marks weblog</a></cite></small></div>    <p>While the <a href=\"irc://irc.freenode.org/%23joiito\">#joiito</a> bot is looking pretty keen, I keep wondering if anyone hacking on it has seen <a href=\"http://www.infobot.org/\">Infobot</a> ?  It&#x2019;s the brains behind purl, the bot serving #perl channels on a few <span class=\"caps\">IRC</span> networks.  Jibot seems to have some funky punctuation-based commands, but purl accepts commands in formulatic english and even picks a few things up from normal channel chatter.  When I look at Kevin Marks&#x2019; dump of Jibot&#x2019;s brains, I can&#x2019;t help but think of the gigantic <a href=\"http://www.infobot.org/factpacks/\">factoid packs</a> available for Infobot.</p>\n",
    "prevPostPath": "2003/09/04/litany-meetings",
    "nextPostPath": "2003/09/03/another-bmblogger"
  },
  {
    "comments_archived": true,
    "date": "2003-09-03T14:59:31.000Z",
    "layout": "post",
    "title": "Another BookmarkBlogger in Python",
    "wordpress_id": 474,
    "wordpress_slug": "another-bmblogger",
    "wordpress_url": "http://www.decafbad.com/blog/?p=474",
    "year": "2003",
    "month": "09",
    "day": "03",
    "isDir": false,
    "slug": "another-bmblogger",
    "postName": "2003-09-03-another-bmblogger",
    "html": "<p><br /><br />\nI haven&#39;t been paying attention to my referrers as much lately,\nbut I probably should.  Because, when I do, I find things like\n<a href=\"http://www.hollytree-house.co.uk/twiki/bin/view/Main/BmBlog\" target=\"_top\">another implementation</a>\nof <a href=\"http://www.decafbad.com/twiki/bin/view/Main/BookmarkBlogger\">BookmarkBlogger</a> in Python, this one by\n<a href=\"http://www.hollytree-house.co.uk/dme/cgi-bin/blosxom.cgi/web\" target=\"_top\">David Edmondson</a>.\n<br /><br />\nHis version has many fewer requirements, using only core Python\nlibraries as far as I can see.  One of these which I hadn&#39;t any idea\nexisted is\n<a href=\"http://www.usatlas.bnl.gov/~fisyak/star/public/WWW/sources/Python-2.3a1/Lib/plat-mac/plistlib.py\" target=\"_top\">plistlib</a>,\n&quot;a tool to generate and parse <a href=\"http://www.decafbad.com/twiki/bin/view/Main/MacOSX\">MacOSX</a> .plist files&quot;.  When I get\nanother few round tuits, I&#39;ll likely tear out all the XPath use\nin my version and replace it with this.  Bummer.  And here I thought\nI was all clever using the XPaths like that in Python :)</p>\n<!--more-->\n<p>shortname=another_bmblogger</p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221089647\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://anode.anotrash.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=6088d1552d399ae7489f66717354bf68&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://anode.anotrash.com\">anode</a>\n</div>\n<a href=\"#comment-221089647\" class=\"permalink\"><time datetime=\"2003-09-03T11:29:32\">2003-09-03T11:29:32</time></a>\n</div>\n<div class=\"content\">This is the same way I was going for my MT API after not being able to get 4suite built.  It's worth mentioning that plistlib requires pyexpat, so it won;t work on a vanilla Apple Python - you either need to build pyexpat or download MacPython 2.3</div>\n</li>\n</ul>\n</div>\n",
    "body": "<br /><br />\r\nI haven't been paying attention to my referrers as much lately,\r\nbut I probably should.  Because, when I do, I find things like\r\n<a href=\"http://www.hollytree-house.co.uk/twiki/bin/view/Main/BmBlog\" target=\"_top\">another implementation</a>\r\nof <a href=\"http://www.decafbad.com/twiki/bin/view/Main/BookmarkBlogger\">BookmarkBlogger</a> in Python, this one by\r\n<a href=\"http://www.hollytree-house.co.uk/dme/cgi-bin/blosxom.cgi/web\" target=\"_top\">David Edmondson</a>.\r\n<br /><br />\r\nHis version has many fewer requirements, using only core Python\r\nlibraries as far as I can see.  One of these which I hadn't any idea\r\nexisted is\r\n<a href=\"http://www.usatlas.bnl.gov/~fisyak/star/public/WWW/sources/Python-2.3a1/Lib/plat-mac/plistlib.py\" target=\"_top\">plistlib</a>,\r\n\"a tool to generate and parse <a href=\"http://www.decafbad.com/twiki/bin/view/Main/MacOSX\">MacOSX</a> .plist files\".  When I get\r\nanother few round tuits, I'll likely tear out all the XPath use\r\nin my version and replace it with this.  Bummer.  And here I thought\r\nI was all clever using the XPaths like that in Python :)\r\n<!--more-->\r\nshortname=another_bmblogger\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221089647\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://anode.anotrash.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=6088d1552d399ae7489f66717354bf68&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://anode.anotrash.com\">anode</a>\r\n                </div>\r\n                <a href=\"#comment-221089647\" class=\"permalink\"><time datetime=\"2003-09-03T11:29:32\">2003-09-03T11:29:32</time></a>\r\n            </div>\r\n            <div class=\"content\">This is the same way I was going for my MT API after not being able to get 4suite built.  It's worth mentioning that plistlib requires pyexpat, so it won;t work on a vanilla Apple Python - you either need to build pyexpat or download MacPython 2.3</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2003",
    "path": "2003/09/03/another-bmblogger",
    "summary": "<p><br><br>\nI haven&apos;t been paying attention to my referrers as much lately,\nbut I probably should.  Because, when I do, I find things like\n<a href=\"http://www.hollytree-house.co.uk/twiki/bin/view/Main/BmBlog\" target=\"_top\">another implementation</a>\nof <a href=\"http://www.decafbad.com/twiki/bin/view/Main/BookmarkBlogger\">BookmarkBlogger</a> in Python, this one by\n<a href=\"http://www.hollytree-house.co.uk/dme/cgi-bin/blosxom.cgi/web\" target=\"_top\">David Edmondson</a>.\n<br><br>\nHis version has many fewer requirements, using only core Python\nlibraries as far as I can see.  One of these which I hadn&apos;t any idea\nexisted is\n<a href=\"http://www.usatlas.bnl.gov/~fisyak/star/public/WWW/sources/Python-2.3a1/Lib/plat-mac/plistlib.py\" target=\"_top\">plistlib</a>,\n&quot;a tool to generate and parse <a href=\"http://www.decafbad.com/twiki/bin/view/Main/MacOSX\">MacOSX</a> .plist files&quot;.  When I get\nanother few round tuits, I&apos;ll likely tear out all the XPath use\nin my version and replace it with this.  Bummer.  And here I thought\nI was all clever using the XPaths like that in Python :)</p>\n",
    "prevPostPath": "2003/09/04/jibot-and-purl",
    "nextPostPath": "2003/09/02/cl-to-rss"
  },
  {
    "comments_archived": true,
    "date": "2003-09-02T17:44:18.000Z",
    "layout": "post",
    "title": "ChangeLog to RSS web service",
    "wordpress_id": 473,
    "wordpress_slug": "cl-to-rss",
    "wordpress_url": "http://www.decafbad.com/blog/?p=473",
    "year": "2003",
    "month": "09",
    "day": "02",
    "isDir": false,
    "slug": "cl-to-rss",
    "postName": "2003-09-02-cl-to-rss",
    "html": "<p><br /><br />\nHanging out on <a href=\"irc://irc.freenode.org/joiito\">joiito on IRC</a> today,\nI read <a href=\"http://www.jspwiki.org/Wiki.jsp?page=JanneJalkanen\" target=\"_top\">Ecyrd</a> asking\naround about any tools to present <a href=\"http://www.gnu.org/prep/standards_42.html\" target=\"_top\">GNU-style changelogs</a>\nas an <a href=\"http://www.decafbad.com/twiki/bin/view/Main/RSS\">RSS</a> feed.  I couldn&#39;t find any, but I did find\n<a href=\"http://people.redhat.com/jrb/files/changelog2.py\" target=\"_top\">this changelog parser</a>, apparently\nby <a href=\"http://people.redhat.com/jrb/\" target=\"_top\">Jonathan Blandford</a>.  So,\nwhen I had a few free minutes, I took some parts I had laying around, along\nwith this parser, and made this:</p>\n<ul>\n<li> <a href=\"http://www.decafbad.com/2003/08/cl2rss?cl=http%3A%2F%2Fwww.ecyrd.com%2F%7Ejalkanen%2FJSPWiki%2Fnightly%2FChangeLog\"><img src=\"http://www.decafbad.com/images/xml.gif\" border=\"0\" /></a> - <a href=\"http://www.ecyrd.com/~jalkanen/JSPWiki/nightly/ChangeLog\">Changelog for JSPWiki</a>\n</li>\n<li> <a href=\"http://www.decafbad.com/2003/08/cl2rss.txt\" target=\"_top\">Source code for cl2rss</a>\n</li>\n</ul>\nThis is at the \"it works\" stage.  It needs much work in what it presents\nin an <a href=\"http://www.decafbad.com/twiki/bin/view/Main/RSS\">RSS</a> feed, so feel free to suggest changes!\n<!--more-->\nshortname=cl_to_rss\n\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221085069\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://insultconsult.com/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=5b73143e72f280abb5b1e3097608860d&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://insultconsult.com/\">Karl-Martin Skontorp</a>\n</div>\n<a href=\"#comment-221085069\" class=\"permalink\"><time datetime=\"2003-09-02T13:47:44\">2003-09-02T13:47:44</time></a>\n</div>\n<div class=\"content\">Subversion (http://subversion.tigris.org/) can output logs in XML. It is really easy to use XSLT to generate RSS from these logs.</div>\n</li>\n<li class=\"comment\" id=\"comment-221085070\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2ac2cffd36ada8c734b90e02a1e5c1ac&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221085070\" class=\"permalink\"><time datetime=\"2003-09-02T13:50:22\">2003-09-02T13:50:22</time></a>\n</div>\n<div class=\"content\">Well, the thing about this particular case is that this ChangeLog file is hand-maintained in the GNU style.  I've also seen that Emacs has some tools for maintaining these files as well.  Otherwise, there're tools for CVS logs to RSS as well.\nI do keep meaning to check out Subversion though.</div>\n</li>\n<li class=\"comment\" id=\"comment-221085071\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.ecyrd.com/ButtUgly/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8f688c7919a6645352e1bb59b2f45ae4&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.ecyrd.com/ButtUgly/\">Janne Jalkanen</a>\n</div>\n<a href=\"#comment-221085071\" class=\"permalink\"><time datetime=\"2003-09-02T15:40:06\">2003-09-02T15:40:06</time></a>\n</div>\n<div class=\"content\">Man, I owe you at least two beers now.  Thanks again! :-)</div>\n</li>\n</ul>\n</div>\n",
    "body": "<br /><br />\r\nHanging out on <a href=\"irc://irc.freenode.org/joiito\">joiito on IRC</a> today,\r\nI read <a href=\"http://www.jspwiki.org/Wiki.jsp?page=JanneJalkanen\" target=\"_top\">Ecyrd</a> asking\r\naround about any tools to present <a href=\"http://www.gnu.org/prep/standards_42.html\" target=\"_top\">GNU-style changelogs</a>\r\nas an <a href=\"http://www.decafbad.com/twiki/bin/view/Main/RSS\">RSS</a> feed.  I couldn't find any, but I did find\r\n<a href=\"http://people.redhat.com/jrb/files/changelog2.py\" target=\"_top\">this changelog parser</a>, apparently\r\nby <a href=\"http://people.redhat.com/jrb/\" target=\"_top\">Jonathan Blandford</a>.  So,\r\nwhen I had a few free minutes, I took some parts I had laying around, along\r\nwith this parser, and made this:\r\n<ul>\r\n<li> <a href=\"http://www.decafbad.com/2003/08/cl2rss?cl=http%3A%2F%2Fwww.ecyrd.com%2F%7Ejalkanen%2FJSPWiki%2Fnightly%2FChangeLog\"><img src=\"http://www.decafbad.com/images/xml.gif\" border=\"0\" /></a> - <a href=\"http://www.ecyrd.com/~jalkanen/JSPWiki/nightly/ChangeLog\">Changelog for JSPWiki</a>\r\n</li>\r\n<li> <a href=\"http://www.decafbad.com/2003/08/cl2rss.txt\" target=\"_top\">Source code for cl2rss</a>\r\n</li>\r\n</ul>\r\nThis is at the \"it works\" stage.  It needs much work in what it presents\r\nin an <a href=\"http://www.decafbad.com/twiki/bin/view/Main/RSS\">RSS</a> feed, so feel free to suggest changes!\r\n<!--more-->\r\nshortname=cl_to_rss\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221085069\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://insultconsult.com/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=5b73143e72f280abb5b1e3097608860d&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://insultconsult.com/\">Karl-Martin Skontorp</a>\r\n                </div>\r\n                <a href=\"#comment-221085069\" class=\"permalink\"><time datetime=\"2003-09-02T13:47:44\">2003-09-02T13:47:44</time></a>\r\n            </div>\r\n            <div class=\"content\">Subversion (http://subversion.tigris.org/) can output logs in XML. It is really easy to use XSLT to generate RSS from these logs.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221085070\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2ac2cffd36ada8c734b90e02a1e5c1ac&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog\">l.m.orchard</a>\r\n                </div>\r\n                <a href=\"#comment-221085070\" class=\"permalink\"><time datetime=\"2003-09-02T13:50:22\">2003-09-02T13:50:22</time></a>\r\n            </div>\r\n            <div class=\"content\">Well, the thing about this particular case is that this ChangeLog file is hand-maintained in the GNU style.  I've also seen that Emacs has some tools for maintaining these files as well.  Otherwise, there're tools for CVS logs to RSS as well.\r\n\r\nI do keep meaning to check out Subversion though.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221085071\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.ecyrd.com/ButtUgly/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8f688c7919a6645352e1bb59b2f45ae4&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.ecyrd.com/ButtUgly/\">Janne Jalkanen</a>\r\n                </div>\r\n                <a href=\"#comment-221085071\" class=\"permalink\"><time datetime=\"2003-09-02T15:40:06\">2003-09-02T15:40:06</time></a>\r\n            </div>\r\n            <div class=\"content\">Man, I owe you at least two beers now.  Thanks again! :-)</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2003",
    "path": "2003/09/02/cl-to-rss",
    "thumbnail": "http://www.decafbad.com/images/xml.gif",
    "summary": "<p><br><br>\nHanging out on <a href=\"irc://irc.freenode.org/joiito\">joiito on IRC</a> today,\nI read <a href=\"http://www.jspwiki.org/Wiki.jsp?page=JanneJalkanen\" target=\"_top\">Ecyrd</a> asking\naround about any tools to present <a href=\"http://www.gnu.org/prep/standards_42.html\" target=\"_top\">GNU-style changelogs</a>\nas an <a href=\"http://www.decafbad.com/twiki/bin/view/Main/RSS\">RSS</a> feed.  I couldn&apos;t find any, but I did find\n<a href=\"http://people.redhat.com/jrb/files/changelog2.py\" target=\"_top\">this changelog parser</a>, apparently\nby <a href=\"http://people.redhat.com/jrb/\" target=\"_top\">Jonathan Blandford</a>.  So,\nwhen I had a few free minutes, I took some parts I had laying around, along\nwith this parser, and made this:</p>\n<ul>\n<li> <a href=\"http://www.decafbad.com/2003/08/cl2rss?cl=http%3A%2F%2Fwww.ecyrd.com%2F%7Ejalkanen%2FJSPWiki%2Fnightly%2FChangeLog\"><img src=\"http://www.decafbad.com/images/xml.gif\" border=\"0\"></a> - <a href=\"http://www.ecyrd.com/~jalkanen/JSPWiki/nightly/ChangeLog\">Changelog for JSPWiki</a>\n</li>\n<li> <a href=\"http://www.decafbad.com/2003/08/cl2rss.txt\" target=\"_top\">Source code for cl2rss</a>\n</li>\n</ul>\nThis is at the &quot;it works&quot; stage.  It needs much work in what it presents\nin an <a href=\"http://www.decafbad.com/twiki/bin/view/Main/RSS\">RSS</a> feed, so feel free to suggest changes!\n",
    "prevPostPath": "2003/09/03/another-bmblogger",
    "nextPostPath": "2003/09/02/xsl-scraper"
  },
  {
    "comments_archived": true,
    "date": "2003-09-02T04:22:53.000Z",
    "layout": "post",
    "title": "Using web services and XSLT to scrape RSS from HTML",
    "wordpress_id": 472,
    "wordpress_slug": "xsl-scraper",
    "wordpress_url": "http://www.decafbad.com/blog/?p=472",
    "year": "2003",
    "month": "09",
    "day": "02",
    "isDir": false,
    "slug": "xsl-scraper",
    "postName": "2003-09-02-xsl-scraper",
    "html": "<p><br /><br /></p>\n<p>\nAfter tinkering a bit with\n<a href=\"http://www.decafbad.com/blog/geek/rss_scrape_urls2.html\" target=\"_top\">web services and XSLT-based scraping</a>\nlast week for generating <a href=\"http://www.decafbad.com/twiki/bin/view/Main/RSS\">RSS</a> from HTML, I ripped out some work I was\ndoing for <a href=\"http://www.decafbad.com/cvs/XPathScraper/\" target=\"_top\">a Java-based scraper</a> I'd started\nworking on <a href=\"http://www.decafbad.com/blog/tech/old/ooobca.html\" target=\"_top\">last year</a> and\nthrew together a kit of XSLT files that does most everything I was trying\nto do.\n</p><p>\nI'm calling this kit <a href=\"http://www.decafbad.com/twiki/bin/view/Main/XslScraper\">XslScraper</a>, and there's further blurbage and download links\navaiable in the Wiki.  Check it out.  I've got shell scripts to run the stuff\nfrom as a cron job, and CGI scripts to run it all from web services.\n</p><p>\nFor quick gratification, check out these feeds:\n<ul>\n<li> <a href=\"http://www.decafbad.com/2003/08/tidyxslt?xsl=http%3A%2F%2Fwww.whump.com%2Fdropbox%2Fnationrss%2Fnation.xsl&amp;doc=http%3A%2F%2Fwww.thenation.com\"><img src=\"http://www.decafbad.com/images/xml.gif\" border=\"0\" /></a> - <a href=\"http://www.thenation.com\">The Nation</a> (using <a href=\"http://www.whump.com/moreLikeThis/date/21/08/2003\" target=\"_top\">Bill Humphries' XSL</a>) \n</li>\n<li> <a href=\"http://www.decafbad.com/2003/08/tidyxslt?xsl=http%3A%2F%2Fwww.decafbad.com%2F2003%2F08%2Fxsl_scraper%2Fscrapers%2Fkurzweilai.xsl&amp;doc=http%3A%2F%2Fwww.kurzweilai.net%2Findex.html%3Fflash%3D1\"><img src=\"http://www.decafbad.com/images/xml.gif\" border=\"0\" /></a> - <a href=\"http://www.kurzweilai.net/index.html?flash=1\">KurzweilAI.net</a>\n</li>\n<li> <a href=\"http://www.decafbad.com/2003/08/tidyxslt?xsl=http%3A%2F%2Fwww.decafbad.com%2F2003%2F08%2Fxsl_scraper%2Fscrapers%2Fjlist.xsl&amp;doc=http%3A%2F%2Fwww.jlist.com%2FUPDATES%2FPG%2F7%2F\"><img src=\"http://www.decafbad.com/images/xml.gif\" border=\"0\" /></a> - <a href=\"http://www.jlist.com/\">J-List -- You've got a friend in Japan!</a>\n</li>\n<li> <a href=\"http://www.decafbad.com/2003/08/tidyxslt?xsl=http%3A%2F%2Fwww.decafbad.com%2F2003%2F08%2Fxsl_scraper%2Fscrapers%2Fumich-jobs.xsl&amp;doc=http%3A%2F%2Fwebsvcs.itd.umich.edu%2Fjobnet%2Fnew_postings_byjobfamily.php\"><img src=\"http://www.decafbad.com/images/xml.gif\" border=\"0\" /></a> - <a href=\"http://websvcs.itd.umich.edu/jobnet/\">New JOBS at the University of Michigan (By Job Family)</a>\n</li>\n</ul>\n</p>\n<!--more-->\nshortname=xsl_scraper\n\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221082688\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://patrick.lioi.net\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=0af1f52a082bc92d355d3fc9b29b4c2e&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://patrick.lioi.net\">Patrick Lioi</a>\n</div>\n<a href=\"#comment-221082688\" class=\"permalink\"><time datetime=\"2003-09-03T19:03:03\">2003-09-03T19:03:03</time></a>\n</div>\n<div class=\"content\">The KurzweilAI.net feed is empty.</div>\n</li>\n</ul>\n</div>\n",
    "body": "<br /><br />\r\n<p>\r\nAfter tinkering a bit with\r\n<a href=\"http://www.decafbad.com/blog/geek/rss_scrape_urls2.html\" target=\"_top\">web services and XSLT-based scraping</a>\r\nlast week for generating <a href=\"http://www.decafbad.com/twiki/bin/view/Main/RSS\">RSS</a> from HTML, I ripped out some work I was\r\ndoing for <a href=\"http://www.decafbad.com/cvs/XPathScraper/\" target=\"_top\">a Java-based scraper</a> I'd started\r\nworking on <a href=\"http://www.decafbad.com/blog/tech/old/ooobca.html\" target=\"_top\">last year</a> and\r\nthrew together a kit of XSLT files that does most everything I was trying\r\nto do.\r\n</p><p>\r\nI'm calling this kit <a href=\"http://www.decafbad.com/twiki/bin/view/Main/XslScraper\">XslScraper</a>, and there's further blurbage and download links\r\navaiable in the Wiki.  Check it out.  I've got shell scripts to run the stuff\r\nfrom as a cron job, and CGI scripts to run it all from web services.\r\n</p><p>\r\nFor quick gratification, check out these feeds:\r\n<ul>\r\n<li> <a href=\"http://www.decafbad.com/2003/08/tidyxslt?xsl=http%3A%2F%2Fwww.whump.com%2Fdropbox%2Fnationrss%2Fnation.xsl&amp;doc=http%3A%2F%2Fwww.thenation.com\"><img src=\"http://www.decafbad.com/images/xml.gif\" border=\"0\" /></a> - <a href=\"http://www.thenation.com\">The Nation</a> (using <a href=\"http://www.whump.com/moreLikeThis/date/21/08/2003\" target=\"_top\">Bill Humphries' XSL</a>) \r\n</li>\r\n<li> <a href=\"http://www.decafbad.com/2003/08/tidyxslt?xsl=http%3A%2F%2Fwww.decafbad.com%2F2003%2F08%2Fxsl_scraper%2Fscrapers%2Fkurzweilai.xsl&amp;doc=http%3A%2F%2Fwww.kurzweilai.net%2Findex.html%3Fflash%3D1\"><img src=\"http://www.decafbad.com/images/xml.gif\" border=\"0\" /></a> - <a href=\"http://www.kurzweilai.net/index.html?flash=1\">KurzweilAI.net</a>\r\n</li>\r\n<li> <a href=\"http://www.decafbad.com/2003/08/tidyxslt?xsl=http%3A%2F%2Fwww.decafbad.com%2F2003%2F08%2Fxsl_scraper%2Fscrapers%2Fjlist.xsl&amp;doc=http%3A%2F%2Fwww.jlist.com%2FUPDATES%2FPG%2F7%2F\"><img src=\"http://www.decafbad.com/images/xml.gif\" border=\"0\" /></a> - <a href=\"http://www.jlist.com/\">J-List -- You've got a friend in Japan!</a>\r\n</li>\r\n<li> <a href=\"http://www.decafbad.com/2003/08/tidyxslt?xsl=http%3A%2F%2Fwww.decafbad.com%2F2003%2F08%2Fxsl_scraper%2Fscrapers%2Fumich-jobs.xsl&amp;doc=http%3A%2F%2Fwebsvcs.itd.umich.edu%2Fjobnet%2Fnew_postings_byjobfamily.php\"><img src=\"http://www.decafbad.com/images/xml.gif\" border=\"0\" /></a> - <a href=\"http://websvcs.itd.umich.edu/jobnet/\">New JOBS at the University of Michigan (By Job Family)</a>\r\n</li>\r\n</ul>\r\n</p>\r\n<!--more-->\r\nshortname=xsl_scraper\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221082688\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://patrick.lioi.net\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=0af1f52a082bc92d355d3fc9b29b4c2e&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://patrick.lioi.net\">Patrick Lioi</a>\r\n                </div>\r\n                <a href=\"#comment-221082688\" class=\"permalink\"><time datetime=\"2003-09-03T19:03:03\">2003-09-03T19:03:03</time></a>\r\n            </div>\r\n            <div class=\"content\">The KurzweilAI.net feed is empty.</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2003",
    "path": "2003/09/02/xsl-scraper",
    "thumbnail": "http://www.decafbad.com/images/xml.gif",
    "summary": "<p><br><br></p>\n<p>\nAfter tinkering a bit with\n<a href=\"http://www.decafbad.com/blog/geek/rss_scrape_urls2.html\" target=\"_top\">web services and XSLT-based scraping</a>\nlast week for generating <a href=\"http://www.decafbad.com/twiki/bin/view/Main/RSS\">RSS</a> from HTML, I ripped out some work I was\ndoing for <a href=\"http://www.decafbad.com/cvs/XPathScraper/\" target=\"_top\">a Java-based scraper</a> I&apos;d started\nworking on <a href=\"http://www.decafbad.com/blog/tech/old/ooobca.html\" target=\"_top\">last year</a> and\nthrew together a kit of XSLT files that does most everything I was trying\nto do.\n</p><p>\nI&apos;m calling this kit <a href=\"http://www.decafbad.com/twiki/bin/view/Main/XslScraper\">XslScraper</a>, and there&apos;s further blurbage and download links\navaiable in the Wiki.  Check it out.  I&apos;ve got shell scripts to run the stuff\nfrom as a cron job, and CGI scripts to run it all from web services.\n</p><p>\nFor quick gratification, check out these feeds:\n</p><ul>\n<li> <a href=\"http://www.decafbad.com/2003/08/tidyxslt?xsl=http%3A%2F%2Fwww.whump.com%2Fdropbox%2Fnationrss%2Fnation.xsl&amp;doc=http%3A%2F%2Fwww.thenation.com\"><img src=\"http://www.decafbad.com/images/xml.gif\" border=\"0\"></a> - <a href=\"http://www.thenation.com\">The Nation</a> (using <a href=\"http://www.whump.com/moreLikeThis/date/21/08/2003\" target=\"_top\">Bill Humphries&apos; XSL</a>) \n</li>\n<li> <a href=\"http://www.decafbad.com/2003/08/tidyxslt?xsl=http%3A%2F%2Fwww.decafbad.com%2F2003%2F08%2Fxsl_scraper%2Fscrapers%2Fkurzweilai.xsl&amp;doc=http%3A%2F%2Fwww.kurzweilai.net%2Findex.html%3Fflash%3D1\"><img src=\"http://www.decafbad.com/images/xml.gif\" border=\"0\"></a> - <a href=\"http://www.kurzweilai.net/index.html?flash=1\">KurzweilAI.net</a>\n</li>\n<li> <a href=\"http://www.decafbad.com/2003/08/tidyxslt?xsl=http%3A%2F%2Fwww.decafbad.com%2F2003%2F08%2Fxsl_scraper%2Fscrapers%2Fjlist.xsl&amp;doc=http%3A%2F%2Fwww.jlist.com%2FUPDATES%2FPG%2F7%2F\"><img src=\"http://www.decafbad.com/images/xml.gif\" border=\"0\"></a> - <a href=\"http://www.jlist.com/\">J-List -- You&apos;ve got a friend in Japan!</a>\n</li>\n<li> <a href=\"http://www.decafbad.com/2003/08/tidyxslt?xsl=http%3A%2F%2Fwww.decafbad.com%2F2003%2F08%2Fxsl_scraper%2Fscrapers%2Fumich-jobs.xsl&amp;doc=http%3A%2F%2Fwebsvcs.itd.umich.edu%2Fjobnet%2Fnew_postings_byjobfamily.php\"><img src=\"http://www.decafbad.com/images/xml.gif\" border=\"0\"></a> - <a href=\"http://websvcs.itd.umich.edu/jobnet/\">New JOBS at the University of Michigan (By Job Family)</a>\n</li>\n</ul>\n<p></p>\n",
    "prevPostPath": "2003/09/02/cl-to-rss",
    "nextPostPath": "2003/09/01/switched-to-jvds"
  }
]