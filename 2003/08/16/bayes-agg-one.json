{"comments_archived":true,"date":"2003-08-16T00:00:00.000Z","layout":"post","title":"Issues in using SpamBayes to filter news items","wordpress_id":462,"wordpress_slug":"bayes-agg-one","wordpress_url":"http://www.decafbad.com/blog/?p=462","url":"/2003/08/16/bayes-agg-one/","summary":"<p>Despite a reading <a href=\"http://www.srijith.net/trinetre/archives/2003/08/11/index.shtml#000373\">an entry by Srijith</a>\ndiscussing Bayes-based classification as unsuitable\nfor use in news aggregators, I tied <a href=\"http://www.spambayes.org\">SpamBayes</a>\ninto my <a href=\"http://www.decafbad.com/viewcvs.cgi/dbagg/\">homebrew news aggregator</a>\nand have been trying it out this week.  I know I&#x2019;ve been <a href=\"http://www.decafbad.com/blog/geek/syndicated_whuffie.phtml\">talking about it</a>\nfor awhile, but procrastination and being busy all round kept me from getting\nto it.  Funny thing is, when I finally got a chance to really check things out,\nthe integration was a snap.  I&#x2019;d anticipated a bit of work, but was pleasantly\nsurprised.  I doubt that any other aggregator written in\nPython would have a hard time with it.</p>\n\n<pre><code>&lt;p&gt;If, that is, anyone else wants to do it.  I already knew it wasn&amp;#8217;t\n</code></pre><p><a href=\"http://diveintomark.org/archives/2003/07/07/linkdumps_are_like_sex\">magic pixy dust</a>\nbut I figured it might be worth a try.  I will be eating my dogfood\nfor awhile with this, but I&#x2019;m thinking already that what&#x2019;s good for spam\nmight not be so good for news aggregators.</p><p></p>\n<pre><code>&lt;p&gt;Srijith&amp;#8217;s &lt;a href=&quot;http://www.srijith.net/trinetre/archives/2003/08/11/index.shtml#000373&quot;&gt;post&lt;/a&gt;\n</code></pre><p>mentions some snags in ignoring some of the semantics of a news item,\nsuch as whether a word appears in the item&#x2019;s title or information about\nthe item&#x2019;s source.  I don&#x2019;t think that this completely\napplies to how I&#x2019;m doing classification, since SpamBayes appears to\ndifferentiate between words found in email headers and the body itself.\nWhen I feed an item to SpamBayes for training and scoring, I represent\nit as something like an email message, with headers like date, subject,\nfrom, and an &#x201C;X-Link&#x201D; header for the link.  However, even with this,\nI think Srijith&#x2019;s got a point when he writes that this method will miss\na lot of available clues for classification.</p><p></p>\n<pre><code>&lt;p&gt;Unlike Srijith&amp;#8217;s examples, though, I&amp;#8217;m not trying to train my\n</code></pre><p>aggregator to sift entries into any specific categories.  So far, I&#x2019;ve\nbeen trying to get it to discriminate between what I really want to\nread, and what I&#x2019;m not so interested in.  So, I figured that something\nwhich can learn the difference between spam and normal email could help.\nBut, although it&#x2019;s early, I&#x2019;m noticing a few things about the results and\nI&#x2019;ve had a few things occur to me.</p><p></p>\n<pre><code>&lt;p&gt;See, in the case of ham vs spam, I really want all the ham and none of\n</code></pre><p>the spam.  A method to differentiate between these two should be\noptimized toward one answer or the other.  SpamBayes offers &#x201C;I don&#x2019;t\nknow&#x201D; as a third answer, but it&#x2019;s not geared toward anything else\nin-between.  However, in measuring something like &#x201C;interest&#x201C;,\ninbetween answers are useful.  I want all of the interesting stuff,\nsome of the sort-of interesting stuff, and a little of the rest.</p><p></p>\n<pre><code>&lt;p&gt;This is also a problem for me in deciding to what I\n</code></pre><p>should give a thumbs up and what gets the thumbs down.  Even though\nI&#x2019;ve subscribed to a little over 300 feeds, every item from each of\nthem is somewhat interesting to me.  I wouldn&#x2019;t have subscribed to the\nfeed if there wasn&#x2019;t anything of interest there, so I&#x2019;ve already\nbiased the content of what I receive.  Some items are more interesting\nthan others, but the difference between them is nowhere near the\ndifference of wanted ham vs unsolicited spam.  So, I find myself\ngiving the nod to lots of items, but only turning down a few.\nSpamBayes would like equal examples of both, if possible.</p><p></p>\n<pre><code>&lt;p&gt;I&amp;#8217;ll still be playing with this for awhile, but I need to look\n</code></pre><p>around at other machine learning tech.  I&#x2019;m just hacking around,\nbut the important thing is to try to understand the algorithms\nbetter and know how they work and why.  Bayes is in vogue right now,\nbut as Mark Pilgrim intimated, it&#x2019;s not magic.  It&#x2019;s just &#x201C;advanced&#x201D; :)</p><p></p>\n<pre><code>&lt;p&gt;In the immortal words of &lt;a href=&quot;http://www.spidereyeballs.com/os6/set3/small_os6_d3_3596_sm.html&quot;&gt;Mark Jason Dominus&lt;/a&gt;: &amp;#8220;You can&amp;#8217;t just make shit\n</code></pre><p>up and expect the computer to know what you mean, retardo!&#x201D; </p>\n","path":"2003/08/16/bayes-agg-one","content":"<p>Despite a reading <a href=\"http://www.srijith.net/trinetre/archives/2003/08/11/index.shtml#000373\">an entry by Srijith</a>\ndiscussing Bayes-based classification as unsuitable\nfor use in news aggregators, I tied <a href=\"http://www.spambayes.org\">SpamBayes</a>\ninto my <a href=\"http://www.decafbad.com/viewcvs.cgi/dbagg/\">homebrew news aggregator</a>\nand have been trying it out this week.  I know I&#8217;ve been <a href=\"http://www.decafbad.com/blog/geek/syndicated_whuffie.phtml\">talking about it</a>\nfor awhile, but procrastination and being busy all round kept me from getting\nto it.  Funny thing is, when I finally got a chance to really check things out,\nthe integration was a snap.  I&#8217;d anticipated a bit of work, but was pleasantly\nsurprised.  I doubt that any other aggregator written in\nPython would have a hard time with it.</p>\n\n<pre><code>&lt;p&gt;If, that is, anyone else wants to do it.  I already knew it wasn&amp;#8217;t\n</code></pre><p><a href=\"http://diveintomark.org/archives/2003/07/07/linkdumps_are_like_sex\">magic pixy dust</a>\nbut I figured it might be worth a try.  I will be eating my dogfood\nfor awhile with this, but I&#8217;m thinking already that what&#8217;s good for spam\nmight not be so good for news aggregators.</p></p>\n<pre><code>&lt;p&gt;Srijith&amp;#8217;s &lt;a href=&quot;http://www.srijith.net/trinetre/archives/2003/08/11/index.shtml#000373&quot;&gt;post&lt;/a&gt;\n</code></pre><p>mentions some snags in ignoring some of the semantics of a news item,\nsuch as whether a word appears in the item&#8217;s title or information about\nthe item&#8217;s source.  I don&#8217;t think that this completely\napplies to how I&#8217;m doing classification, since SpamBayes appears to\ndifferentiate between words found in email headers and the body itself.\nWhen I feed an item to SpamBayes for training and scoring, I represent\nit as something like an email message, with headers like date, subject,\nfrom, and an &#8220;X-Link&#8221; header for the link.  However, even with this,\nI think Srijith&#8217;s got a point when he writes that this method will miss\na lot of available clues for classification.</p></p>\n<pre><code>&lt;p&gt;Unlike Srijith&amp;#8217;s examples, though, I&amp;#8217;m not trying to train my\n</code></pre><p>aggregator to sift entries into any specific categories.  So far, I&#8217;ve\nbeen trying to get it to discriminate between what I really want to\nread, and what I&#8217;m not so interested in.  So, I figured that something\nwhich can learn the difference between spam and normal email could help.\nBut, although it&#8217;s early, I&#8217;m noticing a few things about the results and\nI&#8217;ve had a few things occur to me.</p></p>\n<pre><code>&lt;p&gt;See, in the case of ham vs spam, I really want all the ham and none of\n</code></pre><p>the spam.  A method to differentiate between these two should be\noptimized toward one answer or the other.  SpamBayes offers &#8220;I don&#8217;t\nknow&#8221; as a third answer, but it&#8217;s not geared toward anything else\nin-between.  However, in measuring something like &#8220;interest&#8220;,\ninbetween answers are useful.  I want all of the interesting stuff,\nsome of the sort-of interesting stuff, and a little of the rest.</p></p>\n<pre><code>&lt;p&gt;This is also a problem for me in deciding to what I\n</code></pre><p>should give a thumbs up and what gets the thumbs down.  Even though\nI&#8217;ve subscribed to a little over 300 feeds, every item from each of\nthem is somewhat interesting to me.  I wouldn&#8217;t have subscribed to the\nfeed if there wasn&#8217;t anything of interest there, so I&#8217;ve already\nbiased the content of what I receive.  Some items are more interesting\nthan others, but the difference between them is nowhere near the\ndifference of wanted ham vs unsolicited spam.  So, I find myself\ngiving the nod to lots of items, but only turning down a few.\nSpamBayes would like equal examples of both, if possible.</p></p>\n<pre><code>&lt;p&gt;I&amp;#8217;ll still be playing with this for awhile, but I need to look\n</code></pre><p>around at other machine learning tech.  I&#8217;m just hacking around,\nbut the important thing is to try to understand the algorithms\nbetter and know how they work and why.  Bayes is in vogue right now,\nbut as Mark Pilgrim intimated, it&#8217;s not magic.  It&#8217;s just &#8220;advanced&#8221; :)</p></p>\n<pre><code>&lt;p&gt;In the immortal words of &lt;a href=&quot;http://www.spidereyeballs.com/os6/set3/small_os6_d3_3596_sm.html&quot;&gt;Mark Jason Dominus&lt;/a&gt;: &amp;#8220;You can&amp;#8217;t just make shit\n</code></pre><p>up and expect the computer to know what you mean, retardo!&#8221; </p>\n<!--more-->\nshortname=bayes_agg_one</p>\n<div id=\"comments\" class=\"comments archived-comments\">\n            <h3>Archived Comments</h3>\n\n        <ul class=\"comments\">\n\n        <li class=\"comment\" id=\"comment-221088958\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://philringnalda.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=e68e9944f50a481a64b5a32fdfc02e0d&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://philringnalda.com\">Phil Ringnalda</a>\n                </div>\n                <a href=\"#comment-221088958\" class=\"permalink\"><time datetime=\"2003-08-16T00:54:54\">2003-08-16T00:54:54</time></a>\n            </div>\n            <div class=\"content\">If you want to train a spam classifier quick, you&#39;ve got to feed it spam. If you want to train an aggregator classifier, you&#39;ve got to subscribe to more crap. I do my best to throw you a really stupid post once a week or so, but you need a bunch of feeds yammering on and on about nothing much.\n\nI&#39;d recommend using MyRSS or Blogstreet (or your own scraper  if you&#39;ve got one) on a random selection of Blog*Spot blogs: my RandomFreshBlog bookmarklet seems to turn up an unending supply of training material.</div>\n\n<pre><code>    &lt;/li&gt;\n\n    &lt;/ul&gt;\n\n    &lt;/div&gt;\n</code></pre>"}