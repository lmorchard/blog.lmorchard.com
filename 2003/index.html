<!DOCTYPE html>
    <html>
      <head>
        <title>2003 - blog.lmorchard.com</title>
        <meta property="og:type" content="article" />
        <meta property="og:site_name" content="blog.lmorchard.com" />
        <meta http-equiv="content-type" content="text/html; charset=utf-8" />
        <meta name="author" content="Les Orchard" />
        <meta
          name="viewport"
          content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0"
        />
        <link
          rel="shortcut icon"
          href="https://www.gravatar.com/avatar/b45c48fc9e05922e2f368a9d7d7d8de1?s=16"
        />

        <script
          defer
          data-domain="blog.lmorchard.com"
          src="https://analytics.lmorchard.com/js/plausible.js"
        ></script>

        <link
          rel="stylesheet"
          type="text/css"
          href="/blog.lmorchard.com/index.css"
        />
        <script type="module" src="/blog.lmorchard.com/index.js"></script>

        <link
          href="https://lmorchard.github.io/blog.lmorchard.com/index.rss"
          rel="alternate"
          title="blog.lmorchard.com"
          type="application/rss+xml"
        />

        <link
                href="/blog.lmorchard.com/index.rss"
                rel="alternate"
                title="blog.lmorchard.com"
                type="application/rss+xml"
              />
        
      </head>
      <body>
        <header class="content-grid">
          <div class="masthead">
            <img src="https://www.gravatar.com/avatar/b45c48fc9e05922e2f368a9d7d7d8de1.jpg?s=128" />
            <div class="title">
              <h1>
                <a href="/blog.lmorchard.com/" title="blog.lmorchard.com">
                  <svg
                    xmlns="http://www.w3.org/2000/svg"
                    width="100%"
                    height="100%"
                    viewBox="0 0 250 20"
                  >
                    <text
                      lengthAdjust="spacing"
                      fill="currentColor"
                      y="16"
                      textLength="240"
                      x="5"
                    >
                      blog.lmorchard.com
                    </text>
                  </svg>
                </a>
              </h1>
              <h2>
                <rotating-tagline
                  random
                  initial="1"
                  period="7000"
                  src="/blog.lmorchard.com/taglines.json"
                >
                  <a href="/blog.lmorchard.com/" title="It&#39;s all spinning wheels &amp; self-doubt until the first pot of coffee.">
                    <svg
                      xmlns="http://www.w3.org/2000/svg"
                      width="100%"
                      height="100%"
                      viewBox="0 0 250 20"
                    >
                      <text
                        class="tagline"
                        lengthAdjust="spacing"
                        fill="currentColor"
                        y="16"
                        textLength="240"
                        x="5"
                      >
                        It&#39;s all spinning wheels &amp; self-doubt until the first pot of coffee.
                      </text>
                    </svg>
                  </a>
                </rotating-tagline>
              </h2>
            </div>
          </div>
          <nav class="main-nav">
            <div id="search"></div>
            <ul>
              <li>
                <a href="http://lmorchard.com/"
                  ><span class="fa fa-info-circle"></span> about me</a
                >
              </li>
              <li>
                <a href="/blog.lmorchard.com/archives.html"
                  ><span class="fa fa-archive"></span> archives</a
                >
              </li>
              <li>
                <a href="https://lmorchard.github.io/blog.lmorchard.com/index.rss" title="blog.lmorchard.com"
                  ><span class="fa fa-rss"></span> feed</a
                >
              </li>
              <li class="theme-selector">
                <theme-selector title="Enable dark theme">
                  <label>
                    <input type="checkbox" />
                    <span class="slider"></span>
                  </label>
                </theme-selector>
              </li>
            </ul>
          </nav>
        </header>

        <section class="main"><section class="post-list">
      <section class="index-header">
          <h2>Year: 2003</h2>
        </section>
      <ul class="posts">
        <li class="content-grid date-header">
    <h2 class="date">2003 December 05</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/12/05/hacking-infinite-and-cognition/">Trying to imagine hackers of cognition and the infinite</a>
      </h2>
    
    <p class="summary">
      I've just read Mark Pilgrim's post, "The infinite hotel", which I'm sure I'll need to re-read a few times and chase down references to read.  Also I'm reading Gödel, Escher, Bach again for the third time, since I first read it in high school and needed corks in my ears to prevent brain slurry from spilling out.  I really need to read more of this sort of thing, refresh myself on all the math I took in college, and explore some of this really abstract stuff.


Something I've been musing about lately, without any real novel ideas or insights, is about the history of computation and these thinking machines.  Not history in terms of events and when, but in terms of the concepts and discoveries leading up to keyboards, screens, and code today.  Thinking about things like recursion, and sets, and logic, and all the patterns and revolutions in thought that are the basis for everyday business and life today.


I've been trying to imagine the world in each moment where each of these things were new, when these things were worked out in minds and on paper.  When there were no computational engines available to carry out calculations or work out conclusions to logical constructions.  
Today, these discoveries are crystallized in computing architectures, and so geeks hack and play and learn by example.  The construction of the CPU is objective fact, independent of subjective thought or understanding, and the behavior of code demonstrates the laws and rules.  Before, the rules were carefully reasoned out and intuited from observations on the objective universe, but now they're assimilated by example from mechanically working artifacts.


I'm not sure I'm expressing this very well, or if my thoughts are very well formed altogether, but I'm trying to imagine mental life without readily available, objectively existing computational artifacts with which we can play, without prohibitive investments of effort or time.  No scripting languages with which to just try out logical constructions.  No calculators with which to solve formulae.  All manual, all by hand, all worked out by careful thought and precision.  I'm trying to imagine what geeks like me, as I am today, would be like at a time when everyone dealing in these things was an abstraction astronaut, and there was not really a such thing as that-which-just-works or worse-is-better.  Does this make any sense?


Again, this is not really an expression of anything coherent or novel.  This is mostly me just in awe of how we got here, and trying to get myself above the mode of being just a hacker chasing down the phylogeny of all that's come before, and into some meta-mode of understanding of the things behind what makes these thinking machines and the thinking itself work.  Maybe after a few more decades of this I'll have some thoughts worth sharing synthesized from all that I've learned.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/12/05/hacking-infinite-and-cognition/"
          >788&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/12/05/hacking-infinite-and-cognition/">#</a>
    <a class="time" href="2003/12/05/hacking-infinite-and-cognition/">12:40 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 November 26</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/11/26/polling-and-urgency/">Varied feed polling times versus item urgency in aggregators</a>
      </h2>
    
    <p class="summary">
      The problem with varying the polling interval is that the need varies. It's ok not to poll my little opensource website within 24 hours, but what about the announcements to the civil defence website or local municipal environment alerts, or the nuclear power plant news feed?



Source:Comments on The End of RSS 






Definitely a good point there.  For most of the feeds in my daily habit, what I use is an AIMD variation on my polling frequency per feed based on occurrence of new items.  For feeds with low-frequency but high-urgency items, a different algorithm should come into play.



On the other hand...  should incoming alerts with that much urgency really be conveyed via an architecture driven by polling?  Here's an excellent case for tying instant messaging systems and pub/sub into the works.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/11/26/polling-and-urgency/"
          >155&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/11/26/polling-and-urgency/">#</a>
    <a class="time" href="2003/11/26/polling-and-urgency/">11:02 am</a>
    
  </div>
  </li><li class="content-grid post post-type-entry has-thumb">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/11/26/the-memo/">Didja get that memo?</a>
      </h2>
    <div class="thumb">
      <img src="http://www.userfriendly.org/cartoons/archives/03nov/uf006166.gif" />
    </div>
    <p class="summary">
      
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/11/26/the-memo/"
          >10&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/11/26/the-memo/">#</a>
    <a class="time" href="2003/11/26/the-memo/">9:50 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 November 21</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/11/21/delicious-quicklinks/">Publishing Quick Links in blosxom with del.icio.us via xmlstarlet</a>
      </h2>
    
    <p class="summary">
      In case anyone is interested in using del.icio.us with blosxom in place of my own BookmarkBlogger, get yourself a copy of xmlstarlet and check out this shell script:

#!/bin/bash

<p>DATE=${1-<code>date +%Y-%m-%d</code>}
BLOG="/Users/deusx/desktop/decafbad-entries/links"
FN="${BLOG}/"<code>echo ${DATE} | sed -e 'y/0123456789-/oabcdefghij/'</code>".txt"</p>
<p>curl -s -u deusx:HAHAHA '<a href="http://del.icio.us/api/posts/get?dt='$%7BDATE%7D">http://del.icio.us/api/posts/get?dt='${DATE}</a> |<br>    tidy -xml -asxml -q -f /dev/null |<br>    xml sel -t -o "Quick Links" -n <br>            -e 'ul'  -m '//post' <br>            -e 'li'  -e 'a' -a 'href' -v '@href' <br>            -b -v 'text()' -n  > ${FN}</p>
<p>touch -d "${DATE} 23:59" ${FN}


You could do this with XSLT, but hacking with a REST-ish & XML producing web service entirely in a shell script seemed oddly appealing to me that week.  Extending this sort of thing to blogging systems other than blosxom is left as an exercise to the reader.


Update: Hmm, looks like one of the blosxom plugins I'm using hates the variables in my code above.  So I stuck curly braces in, which seem to get through okay.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/11/21/delicious-quicklinks/"
          >244&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/11/21/delicious-quicklinks/">#</a>
    <a class="time" href="2003/11/21/delicious-quicklinks/">9:47 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 November 20</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/11/20/recipe-web-3/">Building the Recipe Web III</a>
      </h2>
    
    <p class="summary">
      
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/11/20/recipe-web-3/"
          >971&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/11/20/recipe-web-3/">#</a>
    <a class="time" href="2003/11/20/recipe-web-3/">11:34 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 November 18</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/11/18/voodoo-pad-wiki-api/">VoodooPad gets an XML-RPC wiki API</a>
      </h2>
    
    <p class="summary">
      You wanted to share the same documents with your coworkers and friends. Now you can.

With VoodooPad 1.1, you can view, edit, and save to any wiki that supports the 'vpwiki api'.
Source:Flying Meat Software





<p>Funny, I&#8217;ve been tinkering with <a href="http://www.decafbad.com/twiki/bin/view/Main/XmlRpcToWiki">a wiki <span class="caps">API</span></a> along with a <a href="http://www.jspwiki.org/Wiki.jsp?page=WikiRPCInterface">few others tinkerers</a> for a year or so now.  I wonder if we could get these APIs merged or synched and give VoodooPad access to a slew of wikiware?</p>
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/11/18/voodoo-pad-wiki-api/"
          >360&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/11/18/voodoo-pad-wiki-api/">#</a>
    <a class="time" href="2003/11/18/voodoo-pad-wiki-api/">8:36 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 November 16</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/11/16/the-recipe-web-2/">Building the Recipe Web II</a>
      </h2>
    
    <p class="summary">
      Every once in a while, someone gets ideas about crossing recipes and computers. Of course, I love the idea. Two common ideas we hear a lot are 1) to put recipes in XML format and do all sorts of wonderful things and 2) that kitchen appliances should be smart and you should be able to feed them recipes and have your food made for you. They're both great ideas, but invariably, people underestimate the work involved ("But it's just a recipe!") and overestimate the usefulness ("It would be so cool!").


Source:Troy & Gay





Here’s a good response from someone who knows what he’s talking about when it comes to recipes on the web—he’s one of the contributors to the aforementioned RecipeML format and is part of the team responsible for Recipezaar .  While I think that recipes as syndicated microcontent could be a good thing, Troy makes some important points here.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/11/16/the-recipe-web-2/"
          >152&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/11/16/the-recipe-web-2/">#</a>
    <a class="time" href="2003/11/16/the-recipe-web-2/">11:39 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 November 14</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/11/14/the-recipe-web/">Building the Recipe Web?</a>
      </h2>
    
    <p class="summary">
      RecipeML is a format for representing recipes on computer. It is written in the increasingly popularExtensible Markup Language - XML.

If you run a recipe web site, or are creating a software program -- on any platform -- that works with recipes, then you should consider using RecipeML for coding your recipes! See the FAQs and the new examples for more info.



Source:RecipeML - Format for Online Recipes






So I'm all about this microcontent thing, thinking recently about recipes since reading Marc Canter's post about them.  Actually, I've been thinking about them for a couple of years now, since I'd really like to start cooking some decent meals with the web's help.  Oh yeah, and I'm a geek, so tinkering with some data would be fun too.


One thing I rarely notice mentioned when ideas like this come up is pre-existing work.  Like RecipeML or even the non-XML MealMaster format.  Both of these have been around for quite a long time, especially so in the case of MealMaster.  In fact, if someone wanted to bootstrap a collection of recipes, you can find a ton (150,000) of MealMaster recipes as well as a smaller archive (10,000) of RecipeML files.  Of course, I'm not sure about the copyright situation with any of these, but it's a start anyway.


But, the real strength in a recipe web would come from cooking bloggers.  Supply them with tools to generate RecipeML, post them on a blog server, and index them in an RSS feed.  Then, geeks get to work building the recipe aggregators.  Hell, I'm thinking I might even give this a shot.  Since I'd really like to play with some RDF concepts, maybe I'll write some adaptors to munge RecipeML and MealMaster into RDF recipe data.  Cross that with FOAF and other RDF whackyness, and build an empire of recipe data.


The thing I wonder, though, is why hasn't anyone done this already?  And why hasn't anyone really mentioned much about what's out there already like RecipeML and MealMaster?  It seems like the perfect time to add this into the blogosphere.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/11/14/the-recipe-web/"
          >1292&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/11/14/the-recipe-web/">#</a>
    <a class="time" href="2003/11/14/the-recipe-web/">6:51 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 November 12</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/11/12/The-Whuffie-Web-II/">The Whuffie Web II</a>
      </h2>
    
    <p class="summary">
      What I believe we are seeing is domain experts seeking each other out.  Crossing organizational and philosophical boundaries.


Source:Sam Ruby: Whuffie Web





...someone that's G-list globally might be A-list amongst pet owners.


Source:Danny Ayers: Whuffie Web






A very, very good point that I'd missed at first thought about the Whuffie Web.  There's a matter of scale involved here, where the relative A's through Z's are completely different given your choice of grouping.  And, where choice of grouping is around topic area, the world's a bit of a smaller place and getting your questions answered is likely much easier.  Especially if you've built up some Whuffie in that domain area by generating some useful answers and knowledge yourself.  For newcomers to a domain of knowledge, who have lesser stockpiles of Whuffie, they'll hopefully be fortunate enough to find much of what they're looking for chronicled in the archives of blogs of those who've come before.  When they don't, though, it can still be a frustrating experience.



But, semantic web tech in and of itself doesn't solve the problem where data or knowledge is missing altogether.  How could it?  So, although I was a bit dismissive at first thought about what Dave Winer wrote, he nonetheless has a good point.  Even if the semantic web were richly populated with data and running in full swing, it would still be missing large swaths of Things People Know.  And, well, the thing to use in that case is-- wait for it-- People Who Know Things.  And the way you hopefully can get to them is by being nice and interesting, then blog the answers or ask the people answering your query to blog it themselves.  Then, hopefully, we have blogging tools which can do the bits of pre-digestion to allow that knowledge to be accessed via semantic web machinery to fill in the gaps.



This all takes me back to when I first encountered Usenet in my Freshman year of college, and became instantly enamoured with FAQs.  It seemed like there was a FAQ for everything: coffee, anime, meditation, Baha'i faith, Objectivism, and hedgehogs.  It seems mighty naive to me now, but at the time, I so thought that this was the modern knowledge factory.  Through the contentious and anal bickerings of discussion threads on Usenet, and the subsequent meticulous maintenance of FAQ files, every trivial bit about everything within the sphere of human concerns would be documented and verified and available for perusal by interested parties.  Netiquette demanded that one pour over the FAQs before entering the conversational fray, so the same ground wouldn't be endlessly rehashed.  Approval from one's peers in the group came from generating new and novel things to add to the FAQ, and all were happy.



This, of course, summarizes thoughts coming from a Freshman compsci student getting his first relatively unfettered access to the internet, gushing about everything.  On the other hand, I have many of the above enthusiasms for the Semantic Web's promises.  In a few years, I expect that my enthusiasm will be more even, yet at the same time, I expect there still to be some real uses and benefits to this stuff stabilizing out of it all.  Hopefully, it doesn't get obliterated by spam before then, like Usenet, like email, and now (but hopefully not) in-blog discussions.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/11/12/The-Whuffie-Web-II/"
          >554&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/11/12/The-Whuffie-Web-II/">#</a>
    <a class="time" href="2003/11/12/The-Whuffie-Web-II/">1:35 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry has-thumb">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/11/12/as-a-child-64/">As a child, I would have teased Mark Pilgrim</a>
      </h2>
    <div class="thumb">
      <img src="http://www.decafbad.com/blog-images/working-at-c64-cropped.jpg" />
    </div>
    <p class="summary">
      I see that Mark Pilgrim has posted a picture of himself as a kid, working at an Apple //e.  Based on what I wrote this past Summer about being Newly Digital in 1983, I would guess that around the same time I was working on a Commodore 64, and I would have teased him in a relentlessly geeky way about his clearly inferior machine.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/11/12/as-a-child-64/"
          >65&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/11/12/as-a-child-64/">#</a>
    <a class="time" href="2003/11/12/as-a-child-64/">12:48 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 November 10</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/11/10/the-whuffie-web/">How about a demo of the Whuffie Web?</a>
      </h2>
    
    <p class="summary">
      Let's do a demo of the Semantic Web, the real one, the one that exists today. Doc Searls has a question about  the iQue 3600 hand-held GPS. It is sexy. They say it only works with Windows, but Doc thinks it probably works with Linux too. A couple of thousand really smart people will read this. I'm sure one of them knows the answer. Probably more than one. There's the query. Human intelligence is so under-rated by computer researchers, but when we do our job well, that's what we facilitate. Human minds communicating with other human minds. What could be easier to understand?


Source:Scripting News








Well, I certainly wouldn't call this the Semantic Web-- more like the Whuffie Web.  See, if we were all A-List bloggers, with our own constellations of readers willing to pitch in to answer a question, we could all make queries like the above.  A-List bloggers have the big Whuffie.  Most everyone else has much less Whuffie, thus their query powers are much less.  I somehow doubt that the Whuffie Web, if it were to take off in a big way, would work to equal benefit for everyone.  A cousin, the Lazyweb, sometime serves its petitioners well, but it's a fickle and unpredictable thing indeed.  Sometimes you get magic, sometimes you get shrugs.  This also links into the Whuffie Web, in that Lazyweb contributors will be more likely to service a request if it comes from a Big Time Blogger.  It's all about the Whuffie exchange.



On the other hand, if this Semantic Web thing were to take off, it'd benefit anyone who could lay hands on the connectivity to acquire the data, and the CPU power to churn through it.  The data itself could come from anyone with the connectivity to provide the data, and the brain power to create and assemble it from information and knowledge.  No underestimation of human intelligence here.  If anything, it's an attempt to better respect the exercise human intelligence, to conserve it, and make it more available.  Were the Semantic Web to take off in a big and easy to use way, people could spend more time creating answers and less time answering questions, since the machines do the job of fielding the questions themselves.



Of course... without the Whuffie, where's the motivation to provide the data?
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/11/10/the-whuffie-web/"
          >587&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/11/10/the-whuffie-web/">#</a>
    <a class="time" href="2003/11/10/the-whuffie-web/">10:14 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 November 03</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/11/03/reviews-in-rdf/">Reviews in RSS feeds</a>
      </h2>
    
    <p class="summary">
      The RVW specification is a module extension to the RSS 2.0 syndication format. RVW is intended to allow machine-readable reviews to be integrated into an RSS feed, thus allowing reviews to be automatically compiled from distributed sources.  In other words, you can write book, restaurant, movie, product, etc. reviews inside your own website, while allowing them to be used by Amazon or other review aggregators.


Source:Blogware Implements Distributed Reviews






Aww, yeah.  Bring on the microcontent.  Yay, hooray!  This is an XML namespace-based extension to RSS 2.0, and for even more flavor, it uses the work of other pre-existing specs, such as ENT, FOAF, and Dublin Core.  This wouldn't be hard at all to slip into an RSS 1.0 feed and an RDF database as well.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/11/03/reviews-in-rdf/"
          >126&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/11/03/reviews-in-rdf/">#</a>
    <a class="time" href="2003/11/03/reviews-in-rdf/">10:07 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 October 29</h2>
  </li><li class="content-grid post post-type-entry has-thumb">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/10/29/panther-and-forgotten-connections/">Panther, forgotten connections, and no more lockups</a>
      </h2>
    <div class="thumb">
      <img src="http://www.decafbad.com/blog-images/server-disconnect.gif" />
    </div>
    <p class="summary">
      Oh yeah, and, just noticed this upon arriving at work.  In the past 6 months, forgotten mounted shares and the subsequent filesystem-related lockups and beach-ball-spinnings in Jaguar have been my sole reason for reboot.


As it would happen, I forgot to disconnect from shares on my home LAN again, and awoke my PowerBook on the work LAN.  Before Panther, this would have lead to a reboot within 10 minutes.  This time, it did the Right Thing.  Yay hooray!


Oh, and the Grab application works for individual windows now-- something which seemed to always be greyed out before.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/10/29/panther-and-forgotten-connections/"
          >98&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/10/29/panther-and-forgotten-connections/">#</a>
    <a class="time" href="2003/10/29/panther-and-forgotten-connections/">9:14 am</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/10/29/late-to-the-panther-party/">Late to the Panther party</a>
      </h2>
    
    <p class="summary">
      I know I'm late to the blogosphere release party for Panther, but I just got it last night and, biting the bullet, installed it with only minimal effort toward backing things up.  I intend to eventually wipe this PowerBook completely and install fresh, but I couldn't wait.  :)


Mark Pilgrim published the most definitive coverage of the beastie I've seen yet, with help of the denizens of #joiito to manage the onslaught of readers.  So, I won't make any attempt to catalog the new things.


A few impressions though:


Everything feels faster.  Windows slide around and resize like they've been waxed underneath.  Things seem to launch faster.
A few small things have improved, like System Preferences quitting when I close the window, rather than hanging around waiting for me to open the window again or quit.
Some third-party extension I had installed threw Finder into a launch-and-crash loop for awhile.  So, if you've yet to install, try to purge your system of extensions first.  This should be obvious, but is sometimes a surprise when it's actually a problem.
Expose looked like a neat feature when I first heard of it.  I fully expected it to be slow, stuttery, and 'cute' when I finally played with it.  Now, having used it and slowly incorporating it into my usage habits, it's amazing.  Smooth and not stuttery at all, it looks like a computer interface feature from the movies.
Fast user switching, where desktops rotate in and out of view, also looks like you wish it would, and seems like it's from the movies.
I hate metal.
I hate metal.
I hate metal.




That is all.  For now.  Maybe.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/10/29/late-to-the-panther-party/"
          >277&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/10/29/late-to-the-panther-party/">#</a>
    <a class="time" href="2003/10/29/late-to-the-panther-party/">8:38 am</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/10/29/nokia-ngage-schmutz/">A thought about the Nokia N-Gage</a>
      </h2>
    
    <p class="summary">
      After playing with an N-Gage, I think sidetalkin.com is freakin' hillarious.  One thought on this sidetalking thing, though:


At least it keeps the screen from getting all schmutzed.  My Treo 300 screen gets absolutely filthy, due to me pressing the slab up against my head to talk.  Also, there seems to be a defect in the LCD developing, which seems to have something to do with, again, being pressed up against my face.


In most other ways, this thing looks to be a flop...  but the sidetalking thing might just not be such a bad idea.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/10/29/nokia-ngage-schmutz/"
          >97&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/10/29/nokia-ngage-schmutz/">#</a>
    <a class="time" href="2003/10/29/nokia-ngage-schmutz/">8:06 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 October 16</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/10/16/seeing-out-opposites/">Seeking Out Opposites</a>
      </h2>
    
    <p class="summary">
      For the past year or two, I've been trying an experiment in my
personal research and learning.  I've been seeking out tools and
technologies which are as different as possible from those with which
I already have experience.  I want to break up some prejudices and
habits I have, and expose myself to more ways of looking at things.
Now that I write this, it sounds like a great approach to life in
general, but for now I'm focusing on computer science.  :)



My success 
with this has been entirely dependant on free time and brain cycles,
of which I've had precious little.  But, I have managed to wean myself
away from Perl to learning Python, developing a few apps with it and
incorporating it into my problem solving kit.  I've also managed to
get myself away from XEmacs for hours at a time in order to weave Vim
into my work-a-day life.  These two things haven't been easy for me,
since I've been using both Perl and some variant of Emacs for almost
12 years now, and I've done my share of sneering at that which is not
perl or emacs.  



And, although I've yet to spring upon them, I've also been making wary, 
narrowing circles around Lisp, Smalltalk, Prolog, and .NET.  There
been occasional forays into Java, as well as my daily attachment to
Flash and Actionscript lately.  And then, there've been my hefting and
swinging of XSLT and XPath, as well as RDF, countered by a few feints
with plaintext shell tools and YAML.  There's been more, but most
investigations have been too tentative to mention.



If there's a "holy war" between two things, I want to explore them both.
I tend to see two apparently intelligent parties in an extended debate
over which of them has a hold on the One True Way.  In my
experience, though, there's a high likelyhood that such a phenomenon
points toward a real truth which lies somewhere inbetween.  (This, of
course, ignoring such cases where one party is correct, and the other
is WRONG, WRONG, WRONG!)  There tend to be very good reasons why smart
people on either side of a fence have taken up with what they have,
and I want to know both sides thoroughly.  I know full well that both
sides have at least some valid criticisms against the other, but I
want a synthesis of the two.



In this field of computer science, there
are as many ways of working with the dreamstuff as there
are ways of structuring thoughts.  And, rather than there ever being
One True Way to do things, there will always be another smart person
developing another powerfully expressive and insightful way of doing
things.  Someday, I'd like to be one of those smart people, so I need
to have a sense for that truth in the middle that other One True Ways 
bracket and zero in on.  And then, I want to know enough to jump out
of the frame altogether, and in which ways I can invert and twist
things to encircle some new spark.



Someday in the next few years, I'd like to get back into school so I
can get to even higher levels of growing up to be a computer scientist.
But for now, it's back to work for me.  And, if you happen to think of
any geeky holy wars, let me know.  I'm collecting them for study.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/10/16/seeing-out-opposites/"
          >1111&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/10/16/seeing-out-opposites/">#</a>
    <a class="time" href="2003/10/16/seeing-out-opposites/">1:19 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 October 14</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/10/14/when-rss-attacks/">When RSS Developers Attack</a>
      </h2>
    
    <p class="summary">
      I agree with Derek Balling [who criticized Foo Camp], and when you come back to earth, I bet you will too Jeremy.
Did I read that you guys had meetings about RSS? At a private invitation-only event? Do you realize how WRONG that is?



Source:Dave Winer in a comment on "Some Foo Camp Links"






One of the sessions on Sunday morning at FOO Camp was a brainstorming session on how a site could provide a list of feeds.
...A working name for this effort is "FDML".  The stands for Feed (Discovery / Directory / Detailing) Markup Language, depending on who you ask. ;-)



Source:Sam Ruby: FDML






Just so it is absolutely clear: all I have done is listed a set of requirements, many if not most of which are directly from Jeremy himself.  The acronym was suggested by David Sifry.
People are welcome to question, refine, or add to the requirements, or present proposals on how these requirements can best be implemented.  Perhaps even with OPML.



Source:A later comment on Sam Ruby: FDML






For anyone who wonders why people talk about politics and animosity in
the tiny sphere of web syndication tech, here's a case in point.



You see, there was a private event over the weekend, called Foo Camp.
To this, many smart people were invited, and many more weren't.
Grousing about invitations, funding, and elitism aside, it sounded
like a great time and a cool change from your average conference.  I
hope it turns into a regular event, and hope that someday I'm given
the opportunity to go to something like it.  I'm sure a lot of us
out here would like to make it to something like that.



But, for what it was, you can only gather so many people before it
becomes a circus (or a conference).  Charging a price serves as a
limiter, while making the event invitation-only works as well.  The
difference is whether you're bringing in people who can afford it
versus people who are favored by the organizer.  Either way, someone's
going to be pissed about not going.  The difference is whether you're
pissed off at the organizer's economics or the organizer's
personality.  Oh well.



So anyway, around mid-September, Jeremy Zawodny had floated
an idea
involving publishing and discovery of lists of RSS feeds.
He was one of those invited to Foo Camp, and in one of their
huddles, he brought the idea up for a brainstorming session.
From the sounds of it, they tossed around a few ideas, but
didn't really come up with much other than that it was an idea
worth discussing.



No sooner than the camp breaks up, though, and the angry buzz
has already started.  How dare a bunch of geeks talk about
technology they're interested in while at a private gathering?
How dare they not invite all of us?  Conspiracy!  Elitism!
They didn't pick me for their kickball team!  By the way,
this isn't an attempt to put words in mouths.  This is my
off-the-cuff impression of what I read yesterday.  It all
seems repeatedly and unnecessarily childish to me, and it's
certainly not limited to one person.



So, by today, there's already
a wiki
devoted to exploring this idea, along with a scattering of blog
posts. This seems pretty speedy to me,
considering campers returning to the work-a-day world after
a geek retreat.  This doesn't seem at all the work of a sinister
cabal bent on wresting control and domination over a technology,
as what I saw implied in the first comment I quoted above.



Dave Winer's already posted a
first proposal
toward implementing the idea.  And, believe it or not, as Sam comments
on above, this approach has not been ruled out.  In fact,
Jeremy had suggested using OPML in his original posting of the idea.



Why couldn't we just have seen the collaboration without the
antagonism, in at least this case?  Yeah, there was a small, private
gathering at which discussions were had.  Sounds like what happens at
work, or with friends, or in classes.  Granted, I suppose an argument
could be made concerning the relative openness of these gatherings as
compared to Foo Camp.  But, this is mooted by the fact that the
people involved were already moving toward sharing the discussion.



For all the grousing about flame wars and personality clashes on
mailing lists and working groups, sometimes it's nice to work on an
idea in a smaller group with a good dynamic.  It helps to get
something together before throwing the doors open to have the thing
buffeted by opinions and criticism from all sides.  It's one way to
avoid "stop
energy" while trying to build some momentum.



As Dave himself wrote, "I heard at a working group meeting that things
like SOAP can only happen when no one is paying attention."  So, it
sounds like a bunch of geeks tried to get something rolling before the
attentional heat lamps turned on it.  Had they wanted to be a sinister
cabal, we certainly wouldn't have heard about any of this until long,
long after the event.  It would have been kept behind closed corporate
doors until the day of embrace-and-extend.  Then, profit!  As it is, I
think they erred on the side of throwing open the discussion
too early.



So anyway, the reason I write at such length about this is that I
don't think that this should be let to pass without comment or
consideration.  This kind of thing is what's wrong.  We need to take
at least three deep breaths before reacting like this, whether
or not we've taken 900 beep breaths in the past already.  It's the
nature of these things.  As an interested but outside observer, the
atmosphere created by such reactions makes me very sad.  And it's not
just one person doing this, either.



So, chill out.  It's just data.  In fact, the proposal at question
here is just a friggen outline of feeds!  It's just a list of
lists!  Most of the geeks out there just want to play, and are happy
to have more geeks to play with.  Can't we just get along and play the
game together, rather than gaming each other?
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/10/14/when-rss-attacks/"
          >1116&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/10/14/when-rss-attacks/">#</a>
    <a class="time" href="2003/10/14/when-rss-attacks/">11:05 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 October 08</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/10/08/microcontent-and-rss-data/">Microcontent and RSS-Data</a>
      </h2>
    
    <p class="summary">
      In response to the opposition to RSS-Data,
Marc asks,
"Where are the Reviews, Resumes, Recipes, Topics and other cool new
forms of micro-content?"


Well, I did a bit of Googling this morning, and this is what I found:



On the subject of reviews, A.M. Kuchling
has provided an
RDF namespace
for embedding book review metadata within XHTML documents.


For resumes,
Uldis Bojars
has been working on an
RDF schema for resumes and CV.


To offer up recipes, I found
this RDF schema
for recipes hosted on
donnafales.com.


As for topics, well, there's already a straight RSS 2.0 namespace
extension called Easy News Topics.


And, finally, for events there is
mod_event,
and RSS 1.0 module used for presenting calendar event information.





Yes, with the exception of ENT, these are RDF schema or namespaces.
But, any one of them could likely be adapted to straight XML and used as an RSS 2.0
namespace, thereby leveraging the work these people have already done
in modeling these kinds of content, as well as potentially providing
an easy transformation path to RDF for those who care.


What does RSS-Data provide out of the box which makes any of the
above obsolete?  There's no magic here, other than translating between
raw data sctructures.  You'll still need to do the same sort of
modeling and structure work that the authors of all the above have
done.  It's always nicer to have someone else do homework for you.


So, if all this new microcontent is so hot, why hasn't anything like
the above been put into use?  Would adding 5 new tags to an RSS
feed really be an insane burden to express calendar events?  Granted,
some of the other examples above are more complex, but then so are
the things they seek to represent.


What's the RSS-Data magic that improves on all the above?
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/10/08/microcontent-and-rss-data/"
          >776&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/10/08/microcontent-and-rss-data/">#</a>
    <a class="time" href="2003/10/08/microcontent-and-rss-data/">8:30 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 October 07</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/10/07/schemas-freedom-and-control/">Schemas, Freedom, and Control</a>
      </h2>
    
    <p class="summary">
      I'll be at the Enterprise Architect Summit in Palm Springs next week,
on a couple of panels. One's entitled Schemas in the wild: XML takes
on the vertical industries, and the panelists are Jon Bosak and Jean
Paoli. The single most important question I'd like to ask these guys
is: how do we strike the proper balance between freedom and control?
By freedom I mean incremental and iterative evolution of data
structures in response to patterns of real-world use. By control I
mean the predictable regularity enforced by a DTD or XSD.



Source:Jon Udell's weblog, XML vocabularies: freedom and control





For quite awhile now, Jon Udell's been asking the same
sorts of questions as I did in my longwinded write-up yesterday.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/10/07/schemas-freedom-and-control/"
          >122&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/10/07/schemas-freedom-and-control/">#</a>
    <a class="time" href="2003/10/07/schemas-freedom-and-control/">11:12 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 October 06</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/10/06/rss-data-and-schema/">RSS-Data and Schema: Thinking about structure and data</a>
      </h2>
    
    <p class="summary">
      Dare Obasanjo has provided some initial bullet points of what a vocabulary gets from having an XML Schema :




Usually provides a terse and concise description of
 the vocabulary [relative to the prose of the spec]

Enables software to validate that XML documents
 being received from clients or servers actually
 conform to the vocabulary. This prevents issues like
 each application hacking up its own validator or
 "liberal RSS parser". 

Allows vocabulary to co-exist with technologies and
 tools that already support features specific to a
 schema language such as relational to XML mapping,
 object to XML mapping, directed editting, etc.



Source:Finally Atom: Why use schema?





Danny [Ayers]: "...and the same can already be done using RSS 1.0 as it stands."



But are we talking about the same "same"?  The appeal of RSS-Data is that I don't need to work up a schema, get anyone to buy-in, or map anything to an external resource... I take an existing data structure, and plug it into a syndication feed. That's it.

Source:Roger Benningfield in a comment on his "RSS-Data: A Working Demo"



 

Yes - we know that RDF can do many of the things RSS-Data was designed for.? But (believe it or not) it really has nothing to do with RSS 1.0 at all.? RSS-Data is about extending RSS 2.0.? OK?? Not RSS 1.0.



The point here being that the world is bi-forcated and what do we do?? Can't we all live together?? Can't we put our heads together and come up with solutions that BRIDGE between these two standards - which just happen to have almost the same dam name?
I gotta believe there's a way that once we "structure" something - like a Calendar Events, Resumes, Recipes or Reviews - we SHOULD be able to express and subscribe to these micro-content?formats - via EITHER RSS 1.0 or RSS 2.0.
OK - get it?? BRIDGE BETWEEN BOTH RSS 1.0 & RSS 2.0.? That's what we want.? BOTH!
Source:Marc's Voice: We want BOTH RSS 1.0 & RSS 2.0!







So, it looks like this RSS-Data thing is gaining momentum and demos, so I'm guessing that it's going to become one of the thing us rock-bangers will have to contend with at some point or another in tinkering with things in syndication and interoperability.  I have my misgivings about it, which mostly center around the issue of schema.
See, the goal of RSS-Data, as I understand it, is to bridge raw data from one programming environment to another, and package it up to be syndicated within RSS feeds for which an existing infrastructure already exists.  So, it's "easy".  Just throw your data structures at a library, which serializes them into some magic XML.  At the receiving end, another library, written possibly in a different language altogether, transliterates the magic XML into local idiomatic data structures.  You never think much about XML, nor does the consumer of your data.
But...  we're still talking about structures here.  Whether they're represented by XML tags, RDF triples, RDF/XML serialization, or hashtables and arrays-- there's still a structure involved.  From whence did it come?
About RSS-Data, Roger Benningfield writes, "...I don't need to work up a schema...", which is literally true.  He goes on to write, "I take an existing data structure, and plug it into a syndication feed. That's it."
From where did this "existing data structure" originate?  For my examples, I used an existing schema from the Amazon web services.  Where'd you get yours?
I'd guess that you got it from somewhere in the bowels of your scripts, a hash or rough structure once limited to intra- or inter- module data exchange, but now pressed into service as a unit of interoperation.  I wouldn't expect that you'd put much specific effort toward making this data structure particularly concise or friendly for interoperation.  This might not be a big deal for now.  And anyway, why bother with it?  That's not the philosophy with this tech, as far as I understand it.  The idea, is that hopefully this data structure is already good enough for sharing.  And, luckily enough, this is sometimes the case.
On the other hand, maybe you're sitting down to come up with a new data structure for sharing, from scratch.  During this activity, I imagine that you'll be mulling over what goes where, what's contained by what, what this hash or dictionary key means versus that one.  You'll likely be deciding whether to use a string here, or a date time here, and you'll likely have some idea about ranges of values for various things.  This is a bit more abstract an activity than you may have gone through, were you simply creating an internal data structure for your app.  In this case, you'd likely be thinking more about the data in and of itself, rather than the specific needs of your app and its API. In my opinion, this is a bit better for sharing.
But, how's your documentation?  Will I be able to reliably accept data from your application by just looking at a write-up or a rough spec?  Will I have to walk through your source code to reverse engineer general usage?  Will I have to examine RSS-Data dumps to come up with a rough approximation of what to expect from your data structure?  If this is a data structure plucked from the depths of your script, who knows?  If this structure was designed specifically for sharing, I hope that you've documented as you go along.
What RSS-Data makes me worry about is an abundance of fuzzy, adhoc structures for interchange that no one ever quite documents well enough because they're too busy hacking along and pushing things out the door.  Maybe they'll be good enough, given discipline and thoughtfulness, but then maybe they'll end up in a mess.  But, just like many scripting languages, there are no facilities in RSS-Data currently to either require or even merely encourage clean and documented interchange structures.
This is a code-first-schema-later approach:  The schema stems, eventually, from general usage and tradition, and if we're lucky, from documentation.  If the people hacking on the project have discipline and are thoughtful, this documentation will be well maintained, and changes well communicated.  It can be a train-wreck, but it doesn't have to be.
On the other hand, we can circle back to that Amazon Web Services schema I used in my previous examples.  This technology, XML Schema, represents the opposite approach: schema-first-code-later.  In coming up with such a schema, I think still think about information and data structures just as I would while hacking on a script and thinking about a native data structure for sharing.  It's just that, with this approach, I'm doing things in a different order and front-loading the thinking. 
But, there's more: if I build something like an XML Schema, I'm creating something which is both documentation and a machine readable resource.  I'm sure someone out there is working on or has released tools or stylesheets to convert XML Schema into HTML or RTF or something human readable.  Hell, you could even apply some transformation to the schema to generate code or data entry forms.
Once I have a schema, implementing code to produce and handle XML data conforming to it isn't really all that much harder than using straight RSS-Data.  This is an item for much dispute, but my gut and limited experience tells me that the difference in complexity will usually be more like a dozen lines of code or less in a decent environment rather than, say, an order of magnitude.  I think we'll find that things will tend to be consistent with Phillip Pearson's example implementations of an RSS namespace extension versus an RSS-Data example.
What we get for the added complexity, though, is certainty.  I can say, "Here.  This is a URL to the schema for the XML data my application produces."  If I've lived up to my end 
of the bargain, you won't even need to see my application's code or documentation.  You can implement with the schema, and our apps will interoperate.  We can treat the data formats as separate entities from applications.  In other words, we can treat interchange as neutral ground.
The problem, of course, is that this business with schema carries with it a bit of overhead, as well as a demand that you do some homework.  You'll need to know more than your immediate programming environment.  You'll need to think about XML and XML schemas, and you can't just stay in your comfortable favorite environment of programing language idiom.  This is off-putting to some, to say the least.
So...  how about Marc's question?  "Can't we all live together?? Can't we put our heads together and come up with solutions that BRIDGE between these two standards - which just happen to have almost the same dam name?"  On the one side, I see hackers who want to get down and code, and who consider themselves and each other thoughtful and disciplined enough to do the right thing and prevent trainwrecks.  On the other side, I see hackers who want to put discipline and thoughtfulness upfront and in writing (or typing?) before they code, because they don't really trust themselves or others to keep from wrecking the trains all the time.
Personally, I want to live somewhere in the middle.  Just enough distrust of myself and others to discourage sloppy problems, but not too much so that I have to trudge through careful molasses to get anywhere.
I don't think I'm thrilled with RSS-Data.  But if you're going to use RSS-Data anyway, but here's one thought out of all this:  Is there some way we could come up with an RSS-Data-analogue for schema?  Forget about XML schema and standards groups and the like.  Think about some semi-universal way of translating meta-data-structures composed within one's favorite scripting language which forms documentation and a promise about what to expect over the wire?  If done right, maybe we could even generate an XML schema with this, and that could be a bridge between the two approaches.  On the surface, it sounds like a wonky idea to me, but hey...
Thanks for bearing with me through this much-longer-than-usual post.  :)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/10/06/rss-data-and-schema/"
          >1756&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/10/06/rss-data-and-schema/">#</a>
    <a class="time" href="2003/10/06/rss-data-and-schema/">6:52 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/10/06/http-in-rdf/">RDF representations of HTTP transactions?</a>
      </h2>
    
    <p class="summary">
      13:52:29 <monkeyiq> is there a notation for capturing browse
histories in rdf?



13:53:25 <DanC> good question, monkeyiq... I wanted something
like that a while ago...
13:53:30 <DanC> I didn't find anything in particular.
Source:#rdfig: hypertext histories and RDF schemas for HTTP





For what it's worth, I'm looking for this too.  I've done a little bit
of work in cobbling together some RDF representations of HTTP transactions,
in order to record browsing history in a rich way.  I've
basically just been mapping from HTTP/1.1
header fields to RDF properties.  It's been a little while, but I seem to remember that both 
dbproxy's metaminer plugin
and
AgentFrank's MetaMiner plugin
have implementations toward this end.  Sooner or later, I'll get back to one project or
the other, and I'd really like someone else to do my homework on this. :)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/10/06/http-in-rdf/"
          >138&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/10/06/http-in-rdf/">#</a>
    <a class="time" href="2003/10/06/http-in-rdf/">3:45 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 October 03</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/10/03/a-quick-irc-soap-primer/">A quick SOAP primer via IRC (but not SOAP via IRC)</a>
      </h2>
    
    <p class="summary">
      After making those RSS namespace examples, I was thinking aloud about
SOAP on [#joiito](/tag/joiito) yesterday and how it compares to what I did with the Amazon
data.  Sam Ruby
happened to be in the room:

<rubys> deusx: want a quick primer?

<deusx> rubys: I'd love one, though unfortunately at the moment,
I'm about to be off to a meeting :(

f8dy would like a quick primer

<rubys> This is really quick.  Take some XML.  XML that doesn't
have a DTD or any PI's.  Put it in a soap:Body.  Put the soap:Body in
a soap:Envelope.  Voila', you have valid document literal SOAP.

That was a quick primer, and though I know there's more to
it, putting it like that makes me see SOAP a little differently.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/10/03/a-quick-irc-soap-primer/"
          >127&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/10/03/a-quick-irc-soap-primer/">#</a>
    <a class="time" href="2003/10/03/a-quick-irc-soap-primer/">9:28 am</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/10/03/rss-data-versus-namespace-3/">RSS 2.0 namespace versus RSS-Data, Part 3: Electric Boogalee</a>
      </h2>
    
    <p class="summary">
      So, for the same of argument, yesterday I threw together
examples
of what a use of RSS-Data might look like alongside what
the same data in an RSS namespace extension might look like.
I promised code, but never got a chance to circle back around.
Fortunately, Phillip Pearson
connected the rest of the dots for me with two examples:


Parsing RSS-Data
Parsing an RSS namespace extension




I was just a little surprised by his results, since I expected
the code to handle an RSS namespace to be at least a bit more complex
than the RSS-Data example.  But,
as Phillip observed later,
the scripts were pretty much equivalent in length, complexity, and
ease of construction.


Then, this morning, I saw that Danny Ayers had posted an
example in RDF
of this same data.  It doesn't differ very much from my namespace
extension example, except that the few differences there are enables
his example to flow through RDF tools (as well as, usually, XML tools like
XPath and XSLT).


In a comment
on one of Phillip's posts, though, Roger Benningfield makes
the point that this example is a bit biased:


I agree that there won't be a ton of difference between a struct full
of strings and plain ol' XML. But that's kind of a stacked example,
since SDL would allow a lot more than that... arrays, integers, and
arrays of integers inside structs.




What I did could be obscuring some work.  I just took an existing
schema from Amazon, which gave me some initial work already for free.
(Though, there's something to be said for that in and of itself.)
The structures were already established, and the schema was created
with XML representation already in mind.  This could have placed
RSS-Data at an example.  While I really don't think
that XML-RPC serialization offers more flexibility in expression than
XML itself, I could be wrong and I don't want to be tilting
at straw men.  


So, while I doubt that I'll have a whole lot of time today, I think
for the same of completeness, someone should go through the parallel
processes of going from problem statement up through data modeling and
on to production and consumption of RSS-Data and an RSS namespace
extension.  While doing this, capture the work involved in both.


I could see shortcuts taken on the RSS-Data side, since you don't have
to be concerened with various bits of XML tech like DTDs or schema
or whatnot.  You can jump right into coding up an example usage and
come up with your data model on the fly.  Whether this is a good thing
or not, I'm sure many will disagree.  Also, I'm sure others would
go through this differently than I would.  Again, your mojo may
exceed mine.


At this point, I can see the benefits of RSS-Data in rapidly cobbling
together scripts, but I lean toward having a decently defined data
model first.  You can do this in your scripts, but using the existing
XML tech forces you through some specific processes.  On the other
hand, I can see where some busy developers don't have time or spare
brain cycles to absorb all the XML tech.  It could be made easier
at that end of things, which is where I'd rather spend my effort.


Anyway, I'm really interested in seeing where this goes, because
this comparison of RSS-Data, RSS namespace extensions, and even
RDF seems like another very concrete, non-theoretical way to demonstrate
the benefits and drawbacks of these ways of thinking about data
and interoperability.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/10/03/rss-data-versus-namespace-3/"
          >591&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/10/03/rss-data-versus-namespace-3/">#</a>
    <a class="time" href="2003/10/03/rss-data-versus-namespace-3/">8:28 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 October 02</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/10/02/rss-data-versus-namespace-2/">RSS 2.0 namespace versus RSS-Data, Part 2: First impressions</a>
      </h2>
    
    <p class="summary">
      Okay, I got
the example data out there.
Here's what's first on my mind about it:




Man, that RSS-Data is one verbose piece of XML.  The Amazon-specific
namespace version looks much more compact and readable; I'd rather
View Source
on that one.




Python comes out of the box with
xmlrpclib,
and other languages have XML-RPC facilities available as well.  I can't imagine
it'd be too hard to get a hold of the core of it and employ it in
unmarshalling the RSS-Data straight into idiomatic Python structures.
On the other hand, I'll need to write my own handlers for the Amazon XML
using the XML parser modules that come with Python.




With its clean, almost self-documenting structure, the Amazon XML is easily
handled with XPath and XSL.  If I had a pile of ProductInfo elements
in a document, I could yank out all their images with something like:
//az:ProductInfo/az:Details/az:ImageUrlSmall


Using the RSS-Data
example, it'd probably be something more like:
//sdl:data/sdl:struct/sdl:member/sdl:name[@text='ImageUrlSmall']/../sdl:value,
and that's not considering if I have mixed kinds of RSS-Data schema represented in the
feed.


I suppose I could help this out by surrounding the struct with another
struct, containing one member named 'AzProductInfo', making the path something
like so:
//sdl:data/sdl:struct/sdl:member/sdl:name[@text='AzProductInfo']


/../sdl:value/sdl:struct/sdl:member/sdl:name[@text='ImageUrlSmall']/../sdl:value.





And these are the conclusions I'm jumping to at the moment, before experimenting:




RSS-Data's convenience to script authors is at odds with the RSS 2.0
spirit of View Source.


Producing and consuming RSS-Data could be easier than handling
purpose-specific XML schema in scripts.


Since RSS-Data doesn't follow in the spirit of XML specs and schema,
using formal XML tools to handle this stuff will give you
nothing but headaches.  (Then again, it seems like some of the
stuff that's fully in the spirit of XML yields headaches just
the same.)


RSS-Data might catch on and spread nonetheless, because lots
of people don't read XML, don't use formal XML tools, and just
write scripts to get their jobs done.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/10/02/rss-data-versus-namespace-2/"
          >322&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/10/02/rss-data-versus-namespace-2/">#</a>
    <a class="time" href="2003/10/02/rss-data-versus-namespace-2/">12:26 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/10/02/rss-data-versus-namespace/">An example of an RSS 2.0 namespace versus RSS-Data usage</a>
      </h2>
    
    <p class="summary">
      Okay, just for the sake of tinkering, I'm poking at embedding data
from the
Amazon Web Services
into an RSS 2.0 feed.  On one hand, I just shoehorned the Amazon
XML schema into an RSS 2.0 namespace, and on the other, I tried
transliterating the Amazon XML data into
RSS-Data /
XML-RPC serialized data
structures.


To resolve my own love/hate of this RSS-Data idea,
I'm planning to keep going from here and work up some simple Python
scripts to produce and consume data along the lines of both examples,
then to comment on the experience.  (This is assuming I don't run out
of round tuits.)  Some things to note:


Your XML mojo is probably stronger than mine,
so please feel free to correct me.

Although I created the RSS-Data example by hand, it would
otherwise be completely produced and consumed by machine.

Since it's at the root of a few things I'm thinking,
it's worth restating:  RSS-Data is intended to be produced and
consumed by machine, not by humans.  This means that the XML
data needs not look pretty or elegant to you, but to your machine.







So, on with the XML.  First, I
requested data
from Amazon and got the following:


<?xml version="1.0" encoding="UTF-8"?>
<ProductInfo
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:noNamespaceSchemaLocation="http://xml.amazon.com/schemas3/dev-lite.xsd">
  <Details url="http://www.amazon.com/exec/obidos/ASIN/0439139597/0xdecafbad-20">
    <Asin>0439139597</Asin>
    <ProductName>Harry Potter and the Goblet of Fire (Book 4)</ProductName>
    <Catalog>Book</Catalog>
    <Authors>
      <Author>J. K. Rowling</Author>
      <Author>Mary GrandPr?</Author>
    </Authors>
    <ReleaseDate>08 July, 2000</ReleaseDate>
    <Manufacturer>Scholastic</Manufacturer>
    <ImageUrlSmall>http://images.amazon.com/images/P/0439139597.01.THUMBZZZ.jpg</ImageUrlSmall>
    <ImageUrlMedium>http://images.amazon.com/images/P/0439139597.01.MZZZZZZZ.jpg</ImageUrlMedium>
    <ImageUrlLarge>http://images.amazon.com/images/P/0439139597.01.LZZZZZZZ.jpg</ImageUrlLarge>
    <Availability>Usually ships within 24 hours</Availability>
    <ListPrice>$25.95</ListPrice>
    <OurPrice>$18.16</OurPrice>
    <UsedPrice>$3.97</UsedPrice>
  </Details>
</ProductInfo>


From this, I cooked up an example RSS feed with Amazon's XML
schema shoehorned in as a namespace:

<rss version="2.0"
  xmlns="http://blogs.law.harvard.edu/tech/rss"
  xmlns:az="http://www.amazon.com/gp/aws/landing.html"
  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="http://www.amazon.com/gp/aws/landing.html
                      http://xml.amazon.com/schemas3/dev-lite.xsd">
  <channel>
    <title>Testing Amazon Namespace</title>   
    <item>
      <title>Harry Potter and the Goblet of Fire (Book 4)</title>
      <az:ProductInfo>
        <az:Details url="http://www.amazon.com/exec/obidos/ASIN/0439139597/0xdecafbad-20">
          <az:Asin>0439139597</az:Asin>
          <az:ProductName>Harry Potter and the Goblet of Fire (Book 4)</az:ProductName>
          <az:Catalog>Book</az:Catalog>
          <az:Authors>
            <az:Author>J. K. Rowling</az:Author>
            <az:Author>Mary GrandPr?</az:Author>
          </az:Authors>
          <az:ReleaseDate>08 July, 2000</az:ReleaseDate>
          <az:Manufacturer>Scholastic</az:Manufacturer>
          <az:ImageUrlSmall>http://images.amazon.com/images/P/0439139597.01.THUMBZZZ.jpg</az:ImageUrlSmall>
          <az:ImageUrlMedium>http://images.amazon.com/images/P/0439139597.01.MZZZZZZZ.jpg</az:ImageUrlMedium>
          <az:ImageUrlLarge>http://images.amazon.com/images/P/0439139597.01.LZZZZZZZ.jpg</az:ImageUrlLarge>
          <az:Availability>Usually ships within 24 hours</az:Availability>
          <az:ListPrice>$25.95</az:ListPrice>
          <az:OurPrice>$18.16</az:OurPrice>
          <az:UsedPrice>$3.97</az:UsedPrice>
        </az:Details>
      </az:ProductInfo>
    </item>   
  </channel>   
</rss>


Then, I transliterated things into what I understand of RSS-Data:

<rss version="2.0"
  xmlns="http://blogs.law.harvard.edu/tech/rss"
  xmlns:sdl="http://radio.weblogs.com/0113297/2003/10/01.html#a237">
  <channel>
    <title>Testing Amazon Namespace</title>   
    <item>   
      <title>A Sample Item</title>
      <sdl:data>
        <sdl:struct>
          <sdl:member>
            <sdl:name>url</sdl:name>
            <sdl:value>
              <sdl:string>http://www.amazon.com/exec/obidos/ASIN/0439139597/0xdecafbad-20</sdl:string>
            </sdl:value>
          </sdl:member>
          <sdl:member>
            <sdl:name>Asin</sdl:name>
            <sdl:value><sdl:string>0439139597</sdl:string></sdl:value>
          </sdl:member>
          <sdl:member>
            <sdl:name>ProductName</sdl:name>
            <sdl:value>
              <sdl:string>
                Harry Potter and the Goblet of Fire (Book 4)
              </sdl:string>
            </sdl:value>
          </sdl:member>
          <sdl:member>
            <sdl:name>Catalog</sdl:name>
            <sdl:value><sdl:string>Book</sdl:string></sdl:value>
          </sdl:member>          
          <sdl:member>
            <sdl:name>Authors</sdl:name>
            <sdl:value>
              <sdl:array>
                <sdl:data>
                  <sdl:value>J. K. Rowling</sdl:value>
                  <sdl:value>Mary GrandPr</sdl:value>
                </sdl:data>
              </sdl:array>
            </sdl:value>            
          </sdl:member>
          <sdl:member>
            <sdl:name>ReleaseDate</sdl:name>
            <sdl:value>
              <sdl:dateTime.iso8601>2000-07-08T00:00:00</sdl:dateTime.iso8601>
            </sdl:value>
          </sdl:member>          
          <sdl:member>
            <sdl:name>Manufacturer</sdl:name>
            <sdl:value><sdl:string>Scholastic</sdl:string></sdl:value>
          </sdl:member>
          <sdl:member>
            <sdl:name>ImageUrlSmall</sdl:name>
            <sdl:value>
              <sdl:string>http://images.amazon.com/images/P/0439139597.01.THUMBZZZ.jpg</sdl:string>
            </sdl:value>
          </sdl:member>          
          <sdl:member>
            <sdl:name>ImageUrlMedium</sdl:name>
            <sdl:value>
              <sdl:string>http://images.amazon.com/images/P/0439139597.01.MZZZZZZZ.jpg</sdl:string>
            </sdl:value>
          </sdl:member>          
          <sdl:member>
            <sdl:name>ImageUrlLarge</sdl:name>
            <sdl:value>
              <sdl:string>http://images.amazon.com/images/P/0439139597.01.LZZZZZZZ.jpg</sdl:string>
            </sdl:value>
          </sdl:member>          
          <sdl:member>
            <sdl:name>Availability</sdl:name>
            <sdl:value><sdl:string>Usually ships within 24 hours</sdl:string></sdl:value>
          </sdl:member>
          <sdl:member>
            <sdl:name>ListPrice</sdl:name>
            <sdl:value><sdl:string>$25.95</sdl:string></sdl:value>
          </sdl:member>
          <sdl:member>
            <sdl:name>OurPrice</sdl:name>
            <sdl:value><sdl:string>$18.16</sdl:string></sdl:value>
          </sdl:member>
          <sdl:member>
            <sdl:name>UsedPrice</sdl:name>
            <sdl:value><sdl:string>$3.97</sdl:string></sdl:value>
          </sdl:member>
        </sdl:struct>
      </sdl:data>
    </item>   
  </channel>   
</rss>
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/10/02/rss-data-versus-namespace/"
          >613&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/10/02/rss-data-versus-namespace/">#</a>
    <a class="time" href="2003/10/02/rss-data-versus-namespace/">11:52 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 October 01</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/10/01/rss-data/">RSS-Data: XML-RPC encoding in RSS 2.0</a>
      </h2>
    
    <p class="summary">
      A few months ago I approached Dave Winer and a few other people with a very simple idea.? Why not use XML-RPC's data serialization format to create a simple data language for object meta-data in RSS (and other!) applications.? Interestingly, if you subtract the message envelop from XML-RPC, add Unicode and time-zone support to the standard, you've actually got WDDX, quite literally.? Dave really liked the idea, and we came up with the idea of RSS-Data.


Why use RSS-Data?? Pragmatism.? Because of the rapid growth of blogging software, XML-RPC parsers are already implemented in dozens of languages and platforms.? As a result, a simple data language based on XML-RPC's data model could emerge in a matter of days or weeks, as developers quickly refactor their parsers to simply provide data serialization/deserialization components.


Source: Jeremy Allaire's Radio  (via Silicon Valley - Dan Gillmor's eJournal - Expanding the Scope of RSS)



Grr. I can’t decide whether I hate this idea or can live with it.  On the one hand, I have benefitted from XML-RPC and it’s quick integration between disparate scripting environments.  But on the other hand, the tendency to use adhoc data structures in scripting has given me numerous headaches and plenty of inexplicable bugs.The further I get, the less I want quick and dirty, and the more I want thoughtful chaos and at least some documentation.  I’d like some schemas, rather than reverse engineering from example.  But sometimes it’s nice to short circuit over-designed processes and take expedient shortcuts, even if there lies the road to madness.  Sleep is good sometimes.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/10/01/rss-data/"
          >262&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/10/01/rss-data/">#</a>
    <a class="time" href="2003/10/01/rss-data/">4:21 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/10/01/comment-icons/">Comment Icons drawn from author&#39;s RSS or FOAF files</a>
      </h2>
    
    <p class="summary">
      This is an interesting thing over at
Life on Mars:
Comment Icons.


Post a comment, supply the URL to your blog, and if your
blog has a locatable RSS feed which points to an image,
that image will be displayed next to your comments.  As I've
been known to have a mild obsession with LiveJournal, this reminds
me a lot of the usericons in use there, only distributed
across blogspace, which is what I've wanted to see done for a
long time.


All the infrastructure of LiveJournal,
Friendster, and the like could be recast as distributed
feeds and metadata, with smarts on blog servers or
personal clients.  One piece at a time...
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/10/01/comment-icons/"
          >113&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/10/01/comment-icons/">#</a>
    <a class="time" href="2003/10/01/comment-icons/">1:00 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/10/01/mailbucket-feeds/">Mailbucket syndication feeds</a>
      </h2>
    
    <p class="summary">
      Just discovered Tom Dyson's
Mailbucket.org,
and started playing around with signing up mailing lists
for feeds.  It's simple, send an email to
foo@mailbucket.org,
then check http://mailbucket.org/foo.xml
for an RSS feed.
I was tinkering with something like it last week, using
Postfix, Mail::Audit, and blosxom -- but hey, if someone else
has done it, I'll just go use theirs! :)


A few feeds I've set up:


cocoa-dev from Apple
macosx-dev from OmniGroup
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/10/01/mailbucket-feeds/"
          >94&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/10/01/mailbucket-feeds/">#</a>
    <a class="time" href="2003/10/01/mailbucket-feeds/">11:34 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 September 29</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/09/29/dynamic-polling-freq-too/">Dynamic polling times for news aggregators, II</a>
      </h2>
    
    <p class="summary">
      Okay, so that thing with the SQL I did Friday?
I'm not exactly sure what I was thinking with it.  I was doing something
that seems really odd now, trying to collect counts of new items together
by hour, then averaging those hourly counts across a week.  Instead, I'm
trying this now:


SELECT
  source,
  'update_period' AS name,
  round(min(24,max(1,(max(1,(iso8601_to_epoch(max(created)) -
    max(now() - (7*24*60*60), iso8601_to_epoch(min(created)))) /
   (60*60))) / count(id))),2) AS value
FROM
  items
WHERE
  created >= epoch_to_iso8601(now() - (7*24*60*60)) 
GROUP BY
  source


This bit of SQL, though still ugly, is much simpler.  This leaves out
the subselect, which I think I might have been playing with in order
to build a little graph display of new items over time by source.  What
the above does now is to get an average time between new items for the
past week, with a minimum of an hour, and a maximum of a day.  This
seems to be working much better.



An alternate algorithm I've been playing with was suggested in
a comment
by Gnomon,
inspired by TCP/IP's Additive Increase / Multiplicative Decrease.
With this, I subtract an hour from the time between polls when a
poll finds new items, and then multiply by 2 every time a poll
comes up with nothing new.



Using the average of new items over time lessens my pummeling
of servers per hour, but the second approach is even lighter
on polling since it's biased toward large leaps backing off
from polling when new items are not found.  I'll likely be trading
off between the two to see which one seems to work best.



Hoping that, after playing a bit, I'll settle on one and my
aggregator will play much nicer with feeds, especially once
I get the HTTP client usage to correctly use things like
last-modified headers and ETags.  There's absolutely no reason
for a news aggregator to poll a feed every single hour of a day,
unless you're monitoring a feed that's mostly quiet, except
for emergencies.  In that case, well, a different polling
algorithm is needed, or maybe an instant messaging or pub/sub
architecture is required.



Update: As Gnomon
has corrected me in comments, I've got the AIMD algorithm mixed up.
What I really should be doing is making quick jumps up in polling
frequency in response to new items (multiplicative decrease of
polling period) and creeping away in response to no new items
(additive increase of polling period).  As he notes, this approach
should make an aggregator jump to attention when clumps of new
posts come in, and gradually get bored over periods of silence.
I've adjusted my code and will be tinkering with it.



Also, although Gnomon makes
a good point that bloggers and their posting habits are not easily
subject to statistical analysis,
I've further refined my little SQL query to catch sources
which haven't seen any updates during the week (or ever):


SELECT 
  id as source,
  'update_period' AS name,
  round(min(24,max(1,coalesce(update_period,24)))) AS value
FROM sources
LEFT JOIN (
     SELECT
      source AS source_id,
            (iso8601_to_epoch(max(created)) -
              max(
                now()-(7*24*60*60),
                iso8601_to_epoch(min(created))
              )
            ) / (60*60) / count(id)
        AS update_period
    FROM items
    WHERE created >= epoch_to_iso8601(now() - (7*24*60*60)) 
    GROUP BY source
) ON sources.id=source_id


Also, in case anyone's interested, I've checked all the above
into CVS.  This beastie's far from ready for prime time, but it
might be interesting to someone.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/09/29/dynamic-polling-freq-too/"
          >1237&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/09/29/dynamic-polling-freq-too/">#</a>
    <a class="time" href="2003/09/29/dynamic-polling-freq-too/">1:48 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 September 25</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/09/25/dynamic-feed-scan-times/">Dynamic feed polling times for news aggregators</a>
      </h2>
    
    <p class="summary">
      Today, my aggregator got
the following SQL worked into its feed poll scheduling machinery:

SELECT id as source,
       'update_period' as name,
       max(1, 1/max((1.0/24.0),
                    sum(update_count)/(7*24))) AS value 
FROM sources 
LEFT JOIN (
    SELECT source AS count_id,
                round(iso8601_to_epoch(created)/(60*60)) AS hour, 
                count(id) AS update_count 
    FROM items 
    WHERE created>epoch_to_iso8601(now()-(7*(24*60*60))) 
    GROUP BY hour
) ON id=count_id
GROUP BY source
ORDER BY value


It's likely that this is really nasty, but I have only a street-level
working knowledge of SQL.  Also, a few of the date functions are
specific to how I've extended sqlite in Python.  It works though, and
what it does is this:



For each feed to which I'm subscribed, work out
an average time between updates for the past week, with a maximum
period of 24 hours and a minimum of 1 hour.



My aggregator does this daily, and uses the results to determine how
frequently to schedule scans.  In this way, it automatically backs off
on checking feeds which update infrequently, and ramps up its polling
of more active feeds.  This shortens my feed downloading and scanning
time, and is kinder in general to everyone on my subscription list.



Next, among other things, I have to look into making sure that the
HTTP client parts of this beast pass all the
aggregator client
HTTP tests that Mark
Pilgrim put together.



Update: Well, it seemed like a good idea, anyway.  But, on
further examination, it has flaws.  The most notable is that it
assumes a polling frequency of once per hour.  This works right up
until I start changing the polling frequency with the results of the
calculation.  I haven't poked at it yet, but maybe if I take this
into account, it'll be more accurate.



On the other hand, I've also been thinking about a much simpler
approach to ramping polling frequency up and down:  Start out at
a poll every hour.  If, after a poll, no new items are found,
double the time until the next poll.  If new items were found,
halve the time until the next poll.


Provide lower and upper limits to this, say between 1 hour and 1
week.  Also, consider the ramp up and ramp down factor as a variable
setting too.  Instead of a factor of 2, maybe try 1.5 or even 1.25 for
a more gradual change.  To go even further, I wonder if it would be
valuable to dynamically alter this factor itself, to try to get the
polling time zeroed in on a realistic polling time.



Okay.  There the simpler approach leaves simplicity.  I'm sure there's
some decently elegant math that could be pulled in here.  :)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/09/25/dynamic-feed-scan-times/"
          >638&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/09/25/dynamic-feed-scan-times/">#</a>
    <a class="time" href="2003/09/25/dynamic-feed-scan-times/">10:45 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/09/25/atom-is-its-name-o/">Atom is its Name-O?</a>
      </h2>
    
    <p class="summary">
      I would like to propose, nay, admonish, that the name of the format and spec
should be Atom, that the current naming vote should be killed, and we should
move on to grander things without the auspices of "what's it called?!" over
our heads. This has been going on far too long.


Source:Morbus Iff: 'Atom' Should Be It's Name, and It's Name Was Atom





I haven't been anywhere near the epicenter of Atom/Pie/Echo much,
so this is mostly a 'me too' kind of posting.  But, you know, as an
interested hacker waiting for dust to settle before I start paying
much attention, the decision on a name, as superficial as it is,
seems telling to me.

On one hand, I could take it to be representative of what's going
on inside the project as a whole.  (If they can't settle on a name,
how can they settle on what's included in the spec?)  On the other hand,
it could just be that naming the thing is the least interesting aspect
of the project.  But I consider that because I'm a nerd, I've been
there, and I want to see the project thrive.  Others might not be so
charitable or patient. :)

So just name the dang thing Atom already.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/09/25/atom-is-its-name-o/"
          >273&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/09/25/atom-is-its-name-o/">#</a>
    <a class="time" href="2003/09/25/atom-is-its-name-o/">9:31 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 September 21</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/09/21/rss-feedback/">Feedback loops and syndication</a>
      </h2>
    
    <p class="summary">
      Enter attention.xml. Of course it monitors my attention list, noting what feeds are in what order. Then it pays attention to what items I read, in what order, or if not, then what feeds I scan, and for how long. The results are packaged up in an attention.xml file and shipped via some transport (RSS, FTP, whatever) to Technorati. Dave has some ideas about what he will provide in return: "If you liked these feeds and items, then here are some ones you don't know about that you may want to add to your list."

But the real power comes in a weighted return feed that works like this: OK, I see who you think is important and what posts are most relevant to your interests. Then we factor in their attention.xml lists weighted by their location on your list, average the newly weighted list based on this trusted group of "advisors", and return it to your aggregator, which rewrites the list accordingly.
Source: Steve Gillmor's Emerging Opps



Dave Winer says this guy’s full of shit.  I’m not sure why, or it if’s sarcasm.  In a lot of ways, what Steve Gilmore wrote about sounds like syndicating whuffie and what Gary Lawrence Murphy of TeledyN wrote about republishing RSS items read and rated from one’s news aggregator.

<p>Sounds like the next one of the next steps this tech needs to take to hit a new level of intelligence, forming a minimum-effort feedback loop from writers to readers and between readers themselves.  What did I read today, and was it interesting? What did you read today, and was it interesting?  What did we both read and both find interesting?  What did you read, and find interesting, that I didn&#8217;t read and <strong>might</strong> find interesting?  And then, back around to the author again, what of your writings was found very interesting, and (maybe) by whom?</p>
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/09/21/rss-feedback/"
          >313&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/09/21/rss-feedback/">#</a>
    <a class="time" href="2003/09/21/rss-feedback/">3:54 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 September 19</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/09/19/flash-hates-progressive-jpeg/">Flash MX Hates Progressive JPEGs</a>
      </h2>
    
    <p class="summary">
      Okay, I may be the last person fiddling with Flash to
discover this, but here's what I've learned today:


Flash MX hates progressive JPEGs.


From the above: "The Macromedia Flash Player does not have a
decompressor for progressive JPEG images, therefore files of this type
cannot be loaded dynamically and will not display when using the
loadMovie action."


This would have been nice to know, hours ago.  Or maybe fixed in
the past year or so since the above linked tech note.  See, although
I'm a Jack of a lot of Trades, I don't really pay attention much
to things like JPEGs and their progressive natures.  It wasn't
until I finally started randomly clicking buttons on and off in
Macromedia Fireworks while exporting a test JPEG that I finally
narrowed down the problem.


This was after a day worth of examining ActionScript, XML data,
HTTP headers, and a mess of other random dead ends.  And a lot of
last-ditch random and exhaustive twiddling of checkboxes and
options.


Then, once I had the words I
wouldn't have had unless I already knew what my problem was, a Google search for
"flash progressive jpeg"
got me all kinds of info.


Problem is, the JPEGs supplied to the particular Flash app on which
I'm hacking come from a random assortment of people working through
a content management system on the backend.  They upload them
with a form in their browser, and this Flash app gets a URL to the
image via an XML doc it loads.  Me, I'm probably in bed when this
happens.  I'd love to have tested every one... er, rather, no I
wouldn't.


So... Now I just have to figure out how to get all these people
to start making sure that their JPEGs aren't progressive.  Hmph.


I can only hope that this message gets indexed and maybe provides
more triangulation for some other poor sucker in the future.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/09/19/flash-hates-progressive-jpeg/"
          >429&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/09/19/flash-hates-progressive-jpeg/">#</a>
    <a class="time" href="2003/09/19/flash-hates-progressive-jpeg/">2:28 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 September 12</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/09/12/dont-copy-software/">Don&#39;t copy that floppy, or cracked software strikes back</a>
      </h2>
    
    <p class="summary">
      * Orangerobot uses cracked software.  I will respond to the following
commands: !ame <msg>, !amsg <msg>, !quit <msg>,
!open_cd, !switch_my_mouse_buttons

<deusx> Hmm.  If what Orangerobot just emoted is true, that's
funny as hell.

<deusx> !amsg Wang!

<Orangerobot> Wang!

<AnitaR> and what's the purpose?

<deusx> AnitaR: Of the message from Orangerobot?

<AnitaR> yes

<AnitaR> must be part of the joke I'm not getting

<AnitaR> yet

* Orangerobot uses cracked software.  I will respond to the following
commands: !ame <msg>, !amsg <msg>, !quit <msg>,
!open_cd, !switch_my_mouse_buttons

<deusx> AnitaR: Could be a joke, but it appears that this person
is using pirated software that's detected its illegitimacy and is
allowing us to manipulate that user's computer.

<adamhill> or its a social experiment by the person behind OR :)

<deusx> adamhill: Or that. :)  Either way, it's fun

<AnitaR> I'm glad it isn't one of those experiments that tests
how strong a shock we'll give the owner

<Argyle> ?def orangerobot

<deusx> Some googling points to this software:
http://www.klient.com

<deusx> !switch_my_mouse_buttons

<deusx> !ame likes cheddar cheese.

* Orangerobot likes cheddar cheese.

<adamhill> ?learn Orangerobot is either a person using cracked
software or a social experiment by a demented psych student

<jibot> I understand now, Dr. Chandra; orangerobot is either a
person using cracked software or a social experiment by a demented
psych student

<deusx> !open_cd

<deusx> okay, I'm done.

* Orangerobot uses cracked software.  I will respond to the following
commands: !ame <msg>, !amsg <msg>, !quit <msg>,
!open_cd, !switch_my_mouse_buttons

<deusx> !quit hush.

<-- Orangerobot has quit ("hush.")
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/09/12/dont-copy-software/"
          >327&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/09/12/dont-copy-software/">#</a>
    <a class="time" href="2003/09/12/dont-copy-software/">3:35 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 September 06</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/09/06/wiki-apis/">An API for Wikis?  Here&#39;s one.</a>
      </h2>
    
    <p class="summary">
      Some folks are experimenting with using Wiki to build websites.  I particularly like what Matt Haughey did with PHPWiki and a bit of CSS magic dust.  Looks nice, eh?  [Via Seb's Wikis are Ugly? post at Corante]



Janne Jalkanen's Wiki-based Weblog is interesting too.  Hmm.  Maybe blog API(s) can be used for Wikis too.  That reminds me, shouldn't Wiki formatted text have their own MIME type?  Is there one?  "text/wiki"?  For now, different dialects of Wiki formatting rules will have to be accounted for like "text/wiki+moinmoin".
Source: Don Park's Daily Habit







It's been a while since I last worked on it, but I did implement an
XML-RPC API on a few wikis, called XmlRpcToWiki.  Janne Jalkanen
did a lot of work toward the same interface with JSPWiki.  I use this API
in the linkage between my blog and the wiki on this site.  Now that
I've drifted away from XmlRpc a bit and am more in favor of simpler
REST-ish web service APIs, I'd like to see something more toward that
end.  Seems like a lot of people are discovering or rediscovering
wikis since the introduction of Sam Ruby's wiki for Atom/Echo/Pie
work, so it's interesting to see a lot of things come up again like
grousing about APIs and mutant wiki-format offshoots and standards.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/09/06/wiki-apis/"
          >290&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/09/06/wiki-apis/">#</a>
    <a class="time" href="2003/09/06/wiki-apis/">1:50 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 September 05</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/09/05/superworm/">White Hat Worms and robots.txt?</a>
      </h2>
    
    <p class="summary">
      Or maybe it's time to release our own Defender.A worm which could invasively close down the relevant "holes" in Internet security. A defensive worm could use standard intrusion tactics for benign result. For example, it could worm it's way into Windows XP computers and get the owner's permission to turn their firewalls on. It could survey open TCP/IP ports and offer to close them.

Source: Superworm To Storm The Net On 9/11 (via KurzweilAI)



So, anger is my first reaction to the idea of any unwelcome visitors on any of my machines, well intentioned or not.  I’m sure that there aren’t many who wouldn’t feel the same way.  But, although a lot of us try to keep up on patches and maintain decent security, there’s the “great unwashed masses” who just want to “do email“.

<p>On one hand, it&#8217;s easy to say, &#8220;Tough.  Learn the care &#38; feeding of your equipment.&#8221;  Yeah, as if that will help or get any response from all the people who&#8217;ve bought into <span class="caps">AOL</span> and have been reassured for years that computers are friendly and easy beasts (despite their intuitions to the contrary).  Hell, I&#8217;d bet that, more often than not, the same person who gets regular oil changes and tune-ups for the car has no idea how to do the equivalent for a computer (or that it even needs it).  Cars have been positioned differently than computers.  No one expects a Spanish Inquisition when they live in a virtual preschool of a user interface with large and colorful buttons and happy smiling faces.  They know there&#8217;s some voodoo going on underneath, but the UI tells them that it&#8217;s nothing to worry about (until <a href="http://www.decafbad.com/blog/geek/not_working.html">it isn&#8217;t working</a>).</p>

<p>Now if the problem was just that stupid users ended up with broken computers, there&#8217;d be no problem.  But, like cars with problems waiting to happen (like worn down tires), their users become a hazard to others.  Unlike cars, however, the problems of stupid users&#8217; computers are contagious and self-replicating: every tire blowout becomes a 1000 car pileup.</p>

<p>It&#8217;s like everyone sits on their recliners watching TV in their houses; not even realizing that there are doors to lock; not even hearing the intruders rummaging through the fridge in the kitchen; and certainly not knowing that there&#8217;s a guy sleeping on the sofa at night working by day to let his army of clones into the neighbor&#8217;s houses.</p>

<p>So, about what about vigilante &#8220;white hat&#8221; worms?  Wouldn&#8217;t it be nice if there was a guy wandering the neighborhood locking door for the ignorant?  Wouldn&#8217;t it be nice if there was a truck driver on the road that forced cars with bald tires off to the side for free tire replacement?  Okay, maybe that&#8217;s a bit whacky, but then again, people with bald tires aren&#8217;t causing 1000 car pileups.</p>

<p>I&#8217;m thinking that &#8220;white hat&#8221; virii and worms are one of the only things that will work, since I&#8217;m very pessimistic about the user culture changing to be more responsible.  Though, what about a compromise?  Install a service or some indicator on every network-connected machine, somewhat like <a href="http://www.robotstxt.org/wc/robots.html">robots.txt</a> , which tells friendly robots where they&#8216;re welcome and where they&#8216;re not.  Set this to maximum permissiveness for white hat worms as a default.  The good guys infect, fix, and self-destruct unless this indicator tells them to stay out.  Then, all of us who want to take maintenance into our own hands can turn away the friendly assistance of white hat worms.  It&#8217;s an honor system, but the white hats should be the honorable ones anyway.  The ones which ignore the no-worms-allowed indicator are hostile by definition.</p>

<p>So, then, the internet develops an immune system.  Anyone can release a white hat worm as soon as they find an exploit to be nullified, and I&#8217;m sure there are lots of geeks out there who&#8217;d jump at the chance to play with worms and virii in a constructive way.  And if you want to opt-out of the system, go for it.  Hell&#8230;  think of this on a smaller scale as a next-gen anti-virus software.  Instead of internet-wide, just support <span class="caps">P2P</span> networks between installations of your anti-virus product.  When it&#8217;s time to close a hole, infect your network with a vaccinating update.  I doubt this would work as well as a fully open system, but might have less controversy.</p>

<p>Anyway, it&#8217;s a whacky idea to a whacky problem that just might work.</p>
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/09/05/superworm/"
          >1056&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/09/05/superworm/">#</a>
    <a class="time" href="2003/09/05/superworm/">11:10 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 September 04</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/09/04/litany-meetings/">Litany against meetings, courtesy of purl</a>
      </h2>
    
    <p class="summary">
      
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/09/04/litany-meetings/"
          >104&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/09/04/litany-meetings/">#</a>
    <a class="time" href="2003/09/04/litany-meetings/">10:50 am</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/09/04/jibot-and-purl/">Jibot and purl, distant cousins?</a>
      </h2>
    
    <p class="summary">
      What the [#joiito](/tag/joiito) bot knows. I'm dumping it out dynamically with the Twisted webserver, which is all Python too.

Source: Epeus' epigone - Kevin Marks weblog



While the #joiito bot is looking pretty keen, I keep wondering if anyone hacking on it has seen Infobot ?  It’s the brains behind purl, the bot serving [#perl](/tag/perl) channels on a few IRC networks.  Jibot seems to have some funky punctuation-based commands, but purl accepts commands in formulatic english and even picks a few things up from normal channel chatter.  When I look at Kevin Marks’ dump of Jibot’s brains, I can’t help but think of the gigantic factoid packs available for Infobot.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/09/04/jibot-and-purl/"
          >167&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/09/04/jibot-and-purl/">#</a>
    <a class="time" href="2003/09/04/jibot-and-purl/">8:57 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 September 03</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/09/03/another-bmblogger/">Another BookmarkBlogger in Python</a>
      </h2>
    
    <p class="summary">
      I haven't been paying attention to my referrers as much lately,
but I probably should.  Because, when I do, I find things like
another implementation
of BookmarkBlogger in Python, this one by
David Edmondson.
His version has many fewer requirements, using only core Python
libraries as far as I can see.  One of these which I hadn't any idea
existed is
plistlib,
"a tool to generate and parse MacOSX .plist files".  When I get
another few round tuits, I'll likely tear out all the XPath use
in my version and replace it with this.  Bummer.  And here I thought
I was all clever using the XPaths like that in Python :)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/09/03/another-bmblogger/"
          >163&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/09/03/another-bmblogger/">#</a>
    <a class="time" href="2003/09/03/another-bmblogger/">10:59 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 September 02</h2>
  </li><li class="content-grid post post-type-entry has-thumb">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/09/02/cl-to-rss/">ChangeLog to RSS web service</a>
      </h2>
    <div class="thumb">
      <img src="http://www.decafbad.com/images/xml.gif" />
    </div>
    <p class="summary">
      Hanging out on joiito on IRC today,
I read Ecyrd asking
around about any tools to present GNU-style changelogs
as an RSS feed.  I couldn't find any, but I did find
this changelog parser, apparently
by Jonathan Blandford.  So,
when I had a few free minutes, I took some parts I had laying around, along
with this parser, and made this:

  - Changelog for JSPWiki

 Source code for cl2rss





This is at the "it works" stage.  It needs much work in what it presents
in an RSS feed, so feel free to suggest changes!
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/09/02/cl-to-rss/"
          >188&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/09/02/cl-to-rss/">#</a>
    <a class="time" href="2003/09/02/cl-to-rss/">1:44 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry has-thumb">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/09/02/xsl-scraper/">Using web services and XSLT to scrape RSS from HTML</a>
      </h2>
    <div class="thumb">
      <img src="http://www.decafbad.com/images/xml.gif" />
    </div>
    <p class="summary">
      After tinkering a bit with
web services and XSLT-based scraping
last week for generating RSS from HTML, I ripped out some work I was
doing for a Java-based scraper I'd started
working on last year and
threw together a kit of XSLT files that does most everything I was trying
to do.

I'm calling this kit XslScraper, and there's further blurbage and download links
avaiable in the Wiki.  Check it out.  I've got shell scripts to run the stuff
from as a cron job, and CGI scripts to run it all from web services.

For quick gratification, check out these feeds:

  - The Nation (using Bill Humphries' XSL) 

  - KurzweilAI.net

  - J-List -- You've got a friend in Japan!

  - New JOBS at the University of Michigan (By Job Family)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/09/02/xsl-scraper/"
          >141&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/09/02/xsl-scraper/">#</a>
    <a class="time" href="2003/09/02/xsl-scraper/">12:22 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 August 31</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/08/31/switched-to-jvds/">Switching to a JVDS server</a>
      </h2>
    
    <p class="summary">
      It's been one year since I
signed up for a JohnCompanies server,
and though I've had no complaints whatsoever, I've signed up for
a server instance with JVDS.com and have moved
just about everything over.
Why?  Because it's cheaper, and I have less disposable income these
days.  And, well, it seemed like fun to try another virtual server
company, since I've been looking into it so much lately.  The new
server has less capacity than the one I've had at JohnCompanies, but I
really don't need all that much -- just a roof over my files and a
root password.  Well, I don't really need a root password, but it's
nice to have so that I can tinker around with more things with fewer
questions asked of the management.  (For what it's worth, we're still
using JohnCompanies servers for hosting at my work.)
I've almost got this server migration thing down to a science, though,
since I had everything over and up in a few hours.  And that was going
from a FreeBSD system to Debian Linux.  Personally, though I fully
respect FreeBSD and the ports collection, I like Debian and apt-get
so much better.  But who knows, maybe in another year, I'll be moving
again for the hell of it.
I don't have much in the way of reputation for JVDS, but the management
has been very responsive to requests so far.  In fact, they're using
RT for their support ticket
management.  Responsiveness has been one of the most impressive aspects
of JohnCompanies, since between my personal server and the servers
I use at work, it tends to take less than an hour to get resolution
on any problems I've had.  So far, JVDS has yet to disappoint me as
well.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/08/31/switched-to-jvds/"
          >640&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/08/31/switched-to-jvds/">#</a>
    <a class="time" href="2003/08/31/switched-to-jvds/">10:26 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/08/31/bookmark-blogger-python/">Bookmark Blogger in Python</a>
      </h2>
    
    <p class="summary">
      Remember my BookmarkBlogger?  Well, I rewrote it in Python.  For
a little while, I was making little apps in Java, wishing it were a
scripting language.  I've stopped that now.  Also, I've added the
ability to include both link text and a non-linked comment in the
bookmarks to be blogged.  This new version is quite a bit simpler
and contained all in one script -- configuration, template, and all.
Download a tarball here
from my CVS server.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/08/31/bookmark-blogger-python/"
          >78&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/08/31/bookmark-blogger-python/">#</a>
    <a class="time" href="2003/08/31/bookmark-blogger-python/">9:34 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 August 29</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/08/29/again-a-student/">Again a Student</a>
      </h2>
    
    <p class="summary">
      I walked in thinking "I can't believe I'm a student again. I'm a student again? Yee-bloody-ikes, how am I going to manage being a student again?"

And I walked out with a spring in my step, thinking, "Hey! I'm a student again! W00t!"
Source: Caveat Lector: Augusti 24, 2003 - Augusti 30, 2003 Archives



I’m not entirely sure (though I have hunches) on how to go about it, or to whom I should be talking, but this is what I want to be saying in the not-too-distant future.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/08/29/again-a-student/"
          >101&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/08/29/again-a-student/">#</a>
    <a class="time" href="2003/08/29/again-a-student/">1:11 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 August 28</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/08/28/css-rollovers/">CSS, Background Images, and Rollovers</a>
      </h2>
    
    <p class="summary">
      It occurred to me that this ought to be possible by reassigning a  container's background-image property when it is  :hover-ed.

Source: Images and thumbnails, a pure CSS hack (via dbagg: Items by Time)



Yup, and you can do the same for every other pseudo-class of an anchor tag.  I read about this via Eric Meyer’s article on the O‘Reilly Network.  I’m still very much a CSS neophyte, but it’s helped me incredibly at work, where I was able to create a site layout with one set of HTML pages styled by a small library of CSS files for look & feel.

<p>Yeah, yeah, that&#8217;s what it&#8217;s for, you say.  But it surprised the hell out of me that I was able to abuse background image properties of containers to create JavaScript-free rollovers, as well as select between completely different image-based layout elements.  This isn&#8217;t pure utopian <span class="caps">CSS</span> that I&#8217;m doing, and most of my position is still with tables, but thanks to blank pixel images atop <span class="caps">CSS</span>-controlled background images, I can do what I think are amazing things.</p>

<p>Now I just have to break free of the rest of my <span class="caps">HTML</span> crutches, circa 1996.</p>
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/08/28/css-rollovers/"
          >260&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/08/28/css-rollovers/">#</a>
    <a class="time" href="2003/08/28/css-rollovers/">9:41 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 August 23</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/08/23/rss-scrape-urls2/">Scraping with web services: Success</a>
      </h2>
    
    <p class="summary">
      Okay, so I took another shot at scraping HTML with web services with another site that passes the HTML Tidy step.  Luckily, this is a site that I already scrape using my own tool, so I have XPath expressions already cooked up to dig out info for RSS items.  So, here are the vitals:



    Site: http://www.jlist.com
    XSL: http://www.decafbad.com/jlist.xsl
    Tidy URL: http://cgi.w3.org/cgi-bin/tidy?

docAddr=http%3A%2F%2Fwww.jlist.com%2FUPDATES%2FPG%2F365%2F
    Final URL: http://www.w3.org/2000/06/webdata/xslt?
xslfile=http%3A%2F%2Fwww.decafbad.com%2Fjlist.xsl&
xmlfile=http%3A%2F%2Fcgi.w3.org%2Fcgi-bin%2Ftidy%3F
docAddr%3Dhttp%253A%252F%252Fwww.jlist.com%252FUPDATES%252FPG%252F365%252F&
transform=Submit




<p>Unfortunately, although it looks okay to me, this feed <a href="http://feeds.archive.org/validator/check?url=http%3A%2F%2Fwww.w3.org%2F2000%2F06%2Fwebdata%2Fxslt%3Fxslfile%3Dhttp%253A%252F%252Fwww.decafbad.com%252Fjlist.xsl%26xmlfile%3Dhttp%253A%252F%252Fcgi.w3.org%252Fcgi-bin%252Ftidy%253FdocAddr%253Dhttp%25253A%25252F%25252Fwww.jlist.com%25252FUPDATES%25252FPG%25252F365%25252F%26transform%3DSubmit">doesn&#8217;t validate yet</a>, but I&#8217;m still poking around with it to get things straight.  Feel free to help me out!  :)</p>
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/08/23/rss-scrape-urls2/"
          >95&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/08/23/rss-scrape-urls2/">#</a>
    <a class="time" href="2003/08/23/rss-scrape-urls2/">2:52 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/08/23/rss-scrape-urls/">Scraping HTML with web services</a>
      </h2>
    
    <p class="summary">
      After checking out Bill Humphries’ approach to scraping yesterday, I recalled the various things Jon Udell has written about URL-as-command-line and the various places I’ve seen the W3C XSLT Servlet used in XSLT tinkering.  I also remembered that there’s an HTML Tidy service offered by W3C as well.

<p>So&#8230;  these are all URLs.  I figured I could pull together the site <span class="caps">URL</span>, <a href="http://www.whump.com/dropbox/nationrss/nation.xsl">Bill&#8217;s <span class="caps">XSLT</span></a>, the tidy service, and the <span class="caps">XSLT</span> service, and have a whole lot of scraping going on right in my browser or via wget or curl.  Here are the steps in how I composed the <span class="caps">URL</span>:</p>

<ol>
<li><a href="http://www.thenation.com">http://www.thenation.com</a></li>

http://cgi.w3.org/cgi-bin/tidy?docAddr=http%3A%2F%2Fwww.thenation.com
http://www.w3.org/2000/06/webdata/xslt?

xslfile=http%3A%2F%2Fwww.whump.com%2Fdropbox%2Fnationrss%2Fnation.xsl&#38;
xmlfile=http%3A%2F%2Fcgi.w3.org%2Fcgi-bin%2Ftidy%3F
docAddr%3Dhttp%253A%252F%252Fwww.thenation.com&transform=Submit


<p>Unfortunately, this doesn&#8217;t work.  In particular, step [#2](/tag/2) fails, the Tidy service reporting a failure in processing the original <span class="caps">HTML</span>.  I imagine, had that worked, the whole process at step [#3](/tag/3) would be producing <span class="caps">RSS</span>.  On my command line, <span class="caps">HTML </span>Tidy works fine, so I&#8217;ve been thinking of throwing together my own web interface to that program and seeing if that works.</p>

<p>If it works, this with the addition of a cache at each stage could allow for what I think is a pretty nifty, all web-based means of scraping news items from web sites.  </p>

    <p>What would really be nice for apps like this is a better way to express the URLs-within-URLs without escaping and escaping and escaping and...  Thinking some very lightweight scripting here, or some LISP-ish expressions would help.</p>
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/08/23/rss-scrape-urls/"
          >322&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/08/23/rss-scrape-urls/">#</a>
    <a class="time" href="2003/08/23/rss-scrape-urls/">1:57 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 August 22</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/08/22/rss-scrape-xsl/">Scraping HTML with curl, tidy, and XSL</a>
      </h2>
    
    <p class="summary">
      Continuing with making it easier for "Big Pubs" to create RSS feeds. I'm assuming that they have a publishing system, but it wasn't built with RSS in mind, but they want on the bandwagon.

Source: More Like This WebLog: Thursday, 21 August 2003



Using curl, tidy, and XSL to scrape content from HTML pages into an RSS feed.  This is basically what I do now with a half-baked Java app using JTidy, XPath, and BeanShell.  I keep meaning to release it, but it’s too embarassing to share so far.  Yet, it’s been working well enough to scrape what sites I’m interested in such that I haven’t been too motivated to tidy it up and tarball it.  One thing I like better about Bill Humphries’ approach, though, is that it doesn’t use Java :)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/08/22/rss-scrape-xsl/"
          >195&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/08/22/rss-scrape-xsl/">#</a>
    <a class="time" href="2003/08/22/rss-scrape-xsl/">1:32 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/08/22/email-feeds/">Syndication feeds to replace email?</a>
      </h2>
    
    <p class="summary">
      Let's face it, email has become unuseable, the latest worm to strike is likely only the tip of the iceberg we're about to collide with. I've never liked the metaphore of an 'inbox', certainly not one that fills up and can't accurately be filtered.

Source: Email is Dead, Long Live Email!



I linked to D.J.Bernstein’s Internet Mail 2000 project a little while back, and I think what Adam Curry says here is along a similar path.

<p>Internet Mail 2000 starts off with the assumption, &#8220;Mail storage is the sender&#8217;s responsibility.&#8221;  So, you want to send me an email?  Post it on your server and tell me to come &#38; get it.  When I get the notification, I&#8217;ll then decide whether or not I want to bother.  There are a lot of details to fill in here, such as secure posting and retrieval, trust and identity, notification mechanisms.  But, it certainly would seem to balance out the equation a bit.</p>

<p>How to do it, though, so that things are still at least as simple to use as existing email, such as it is?</p>
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/08/22/email-feeds/"
          >873&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/08/22/email-feeds/">#</a>
    <a class="time" href="2003/08/22/email-feeds/">12:51 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 August 19</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/08/19/cookies-are-yummy/">Cookies are yummy</a>
      </h2>
    
    <p class="summary">
      In case it had been an annoyance to anyone, I’ve finally gotten around to adding a “Remember my personal info” cookie to my comment forms.  Let me know if it breaks.  Otherwise, carry on!
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/08/19/cookies-are-yummy/"
          >35&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/08/19/cookies-are-yummy/">#</a>
    <a class="time" href="2003/08/19/cookies-are-yummy/">12:51 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 August 16</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/08/16/bayes-agg-one/">Issues in using SpamBayes to filter news items</a>
      </h2>
    
    <p class="summary">
      Despite a reading an entry by Srijith
discussing Bayes-based classification as unsuitable
for use in news aggregators, I tied SpamBayes
into my homebrew news aggregator
and have been trying it out this week.  I know I’ve been talking about it
for awhile, but procrastination and being busy all round kept me from getting
to it.  Funny thing is, when I finally got a chance to really check things out,
the integration was a snap.  I’d anticipated a bit of work, but was pleasantly
surprised.  I doubt that any other aggregator written in
Python would have a hard time with it.

<p>If, that is, anyone else wants to do it.  I already knew it wasn&#8217;t

magic pixy dust
but I figured it might be worth a try.  I will be eating my dogfood
for awhile with this, but I’m thinking already that what’s good for spam
might not be so good for news aggregators.
<p>Srijith&#8217;s <a href="http://www.srijith.net/trinetre/archives/2003/08/11/index.shtml#000373">post</a>

mentions some snags in ignoring some of the semantics of a news item,
such as whether a word appears in the item’s title or information about
the item’s source.  I don’t think that this completely
applies to how I’m doing classification, since SpamBayes appears to
differentiate between words found in email headers and the body itself.
When I feed an item to SpamBayes for training and scoring, I represent
it as something like an email message, with headers like date, subject,
from, and an “X-Link” header for the link.  However, even with this,
I think Srijith’s got a point when he writes that this method will miss
a lot of available clues for classification.
<p>Unlike Srijith&#8217;s examples, though, I&#8217;m not trying to train my

aggregator to sift entries into any specific categories.  So far, I’ve
been trying to get it to discriminate between what I really want to
read, and what I’m not so interested in.  So, I figured that something
which can learn the difference between spam and normal email could help.
But, although it’s early, I’m noticing a few things about the results and
I’ve had a few things occur to me.
<p>See, in the case of ham vs spam, I really want all the ham and none of

the spam.  A method to differentiate between these two should be
optimized toward one answer or the other.  SpamBayes offers “I don’t
know” as a third answer, but it’s not geared toward anything else
in-between.  However, in measuring something like “interest“,
inbetween answers are useful.  I want all of the interesting stuff,
some of the sort-of interesting stuff, and a little of the rest.
<p>This is also a problem for me in deciding to what I

should give a thumbs up and what gets the thumbs down.  Even though
I’ve subscribed to a little over 300 feeds, every item from each of
them is somewhat interesting to me.  I wouldn’t have subscribed to the
feed if there wasn’t anything of interest there, so I’ve already
biased the content of what I receive.  Some items are more interesting
than others, but the difference between them is nowhere near the
difference of wanted ham vs unsolicited spam.  So, I find myself
giving the nod to lots of items, but only turning down a few.
SpamBayes would like equal examples of both, if possible.
<p>I&#8217;ll still be playing with this for awhile, but I need to look

around at other machine learning tech.  I’m just hacking around,
but the important thing is to try to understand the algorithms
better and know how they work and why.  Bayes is in vogue right now,
but as Mark Pilgrim intimated, it’s not magic.  It’s just “advanced” :)
<p>In the immortal words of <a href="http://www.spidereyeballs.com/os6/set3/small_os6_d3_3596_sm.html">Mark Jason Dominus</a>: &#8220;You can&#8217;t just make shit

up and expect the computer to know what you mean, retardo!”
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/08/16/bayes-agg-one/"
          >731&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/08/16/bayes-agg-one/">#</a>
    <a class="time" href="2003/08/16/bayes-agg-one/">12:28 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 August 14</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/08/14/tree-files-too/">Tree files too (the prequel)</a>
      </h2>
    
    <p class="summary">
      16:06:23 [neo85] DO I NEED TO GO TO A SPECIFIC FOLDER TO LOAD 
                  THE HTMAL?
...
 16:07:37 [Ash] neo85: you may need to clear out the old HTMAL 
                files first with DELTREE C:\ /y
 16:08:10 [Ash] Anyway, then type 'LOAD HTMAL'
 16:09:11 [Ash] neo85: Did that work?
 16:09:30 [neo85] I PUT IN /Y?
 16:09:36 [Ash] Yes.
 16:10:02 [neo85] THATS ALL?
 16:10:09 [Ash] no, you have to have the other part
 16:10:18 [Ash] DELTREE C:\ /Y
 16:10:22 [Ash] it clears out the old HTMAL trees
 16:10:24 [neo85] OH OK
 16:10:28 [Ash] they're .TREE files
 16:10:59 [neo85] IT SAYS DELETE SUHDLOG.DAT
 16:11:37 [neo85] DETLOG.TXT?
 16:11:47 [Ash] yeah, just delete all the trees
...
 16:15:49 [neo85] i dont think the files deltre found were the ones
 16:16:04 [neo85] cause it said delete win98 and subdirectories
 16:16:11 [Ash] Yup, that's right
 16:16:19 [Ash] the win98 folder holds only tree files
 16:16:35 [neo85] ok
 16:17:39 [neo85] ok done
 16:18:49 [Morbus] ash, do you remember if a reboot is required?
 16:18:58 [Morbus] i keep forgetting, and all  my notes are on my 
                   other machine.
 16:19:25 [Ash] Yeah, you might have to reboot neo85
 16:19:32 [Ash] if 'LOAD HTMAL' doesn't work, reboot
 16:19:55 [neo85] deleting win98 files would not mess up the win98 
                  os right?
 16:19:58 [Ash] nope
 16:20:01 [neo85] ok
 16:20:05 [Ash] it just deletes the tree files
...
 16:26:43 [Morbus] neo, having any luck with the LOAD command?
 16:45:09 [neo85] *** neo85 has quit (Read error: 110 (Connection 
                  timed out))

 Source: IRC log of swhack on 2002-04-05


Heh, heh.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/08/14/tree-files-too/"
          >265&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/08/14/tree-files-too/">#</a>
    <a class="time" href="2003/08/14/tree-files-too/">3:53 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/08/14/tree-files/">Tree files</a>
      </h2>
    
    <p class="summary">
      23:58:35 [Ash] MorbusIff: Got any tree files?
23:58:39 [MorbusIff] heh
23:58:45 [MorbusIff] uh, tree files?
23:58:48 [MorbusIff] what are tree files?
...
23:59:39 [sbp] yes, you need to run DELTREE to get rid of themSource: IRC log of swhack on 2002-04-23


Heh, heh.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/08/14/tree-files/"
          >44&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/08/14/tree-files/">#</a>
    <a class="time" href="2003/08/14/tree-files/">3:48 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 August 13</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/08/13/dream-cruise-spy-cams/">Wireless cams for police at Detroit Dream Cruise</a>
      </h2>
    
    <p class="summary">
      Six remote-controlled surveillance cameras have been set up to transmit live video images of crowd and traffic conditions to handheld and laptop computers carried by cops. 

Source: freep.com: Police try spy cameras for better cruise control 



This has privacy advocates around here worried.  I’m thinking it’s a tempest in a teacup, but reading a quote like this is a bit unfortunate:

<blockquote>&#8220;We can zoom in tight enough to read someone&#8217;s watch,&#8221; said Jonathan Hollander, chief technology officer for GigaTrans, which designed the system for the use of the Oakland County Sheriff&#8217;s Department and local police departments along the route.</blockquote>



<p>It also doesn&#8217;t help that a <a href="http://www.freep.com/news/locway/probe12_20030612.htm">Federal investigation into the Detroit Police</a> found that they were &#8220;the most troubled force they have seen in 10 years of scrutinizing police nationwide&#8220;.  But, as a futurist geek, what I really want to know, having read David Brin&#8217;s <a href="http://www.amazon.com/exec/obidos/ASIN/0738201448/0xdecafbad-20">The Transparent Society</a> , is when I get to look for traffic jams up ahead using my <strong>own</strong> wireless communicator.</p>
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/08/13/dream-cruise-spy-cams/"
          >165&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/08/13/dream-cruise-spy-cams/">#</a>
    <a class="time" href="2003/08/13/dream-cruise-spy-cams/">1:12 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 August 04</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/08/04/pie-name-vote/">Final round of voting for pie/atom/(n)echo name?</a>
      </h2>
    
    <p class="summary">
      Voting is open.  OpenPoll  Names were vetted until 31 July 2003 while putting out an all-blogs call to vote. Please Blog the Vote.

Source: NameFinalVote - Atom Wiki



Is this final?  Gawd, I hope so.  I’m stringing too many slash-inated names together these days.  :)

<p>I voted for Feedcast, since it seems to be the least &#8220;clever&#8221; name yet identifies the concept.  It could be used in corp-speak and geek-speak without too much wincing.  And it&#8217;s not an acronym.  All good things, in my short span of experience.</p>
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/08/04/pie-name-vote/"
          >107&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/08/04/pie-name-vote/">#</a>
    <a class="time" href="2003/08/04/pie-name-vote/">4:13 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/08/04/minipcs/">MiniPCs, Wave of the Future</a>
      </h2>
    
    <p class="summary">
      And the next thing: at a very specific level, mini-ITX motherboards and cases are The Way To Go. Tiny, cheap, fanless PCs with trailing-edge processors -- only  1GHz -- are nevertheless a really amazingly cool idea, especially when you start thinking in terms of turning them into personal video recorders (running things like FreeVo) or in-car GPS navigation systems. Or Beowulf clusters.

Source: Charlie's Diary    (via Boing Boing)



Although I currently am on the low end of disposable income, I’m keeping my eye on tiny cases, motherboards, and just-slightly-slower-than-insanity CPUs for projects just such as these.  I want a PVR, a few file servers, maybe a homebrew game console.  I also wouldn’t mind buying a pile of OpenBricks for general living-in-the-future purposes around the house, and to experiment with clustering and networking.  Would also be neat to learn some hardware hacking again to build some clever devices like this CD changing robot
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/08/04/minipcs/"
          >152&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/08/04/minipcs/">#</a>
    <a class="time" href="2003/08/04/minipcs/">12:41 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 August 02</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/08/02/software-and-community/">Software and Community</a>
      </h2>
    
    <p class="summary">
      I joined the Apache project for the software. I stayed for the community. Likewise Perl. The software is interesting, but the people are more interesting. So now that I'm really not even writing much Perl, I'm still involved with the community, to some degree, because they are cool people. 

Source: DrBacchus' Journal: Software and community



I’ve been working with Perl for just about 10 years now, and though I’ve been a bit of a stranger lately, I used to be a regular on [#perl](/tag/perl) on several IRC networks.  And, when companies I worked for paid for travel as freely as for paper clips, I made rounds at a few conferences.  I was lucky enough to meet a few other [#perl](/tag/perl) regulars.  I doubt most of them remember me since they‘re a fairly close-nit group, and I’d only made the one appearance, despite constantly swearing I’d make it to a YAPC at some point.  But I always thought it was cool as hell to actually have had a beer at the same table in Boston with authors of some of my favorite O‘Reilly perl books.

<p>But, I got busy, stopped hanging out in <span class="caps">IRC</span> so much, and also decided that I needed to expand my horizons and stop being so narrowly focused on one language.  I got into Java, Python, shell scripting, and <span class="caps">PHP</span>.  I started this weblog, and I tried to purposefully keep away from Perl.  Of course, I can&#8217;t stay away, because Perl code comes out of my fingertips as naturally as breathing when a problem presents itself for solution.</p>

<p>And then there&#8217;s community.  I&#8217;ve yet to find a Java community as quirky and entertaining as that surrounding Perl.  Thus, Java bores me.  I use it, but it&#8217;s strictly business, mostly.</p>

<p>When what you&#8216;re doing <strong>is</strong> strictly business, I guess that&#8217;s desirable.  But when you eat, sleep, and breathe this stuff, having a group of people constantly doing clever things and being odd certainly makes it more rewarding.  It&#8217;s predictability versus creativity.  To get the job done, you want solid and dependable tools.  To have fun, you want some challenge and unexpected results.</p>

<p>To me, Perl and its community offers both.  I think Python might, also, but I&#8217;m not as familiar there.  Java and other technologies are mostly business.  Maybe this also crosses over into the difference between IT people and CS people, and whether you&#8216;re here to work or here to play and get paid.</p>

<p>Hmm.</p>
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/08/02/software-and-community/"
          >566&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/08/02/software-and-community/">#</a>
    <a class="time" href="2003/08/02/software-and-community/">4:22 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 July 30</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/30/ge-blog-of-day/">GeniusEngineer Blog of the Day</a>
      </h2>
    
    <p class="summary">
      Wow.  It appears that this is the Blog of the day at
GeniusEngineer.com.  I've never visited the
site before, but I'm flattered by being chosen just the same.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/30/ge-blog-of-day/"
          >29&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/30/ge-blog-of-day/">#</a>
    <a class="time" href="2003/07/30/ge-blog-of-day/">1:41 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/30/video-on-tape/">Videos on tape (Travan, not VHS)</a>
      </h2>
    
    <p class="summary">
      Oh and while I'm writing about watching video files on my TV, I've
been thinking of getting myself a tape drive.  Sure, I'll use it to
actually, finally, back up all the important things I have littered
around my handful of machines.  Having established a backup routine
at work, I've gotten to thinking.
How bad an idea would it be to use a tape drive to store TV shows?
I've been capturing them with the VCD format, which gives me around
600MB per hour of show.  This fills up my drive pretty quickly,
obviously.  I know I really should take sometime to revisit things and
try another video codec, since originally I used VCD because I burned
everything to CD for my DVD player, but now I'm streaming files to my
Powerbook over the network which gives me a lot more flexibility in
recording options.
However, not burning to CD leaves me with a hard drive full of video
that I'm hesitant to delete yet have no good reason to need laying around on a
high speed hard drive.  But, burning all that to a spindle-worth
of blank CDs without a Lego Mindstorms based CD-changer robot leaves
me shuddering.  I recall reading about a DJ-bot
that did this for playing music, and I notice via Slashdot that someone with a
decent woodshop has provided plans
for such a beast for a CD writer.  But I can't afford the Legos at
the present moment, and I'll only end up hurting myself working with
power tools.
Then, I remember that high capacity tapes make backing up lots of data
easy at work.  I know that the tape trade off is capacity and price
for speed of access.  But, if all I need to do is skip from one file
to the next and only need relatively low bandwidth to stream the file
from the tape, this sounds like a great way to archive video.
Depending on the video compression, maybe I could fit a whole season
or two of a show onto a single tape.
Seems like a good idea, though pricey.  But maybe the price and cost
of media would offset the pain in the ass of any other method.  I probably
should look more into the price and pain of a DVD burner, but the idea
of more disc-like things laying around worries me.
What do you think?
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/30/video-on-tape/"
          >995&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/30/video-on-tape/">#</a>
    <a class="time" href="2003/07/30/video-on-tape/">10:58 am</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/30/powerbook-on-tv/">My Powerbook&#39;s on TV</a>
      </h2>
    
    <p class="summary">
      I don't gush about it very often, but I love my 12" Powerbook.  Since
I got it this past March, it has been my primary machine for both work
and home.  And other than wishing that there was a 1GB memory module
out for it and grumbling that I've lost one of the rubber footies on
the bottom, I've been extremely happy with it.
And just last night, I was reminded of yet another feature that's made me
glad I got it: the included
Composite/SVHS video adapter.
I'd had the AV cable
for my iBook before it, but the use of the adapter on the Powerbook
has a very important difference: dual display mode.
See, when I connected my iBook up to my home entertainment complex,
I got reduced resolution back on the LCD, and anything I did that went
full screen (ie. playing a DVD or a movie file) took over the machine.
But with the Powerbook, its connection to my television is just a second
desktop, not much different than the second monitor I use at work.
So, while I'm at home on the futon with my girlfriend, I often stream
videos off a PC in the next room that's been recording TV shows for
me, and present them on this second desktop.  Most apps I use to view
movies, such as Quicktime Pro
and VideoLAN,
allow me to pick a monitor for fullscreen mode. Meanwhile, the LCD on the
Powerbook is still available for other work while we watch.
It's just a little thing, but it's a thing that lets me get much of the
benefit of a dedicated
Home Theater PC without
having to buy or build a box that looks nice alongside all our
video game consoles.
While I'd still like to take on the project someday, my Powerbook does
just fine for the display and audio end of things, while an aging Windows PC
in the next room snags a few TV shows
for me.
Of course, if all you want is an HTPC, the Powerbook is expensive
overkill.  But, if you're shopping for a laptop and want some fringe
benefits, I think this is definitely one that doesn't get much attention.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/30/powerbook-on-tv/"
          >459&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/30/powerbook-on-tv/">#</a>
    <a class="time" href="2003/07/30/powerbook-on-tv/">10:23 am</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/30/mm-central-works/">Macromedia Central and Deja Vu?</a>
      </h2>
    
    <p class="summary">
      Macromedia Central provides a safe environment for developers to deploy occasionally-connected applications. Using Macromedia Central, developers can create an application and give it away for free. Or they can sell it to end users using the Try/Buy framework that is part of Central.                                            

Source: Macromedia - DevNet : Macromedia Central: How it Works



I’ve had a bit of enthusiasm for Flash lately.  So, this Macromedia Central thing that’s been on its way for a little while now looks very interesting.

<p>But&#8230;  What differentiates it from every other &#8220;widgets on your desktop&#8221; or &#8220;widgets in a little box&#8221; technology that&#8217;s come before?  <a href="http://www.google.com/search?q=dodots">Remember</a> <a href="http://disobey.com/ghostsites/show_exhibit/dodots">DoDots</a> ?  <span class="caps">CNN</span> called them <a href="http://www.cnn.com/2000/TECH/computing/04/07/dodots.idg/">the web without a browser</a> and there was general gushing here and there about it.  At one point, I was close to being drafted to write a few promotional games using their <span class="caps">SDK</span>, and it seemed nifty enough.  No clients bit, though.  And all that remains of the company on the web are ghost pages and ex-employee photo albums and reunions.  Oh, and I still have a mousepad and a clipboard from the dev kit.</p>

<p>And then there&#8217;s <a href="http://java.sun.com/products/javawebstart/">Java Web Start</a> and <a href="http://www.konfabulator.com/">Konfabulator</a> .  Have any of these sorts of things really taken off?  I mean, they all have their share of nifty things, but has this idea of a centrallized corral of mini-apps ever paid off?  Flash is yet another cool technology with which to develop these things, but will Central take off?</p>

<p>I&#8217;m not trying to whiz on anyone&#8217;s Cheerios, since I honestly think these things are nifty, but then again I like widgets with fun buttons to push.</p>

Update: Hmm...  Mike Chambers is inviting questions about Central.  Maybe I should wander over there and ask.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/30/mm-central-works/"
          >536&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/30/mm-central-works/">#</a>
    <a class="time" href="2003/07/30/mm-central-works/">8:26 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 July 29</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/29/google-ads-monotony/">Google ads getting monotonous?</a>
      </h2>
    
    <p class="summary">
      Well, I forgot to mention it, but I emailed Google awhile back about their
rejecting my site for
Google ?AdSense.  They got back to me and let me in the club, which is
demonstrated by the skyscraper ad to the right.  So far, I seem to be on the
road to earning free hosting for the month, if my clickthroughs keep up,
which is more than I'd hoped for.  I only hope that if everyone's seeing this
kind of performance, that Google makes some money at it and doesn't have to
cancel the program.
My only complain now is this:  Can I get some ad rotation?  I'm not sure what
you're seeing, but I've been looking at the same 4 ads for backup solutions
since I first plopped the code in.  At first I thought it was neat, since
I'd been talking about backups at the time and the ads seemed an intelligent
complement.  But that story's long since scrolled off the page, and nothing
else interesing has come up since.  Maybe this is by design, but I expect
my clickthroughs to stop pretty soon.
Now, I have no ambitions to get rich quick via Google.  If they happen to
pay out enough to cover my hosting costs, I'm abso-frickin-loutely
ecstatic.  So, I won't be spending
much time obsessing over search terms and "borrowing" public domain works to
boosting my ?AdSense revenue,
but it seems like the service could use a little freshening.
Am I missing something?
Update: Heh, funny thing.  No sooner do I post this and visit the site to
check out how things look, the Google ad appears to have rotated.
Is someone watching?  Heh, heh.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/29/google-ads-monotony/"
          >413&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/29/google-ads-monotony/">#</a>
    <a class="time" href="2003/07/29/google-ads-monotony/">10:33 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 July 28</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/28/desktops-rock/">Desktops are better than laptops?</a>
      </h2>
    
    <p class="summary">
      What I've discovered, though, is that my desktop PC, for standard development tasks, is astoundingly faster than my work laptop for just about everything.

Source: rc3.org | Developing on my game box



Personally, though I really do want a new PowerMac G5 I can’t see myself investing much in desk-anchored computing anymore.  Not since I got my first laptop, and later my first wireless ethernet card.  What I can see myself doing, though, is maybe investing a little bit into a new PC for games, and maybe for a box with lots of storage and CPU power to stick in a closet somewhere and use via network.

<p>Sure, a dirt cheap box tied to the spot via a dozen cables should be able to smoke my lightweight personal computing device&#8230;  but what if I use that stationary box <strong>from remote</strong> with that lightweight device?  It&#8217;s client/server all over again, but this time I own both the server and the client.</p>

<p>See&#8230; that&#8217;s where I <strong>really</strong> think it&#8217;s at. :)</p>
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/28/desktops-rock/"
          >1268&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/28/desktops-rock/">#</a>
    <a class="time" href="2003/07/28/desktops-rock/">12:06 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 July 26</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/26/amazon-rss/">Finding the RSS in Amazon searches</a>
      </h2>
    
    <p class="summary">
      Amazon.com Syndicated Content is delivered in RSS format. RSS is a standard format (in  XML) for delivering  content that changes on a regular basis. Content is delivered in small chunks, generally a synopsis, preview, or headline. Selected categories, subcategories and  search results in Amazon.com stores now have RSS feeds associated with them, delivering a headline-view of the top 10 bestsellers in that category or set of  search results.

Source: Amazon.com Syndicated Content  (via Silicon Valley - Dan Gillmor's eJournal - Amazon Does RSS, Officially)



This is very cool, though the feeds a little hard to find at first.  Don’t look for the orange XML or RSS buttons – use RSS autodiscovery to find the feed associated with a search.  (In other words, the URL will be in a link tag in the header of a search results page.)

<p>And though I don&#8217;t really want to stir up trouble, I find it strange that Amazon uses <span class="caps">RSS</span> v0.91, and that they link to <i>Netscape</i> (an all but defunct entity) and not a spec hosted by UserLand or <a href="http://www.thecrimson.com/today/article348552.html">Harvard</a>.</p>

<p>Anyway, at least they&#8216;re providing feeds in <strong>some</strong> format!</p>
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/26/amazon-rss/"
          >186&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/26/amazon-rss/">#</a>
    <a class="time" href="2003/07/26/amazon-rss/">2:59 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 July 23</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/23/from-foaf-rss/">HTTP/1.1 From header and FOAF use in RSS aggregators</a>
      </h2>
    
    <p class="summary">
      Privacy issues aside (for the moment), there is a request header called "FROM", RFC 2616 s14.22 describes it. 




Now, it does say it should, if given, contain an Internet e-mail address for the human user who controls the requesting user agent.  SHOULD isn't MUST though, so what putting the user's homepage there?
It also says "In particular, robot agents SHOULD include this header so that the person responsible for running the robot can be contacted if problems occur on the receiving end."
Source: eric scheid: Atom aggregator behavior (HTTP level) [dive into mark]



Ask a stupid question , get a smart answer .

<p>Last year, I thought it was a good idea to <a href="http://www.decafbad.com/blog/tech/old/oooahe.html">abuse referers</a> in order to leave footprints behind when I consume <span class="caps">RSS</span> feeds.  Then, this past January, the abuse in the practice was revealed and <a href="http://www.decafbad.com/blog/tech/old/ooodoe.html">using the User-Agent header</a> was recommended for this.</p>

<p>So, just for the hell of it, I <a href="http://diveintomark.org/archives/2003/07/21/atom_aggregator_behavior_http_level.html#c003136">asked about the User-Agent header</a> for use in the context over at <a href="http://www.diveintomark.org">Mark&#8217;s place</a> to see what responses I&#8217;d get.  The one that seemed most informative was from <a href="http://IAwiki.net/EricScheid">Eric Scheid</a> as quoted above, referring me to <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.22">the <span class="caps">HTTP</span>/1.1 spec, section 14.22</a></p>

<p>As per Eric&#8217;s comment and the spec, the value of a &#8220;From&#8221; header <span class="caps">SHOULD</span> be an email address, but I would think that using a <span class="caps">URL</span> wouldn&#8217;t be <strong>too</strong> much an abuse of this header.  Seems like a good idea to stick either the <span class="caps">URL</span> to a blog here, or even better, stick the <span class="caps">URL</span> to your <span class="caps">FOAF</span> file here.</p>

<p>I&#8217;d really like to see this get built into aggregators as an option, though not turned on by defauilt for privacy&#8217;s sake.  I like the idea of leaving my name or a trail back to me at the doorstep of people whose feeds I&#8217;m reading, and I like the idea of standardizing the practice as cleanly as possible.  Using the &#8220;From&#8221; header seems to be the best option so far, versus header abuse and User-Agent overloading.</p>

<p>Man.  One of these days, I really have to get around to studying those specs in full, rather than just sporadically referencing them.  Thank goodness for smart guys like <a href="http://www.diveintomark.org">Mark</a> and <a href="http://IAwiki.net/EricScheid">Eric</a> (among others) who actually take the time to read these things and try to communicate the gist to the rest of us busy developers!</p>
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/23/from-foaf-rss/"
          >701&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/23/from-foaf-rss/">#</a>
    <a class="time" href="2003/07/23/from-foaf-rss/">5:00 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry has-thumb">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/23/sleep-apnea/">This evening&#39;s sleep brought to me by science.</a>
      </h2>
    <div class="thumb">
      <img src="http://stat.livejournal.com/img/userinfo.gif" />
    </div>
    <p class="summary">
      For a change, I feel awake today.
It's ironic that much of my writing in journals and much of my thought goes toward the topic of consciousness and thought itself.  I've been studying and contemplating issues of cognition, awareness, and self for as long as I can remember.  I've wolfed down self-help books and pop-psych in high school, went on to get a minor degree in psychology proper in college.  
I don't use drugs to tinker with my consciousness (other than caffeine, that is), but I've tried various more controlled forms of meditation, visualization, and introspection.  I flirted with Dianetics & Scientology (but ran far, far away), employed psycho-cybernetics, got motivated by Anthony Robbins, twisted my inner eye around to see itself with the help of Douglas R. Hofstadter, studied concept-formation and knowledge ala Ayn Rand, considered the multiplicity of self with Marvin Minsky, and explored dreams and archetypes with C. G. Jung.  With the help of each influence, I've been stitching together a rough manual to my mind.  Just like I've hacked around with computing devices, I've worked to understand and tweak my own mentality.  
Oh, but I probably need to explain the irony: For the past few months-- likely the past few years-- I've been suffering from sleep apnea.  LIke my father, and his father before him, I've developed a horrible snore and have started fighting a losing struggle with sleepiness.  My dad is known for falling asleep constantly: in the midst of conversation, while eating, while getting his haircut, while using a computer.  And lately, those have all been things that I've begun to "enjoy".  Especially bad has been my tendency to fall asleep at work, and especially dangerous has been me falling asleep whenever I have to drive for more than 10 minutes.
This condition seems to have come upon me so gradually that it's only been recently, with the scare of losing my new job, and missadroit's persistent persuasion, that I finally ackowledged the problem and sought treatment.  So, I managed to get an appointment at the University of Michigan Sleep Disorders Clinic, where one evening at the beginning of the month I was covered with wires and sent to bed.  About a week later, they called me back to inform me that I had very severe sleep apnea, and was barely getting any sleep at all in a night with about 2-3 breathless episodes per hour.
Within a few days of that news-- yesterday, in fact-- I was given a new toy: The REMstar Pro CPAP System.  After one night with the thing, my snoring is gone except for the occasional snort as I become accustomed to a breathing mask, and I feel quite a bit more rested than I have in recent memory.  I still feel a bit tired, but that's to be expected: I've got many nights to catch up for.
I'd gone from being able to track "seven, plus or minus two" things at once down to barely one thing at a time, and that was if I didn't doze off in the middle of the task and have to rebuild the thought process when I snapped back awake.  The irony of it all is similar to something I was reminded of last week: As it turns out, software needs hardware to run.  So, for all my introspective experimentation on myself, and all my attention to consciousness, I've been feeling it slipping away from me lately.  As a "software" guy, I can't do much with my "hardware".  
So, I'm very happy that I finally-- after much denial and procrastination by me, and after much encouragement and tolerance by missadroit-- called and started the process that ended up with me sleeping through the night again.
And now maybe I can close my eyes and meditate without losing consciousness again.
Now maybe I can be myself again.
(P.S.:  Thank you, missadroit.  I love you and don't know what I'd do without you.)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/23/sleep-apnea/"
          >1117&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/23/sleep-apnea/">#</a>
    <a class="time" href="2003/07/23/sleep-apnea/">2:07 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 July 22</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/22/two-track-buttons/">Tap + Click = Two mouse buttons on a Mac trackpad?</a>
      </h2>
    
    <p class="summary">
      I have my powerbook trackpad set to accept taps as mouse clicks, which makes the behavior identical to the button.
 
What I'd like to do is set one of them to behave as a second mouse button. That sounds like it should be possible. All of the usual suspects have thus far failed me. I'm surprised there isn't something on versiontracker -- it seems like it would be a popular hac
Source: osxhack: new powerbook - two button mouse from trackpad?



Sounds like a great idea to me.  Has it been done?  Or has someone realized that it’s actually a really bad idea for some reason I haven’t thought of?
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/22/two-track-buttons/"
          >241&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/22/two-track-buttons/">#</a>
    <a class="time" href="2003/07/22/two-track-buttons/">7:57 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 July 18</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/18/textile-wiki/">Textile + Wiki = ...?</a>
      </h2>
    
    <p class="summary">
      Yesterday, I downloaded Mark Pilgrim’s Python implementation of Textile and integrated it into the new hackish blog posting feature I added to my aggregator, and it works great.  Now, I want Textile in my wiki.  I google for it and don’t find much on wikis and Textile together.  I wonder how this could be most easily done?  In TWiki ? MoinMoin ? KWiki ?
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/18/textile-wiki/"
          >175&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/18/textile-wiki/">#</a>
    <a class="time" href="2003/07/18/textile-wiki/">8:56 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/18/not-working/">&quot;It isn&#39;t working.&quot;</a>
      </h2>
    
    <p class="summary">
      Words to strike terror into the heart of the home's designated computer geek...

Source: Caveat Lector: Iulii 13, 2003 – Iulii 19, 2003 Archives



This doesn’t happen to me at home, but it strikes terror into me whether I’m at work, visiting relatives, or mistaken for an employee at some computer store.  “It doesn’t work” always seems to be the introduction into a great, murky mystery which usually leads me into wishing I was either a mind reader or had a cluebat on me.  :)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/18/not-working/"
          >400&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/18/not-working/">#</a>
    <a class="time" href="2003/07/18/not-working/">12:53 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 July 17</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/17/1058457401/">As it turns out, software needs hardware to run.</a>
      </h2>
    
    <p class="summary">
      RAM and motherboards are the least likely suspect in kernel panics, but if you just have a new system, and or just installed new memory and you get a kernel panic, that's the most likely place to start looking.  ... use the Hardware Test CD ...

Source: Mac OS X Kernel Panic FAQ





In my current job as jack-of-all-trades tech guy, I have to deal with everything.  Lately, it’s been a 15” PowerBook that’s been having random crashes and happily corrupting its hard drive.  Being a software guy, I run every program I can think of:  Disk First Aid, DiskWarrior, fsck.  Reinstalled Photoshop.  Then, tried wiping the machine and installing OS X, which was fine until the installer itself crashed. Kernel panic after kernel panic.  At one point, I considered consulting Eliza. 

<p>Turns out it was the memory.  We found this out by finally running the one bit of software that, as a software focused guy, I hadn&#8217;t even conceived of: The Hardware Diagnostics CD.</p>
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/17/1058457401/"
          >165&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/17/1058457401/">#</a>
    <a class="time" href="2003/07/17/1058457401/">12:02 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 July 16</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/16/linkblog-changes/">Changes in my link blogging</a>
      </h2>
    
    <p class="summary">
      You might notice a sudden rise in link-quote-comment entries around
here, depending on how well this works for my lazy self.  I just threw
together a quick bookmarklet and aggregator-integrated posting hack
for myself, hoping it will be as easy as BookmarkBlogger for noting
down URLs of interest throughout the day.  Nothing revolutionary,
just slightly new for me in daily use.
But, I was starting to wish that I could provide a little more info
around my posted links, such as why I was sharing the link and
from where I found it.  So, I'll be trying a slightly different
approach.  Let me know if it gets annoying.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/16/linkblog-changes/"
          >109&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/16/linkblog-changes/">#</a>
    <a class="time" href="2003/07/16/linkblog-changes/">11:55 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 July 12</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/12/echo-unique-namespaces/">On tag uniqueness and versioning in Pie/Echo feeds</a>
      </h2>
    
    <p class="summary">
      "feed" is not a very unique name, and if another format were to come
along with the same top level element we would not be able to write a
format driver for it. Our architecture keys off the top-level
element. I suggest changing the top-level element to indicate the
format, and also add a version number so that aggregators can have an
idea of what spec the content provider is using. I imagine Radio is
not the only aggregator that would like to key off the name of the
top-level element.



Source:Radio UserLand: Radio gets some kind of Echo support







Nope, "feed" seems like a pretty poor choice as a name if the goal was
uniqueness in the tag name itself.  But, since we have XML namespaces
to ensure uniqueness between vocabularies, we can instead focus on a
clear and simple name that only needs to be unique within the
vocabulary.  And as for versioning, why not consider different
versions of a namespace to be entirely different vocabularies,
each with different namespaces?
I did some quick Googling and found the following:

... documents, containing multiple markup vocabularies, pose problems
of recognition and collision.  Software modules need to be able to
recognize the tags and attributes which they are designed to process,
even in the face of "collisions" occurring when markup intended for
some other software package uses the same element type or attribute
name.
These considerations require that document constructs should have
universal names, whose scope extends beyond their containing document.
This specification describes a mechanism, XML namespaces, which
accomplishes this.



Source:Namespaces in XML








One of the core features of XML is its ability to deal with changes in
the rules for data (hence the extensible in its name -- Extensible
Markup Language).  As changes are made to XML vocabularies, the
creation of multiple versions is inevitable.  This makes it necessary
to mark the versions clearly, for human and machine information.  The
clear marking of versions can be used for driving validation, or for
branch processing according to the requirements of each version.



You can mark the version of an XML vocabulary in many ways.  This
discussion focuses on the use of XML namespaces for marking versions.



Source:Tip: Namespaces and versioning







I haven't looked into RadioUserLand feed handling architecture,
but how difficult would it be to use the namespace and tag together
as key, rather than the tag alone?
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/12/echo-unique-namespaces/"
          >484&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/12/echo-unique-namespaces/">#</a>
    <a class="time" href="2003/07/12/echo-unique-namespaces/">1:36 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 July 11</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/11/ultra-liberal-feed-parser/">Ultra-liberal feed parser</a>
      </h2>
    
    <p class="summary">
      This is an ultra-liberal feed parser, suitable for reading RSS and
Pie feeds as produced by weblogs, news sites, wikis, and many other
types of sites.



Source:Dive Into Mark: Feed Parser







As I guessed and
as Mark replied,
his ultra-liberal feed parser now
supports initial Pie (nee nEcho (nee Echo (nee Pie))) feeds.
But you know what else?  He left in support for RSS.  My news
aggregator remains fully able to read all my feeds even after dropping in his
new code.  No breakage here.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/11/ultra-liberal-feed-parser/"
          >132&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/11/ultra-liberal-feed-parser/">#</a>
    <a class="time" href="2003/07/11/ultra-liberal-feed-parser/">10:14 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 July 07</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/07/backup-question/">Backups with my eyes closed?</a>
      </h2>
    
    <p class="summary">
      Okay, so at my new job I'm the Guy if it has a transistor in it.  I'm
developer, sysadmin, and hardware jockey all in one.  This is fun
to a certain extent, since it tests pretty much everything I know from
A through Z.  And so far, I'm doing okay.  Every now and then, though,
I get a bit stumped.
My most recent adventure involves developing a backup routine for the
office.  I just got tape backup working on a Linux box for a big
Samba-shared directory that we all work out of.  I'm currently winging
it with star and cpio in =CRON=-scheduled scripts that manage a
6-tape rotation for me.
Full backups on alternating tapes on Fridays,
with incrementals inbetween on tapes labeled by the day.  I even have
the server eject the tape and IM me a few times until I go change to
the day's tape.  Tested recovery, and though it could be smoother, it
is at least possible at the moment.  I figure this is pretty good
for my first personal encounter with managing serious backup.  I plan
to keep researching and to upgrade software at some point soon.
So, now my boss asks me:  "Hey, can you backup this other folder for me?
I don't want to share it, though, and I don't want you to be able to
read the files."  This folder contains some important yet sensitive
things like salary information and other things to which I have no
business having access.
My stumper then, is this: How do I grab (or cause to be uploaded) a
folder of files for backup, say as large as 2GB, from a WinXP machine,
without having any access myself to read the file contents.  I'll be
able to install whatever I need on the WinXP machine, but the idea is
that, when the bits leave that machine for the Linux backup server,
there should be no way for me to read their contents.  But, I must be
able to usefully backup and, in conjunction with the owner of the
files, restore in case of disaster.
Oh yeah, and I have no budget for software.  So, I'm trying to work
this out using only free tools.
So, my first though is some sort of encryption on the WinXP machine.
Encrypt with GPG or something, leaving my boss with the secret key
on a floppy and the passphrase in his head.  Upload these files
to a special folder on our shared drive, and it all gets backed up
like everything else.
Or, since I don't even really want to know the names or number of
files in this sensitive folder, can I somehow ZIP up the whole
shebang and encrypt that before uploading?
Under Linux, none of this would be much of a problem to me.  But,
under WinXP, my knowledge of available tools and means of automation
fail me.
Any hints from out there?
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/07/backup-question/"
          >1697&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/07/backup-question/">#</a>
    <a class="time" href="2003/07/07/backup-question/">2:45 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/07/syndications-formats/">Is the magic in RSS, or in Syndication?</a>
      </h2>
    
    <p class="summary">
      Tools will start to support necho as well as RSS. The formats will
coexist, just as RSS 0.91 and RDF and RSS 2.0 coexist
today. Furthermore, this coexistence will be transparent, just like
today. Over time, necho will, hopefully, become the standard. In the
meantime, there will not be a major catastrophe of incompatibility...
Eventually, some of the other formats might become less used, and will
be phased out (this is something that is already happening, for
example, with the transition from RSS 0.91 to RSS 2.0). And because,
currently, RSS is being almost exclusively used for updates and
regenerated constantly at each endpoint, there will be little if any
switchover cost, again, as an example of this I put forward the
transition from RSS 0.91 to RSS 2.0 that happened last year.



Obviously, it's on us, the developer community, to add necho support
without disruption, and it's not a problem. After all, we are already
doing it today, and moving most (hopefully all) tools into necho will
eventually reduce work for developers in the future, allowing us to,
finally, concentrate on improving the tools rather than on how to let
them connect to each other.



Source:d2r: why (not)echo is important -- part 2







When I read
Dave's post
that developers were trying to "rip up the pavement, break
everything and start over", I wondered what he was talking about.
(Strangely, I can't find the original posting on Dave's blog.  Maybe
the statement was revised
in the face of a later endorsement of the
project?)  The reason I was wondering is because nothing broke
on my desktop.  Every RSS feed to which I subscribed was still feeding
me RSS, and my home-brew aggregator continued crunching and delivering
my fix.
In fact, my aggregator's RSS consumption is based on
Mark Pilgrim's Ultra-liberal RSS parser.
And, it looks like Mark's been one
of the developers involved in the (not)Echo project.  Mark didn't
break anything for me, and couldn't if he wanted to.  On the contrary,
he continues to offer his code, and even updated it not more than a
month ago to address link-vs-guid concerns in a useful way.  Hell, even
though Mark demonstrated his break with RSS tinkering rather concretely
by implementing a very literal interpretation of the spec, I can still
download
his working RSS parser code.
I'm a user and a developer all at once: I produce RSS, I consume RSS,
I develop with RSS, and yet I'm watching (not)Echo with great interest
and welcome it when it's ready.  I fully expect that, in my tinkering,
it'll take me less than a lazy evening's work to put together a
template to publish a (not)Echo feed from my blog, and to add
(not)Echo support to my aggregator.  Hell, I might even get another
parser from Mr. Pilgrim to drop into my project.  But, as long as
others are still producing and expecting RSS, I'll still accept and
offer RSS.  No breakage here.  In fact, if I get off my lazy butt,
I'll unfunkify
my own feed and upgrade it to RSS 2.0 while I'm at it.
This isn't really heavyweight stuff here.
Then, I read things like
Jon Udell's Conversation with Mr. Safe
and other worries that the whole technology of web content syndication
and management will be avoided by big money, or even more horribly,
co-opted by big money in the confusion.  Has the BBC or the New York Times
expressed any change of heart with their decision to offer their content
in a syndication format?  Has the basic tech stopped working?  There are no
pieces of sky on my balcony, though I fully admit that I might be too
naive to see them.
See, to me, RSS ain't the thing.  Content syndication and aggregation
are the thing, and that's going strong.  Are the people with big money
interested in this geeky thing called RSS, or are they interested in
syndication and aggregation?  You know, getting their content out
there and read?  Do they know that this (not)Echo effort hasn't
actually made RSS-supporting software stop working, nor will it ever?
Just because a bunch of bloggers and tinkerers got together and decided
to start making an alternate format and API doesn't mean that the
existing, mature technology suddenly goes sproing.
In fact, unless or until this upstart (not)Echo project builds
something amazing in terms of in-spec capabilities and vendor support,
the currently working RSS-based tech is a safe bet.  And, in fact, I'd
be willing to bet that RSS will still be a force to consider in years
to come, even if (not)Echo introduces some irresistable pull.
Companies like Blogger and ?SixApart would reveal themselves to be run
by morons if they screwed users by dumping RSS overnight.  (And that's
ignoring the fact that someone would come along and whip something
up to fix their idiocy somehow.)
And, I'm sure Microsoft or some well-heeled vendor could try stepping
in with a format of their own and try to steamroll it through with
their own blogging tools and aggregation services, but you know,
they're not omnipotent.  The Internet didn't go away when MSN was
introduced, and the web full of RSS feeds won't go away even if they
introduce MSNBlogs or some such.  It'd take a gigantic fight, lots of
very shiny bits, or many bribes.
I mean, that's what it takes to get my cats to do anything.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/07/syndications-formats/"
          >1028&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/07/syndications-formats/">#</a>
    <a class="time" href="2003/07/07/syndications-formats/">12:40 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/07/washed-up-huh/">Washed Up, Huh?</a>
      </h2>
    
    <p class="summary">
      Mr Safe: Tim Bray said you're all washed up, kind of like Charles Goldfarb.



Source:backend.userland.com: Checking in with Mr Safe





Dave Winer has done a tremendous amount of work on RSS and invented
important parts of it and deserves a huge amount of credit for getting
us as far as we have. However, just looking around, I observe that
there are many people and organizations who seem unable to maintain a
good working relationship with Dave.



I regularly get pissed-off at Dave but I really truly do think he's
trying to Do The Right Thing; but there are many people out there who
can't get past being pissed off. This is what life is like.
There's an uncannny echo here, for me.  The thing that came before XML
was called SGML. SGML was largely invented, and its landscape
dominated, by a burly, bearded, brilliant New Yorker, Charles
Goldfarb, who is currently making a well-deserved killing bringing out
the Definitive XML Series of books for Prentice-Hall.  Charles is
loquacious, persistent, smart, loud-voiced, and nearly always gets his
way.
There were a lot of people out there (still are, I guess) whom Charles
drives completely nuts and just won't work with him. Which is one of
the reasons that, when we invented XML, we felt the need to give it a
new name and a new acronym and so on. Mind you, Charles, who as I said
is no dummy, climbed on board the XML bandwagon about fifteen seconds
after it got rolling and was a major help in getting the thing
finished and delivered.



Source:ongoing: I Like Pie







I'm very confused about this.  Dave (or rather, Mr Safe) says that Tim Bray
said something nasty about him here.  In fact, Dave says that Tim said
he's all washed up, like Charles Goldfarb.
But as I read it, I'd love to be washed up like Charles Goldfarb,
seeing as he's "currently making a well-deserved killing bringing out
... books for Prentice-Hall", having "climbed on board the XML bandwagon
about fifteen seconds after it got rolling and was a major help
in getting the thing finished and delivered".  Sounds like Mr. Goldfarb
is still very active in his community, still considered an authority,
and is being rewarded for it.  I hope I'm that kind of washed up someday.
In fact, it'd be pretty keen if that's what people meant if someday
they said, "Les is Dead", though I can't find where Tim said that.
So, where's the nastiness?  It's not like Tim took notes from
Mark's spanish lessons
and told Dave to go "chinga tu madre" or "come verga".  That's nasty.
Far as I can tell, Tim compared Dave to a guy in another community
who has his own contingent of haters yet is still undeniably a brilliant
guy just trying to Do The Right Thing as he sees it.
Was the nastiness in saying that some people can't "maintain a good
working relationship with Dave"?  Or that Tim gets "regularly ...
pissed-off at Dave"?  I mean, they're both obviously true.  It would
have been nasty and untrue had Tim said that no one can maintain a
good relationship with Dave, because there are also obviously a lot of
people who do.  But, Tim didn't say that.
So, as far as I see, I'd personally be happy to have Tim Bray write
about me like this in public.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/07/washed-up-huh/"
          >920&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/07/washed-up-huh/">#</a>
    <a class="time" href="2003/07/07/washed-up-huh/">11:54 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 July 05</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/05/added-a-scroll/">Added a scroller?</a>
      </h2>
    
    <p class="summary">
      Just added a small script to the bottom of my weblog to run a scroll.


Source:John Robb's Radio Weblog







Not only that, but you added a scroller to my news aggregator page, too!  :)  Gah.
While not as dramatic as
Platypus Day, it does
have me adding an item to my TODO list to
more safely consume RSS in my aggregator.  I feel like I'm tooling around the blogosphere
with my pants off.
And, it makes me want to get back to working on AgentFrank, so I can insert some
filters to block JavaScript code that hijacks my status bar.  Bah.  No offense,
since the message itself is worth attention, but scrollers are so...  1998.
Update: And, John Robb 
has removed 
the scroller.  Thanks!  I still need to look into securing my aggregator
though.  Whether I like status bar scroller or not, my news aggregator
should keep them out anyway.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/05/added-a-scroll/"
          >151&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/05/added-a-scroll/">#</a>
    <a class="time" href="2003/07/05/added-a-scroll/">9:52 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 July 02</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/07/02/syndicated-whuffie/">Syndicating Whuffie</a>
      </h2>
    
    <p class="summary">
      ... there's excellent knowledge in blogs if only we had the tools to extract it. 



What sort of tools?  Relevance and reputation based feeds and
aggregators for one.  The problem of quickly finding what's good from
among the great muck of the blogosphere is, if you ask me, a far more
urgent problem than seeing the correct authorship or harmonizing
dc:date and pubDate before I even read the thing.
... facilitate P2P trading of RSS from desktop to desktop as well as
server to desktop -- you subscribe to 1000 feeds, aggregate them, rate
them (explicitly or by statistical filtering based on past use
patterns) and then rebroadcast your new rated feed.  Aggregators could
then /use/ redundant items from feedback loops because each RSS source
has a reputation rating that weights the contained individual item
ranking; repeated items add their rankings.



Source:TeledyN: Echos of RSS







Yes.  This is it.  This is what I want to see come next from aggregators
and blogs and syndication and all this mess.  It's what I've been tinkering
with in small steps for most of a year.  It's what I intend BookmarkBlogger
to facilitate, as well as AmphetaOutlines and the homebrew aggregator I'm
hacking around with right now.
At first thought, I'm not sure whether or not building and
republishing RSS (or Echo) feeds is where it's at.  But, the more I think
about it, the more it seems perfectly elegant to me.  All the elements are
there, except for an extension to capture ratings.  Extend aggregators to
consume these rating-enriched feeds, and instead of just spooling the items
up into your view, extract and assimilate the ratings into a growing
matrix of rater versus rated.  Apply all the various algorithms to
correlate your rating history with that of others to whose ratings you
subscribe.  Mix in a little Bayes along with other machine learning.
As for the interface... well, that's a toughie.  At present, I think I could
sneak ratings into my daily routine by monitoring my BookmarkBlogger use and
watching the disclosure triangle clicks and link visits in my AmphetaOutlines
based news aggregator.  I could easily see adding an iTunes-like 5-star
rating interface, but unless I get some pretty significant payoff from
painstakingly rating things, I'll never use it.  At least in iTunes, I get
to have playlists of my faves automatically jumbled together, if I remember
to use the ratings in the moment. 
The cool thing will be when sites like
Technorati and Feedster start
using these ratings, but the even cooler thing is when all that's on
my desktop.  This could be easy, though, couldn't it?  What do we call
it, Syndicated Whuffie?
(Which reminds me:  Eventually, we really gotta get back to the subscription
problem.  All these agents polling files everywhere will get to be nasty.
Obviously.  This has been talked about already, but little has happened.
We need some ?PubSub, maybe some caches and concentrators.  All stuff that's
been mentioned in passing before, and left by the wayside as unsexy.)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/07/02/syndicated-whuffie/"
          >1086&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/07/02/syndicated-whuffie/">#</a>
    <a class="time" href="2003/07/02/syndicated-whuffie/">12:55 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 June 30</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/06/30/plz-fix-xmlrpc-spec/">Please fix the XML-RPC spec</a>
      </h2>
    
    <p class="summary">
      I've written before that I love XML-RPC, and
that it has served me well in the past couple of years.  I think it's the right tool for a broad
range of jobs.  But, after having studied the spec, and after having implemented it in a handful
of languages for a handful of well-used apps, I think the spec needs just a bit of fixing.
In particular, the spec needs a tweak with regards to this "ASCII limitation".  There is confusion
about this, period.  I've had to hash this out with clients before, this 
was an issue of note while
working out an XML-RPC based Wiki API,
and it's obviously an issue in many other projects.  This, of course, includes the current
hubbub surrounding weblog APIs and whatnot.
So, please fix the spec.  It shouldn't take long to make this issue a non-issue by some simple
clarification in the main XmlRpc to which everyone refers.
Yes, I know there's a bit of clarification at the end of the spec, involving escaping (
not encoding) < and & along
with the statement that "A string can be used to encode binary data."  
Well, yeah, I do that
all the time with Base64.  And, since
the spec earlier had called for "ASCII", I assume that's what encoding
binary data means in the context of this spec.  To me, encoding implies a transformation 
from original form to some other form later requiring decoding.
But, apparently, my interpretation and 
the interpretation of others
is wrong on that score.  But still, I've been confused, and so have others.  Consider this a bug report.
I've been referred by Fredrik Lundh (via Dave Winer), 
to "private conversations",
"various public fora", and "early archives for the XML-RPC mailing list".  And, again by Fredrik Lundh,
I'm told:
But even if you don't know all this, it's not that hard to figure it out for
yourself. Just make sure you read and digest the entire specification, apply some common sense
to sort out the contradictions, and you'll find that it's pretty obvious that the intent is that
you can use any character allowed by XML.





Well, let's see.  I read the whole spec, more than once, and what I figured out for myself with my 
"common sense" is what I wrote above.  I thought
the spec called for ASCII (as in: ASCII), and assumed that
encoding binary data called for something like Base64.  Yes, I realize that XmlRpc is XML, but
when a spec calls for ASCII as a particular part, I assume that there's a reason for it
since that's what the specification specified.  
In my experience, specifications are not about common sense, figuring it out, and
connotation.  Specifications are
about declaration, clarity, and 
denotation.  
Yes, I understand that no
spec is perfect, and that many are steaming piles meeting none of the criteria I just mentioned,
but that doesn't alter the goal.  A spec can always be made better by revising 
with these things in mind, given the input of consumers of the spec.  This is what a process
of communication is all about, and specifications are intended as a form of communication.
So, instead of talking about intent and things that have been talked about somewhere
at some time, with the implication that I should just go off and search for these things, can 
we just get a clarifying fix to the XmlRpc spec?  I don't want to send my clients off to 
mailing list and discussion archives, or present XmlRpc with any corrections or caveats.  I
want to say, as I have been, "Here, go to xmlrpc.com, read the spec, implement to the API
I emailed you, and get back to me."  Only, it'd be nice if the first question is about my API, 
not about character encoding.
I've been confused, and so have others.  I consider myself a smart person, and I consider most
of the others who have been confused as even smarter.  I apologize if my "common sense" is of a
different sort, but that's what you have to deal with in the world of people.  As young as I am,
even I've discovered this already.
So, can we just get a clarifying revision of the spec?  And if not, why not?
Update: Rock on.  After catching up 
on a bit of banter over at Sam's place, I see that
the same Fredrik Lundh I quoted before has already begun an
XML-RPC errata page with the goal of clarification.
(I just missed it in my daily reading thus far.)  As 
Mark comments, I fear bumps in the
road as any confused implementors find things weren't what they thought, but I'm happy to see
the clarification accepted.
Update again: If you've stopped rocking, resume.  Dave Winer 
updated the XML-RPC spec.
It was a small change, could have been more, but had not been done at all until now.  I
doubt that my asking please really had much to do with it, but I couldn't guess that it 
hurt.  Thanks!
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/06/30/plz-fix-xmlrpc-spec/"
          >1015&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/06/30/plz-fix-xmlrpc-spec/">#</a>
    <a class="time" href="2003/06/30/plz-fix-xmlrpc-spec/">8:25 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 June 26</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/06/26/so-like-i-was-saying/">Like I was saying about RSS...</a>
      </h2>
    
    <p class="summary">
      So yeah,
like I was saying,
I've kept my head out of the RSS frey lately.  This past post about GUIDs and
their properties of rocking in RSS hadn't had much thought behind it, other
than that the idea of having something well defined and uncontestably intended
for the use or uniquely identifying a weblog post seems like a good idea,
especially if it's a permalink.  Because, you know, permalinks seem great things
to serve as both globally unique identifier and locator in one go.
I had a feeling that I was confused about the purpose of the link element in RSS
2.0, but having not really studied the spec, I just kept to maintaining a student
mind and assumed that there were Things Not Yet Understood.  Now I read the spec,
curiosity sparked by the recent hubbub over at
Mark's place
and Phil's place.
Dave
wrote that
the link tag in items was "designed for something else".  Cool
by me, I assume that I am not yet well informed.  So, I read in the
spec, where assumedly I'll be illuminated as to its designed purpose,
that link is "The URL of the item".  To me, this means that the link
tag was designed to point at the item, being the URL of that item.
And, as far as I can tell, "the item" is what is being described by
the item tag, in other words: the weblog entry.
But this seems contrary to the statement that it's been "designed for
something else".  Designed when and documented where?
Jon Udell writes
that RSS is in no way broken, but I personally think it's got a funky widget
or two in it and is not free of confusion.  Bah, really I
don't care.  I still think a GUID for a weblog entry is a good idea,
and that maybe some people who comment on links exclusively should
have a tag devoted to that.  Maybe in a separate namespace devoted
to link-blogger vocabulary.
Meanwhile, I'll be making occasional pokes at participating
over at Sam's wiki and The Echo Project.
I like the wiki approach he's
offered for participation, especially the potential for zero-ego participation
when it works.  I love seeing something I contribute in a wiki eventually
float free from my attribution, to later land in the midst of a summary
elsewhere.  And in the end, if it all works right, it'll be something
that everyone had a part in, yet no one owns, and further yet didn't take a
formal committee to approve.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/06/26/so-like-i-was-saying/"
          >802&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/06/26/so-like-i-was-saying/">#</a>
    <a class="time" href="2003/06/26/so-like-i-was-saying/">1:28 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 June 25</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/06/25/adsense-no/">No Google AdSense for Me</a>
      </h2>
    
    <p class="summary">
      Google ?AdSense is for web
publishers who want to make more revenue from advertising on their site while maintaining editorial
quality. ?AdSense delivers text-based Google ?AdWords ads that are relevant to what your readers see
on your pages and Google pays you. 


Source:Google AdSense







Your website is a type of website that we do not currently
accept into our program. Such websites include, but are not limited
to, chat sites, personal pages, search engines, sites that contain
predominately copyrighted material, and sites that drive traffic
through cybersquatting.


Source:Response to an AdSense application for decafbad.com







Hmph.  No chat around here.  I suppose things are a little personal, and there's a search
engine.  But, if there be warez here, I must've been hacked, and nobody seems to want
this domain but me, so there doesn't seem to be any squatting going on.
Guess I'm not a web publisher who wants to make more revenue while maintaining editorial
quality.  :)  (I'm guessing I've been rejected as a web publisher.)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/06/25/adsense-no/"
          >403&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/06/25/adsense-no/">#</a>
    <a class="time" href="2003/06/25/adsense-no/">8:23 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/06/25/guids-in-rss-rock/">GUIDs in RSS rock</a>
      </h2>
    
    <p class="summary">
      Guids sure have a funny name, but they're quite useful. If your weblog tool supports them, use them. If not, ask the developer to add the support. It's not very hard.



Further, I strongly believe that all aggregators and readers should pay attention to guids where they are available. It's a convenience that many users will appreciate, especially people who are in a hurry
Source:Guids are not just for geeks anymore ;->







Haven't really been saying much lately about the recent plunge, albeit more amiable this time, back
into the RSS and weblog syndication frey.  Mostly because I haven't had the time, and mostly because
people more eloquent than I were already saying what I thought.
In the meantime, I've been working, and puttering around with 
my own aggregator as spare time comes up.
And you know, I'm tired of having to come up with some mechanism to detect new entries.
This GUID thing is what I need.  I don't want to run MD5 on another RSS item, and I don't
care to track the minor edits people do on their entries, like Dave said.
Personally, I think the GUID should be the permalink, if at all possible.  I used 
to think that that was what the link of an RSS item should be, but then I never really
maintained a weblog in the quote-link-comment style for long stretches.  My entries
aren't usually completely about someone else's article.  But, some weblogs are 
like that.  So, link points to a subject under comment, GUID identifies the entry and
ideally does it via permalink.
Nifty.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/06/25/guids-in-rss-rock/"
          >719&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/06/25/guids-in-rss-rock/">#</a>
    <a class="time" href="2003/06/25/guids-in-rss-rock/">7:12 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry has-thumb">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/06/25/font-borken/">Why is my Monaco Borken?</a>
      </h2>
    <div class="thumb">
      <img src="http://www.decafbad.com/blog-images/font-issues.gif" />
    </div>
    <p class="summary">
      Okay, what's wrong with this picture?






Each of those lines is from a terminal I have open, trying to find
one of my monospace fonts that works correctly and I don't hate.  My
past favorite has been Monaco for the longest time, but recently (when,
I can't quite remember) it seems that it likes to combine "l" and "/"
into one symbol.  So does Courier.  
On the other hand, I have this font
called Monaco CY which looks close enough to my favorite Monaco, until I 
discover that it mashes double dashes together.
This leaves me with only two monospace fonts on my ?PowerBook that don't
mangle things (however minor) in the terminal. They are Courier New and
Andale Mono, both of which I very much dislike.
So, though I've found one other person 
complain a bit about this, I can't seem to find any explanations why.  Best
I can figure is that I had to dump a slew of fonts onto my system recently
in order to be able to do some client work, so maybe I clobbered an out-of-box
version of my previously favored Monaco.  But that doesn't make much sense, since
I tried snagging a copy of Monaco from my girlfriend's iBook to no avail.
Anyone out there have a clue as to what this is?
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/06/25/font-borken/"
          >554&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/06/25/font-borken/">#</a>
    <a class="time" href="2003/06/25/font-borken/">5:30 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry has-thumb">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/06/25/sync-not-my-bookmarks/">Sync My Bookmarks No Longer!</a>
      </h2>
    <div class="thumb">
      <img src="http://www.decafbad.com/blog-images/bookmarks_sync_off.gif" />
    </div>
    <p class="summary">
      So, I downloaded Safari 1.0 yesterday and was very pleased to notice
a new checkbox option on the Bookmarks section of the preferences.






Notice the off state of the checkbox.  Goodbye, bookmark syncing, I hardly wanted to know ya.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/06/25/sync-not-my-bookmarks/"
          >59&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/06/25/sync-not-my-bookmarks/">#</a>
    <a class="time" href="2003/06/25/sync-not-my-bookmarks/">5:27 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 June 23</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/06/23/wwdc-love-the-web/">WWDC (or, I love the net)</a>
      </h2>
    
    <p class="summary">
      At the moment, I'm working on a bit of HTML and form processing, but
I'm also monitoring three IRC channels and two web pages since I can't be 
at WWDC for the Keynote.  But, it's almost like I'm there.  
Except I don't get a free iSight.  Bummer.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/06/23/wwdc-love-the-web/"
          >61&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/06/23/wwdc-love-the-web/">#</a>
    <a class="time" href="2003/06/23/wwdc-love-the-web/">2:56 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 June 20</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/06/20/algorithm-for-reality/">About That Algorithm</a>
      </h2>
    
    <p class="summary">
      Let's say you're torn between two
worlds. You know that
one is a fevered delusion that your mind has created and the other one is reality,
but which is which? ...  Apply this
algorithm in both worlds...


Source:Algorithm for Determining Imagination from Reality







So, after having seen Matrix Reloaded, and having read advice on 
how to live in a simulation,
I find myself wondering, how might I determine whether I'm living in a simulation?Well, I figure chances are, I'm not even living in a decent simulation.  In fact, I could
just be hallucinating right now.  So, Aaron Swartz comes to the rescue with a very
reasonable empirical test I can perform.  Everything seems to check out.
Problem is, though, the test is completely dependant upon me and my perceptions.
First, I have to pick a really big number that's outside my ability to perform
a square root on it in my head.  Then, someone else performs the square root
on a calculator.  I then square that number by hand, and that answer should match
my first, and since I couldn't possibly perform a square root that large in
my head, the answer must've come from outside my head.
Except for this:  If I'm hallucinating, then there's a subdivision of me controlling
the perceptions of another subdivision of me.  Who's to say that the me who's
performing this test isn't a complete idiot, and all the math skills are in the
part producing the hallucinations?  Or, hell, what if for the duration of the test
my hallucination producing side decides to make me blind to any numbers greater than
4?
Hmm.  Well, just to be safe, I won't try the alternate "Step in front of a bus
and see what happens" test.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/06/20/algorithm-for-reality/"
          >395&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/06/20/algorithm-for-reality/">#</a>
    <a class="time" href="2003/06/20/algorithm-for-reality/">7:39 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 June 19</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/06/19/flash-agg/">Desktop server + Flash GUI?</a>
      </h2>
    
    <p class="summary">
      Still have been busy like crazy, but 
as I wrote back in April,
some of what I'm doing has been pulling me further into Flash MX and XML.
Also, in the few moments of free time I've had lately, I've been toying
with my own news aggregator.  It's a
PersonalServer, written in Python, based on Twisted, and uses
SQLite via PySQLite
for storage and juggling of items.
So, today I've been thinking:  How hard would it be to bundle together a desktop app
composed of a backend in Python and a GUI in Flash?  Connecting the two is no problem
given whatever method of XML communication you want to pass between them.  Pairing
the two together to be launched on the guest OS would seem to be a bit of an
oddity.
See, I like my news aggregator GUI in the browser.  It seems native there.  But
on the other hand, as far as interfaces go, what I want to make the browser
do tends to sound ugly.  I mean, yeah, there're all sorts of DHTML and CSS tricks
and XUL looks promising, but damn have I been noticing how slick Flash is
lately.  And fiddling around with ?ActionScript has been pretty fun lately.?JavaScript has gotten a pretty bad reputation via crashy implementations, but
as dynamic scripting languages go, there are some nifty elegances I can pull
off in it.
So...
  I've been reading a bit about 
Macromedia's Central as far as 
desktop Flash goes, and I've seen the 
News Aggregator sample app,
but 
how about a maniacal mutant hybrid of Python and Flash?
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/06/19/flash-agg/"
          >322&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/06/19/flash-agg/">#</a>
    <a class="time" href="2003/06/19/flash-agg/">1:34 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 June 13</h2>
  </li><li class="content-grid post post-type-entry has-thumb">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/06/13/newly-digital/">Newly Digital in 1983</a>
      </h2>
    <div class="thumb">
      <img src="http://www.old-computers.com/museum/photos/atari_800.jpg" />
    </div>
    <p class="summary">
      I caught Gizmodo 1983 this week,
along with the news
that NBC may be revisiting the old 1983 scifi series "V", and I was reminded that that
was right around the time I got my first computer.  I've been meaning
to write something for Newly Digital,
so here goes:
My history with computers starts a few years earlier than 1983,
though.  I think it was during the first grade, when I was a hyper,
easily bored kid.  I would get class work done quickly and early, yet
forget to turn it in.  Then, I would disrupt class until I was somehow
calmed down or sent to the principal.  I seem to remember that, once,
I was caught scaling a classroom wall via the curtains.  How far I
made if before being caught, I'm not sure, but it seemed like miles
to me at the time.  I remember being the only one happy about it.
One day though, the usual trip to the principal changed.  I remember
him as a tall, bald, and imposing man whose breath always smelled
funny.  (This was long, long before I knew about coffee and had become
hopelessly addicted myself.)  The man scared me, since he was known
have spanked students in the old days, and though he wasn't allowed to
do that anymore he still had the power to call my Mom.  And I'm pretty
sure most everyone knows the little-kid terror of that.

This particular visit, though, he led me back into his office, and sat
me down in front of an
Atari 800
and a TV screen.  Though I had
already been introduced to video games via our Atari 2600 at home, I
had little idea what this thing was.
He showed me how to turn everything on, and introduced me to a stack
of workbooks as tall as I was.  Each book was about 1/4" thick and the
cover colors were a rainbow of progressive difficulty.  He told me
that he was trying to decide whether or not to start teaching
computers in the school, and that these books were what the company
sent him for classes.  He wanted me to try them out for him and see
what I could do with the computer before he bought more for the
school.
From then on, when my class work was done, I had a pass to go to the
principal's office and work through the books with the computer until
either I ran out of books or the year ended.  I worked mostly on my
own, with a heavy sense that it was something special I'd been trusted
with.  As the principal went about his daily work, I was barely
supervised with this expensive machine, and I felt I needed to prove I
was worth it.

My grades and my behavior improved as I tore through the workbooks in
his office.  There was so much to learn and play with.  I remember
with unusual clarity writing a program that asked me for my birthday
and replied with my age in the year 2000.  It dazzled me that
something I programmed into the computer could tell me about myself,
all grown up, in the twenty-first century.  You know, the year when
all science fiction stories came true!  But there I was, playing with
the stuff of sci-fi already.



And the greatest thing, as the books began to ask more creativity and
originality from me in my assignments, I felt my mind stretch.  I'd
never quite felt that before, and it was so amazing.  Part of it was,
I'm sure, just a property of the elasticity of the brain at that age,
but I'm sure my time at the computer helped.  Every day, I remembered
and could do more.  My thoughts were becoming more ordered and
organized, as programming the computer required it.
But, after a few months, observing my obvious enthusiasm for the work,
the principal took me out of his experiment.  I was disappointed but
he told me that he'd decided to build a computer lab and turn what I'd
been doing into a real class for everyone in the school.  I crossed my
fingers: There were still plenty of books left to get through, and I
was just getting to the fun things like graphics and sound.
When the school's little computer lab was finally opened, all the kids
got sorted into groups of five or so, and each rotated through a
weekly schedule of hour-long visits.  When my group's turn came, I was
crushed: I found that there were no assignments, just Pac Man and
Missile Command and a smattering of math and vocabulary games.  We
were handed joysticks and told not to touch anything else.

These machines were Atari 400's 
and looked so much less advanced than what I'd been used to.  I
remember there being an intense nervous aura radiating from the
supervising teacher on duty in the lab, just waiting for one of us to
destroy these things.  And, when I asked if I could have a BASIC
cartridge to work on some of my programs, I told that if I didn't
want to participate in the computer activities I could just go back to
class.  As bitter as a first or second grader could be, I was.
See, I'd gotten teased a bit for the special treatment in the
beginning, but I didn't mind.  And, now that everyone played with the
computers, I got teased for not being so special anymore.  What I
couldn't get across to anyone, not even my teachers, was that they
weren't getting what I had.  There was so much more they could have.
Well, I'm not sure my thoughts were so mature at the time, but I felt
like everyone, including me, had been cheated.

So that ended my education in hands-on programming, temporarily.  I took to
reading more computer books, often bought from the school book fair,
like David Ahl's
BASIC Computer Games.
Lacking a computer of my own, I read and ran though the
programs in my head.

For the next year or so, I had sporadic access to computers.  My Uncle had a
TRS 80 Model III
that he let me use during visits.  That thing mostly
confused me though, as I was introduced for the first time to an
alternate flavor of BASIC.  And still, there was the not-mine feeling
and my Uncle's protectiveness of his expensive business machine.
My grandparents also had a
VIC-20,
but sans tape drive or hard drive, so every visit was starting over
from scratch.  Nothing would substitute for what I'd had: My own time
with the machine, doing things myself, building one thing atop another.
Then, the
Commodore 64
arrived at the local K-Mart.  I was in love.  This was it for me, and
I raved about it constantly.  I never quite expected to get one,
though, since the thing was expensive, especially for a kid my age.  And
besides, computers were always something that someone else had.  But I
guess I must've really gotten on Santa's good side, because I was met
with this surprise on Christmas morning that year:






That first computer was really something.  It was mine, given to me by
my family as a whole.  No one protecting it from me, fearing I'd break
it.
So I attacked it.  I learned everything about it, buried myself in
books and magazines, figured out how every bit of it worked and could
be used.  More than once, I'd gone at it with a screwdriver to see
what was inside.  Then I went at it with a soldering iron to add
things like a reset switch and RCA audio output.  I made friends with
people at a local computer store, and they let me be a guinea pig to
test new software and hardware for the thing.  At one point in fourth
grade, I learned 6502 assembly, printed out a disassembly of the
machine's kernel, and mapped out what everything did.  I still have
that print-out, bound with rubber cement, and full of my scrawlings.
That Commodore 64 would be my gateway to all sorts of further hackery
and geekery, as well as a means of meeting more of my kind.  After
getting a modem, it became my entry point to local (and not-so-local)
bulletin boards, and eventually my first tastes of the Internet.  I
was still using that Commodore 64 up until my last year of High
School, coincidentally the year of the machine's last production
run.
I've had other computers since that Commodore 64, but it was opening
that box on Christmas Morning that let me continue the process that my
Elementary School principal had started for me, and I haven't stopped
since.  I love to feel my mind stretch, and I love to take things
apart and see what's inside.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/06/13/newly-digital/"
          >1529&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/06/13/newly-digital/">#</a>
    <a class="time" href="2003/06/13/newly-digital/">7:06 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 June 02</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/06/02/blo-gs-gone-wild/">Blo.gs Pings Gone Wild</a>
      </h2>
    
    <p class="summary">
      Shawn Yeager just dropped me a line to let
me know that my blog has apparently been pinging blo.gs like crazy today, and
since he's set to recieve IM's on blog updates from blo.gs, he's been getting
flooded with IMs.
First off, if this is happening to you:  Sorry out there!
Second thing, this
might be interesting for anyone using a blosxom plugin to ping blo.gs or weblogs.com like me.
Basically, I took the ping_weblogs_com
plugin for blosxom, replaced the weblogs.com request with one to blo.gs,
and searched for the pattern 'congratulations' instead of 'Thanks for the ping'
in the response.  Finding the pattern is assumed to mean the ping was successful.
A successful ping, then, causes the plugin to update the contents and timestamp
of the status file with the response.
The status file is used by the plugin to determine whether or not a ping
should be sent.  This check is made everytime an item is viewed on my blog,
and if the plugin sees a blog item whose timestamp is newer than that of
the status file, a ping is sent.
So!  Onto the punch-line: The appearance of the word 'congratulations' and
the successful registration of a ping are not the same thing.  Apparently,
blo.gs has been throwing up an error message in response to a ping, while
still registering a ping.  This error message does not contain the word
'congratulations', and so my plugin never updates the status file, and so
it happily tries pinging blo.gs again with the next blog view.
Two lessons learned here:

 When using a web service, whether a "real" service or a "scraped" service, be very sure to know and handle the difference between a valid response and an exception or error in the service itself.

 When using a web service, take care with your usage pattern.  That is, just how important is success?  Important enough to try again and again?  Or could you wait awhile, whether successful or not?  Or should you even try again?





My plugin doesn't know the real meaning of the response to a ping.  And further,
the fact that it's designed to try, try again in the case of apparent failure
is not the greatest choice for a usage pattern.
So... longwinded post, but I think the realizations are valuable.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/06/02/blo-gs-gone-wild/"
          >440&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/06/02/blo-gs-gone-wild/">#</a>
    <a class="time" href="2003/06/02/blo-gs-gone-wild/">4:10 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 May 31</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/05/31/games-stuff/">Don&#39;t Call It an Obsession</a>
      </h2>
    
    <p class="summary">
      Just read Matt Gemmell's bit of a catalog
of his Nintendo collection, and ever since Russell professed his love
for his ?GameBoy Advance, I've been meaning to write something about my personal video game addiction.
For the past few months, with everything
that's been
going on
in my life,
I've not had much time for nursing my habit.  But, since things have calmed
down a bit, and my girlfriend and I
both purchased ?GameBoy SP's, our time mashing buttons and cursing at glowing
screens has picked back up.  I count myself as infinitely fortunate to have
found a girl who not only tolerates my video gaming ways, but insists that
we display the collection of consoles in the living room.
I have a photo of the entertainment rack around here somewhere, but it
may have been a casualty of the thirsty iBook
incident.  (Still tinkering with getting a Linux box to mount the HFS+
partition on the apparently undamaged hard drive.)  From where I'm sitting,
though, I see the following systems either connected via switchbox to
the TV, or stowed away in a mesh drawer:

 Nintendo

 NES (classic frontloader)

 SNES

 N64

 ?GameCube

 ?GameBoy

 Classic

 Pocket

 Color

 Advance 

 purple with TV connector mod

 pink 





 Advance SP (x 2 platinum)









 Sega

 Genesis

 Dreamcast





 XBox

 PS2





Stowed away in closets and, possibly, at my Mom's house, I've also
got an Atari and ?ColecoVision.  Also, I have a small start on a
computer collection as well, including a C64, Atari 800, Amiga 1200,
and of course a smattering of random PCs.
Eventually, I want a house, and a room in this house will be dedicated
to the display and use of these machines.  Also, eventually, I want
to work on a proper collection of these things and their games and
software.  (For instance, I'm in desperate need of a second generation
top-loading NES.)
The funny thing is that people still ask me occasionally if I really
need or use all this stuff.  How could the answer be anything but yes? :)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/05/31/games-stuff/"
          >472&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/05/31/games-stuff/">#</a>
    <a class="time" href="2003/05/31/games-stuff/">3:44 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/05/31/thanks-readers/">Thank You, Readers</a>
      </h2>
    
    <p class="summary">
      Oh, and I've been meaning to post a little note of thanks to everyone
who're still reading this blog.  I haven't done or said much of note
around these parts in some time, with the only saving grace being my
automated BookmarkBlogger posting every night.  More than I expected,
those posts have actually caught the interest of a few people.
But I never wanted this
place to turn into just another link-blog.  And I also have been feeling
a bit guilty that my Quick Links give no indication of source where
I found these tidbits.  They are, more often than not, gleaned from
the 320 or so sites whose RSS feeds I slurp down 12 or so times a day.
I really need to get some sort of blog roll going again, but somehow I
doubt that everyone wants to download my RSS feed list when they visit
here.
Anyway, that's all.  Thanks for reading and sticking around as I get
things sorted and stitched back together in the offline world.  I hope
to come back with some nifty things soon, since I'm itching to hack.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/05/31/thanks-readers/"
          >187&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/05/31/thanks-readers/">#</a>
    <a class="time" href="2003/05/31/thanks-readers/">3:43 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 May 21</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/05/21/no-more-mr-rssify/">No More Mr. RSSify</a>
      </h2>
    
    <p class="summary">
      RSSify is a rather horrible hack that shouldn't be needed any more. Please ask the owner of the site you're reading (...) to change to a system that generates RSS natively such as Blogger Pro or Movable Type. Alternatively consider hosting RSSify yourself rather than using my bandwidth.


Source:22-May-03 Moving away from RSSify







Noticed this show up suddenly today as the new item to a surprising number of
feeds to which I subscribe.  I knew Julian Bond's public RSSifying service
had gotten used far and wide, but wow.  The bandwidth bills must've been getting
quite annoying, having become a sort of adhoc bit of the
Rube Goldberg blog
infrastructure.  So, as for my own consumption, thanks for the use of your tool Julian, and
all apologies for being a leech!
Well, I'm still working a bit on my own Java-based transmogrifier robot
to scrape disparate sources of info into RSS feeds for me.  I suppose I
should get to work trading my RSSify-based subscriptions for my own
DIY-scraped versions.  If I get some time soon, I'll wrap this thing
up and release it.  But first, I hope to get it fully automatedly working with the
iTunes Music Store, as I've been tinkering.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/05/21/no-more-mr-rssify/"
          >306&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/05/21/no-more-mr-rssify/">#</a>
    <a class="time" href="2003/05/21/no-more-mr-rssify/">9:06 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/05/21/web-services-book-thanks/">Programming Web Services with Perl</a>
      </h2>
    
    <p class="summary">
      A copy of Programming Web Services with Perl
surprised me yesterday by arriving on my doorstep.  I'd forgotten that back in March,
Paul Kulchenko
(one author
of the book's two) had offered me a free copy of it response to
a quick thought of mine about
a more Unix-like model for filtering web services (something I want to get back to).
Anyway, I've yet to get very much into the book, but a cursory skim tells me
that this looks like a great book.  Thank you very much for sending me a copy, Paul!
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/05/21/web-services-book-thanks/"
          >95&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/05/21/web-services-book-thanks/">#</a>
    <a class="time" href="2003/05/21/web-services-book-thanks/">10:34 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 May 19</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/05/19/mad-trackback-disease/">Mad Trackback Disease</a>
      </h2>
    
    <p class="summary">
      I've just started experimenting with integrating
Sam Ruby's autoping.py with my blogging
rig here, and discovered that I really had rushed things a bit and didn't
understand what the thing was doing.  I think my caffeine intake for today is
way below baseline, so if yours happens to be one of the sites I mistakenly
vandalized or spammed with broken or erroneous trackbacks, I apologize profusely!
Update:  Speaking of Trackback, I just duct taped an initial implementation on
the receiving end with a revision to my BlosxomDbcomments plugin.  It needs some testing,
so if you see this, and don't mind, pummel this entry with trackbacks!  Next, I'm
considering integrating referrers, thus bringing this new blogging rig up to
where I was a little over a year ago.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/05/19/mad-trackback-disease/"
          >416&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/05/19/mad-trackback-disease/">#</a>
    <a class="time" href="2003/05/19/mad-trackback-disease/">2:30 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/05/19/serval-whuffie-agg/">You&#39;ve Got Your Whuffie in My Aggregator!</a>
      </h2>
    
    <p class="summary">
      I've given the aggregator a concept of whuffie. I can give any item that has been aggregated a thumbs up or thumbs down, increasing or decreasing the item and site's wuffie. I sort the sites out as I display them by their whuffie. It is a simplistic way of keeping the sites I'm interested in at the top of the list. I'd like to wire in a Bayesian classifier too, and see if that helps me get the items I like to the top.


Source:Serval, an aggregator with Whuffie via matt.griffith







Yay, an aggregator with whuffie-tech!  This is very similar to what I was doing with
AmphetaOutlines for AmphetaDesk - when I click on an item from a channel, I increment
a counter for that channel.  And, when I sort channels for display, I use that count as
a factor in the sort.





And, of course, I want to use Bayesian filtering to see what I do want.
What would really be whuffie-riffic about aggregators that support this kind of
thumbs-up/down tracking, would be to have some P2P sharing of these decisions
to come up with something actually more like whuffie.  That is, I would like
to see how much right-handed whuffie some item has gotten, and possibly
bubblesort up or visually tag items I've yet to read based on that whuffie.
Right-handed whuffie being, of course, the accumulation of whuffie an item
has be given by authors to whom I've given lots of whuffie.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/05/19/serval-whuffie-agg/"
          >458&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/05/19/serval-whuffie-agg/">#</a>
    <a class="time" href="2003/05/19/serval-whuffie-agg/">1:02 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 May 16</h2>
  </li><li class="content-grid post post-type-entry has-thumb">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/05/16/matrix-phone/">The Matrix BrickPhone</a>
      </h2>
    <div class="thumb">
      <img src="http://www.samsungtelecom.com/matrix/images/home_phone.jpg" />
    </div>
    <p class="summary">
      Okay, no.  
This new Matrix-inspired phone is ugly as hell and not cool at all.  Do they actually use this thing in the movie?  I hope this isn't a sign for what the movie will be like -- clumsy, bulky, cartoonish and not at all subtle like the original.  See, the first movie had a phone.  I forget the model number, but I think it was a Nokia.  its sliding keypad cover was modified especially for the movie with a switchblade-springload action for extra cool factor.  And, unlike a lot of phones at the time, it was slick and sleek and tiny.
So what the hell is this thing?  It looks like a walkee-talkee for grade school kids, not the "ultimate conversation piece".
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/05/16/matrix-phone/"
          >942&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/05/16/matrix-phone/">#</a>
    <a class="time" href="2003/05/16/matrix-phone/">8:27 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 May 09</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/05/09/google-blog-clog/">Google Blog Clog?</a>
      </h2>
    
    <p class="summary">
      ...Personally, I'm getting SICK of running into my OWN BLOG while doing research into any of the topics that I've ranted about here. I spend a couple posts talking about a technology with questions or thoughts, then later I go to implement this tech and need specifics and yet 2 or 3 of the top ranks are filled with my annoying blather. Urgh!...


Source:Russell Beattie Notebook: Those who Live by Google...







Amen.  More and more, I'm running into myself on Google.  I'll be looking for expert information
on something I'm trying to tinker with, and discover that one of more of the top
search results are me writing about looking for expert information on the thing I'm
trying to tinker with.  Just occasionally do I find myself having actually provided
the information that I'm currently seeking.
I mean, it's not a gigantic shocker-- my interests are relatively stable over
time, and I circle back to things after long periods of time, so this is to
be expected I suppose.  But I'm starting to feel like I'm in a bad time travel
movie.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/05/09/google-blog-clog/"
          >317&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/05/09/google-blog-clog/">#</a>
    <a class="time" href="2003/05/09/google-blog-clog/">8:27 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 May 08</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/05/08/rssbayes-now/">Bayesian Filtering for what I DO want?</a>
      </h2>
    
    <p class="summary">
      I've never gotten much spam. I closely guard the email addresses I care about. Spamex makes it simple but I did it before without Spamex. My problem is information overload. I'm much more interested in seeing the same thing for RSS. Instead of blocking stuff I don't want I want it to highlight the stuff I might want. 



I've been out of the loop lately because I can't keep up with all of the feeds I would like to monitor. I need help.
Source:matt.griffith: Where is RSSBayes?







Ditto.  Using a Bayesian approach, or some other form of machine learning, as applied
to my aggregator and my viewing patterns is something I've been wanting for awhile now.
I've done some very, very primitive self-monitoring with AmphetaOutlines, but I'd
like to get back to some machine learning research and build an enhanced
aggregator that learns what makes me click.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/05/08/rssbayes-now/"
          >216&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/05/08/rssbayes-now/">#</a>
    <a class="time" href="2003/05/08/rssbayes-now/">10:47 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 May 07</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/05/07/itunes-rss/">iTunes Music Store RSS Feeds</a>
      </h2>
    
    <p class="summary">
      Yeah, I know I gave the iTMS a 'bah'
last week in response to discovering DRM under the hood.  But I've softened in
my opinion since then.  And bought a few more songs that I haven't heard in years.
And burned an Audio CD.  And wasn't too inconvenienced.  
My girlfriend and I almost
bought iPods last night, and though we resisted the temptation this time, I expect that
we'll end up with them before long.  And when that happens, I imagine we'll try sharing
tracks, and that doesn't seem to be too inconvenient either.  And then, there's the
fact that the iTMS seems to have a pretty nifty set of underpinnings that look like
fun to play with.
So now, like anything I'm interested in on the interweb, I want to swallow it up with my aggregator.
Thus, I attempt a new project:  ItunesMusicStoreToRss
Progress so far, but I've hit a stumbling block.  Anyone want to help?
Update: A little bit of cut & paste from the wiki page:
If you spy on iTunes while browsing to a "Just Added" section of a genre, you'll find that a URL like the following is accessed: 
(it's a long URL)
The response to that URL is some very interesting XML that looks like a GUI language.  Buried in the GUI recipe, however, is what I want flowing into my aggregator.  So, I dust off my XSL skills and have a go at mangling this content into RSS.  I seem to have been successful.  A test run appears to validate, and is accepted in my aggregator. 
The problem, though, lies in the aforementioned URL.  Everything seems pretty clear and straightforward, and I can change genre's by supplying discovered ID's to the id parameter.  However, the  "fcid=145690" parameter  is an unknown to me.  It seems to change, though I haven't yet investigated its derivation or how often it changes.  I was working on things yesterday, and the value was one thing, this morning it was another. If the number is not valid, unexpected results happen, sometimes resulting in HTML output describing an application exception.  So, until the fcid mystery is solved, I've yet to automate this transformation. 
Any ideas out there on the lazyweb?  Visit the wiki page (ItunesMusicStoreToRss) and feel free to poke fun at my XSL skills.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/05/07/itunes-rss/"
          >716&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/05/07/itunes-rss/">#</a>
    <a class="time" href="2003/05/07/itunes-rss/">5:21 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 April 30</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/04/30/strange-component-error/">Getting a Strange &quot;Component Manager&quot; Message Under OS X?</a>
      </h2>
    
    <p class="summary">
      Posting this just in case anyone needs it.  I've been getting the
following strange message lately in logs and consoles under OS X:
## Component Manager: attempting to find symbols in a component alias of type (regR/carP/x!bt)





As it turns out, I had just installed Toast.  A quick Google search
leads me to blame Toast and remove a QuickTime component supporting Video CD.
That's pretty obscure.  Hmph.  So much for never again worrying about strange drivers and
cryptic error messages under OS X.  :)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/04/30/strange-component-error/"
          >122&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/04/30/strange-component-error/">#</a>
    <a class="time" href="2003/04/30/strange-component-error/">2:22 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 April 29</h2>
  </li><li class="content-grid post post-type-entry has-thumb">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/04/29/itunes-does-drm/">iTunes Does Indeed Do DRM</a>
      </h2>
    <div class="thumb">
      <img src="http://www.scotlandsoftware.com/images/bah.png" />
    </div>
    <p class="summary">
      How unobservant am I?  It took 
an article from The Register
to make me realize that this new Apple music store does indeed
use DRM to lock up purchased music.  The files aren't mine.  (Though, whoopie, I'm 
allowed to use them on up to 3 computers.)
Crap.  No thanks.  I guess
that 10% of the catalog doesn't look quite so attractive at a buck-a-song now.
I mean, I've already destroyed one computer 
with a tumbler of water, why would
I want to lose all my music with the next one I douse?  And what happens in 10
years or so, when I want to listen to all those hypothetical Talking Heads
tunes I bought?  Of course, I'm still listening to CDs and tapes I acquired back
in junior high, and I don't need to query anyone's permission to do so.
I hereby bestow this award to the Apple Music Store:
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/04/29/itunes-does-drm/"
          >243&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/04/29/itunes-does-drm/">#</a>
    <a class="time" href="2003/04/29/itunes-does-drm/">7:10 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry has-thumb">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/04/29/isync-bookmarks-huh/">What is my iSync doing?</a>
      </h2>
    <div class="thumb">
      <img src="http://www.decafbad.com/downloads/isync-bookmarks.gif" />
    </div>
    <p class="summary">
      Umm...  what is iSync doing?  I didn't know that it had anything to do
with my bookmarks.  Lately I've been using bookmarks more since I started
using BookmarkBlogger.  Nearly every time I try dragging a bookmark into a
toolbar folder, though, I'm rebuffed by this dialog.  What gives?  The bookmarks
don't show up on my PDA, or my calendar.  With what are they being synched?



I see that Scot Hacker has
discovered the same thing happening to him.  Lots of comments, but still no
answer as to what's up with this.  Hmm.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/04/29/isync-bookmarks-huh/"
          >230&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/04/29/isync-bookmarks-huh/">#</a>
    <a class="time" href="2003/04/29/isync-bookmarks-huh/">4:24 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/04/29/rdf-tunes/">Indie Music Service (ala Apple)?</a>
      </h2>
    
    <p class="summary">
      Okay, so in between all the other hecticity currently ongoing in my life,
I managed to check out Apple's new music service.  Although I'm not interested
in approximately 90% of the music offered so far, that still leaves me with
2000 songs whose "buy" buttons call my name.  The process is simple, the files
are mine and not locked up with DRM, and although I hope and expect the price
structure to change (ie. maybe price based on popularity?), a dollar a song
isn't horrendous considering that I get what I want on demand and without 
hopping in the car and going anywhere.  So far, so good.
So...  This got me to thinking in the last 10 minutes:  What about an indie
clone of the Apple Music Service?  One using RDF or some other XML format to
offer up the catalogues of record labels?  Include all artists, albums, songs,
and any various and sundry bits of trivia about all the above.  Establish a
modular mechanism for specifying payment process (ie. paypal, credit card,
free, upload a song), and make the whole interface as slick and easy as
iTunes'.
The real trick I see in this, though, is to make the file format for music
vendors fairly easy yet flexible.  It should be as easy or easier than an
RSS feed for a blog.  Let a hundred of these mushrooms bloom, aggregate, 
search, and buy.  Make it distributed and not dependant on any particular
music company or technology company.
Not a terribly original idea, but that's what I just thought of.  Sounds
like a good semantic web app that could have some umph going for it in
the immediate future.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/04/29/rdf-tunes/"
          >366&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/04/29/rdf-tunes/">#</a>
    <a class="time" href="2003/04/29/rdf-tunes/">8:28 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 April 22</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/04/22/wonders-of-rsync/">rsync: It&#39;s a damn brilliant thing.</a>
      </h2>
    
    <p class="summary">
      I take rsync for granted.  It's just the best way to keep stuff out there
up to date with stuff over here, and vice versa.  And lately, I've been
using it to supplant my usage of scp.  And it works.  Brilliantly.  And until
recently, I hadn't stopped to realize:  Hey, you know, this thing somehow works
out differences between files out there and over here long before
what's here gets there.  I know, duh, but I just hadn't considered it.
Well,
Paul Holbrook reminded me
of this tonight, with links to Andrew Tridgell's
paper on the algorithm, among other things.  Damn, things like this remind me
that I'm supposed to be getting my butt back into school...
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/04/22/wonders-of-rsync/"
          >179&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/04/22/wonders-of-rsync/">#</a>
    <a class="time" href="2003/04/22/wonders-of-rsync/">11:00 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/04/22/flash-xml-magic/">Learning How to Do Magic with Flash and XML</a>
      </h2>
    
    <p class="summary">
      Was thinking about learning new tech, and well, I haven't gotten much
farther into .NET
as I'd wanted to,
given moving and a sudden appearance of work.  Instead, I've had
a project hurled at me that combines Flash MX and XML, something I've
just barely touched before.
Wow, is this stuff fun.  And I write that without a trace of sarcasm--
this app I've inherited for maintenance and extension, though it's a
bit grungy and shows some signs of late-night expediency, does some
neat things with actions and buttons dynamically wired up in response
to XML config files loaded via URL, which are in turn generated from a
database managed by a simple end-user admin interface.  Not sure how
much more I should write about it, but I'm dying to post a link.  Of
course, this isn't revolutionary stuff in general.  It's just a revelation
to me.
The last time I had an opportunity to really, really dig around in
Flash was just about when Flash 5 came out.  I was immersed daily in
Flash in the years between the initial acquisition by Macromedia, up
through version 4, and just started drifting away, sadly, when things
started getting really interesting with v5.  That was when my daily
job swung entirely into the backend, and client-side concerns were
no longer my task.
But now I'm back in this old neighborhood, and I can see why some
people would love nothing better but to build entire websites in
Flash.  Yeah, that's evil, but it's sexy.  Despite some clunkiness,
there are some very nice possibilities I see now.  I love Java, and
loved cobbling together funky applets 5 years or so ago, but Flash
makes me want to toy with rich client-side apps again.
And then, there's this
Sony Clie PEG-TG50
handheld I've recently started pining for, and it appears to run a
Flash 5 player.  It's probably underwhelming, but who knows?
Anyway, back to work, but just had to spill some enthusiasm for
Flash.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/04/22/flash-xml-magic/"
          >543&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/04/22/flash-xml-magic/">#</a>
    <a class="time" href="2003/04/22/flash-xml-magic/">12:22 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/04/22/shitstorms-abound-2/">Do NOT Taunt the Happy Fun Dave</a>
      </h2>
    
    <p class="summary">
      Mark Pilgrim asks: What's your Winer number?
I duck & cover under our new futon.  The one that I broke already, but it's better than nothing.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/04/22/shitstorms-abound-2/"
          >27&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/04/22/shitstorms-abound-2/">#</a>
    <a class="time" href="2003/04/22/shitstorms-abound-2/">1:28 am</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/04/22/shitstorms-abound/">Do Not Taunt Happy Fun Bloggers</a>
      </h2>
    
    <p class="summary">
      Wow.  Missed this from Mark over
the weekend, and then further missed Sam's link to it
and the subsequent whirling mass of shitstorm that rolled past in its wake.  Well, at least everyone 
just ends up being an asshole in the end, and no nazis or ethnicities 
or monsters were invoked in the process.  And no one co-opted any acronyms, though I think
someone got ketchup on their tie.  Hope it wasn't silk.  And does anyone know if all us assholes
are actually alive or dead in Schroedinger's Trunk?
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/04/22/shitstorms-abound/"
          >127&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/04/22/shitstorms-abound/">#</a>
    <a class="time" href="2003/04/22/shitstorms-abound/">1:09 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 April 21</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/04/21/down-and-out/">Further Bitchun Reading...</a>
      </h2>
    
    <p class="summary">
      Finally got around to reading Cory Doctorow's Down & Out in the Magic Kingdom,
and though I loved it, I wish it were longer.  Or, at least,
I'd love to see more stories from the same setting or playing with the
same themes of the Bitchun Society.  I have seen some of these things
in stories before, though.  So, hey, I haven't posted anything here in
a few days - have some babble and book links (feel free to comment and
leave some more links):
Of course I love the notion of ubiquitous computing and personal
HUD's.  I've babbled about that at length for sure.  If you want more
of that, go check out Vernor Vinge's
Fast Times at Fairmont High.
Mediated reality with P2P computing woven into clothing and projected
across contact lens displays.  A little less obtrusive than
seisure-inducing in-brain electronics, but just as post-human.
And then there's backup-and-restore and the cure for death.  Although
in David Brin's
Kiln People,
things start with disposable
doppelgangers, survival of personality after bodily death is promised
in the ending.  What could change human nature more than transcending
mortality?
As for deadheading, check out Vinge's
Across Realtime
series.  In
particular, read up on bobbling in Marooned in Realtime.  There's also
Orson Scott Card's The Worthing Saga.
A one-way trip into the far future
through geological periods of time seems particularly external to
known human experience, especially when combined with immortality.
One thing I've yet to see much in stories or speculations is how
society could function in a post-mortality and post-scarcity
conditions.  I've never been satisfied with the way Star Trek dodges
the day-to-day realities of a post-capitalistic Federation of plenty.
Walter Jon Williams' Aristoi
explores an interesting track with a
meritocratic society whose top members have godlike powers matched to
godlike creativity and self-possession (not to mention possession by
multiple selves).
But so far, Whuffie and its currency in reputation is the best game
I've seen yet.  Since, even if the problems of mortality and material
scarcity are solved, human attention and cooperation will never be
gratis.  So, how else do you herd the cats when you can neither
threaten nor reward them via any physical means?  Seems like the
blogosphere, gift culture, and open source noosphere brought to
reality.
Kinda makes me want to get back to fiction writing meself and finally
get out the dozen or so stories I've had bouncing around in my head
these past years.  Doesn't necessarily mean I'd churn out anything
good, but who knows?  Maybe after some work and some stumbling I could
produce something passable.  All those creative writing classes in
college and short stories in spiral-bound notebooks from high school
have to count for something.  I'd even love to squat in the Bitchun
Society for a few stories, but that might be a bit presumptuous, even though
Mr. Doctorow himself has let on
that he's not likely to write more
tales from the same Bitchun universe.
Better to get some practice in before jamming in someone else's club.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/04/21/down-and-out/"
          >703&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/04/21/down-and-out/">#</a>
    <a class="time" href="2003/04/21/down-and-out/">2:30 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 April 16</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/04/16/opml-vs-oml/">OPML vs OML - Fork but don&#39;t fight!</a>
      </h2>
    
    <p class="summary">
      In my intermittent online presence, I've been happily watching Dave Winer's
ramp-up with OPML toward OSCON with things like 
"How to implement an OPML directory browser".
I love outliners, and though it's been a little while since I played with Radio, I loved Instant Outlining
and the transclusion of outside outlines into the
one at hand via URL.  And when Dave first introduced the idea of an OPML-based distributed web directory,
I figured it was the start of another nifty twist in the web fabric.  (You know, the kind that makes wrinkles?
The kind of wrinkles that make brains smarter?)
Anyway, even given all this, OPML has always bugged me, and I'm not alone.  In fact, today I found a
link to OML, the Outline Markup Language project on ?SourceForge,
which seems to seek to address many of the same things that have bugged me.  That is, things like
UserLand application-specific tags, and extension via arbitrary attributes.  Though I'm no master
of deep XML magic, these things struck me as grungy.
But you know, we're designing for recombinant growth with the lazyweb here
(or at least, Dave Winer was and is), and OPML looks like one of those dirty things that got
thrown together quickly in order to enable a laundry list of further projects.  It works, isn't
all that hard to grasp, and has gotten adopted quickly.  There's momentum there.  As 
Dave says, there is no wait for
tools.
So, now there's also OML starting.  Hopefully this won't become another rehash of the RSS fight.Because, I sense many similar issues between the two.  Maybe it would have been better still if OML had been named something
completely avoiding the letters O, P, M, or L.  I already see mailing list charters being called out in order to quiet unwanted
discussion of fundamentals, but, hopefully we can avoid anyone claiming that they have the One True Format, all fighting for the
same name and slapping each other around with version numbers.  Gah.
Anyway.  I like OML but see some grunge in it as well.  At the moment, I'm using an OPML-supporting tool. I can't imagine that
conversion would be more than an XSLT file away.  Well, maybe more than that.  Beyond that, let's agree to disagree and viva le
fork.  Let the best, most demonstratably capable format win.  Meanwhile, I'm still considering that Tinderbox license to see if I
might like multi-dimensional outlining...
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/04/16/opml-vs-oml/"
          >741&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/04/16/opml-vs-oml/">#</a>
    <a class="time" href="2003/04/16/opml-vs-oml/">4:40 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 April 15</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/04/15/safari-tabs/">Safari has tabs now, but I&#39;ve changed my mind.</a>
      </h2>
    
    <p class="summary">
      So yeah, I wanted tabs in Safari.  Or something like tabs.
But since discovering that the "Window" menu in OS X is not painful to
use, and that CMD-Backquote rotates between open windows, I've not missed
tabs an incredible amount.  I think my tab usage was a response to my experience
with Windows and Linux window managers, though even those have changed since
I started using tabs in my browser.
However, I still love using pwm as
my window manager under X11, with its tab collections and windowshading.  Go
figure.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/04/15/safari-tabs/"
          >91&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/04/15/safari-tabs/">#</a>
    <a class="time" href="2003/04/15/safari-tabs/">10:36 am</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/04/15/still-breathing/">Still Alive Out Here</a>
      </h2>
    
    <p class="summary">
      Been out of touch with my usual online haunts as of late, and have barely had time to think straight,
let alone write. 
My girlfriend and I have moved just from one end of town to the other, and we have an overlapping
month of leases between the new place and old.  In theory, this is plenty of time to accomplish moving
and cleaning and decorating.  But, some things are hard to move gradually, especially when both she
and I have compact cars and trucks rent by the hour.  And then there's the fact that our new residence
is found on the third floor, providing much exercise to the both of us.  So, it's been a hectic couple
of weeks so far, though well worth it for us to start settling down in new and improved digs.
And then, right in the middle of things, I was offered an opportunity for a few months' work as a
contractor for a startup located almost (but not quite) within walking distance of the new apartment. 
So, I decided to snatch that up, and since then things have been doubly busy.  Whew.  This'll give me
some breathing room to figure out what's next, hopefully.
So anyway, here's hoping things settle down a bit and stop feeling like I've jumped the tracks.  After
getting life in general into some semblance of happy chaos, I hope to get a chance to catch up on
happenings and maybe even take a stab at some of my projects around here again.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/04/15/still-breathing/"
          >340&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/04/15/still-breathing/">#</a>
    <a class="time" href="2003/04/15/still-breathing/">10:36 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 March 26</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/03/26/arthurs-blogroll/">Arthur&#39;s got a bulging blogroll</a>
      </h2>
    
    <p class="summary">
      0xDECAFBAD (I love that name) has a new design, powered by Blosxom. I like it. You're going in my bulging blogroll, Les.


Source:Time is Tight: 0xDECAFBAD v2.0







My referrer monitoring scripts have been out of action since shortly
after I revised my site design, so I've been missing links.  Today, I
fired things up again for the first time since the beginning of the
months and caught the above.  Wow, and I'm an Elite Geek, at that!
Welcome to 0xDECAFBAD!  You can do anything at 0xDECAFBAD!  The
unattainable is unknown at 0xDECAFBAD!  Yes, this is 0xDECAFBAD, and
welcome to you who have come to 0xDECAFBAD!  Welcome!
(Please tell me someone out there knows what I'm going on about.)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/03/26/arthurs-blogroll/"
          >232&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/03/26/arthurs-blogroll/">#</a>
    <a class="time" href="2003/03/26/arthurs-blogroll/">6:01 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/03/26/a500-not-3g/">The A500 ain&#39;t 3G</a>
      </h2>
    
    <p class="summary">
      Sheesh. Okay, come back to us when you get a real phone.


Source:Mobitopia: Slashdot - Life in 3G







So says Mr. Beattie.  And I say, "Hey, that's my phone!"  And then I
say, "Oh yeah, that's right, that's my phone."  I like my phone, it's a
nice phone.  I had a Treo Communicator, but it went kaput.  I thought the
A500 would be a decent 3G device.  It's not.  But it's a nice phone...
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/03/26/a500-not-3g/"
          >75&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/03/26/a500-not-3g/">#</a>
    <a class="time" href="2003/03/26/a500-not-3g/">3:42 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/03/26/singularity-vs-human-nature/">The Singularity vs Human Nature</a>
      </h2>
    
    <p class="summary">
      Apologies in advance if this post-cum-essay runs a bit long...
We could conclude that modern human intelligence is an unfinished product, and something that nature hasn't quite got around to polishing yet. The problem-solving intelligence part can be tuned and revved up to high levels, but it becomes unstable like early supersonic jet prototypes that shook themselves to pieces just after reaching the sound barrier. Nature has outstripped itself, producing a freak organism with a feature that's obscenely over-developed but under-refined. We've seen examples of evolution getting ahead of itself before, like the rapid conversion to an erect, bipedal skeletal frame without properly modifying the spine to withstand the back-aching load of pregnancy. To get a better grip of human failings, and human stupidity, you have to realize that modern Homo sapiens sapiens just isn't done yet.


Source:Disenchanted: * Early prototype, expect instability




When our own instincts are inadequate, or become a hazard, and the surrogate activities to control them aren't sufficient anymore, then there certainly will be a push to change human nature to fit his new, self-crafted niche. And the answer to my original question?that man will invent something that knocks him out of his niche with fatal consequences?is yes. Homo sapien will die, and homo modified will inherit the earth.


Source:Disenchanted: Invent this and die







There's only an essay or two per month published over at Disenchanted,
but they're gems, each and every one.  And what I read almost never
fails to resonate with something I've been thinking or musing about,
from my perspective as a geek wondering about life, the universe, and
everything and as a fan of Kurzweil, Vinge, and all of post-humanity.
But my anticipation of the Singularity is constantly swayed by things
such as the theses of the above quoted essays.
See, as an irredeemable believer in the ways of better living through
technology, I look forward to our increasing ability to further
self-improve and bootstrap to higher levels of living, longevity,
ability, understanding, and exploration.  But, there's a neopagan
mystic and naturalist in me who keeps looking for the catch.  There
must be natural limits we don't yet understand.
No matter the precocious cleverness of our species, there's got to be
plenty of good reasons it takes millions of years to achieve progress
in forms and patterns of life.  There are lots of little subtle
details to be easily missed.  We're smart, but not yet endowed with
the patience and wisdom that eternity grants.  I both breathlessly
await and fear the arrival of our ability to fundamentally change
human nature directly through genetic manipulation and device
implantation.
As the first essay quoted above asserts, I believe the human species
is unfinished.  But as with the second essay, I think we've outpaced
evolution in terms of changing the conditions under which the process
itself occurs.
Just look around you.  You're likely indoors, in a building composed
of simple straight lines which register easily on your visual pattern
recognizers, with corridors and doorways and rooms proportioned to
your bodily dimensions.  The air is conditioned to your respiratory
and temperature tolerances.  Things are padded and accessible.  Food
and drink are likely plentiful.  The only predators you're likely to
meet up with during your day are of your own species.  Nothing really
challenges your basic nature.
Yet, this is just what the universe has been doing to forms of life
throughout the history of evolution.  Only now, we've jumped the
tracks, reversed the flow of control, and have reshaped our corner of
the universe to fit our status quo.  So, where does that leave the
natural process of evolution with regard to us?  Stopped or slowed to
a crawl, that's where.  Maybe falling backward, since we have
prosthetics, glasses, and other forms of propping up imperfections
that would have otherwise been faced with disincentives by natural
selection.
So, where are we without a natural evolution?  We're left as an
unfinished species, with a peculiar mix of awesome abilities matched
with amazing disabilities.  Very clever people, but with a lot of
blind spots.  There are certain ways in which it is very difficult and
sometimes nearly impossible for us to think.  We have biases toward
grouping things by similarity, dividing them by difference - which
allows for a very elegant economy of memory and thought, but allows
for peculiarly devastating things like racism and xenophobia.
Critical thinking is counterintuitive, yet is one of our most powerful
tools.
And there are definite flaws in our perceptions of reality, as any
book of optical illusions will tell you.  One thing that struck me
like a thunderbolt came from a human biology class: Ever try following
a common housefly with your eyes?  Isn't it frustrating how it just
seems to vanish from your sight?  I can't find a reference to back
me up, so this is just from memory: I was taught that flies have
developed a particularly zig-zaggy and erratic flight pattern to evade
just our kind of mammalian vision system.  But, studies of fly-eating
frogs have shown that their vision systems appear particularly tweaked
to react to a fly's midair dance.  Imagine what else slips past us, or
comes to our attention garbled because our very apparatus contains
biases of which we're yet to even conceive?
Here we are, then, flawed and incomplete yet with a growing ability to
self-modify.  As an amateur computer scientist, I shudder a bit at any
code that's self-modifying.  It can be done, and it can be powerfully
enabling, but it's just so damn easy to blow a foot off with the
technique.  So too with ourselves, then.  There's a possiblity that we
can push ourselves into a richer level of thought and perception and
ability without destroying ourselves completely.  But, we're going to
miss things, important things.
If we're lucky, we'll roll with it and survive.  But, as the second
Disenchanted essay explores, we'll most certainly render the species
as we know it extinct, and push ourselves our of a natural niche and
into a wholly artificial niche in need of perpetual maintenance and
renewal.  Maybe this artifical niche will be easily sustained and
portable enough to take with us if we want to leave the planet.  On
the other hand, maybe this artificial niche will prove our undoing as
it outstrips our ability to keep it up.
So, given all this, I think the inevitable predicted verticality of
the Singularity's curve has an incredibly strong counter-force
stemming from human nature itself.  What does this mean?  Not sure.
What to do?  Not sure.  But it tells me that the Kurzweilan and
Vingian predictions of which I'm so fond face some severe reality
checks.
More thinking to do.  Thanks to Disenchanted for making me think this
far today.  :)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/03/26/singularity-vs-human-nature/"
          >1507&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/03/26/singularity-vs-human-nature/">#</a>
    <a class="time" href="2003/03/26/singularity-vs-human-nature/">12:32 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 March 25</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/03/25/i-want-a-gp32/">I want to trade my Gameboy Advance for a GP32.</a>
      </h2>
    
    <p class="summary">
      It comes out the box with an English manual, a PC link cable, the GP32
uses PC smartMedia as its Hard disk and has 8meg of internal ram + its
(upgradeable) OS, a USB port, a large hires screen (which is SO much
better than the GBA one), two stereo speakers (one on each side), a
joypad and 6 buttons (4 on front and 2 shoulder buttons), a 3v in
socket, a headphone socket, volume control, battery compartment (2xAA
for 10-14 hours) & an EXT out port which allows you to do many things
including using the gp32 on your TV or for wireless multiplayer.
...The console is open source and fully supports people making their
own programs for it, there is a GCC based devkit complete with
graphics and sound libs.



Source:GBAx.com review of the GP32







Just read a review of the GP32,
a handheld game console I'd never heard of before.
Pictures of it look amazing,
and the specs aren't too shabby either.  Powerful enough to run
emulators of a sickening array of game platforms, uses ?SmartMedia
cards, support wireless multiplayer via cell phone.  And, oh yeah, it
looks like you can actually see the screen.
The biggest flaw I see in this thing is that it would be so easy to
pirate games for it.  Supposedly there were some attempts to provide
for a mechanism to "lock" games to a particular handheld, but that
appears to already have been circumvented.  So, while the thing looks
like a dream machine to me, it probably looks like a nightmare to game
producers.
Still, though, I want one.  And I bet Russell Beattie wouldn't mind
one either, if he hasn't heard about it yet, given his
professed love for his GameBoy Advance.
And, speaking of Russell, I wonder just how well that wireless
multiplayer support works...
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/03/25/i-want-a-gp32/"
          >307&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/03/25/i-want-a-gp32/">#</a>
    <a class="time" href="2003/03/25/i-want-a-gp32/">4:59 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 March 24</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/03/24/new-bookmark-blogger/">New release of BookmarkBlogger available</a>
      </h2>
    
    <p class="summary">
      Playing with a few other little widgets here and there, I thought I'd 
fire off a new revision to the BookmarkBlogger for Safari I've been using
off and on.  This one's a big more OS-X-ish, and uses a properties file
for configuration instead of completely confusing command line options.
ShareAndEnjoy!  
Also working on a lil DOM4J-, JTidy-, and ?BeanShell-based scraper
for producing RSS from arbitrary web sites.  Yeah, it's been done before,
but not by me and not quite like this.  And eventually I think I want to 
try turning both this and the BookmarkBlogger into dual-purpose standalone
and AgentFrank plugin packages.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/03/24/new-bookmark-blogger/"
          >132&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/03/24/new-bookmark-blogger/">#</a>
    <a class="time" href="2003/03/24/new-bookmark-blogger/">3:29 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 March 17</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/03/17/dot-net-newbie/">.NET Newbie</a>
      </h2>
    
    <p class="summary">
      So, while my time is mine, I've decided that I want to expand my
practical horizons.  And, one of the first things I can think of is to
go lateral and approach something I've looked upon with mild disdain:
Microsoft technologies.  In particular: .NET
I already understand Unix well enough to do damn near anything -- this
is not to say that there aren't still years worth of things left for
me to learn in that sphere, but I'm not nearly as adept with
Microsoft's offerings.  And, besides the practical concerns with being
flexible enough to take on what work the world offers me, I also have
a hunch that this .NET thing will make me think as differently about
Microsoft as OS X made me change my mind about Apple.
Maybe.  But it's still a good attitude with which a punk unixhead can
approach the subject, I think.  I'm going to assume that brighter
people than myself have applied themselves to the creation of .NET and
prepare to be surprised.  This attitude has always served me well in
the past when trying something new.  (Take Python, for instance.)
Okay.  Got a good attitude.  Have installations of WinXP and Win2003
preview (which I'm kinda, grudgingly digging so far) running in
Virtual PC on my ?PowerBook.  Could even draft a PC at home into
service running an appropriate OS if need be.  Have downloaded the
.NET Framework and installed it on XP and Win2k3.
Now what?  Were this Java, I'd pop open an emacs window and start
playing.  I'd grab some free app servers and check some things out.
Being on a fixed budget, I don't think I can spring for any packages
like Visual Studio .NET.  And being a unixhead, I'm used to being able
to find dev tools for free.
Anyway, this absolute newbie is continuing to poke around.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/03/17/dot-net-newbie/"
          >1204&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/03/17/dot-net-newbie/">#</a>
    <a class="time" href="2003/03/17/dot-net-newbie/">2:20 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/03/17/no-more-searchling/">No More Searchling?</a>
      </h2>
    
    <p class="summary">
      So, as I'm working to recover all the old tools I knew and loved on my
iBook, I see this on the
Searchling home page:
Work on Searchling has ceased to focus on its successor
-- iSeek.


...and there are no downloads for searchling available, neither binary
nor source.  Harumph!  
And the screenshots of iSeek don't please me much -- I see a search
field wodged into the menu bar in place of the nice, slick ghostly
search field that would materialize with a quick Cmd-Space or a click
of the magnifying glass.  Gagh.  My menu bar's already crowded enough
with menu entries on this 12" screen as it is.
But, if I'm completely wrong, and there ends up being a feature to
make iSeek work and feel just like my old friend the Searchling...
well, then I say congratulations to its author for cobbling together a
saleable lil widget, and I'll be waiting impatiently for its release.
:)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/03/17/no-more-searchling/"
          >237&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/03/17/no-more-searchling/">#</a>
    <a class="time" href="2003/03/17/no-more-searchling/">1:40 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/03/17/blosxom-paginate/">Pagination for Blosxom</a>
      </h2>
    
    <p class="summary">
      Here's a little something I whipped up last week:  BlosxomPaginate.
I've been using Blosxom and Blagg for my news aggregator lately, just
for a change, and one thing I was really missing was some way to see
entries that fell off the end of the front page.  
So, I made this.  It
lets me flip back and forth between pages of Blosxom entries, and I
even went so wild as to include full flavour-based template support of
the display of the navigation elements.
ShareAndEnjoy
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/03/17/blosxom-paginate/"
          >342&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/03/17/blosxom-paginate/">#</a>
    <a class="time" href="2003/03/17/blosxom-paginate/">11:12 am</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/03/17/first-week-off/">Happy Trails to Me, I&#39;m Job-Free: Week One</a>
      </h2>
    
    <p class="summary">
      I hadn't written much last week, between the job search and getting
myself hooked up with a new laptop.  I'd meant to revise my initial
post announcing my being laid of - but instead, I simply lost it
when the iBook got doused.
So, to those of you who haven't heard my news: I was laid off a little
over a week and a weekend ago.  No hard feelings or fireworks, just
typical bad economy reasons.  Nevertheless, it took me by surprise.
So now I'm shopping my resume around.
If you're interested, my resume is available here:

 http://www.decafbad.com/2003/03/l-m-orchard-resume.doc

 http://www.decafbad.com/2003/03/l-m-orchard-resume.pdf







Last week was strange.  Having been let go on a Friday, I had a
weekend to pretend things were all as usual.  But, when Monday hit,
things were different.  I still got up at the usual time, did the
usual morning things, and got out of the apartment as if I were going
to work.  But instead of heading for the highway, I headed for a
coffee shop
near campus with wireless internet.  Trying to keep the old
patterns as normal as possible, only now my job is finding a job and
getting myself in shape for what's out there.
It wouldn't be news to anyone to hear that the job market, at least
what I've seen of it so far, is nothing like the verdant plains and
valleys of even 3 years ago - which is about the last time I took a
serious look.  After a first survey of a few job boards online, I
fired off a handful of resumes and apps, and took notes on what's
being asked for so as to prepare some semblance of a learning plan
while I'm off.
So by the end of last week, I'd accomplished these various and sundry
things:

 5 cups of coffee consumed per day

 1 resume updated and revised

 6 resumes emailed and 4 online applications filled

 5 profiles completed at online recruiting sites

 1 application for unemployment filed

 1 12" G4 ?PowerBook acquired and configured

 3 Microsoft operating systems installed and configured under Virtual PC

 1 .NET Framework installed and exploration begun

 1 novel finished, Close to the Machine by Ellen Ullman

 6 hours of Metroid Prime played




There's been more, but it's the amount of Metroid Prime play I'm most
proud of - had I not gotten out of the apartment in the morning, the
hours invested in that would have been immensely greater.  Maybe after
I've fired off a few more resumes, I'll feel better about actually
taking a rest since my brane's been going full speed for months now at
work.
Thought a bit about striking out on my own with freelance work, but
the Ellen Ullman book has given me a bit of a strange mood.  She makes
working for oneself sound both promising and desolate at once - though
the promising bits would seem to be the things that disappeared with
the 90's.  So that leaves it sounding pretty unpalatable.  Who knows,
though - I always wanted to work from (but not at) a coffee shop.  
Well, back to searching and my first baby steps with .NET - wish me
luck.  And if you happen to be in town, stop by and say haloo.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/03/17/first-week-off/"
          >812&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/03/17/first-week-off/">#</a>
    <a class="time" href="2003/03/17/first-week-off/">8:57 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 March 11</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/03/11/thirsty-ibook/">iBooks Don&#39;t Get Thirsty</a>
      </h2>
    
    <p class="summary">
      Just for future reference:  No matter what your cats think, iBooks 
never get thirsty for a nice big tumbler of water.  Nor do they
ever have a need to soak in the contents of said tumbler overnight.
Although now, I have an expensive, dead laptop that makes white
noise sounds not unlike the ocean when it's plugged in.  And it 
smells like the magic blue smoke when it's let out of the chip.
I just hope that the hard drive is recoverable.  Updates will be
sporadic as I try to reconstruct my environment and remember passwords
and try to find serial numbers.
Oh yeah, and still on the trail of the job hunt.  Going to be
tweaking some things around here as I have time, to make things
a bit more presentable for company.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/03/11/thirsty-ibook/"
          >552&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/03/11/thirsty-ibook/">#</a>
    <a class="time" href="2003/03/11/thirsty-ibook/">9:25 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 March 09</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/03/09/ping-pong/">Ping Pong to Weblogs Dot Com</a>
      </h2>
    
    <p class="summary">
      Simon Willison writes
that he'd read my blog more if I
pinged weblogs.com
more often.  I used to, via MovableType, but my new blog doesn't.  Enter
ping_weblogs_com,
a Blosxom plugin to ping weblogs.com.  I've
just installed it.
Let's see if he notices.  :)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/03/09/ping-pong/"
          >182&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/03/09/ping-pong/">#</a>
    <a class="time" href="2003/03/09/ping-pong/">8:27 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 March 06</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/03/06/web-service-pipelines/">Building Pipelines with Web Services</a>
      </h2>
    
    <p class="summary">
      So on this day last year,
I was excitely thinking about pipelining webservices together like commands in a
UNIX command line shell.  Lately, I've been doing quite a bit of work at the
command line level, more so than I ever have before.  And for all the clunkiness
and inelegances to be found there, I think the zen has stuck me.
Sure, it's an ass-ugly string of characters that connects commands
like find, sort, awk, sed, grep, and ssh together.  But, in constructing such
monstrosities, I find myself generating new disposable tools at a rate
of at least one every minute or so.  And, though a few have found themselves graduating
into fuller, cleaner, more general tools, I would have been stuck for
hours were it not for a quick multi-file grep across a vast plain of comma-separated
value files digested by a tag team of sed and awk.  Then, like magic, I toss in
an incredibly slow yet, at the time, convenient call to mysql on another server
behind a firewall via ssh with a SQL call constructed from the regurgitations
of said sed and awk brothers.
So, I'm thinking again:  How hot would this be if it were web services replacing
each of my commands?  How hot would it be if there was a STDIN, STDOUT, and STDERR
for a whole class of web services?  Imagine an enhanced bash or zsh piping these
beasts together.  For awhile, I thought my XmlRpcFilteringPipe API was the way to
go, but lately I've been thinking more in the direction of REST.  I have to admit
that the XML-RPC API is a bit clunky to use, and besides, no one's really paid
it much notice besides using it in the peculiar fashion I do to make my WeblogWithWiki.
How about this for a simpler API:  Post data to a URL, receive data in response.
There's your STDIN and STDOUT.  What about STDERR?  Well, I suppose it's an
either-or affair, but standard HTTP header error codes can fill in there.  What
about command line arguments?  Use query parameters on the URL to which you're
posting.  This all seems very web-natural.
Now I just have to write a shell that treats URLs as executable commands.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/03/06/web-service-pipelines/"
          >725&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/03/06/web-service-pipelines/">#</a>
    <a class="time" href="2003/03/06/web-service-pipelines/">12:39 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/03/06/throwable-phone/">Did I dream the urchin phone?</a>
      </h2>
    
    <p class="summary">
      Okay, I don't think I made this up:  I was reading Wired Magazine a
few months ago, and I saw a phone featured in the Fetish section
that was designed like a KooshTM ball or a sea-urchin.
The idea is that it would be used in a teleconference, thrown back
and forth across the room from speaker to speaker.
We need this at my work.
Has anyone else seen this thing, remember what it was called, or
where they're selling it?  I can't seem to find it again in any of
the Wired issues I can find in my apartment and office.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/03/06/throwable-phone/"
          >203&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/03/06/throwable-phone/">#</a>
    <a class="time" href="2003/03/06/throwable-phone/">12:21 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 March 05</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/03/05/bad-apple-no-battery/">Bad Apple, No Battery</a>
      </h2>
    
    <p class="summary">
      So, sometime around last November, my iBook started having battery 
problems.  It went from 3 hours of life, down to an hour, and finally
down to about 15 minutes' worth of life.  Being lazy and busy, and 
having my iBook mostly at desks near outlets, I put off taking it into
the shop -- I'd just taken it there to replace the hard drive, and I
didn't feel like parting with it again.  Stupid, I know.  Lazy, I know.
Well, since then, the problem hasn't gotten better, and I was just about 
to get off my ass to do something about it when I see this:
MacNN: iBook users experience 10.2.4 battery bug
So after browsing around forums a bit, I learned how to reset my Power Management Unit,
did so, and discovered that the battery began to charge again.  I left 
the iBook off and watched the 4 LEDs on the battery gradually light up
over a bit of time while working on my desktop.  Looks like the problem's
solved for now.
Ugh.  I'm glad, at least, that it wasn't a physically dead battery.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/03/05/bad-apple-no-battery/"
          >206&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/03/05/bad-apple-no-battery/">#</a>
    <a class="time" href="2003/03/05/bad-apple-no-battery/">12:56 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 March 04</h2>
  </li><li class="content-grid post post-type-entry has-thumb">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/03/04/feeling-lucky/">Oh, I&#39;m feeling lucky.</a>
      </h2>
    <div class="thumb">
      <img src="/blog.lmorchard.com/blog-images/lucky-sm.jpg" />
    </div>
    <p class="summary">
      Oh yeah, and a giggle for me today:  

 Go to Google.  

 Enter "I'm Feeling Lucky".  

 Click "I'm Feeling Lucky".  




What do you see?  If you're seeing what I'm seeing, it's this very site!Now, I'm not sure how long this will last, or whether it means someone at
Google H.Q. loves me, but it's pretty dern nifty.
Thanks to Nathan Steiner of web-graphics.com for the tip!
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/03/04/feeling-lucky/"
          >439&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/03/04/feeling-lucky/">#</a>
    <a class="time" href="2003/03/04/feeling-lucky/">10:18 am</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/03/04/some-turbluence/">Heading through some turbulence, folks.</a>
      </h2>
    
    <p class="summary">
      Thanks for bearing with me out there in the blogopshere.  This transition, though
smoother going than I'd thought, is still exposing some rough spots and things
I hadn't thought to check.  Seems my RSS feed hasn't come through quite as intact
as I'd hoped -- and an unexpected bug in the rss10 plugin for ?Blosxom seems
to have caused some news aggregators to implode.  Apologies all around!
But, I'm watching, and tweaking, and will be shortly reporting all that I've done
around here to change things.  I'll be cleaning up and releasing my small pile of
blosxom plugins and patches, once I have a bit more time to do so.  In the meantime,
I've got an error log rolling in one window, and I'm keeping an eye on comments and
email.  Hopefully all this will be nice and smooth before the end of the week.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/03/04/some-turbluence/"
          >151&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/03/04/some-turbluence/">#</a>
    <a class="time" href="2003/03/04/some-turbluence/">10:02 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 March 01</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/03/01/oooooa/">Welcome to 0xDECAFBAD v2.0</a>
      </h2>
    
    <p class="summary">
      Not much to see here yet, but I've burnt down my old weblog and
replaced it with this.  Planning to start out simple and gradually
re-introduce features from the previous incarnation very slowly and
carefully.  I've enjoyed many of the toys I've piled on top of this
blog, but its time to revise and simplify.
I've also been thinking of expanding the focus around here a bit: Up
until now, this place has just been the home of my nerdy brane dumps.
But, I'd like to entertain the notion of opening the place up to more
of my writing.  Assuming, that is, that I can reacquaint myself with
certain muses and notions of free time and management thereof.
I really appreciate every reader of this site, though, so I've tried
to minimize the impact of changes.  Broken links are bad.  Links to
individual blog entries from the old site should redirect themselves
to their newly converted counterparts.  And, no matter what new trash
I start publishing here, the old RSS feed will continue to show mostly
nerdy brane dumps.  Should you want to follow any expanded content I
start to spew here, you'll need to update your links and
subscriptions.  It's up to you.
Anyway, thanks for reading, bear with me, and wish me luck.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/03/01/oooooa/"
          >299&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/03/01/oooooa/">#</a>
    <a class="time" href="2003/03/01/oooooa/">8:27 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 February 20</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/02/20/ooodae/">Stop using numbers in your IP addresses.</a>
      </h2>
    
    <p class="summary">
      By the way, Namber DNS at mysteryrobot.com (found via DiaWebLog) is damn nifty.  As I understand it, it works from a set of 256 very short and simple words.  Assemble four of these, and you can represent any IP address.  Seems like this would make for very easily remembered IP addresses, as well as fairly simple to recite over the phone.
For example: decafbad.com is sing.far.dry.today.mysteryrobot.com
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/02/20/ooodae/"
          >294&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/02/20/ooodae/">#</a>
    <a class="time" href="2003/02/20/ooodae/">12:46 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/02/20/ooodad/">Still here, still reading.</a>
      </h2>
    
    <p class="summary">
      Whew.  Still really busy.  Times like these, I wish I had my Blosxom and link-blogger action going, because I'm still out here, grazing on the links everyone else is publishing.  I haven't had much energy to write much while wrapping up this work project and getting AgentFrank lumbering about.  And there hasn't been much I've wanted to say that others haven't said.  So, at least nodding my head by echoing some links would make me feel like I'm still making some useful noise.
Maybe I'll have time for that burn down and rebuild next month.  :)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/02/20/ooodad/"
          >104&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/02/20/ooodad/">#</a>
    <a class="time" href="2003/02/20/ooodad/">12:35 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 February 17</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/02/17/ooodac/">Agent Frank isn&#39;t the only one.</a>
      </h2>
    
    <p class="summary">
      Oh, and I completely forgot to toss a link his way, but Kevin Smith of electricanvil.com is working on a Java PersonalWebProxy project also.  With AgentFrank, I've been leaning toward patching the core together as quickly as possible to enable the plugins and scripting I wanted to play with.  But it looks like Kevin's spending more time carefully architecting the core using Jakarta Phoenix & some homebrew proxy work.  Would be nice to borrow from his work soon.
Who else has code out there that could be assimilated? :)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/02/17/ooodac/"
          >218&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/02/17/ooodac/">#</a>
    <a class="time" href="2003/02/17/ooodac/">5:10 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 February 15</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/02/15/ooodab/">Agent Frank&#39;s first download?</a>
      </h2>
    
    <p class="summary">
      Les has been very quiet lately, but that's because he's been heads down working on his Personal Proxy he's dubbed "Agent Frank" (it's got a little logo and everything). He just set up an Agent Frank ?WikiPage with download and install instructions. 
I'm downloading now (it's pretty huge - like 11 megs), but the Wiki page has lots of good info, including Les' new acronym, PIIC. ... Very cool. I'm going to start playing right now. 


...
Later... Urgh! It's GPLed! Bleh! 
Source:The UPP Lives: OxDECAFBAD Launches Agent Frank .




So Russell noticed my late night release of AgentFrank.  Cool!  Hope it actually works for him.
Currently it's very big, because it's got everything in it, all the JARs and the kitchen sink from everything I thought I'd start using at some point.  My actual original code is likely less than 100k so far, if that.  Suggestions are more than welcome.  
The same goes for the license - all I want out of this thing is to share it and get interested tinkerers tinkering.  It'd be nice if anyone who tinkers with it gets credit for said tinkering, but that's about all I care about.  Hell, if it gets incorporated into a commercial product, I'd like some credit, and some cash would be nice, but otherwise I'd just be flattered.  Is there a license to cover that?  Maybe I should research a ShareAndEnjoy license.
This first code dump is very much premature - I'm not even pretending that this deserves a version number.  It's more a conversation piece and an a tangible starting point to play with things I've been thinking.  It's 99% crap code that apparently works, at this point.  I fully expect it to get rewritten before it rates a version number.
So... have at it.  Play with it, make fun of it, send me patches and abuse.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/02/15/ooodab/"
          >1343&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/02/15/ooodab/">#</a>
    <a class="time" href="2003/02/15/ooodab/">4:29 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry has-thumb">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/02/15/ooodaa/">Say hello to Agent Frank</a>
      </h2>
    <div class="thumb">
      <img src="http://www.decafbad.com/downloads/frankHeader.gif" />
    </div>
    <p class="summary">
      I've been quiet - too quiet.  Work's had me busy again, as has life in general.  But I still have had something in the PersonalWebProxy works:






It's ugly, but it works and does stuff.  And I was feeling pretentious enough to give it a quick logo and a wiki page.  Enjoy!
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/02/15/ooodaa/"
          >116&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/02/15/ooodaa/">#</a>
    <a class="time" href="2003/02/15/ooodaa/">4:26 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 February 05</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/02/05/ooodao/">On the road to a rebuild</a>
      </h2>
    
    <p class="summary">
      Of course, along with changes I want to make around here, one of the first is the design.  Thinking I might follow in Mark Pilgrim's steps a bit, and just strip the thing down to essentials and then more carefully consider what I slap back on the thing.  I've been meaning to pay more attention to his accessibility work for awhile now, among other things.
I'm also thinking of ditching Movable Type for pyblosxom - since although I want to tear down the hierarchical filesystem, there still are a load of decades-old tools that I know and love under UNIX to manipulate directories and text files.  That, and the MT-to-blosxom converter that came with pyblosxom, along with some tweaks to the genericwiki preformatter, seems to have brought nearly all of my entries across without harm.  I'll just have to work out some way to redirect requests for "old" URLs to the new content.
Of course, after that, I'll have to reconstruct my comments and trackback system, among other things...  might be fun though.
Oh, and a PS to Wari Wahab of pyblosxom:  It works just fine on my iBook, and I plan to use it to preview my entries before they get rsync'd up to my decafbad.com server.  :)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/02/05/ooodao/"
          >357&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/02/05/ooodao/">#</a>
    <a class="time" href="2003/02/05/ooodao/">5:45 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/02/05/ooodoi/">Now with SimpleComments!</a>
      </h2>
    
    <p class="summary">
      Now using Kalsey's SimpleComments MT plugin.  Planning to integrate referrers into it at some point, also, along with an easy yea/nay interface via email or Jabber to ask me whether I want to allow a new referrer to be published or not.  Having had my site used to advertise adult movies and anal sex this week was not appreciated.
This blog's first birthday is coming up, and though I doubt I'll have time, I've got a few things I'd like to renovate around here...
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/02/05/ooodoi/"
          >157&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/02/05/ooodoi/">#</a>
    <a class="time" href="2003/02/05/ooodoi/">1:11 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 February 04</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/02/04/ooodoh/">Bookmark blogging from Safari via a quick hack</a>
      </h2>
    
    <p class="summary">
      Well, it doesn't look like I'm getting the new Java-based PersonalWebProxy code released last week or soon this week, but if you'd like something to poke fun at, try this...
BookmarkBlogger - a quick hack for Safari users to generate blog entries from bookmark folders.
Hope it's useful, bet it's ugly, but it was fun in the making.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/02/04/ooodoh/"
          >321&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/02/04/ooodoh/">#</a>
    <a class="time" href="2003/02/04/ooodoh/">9:12 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/02/04/ooodog/">Perl and Bean Scripting Framework?</a>
      </h2>
    
    <p class="summary">
      So... has anyone gotten to making a Perl engine for the Bean Scripting Framework?  I can't seem to find a decent archive of the dev mailing lists, and the links from the Jakarta home page are broken.  And, of course, Google doesn't help me much except to point me at all sorts of pages saying that BSF supports scripting languages "like Python and Perl", but without actually showing me the Perl money.
Well, if not, I have a horribly hackish and inefficient idea that might just work, involving either pipes or sockets to external perl daemons and extreme abuse of perl's AUTOLOAD and Java's reflection to build proxy objects.  Yeah, yeah, someone could maybe embed Perl in a JNI-ish thing, but I'm not at the level of wizardry to be mucking about with Perl guts - nor do I want to be.  But, I think this idea of mine just might work.
Why bother?  Because it's depraved and possibly very fun.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/02/04/ooodog/"
          >162&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/02/04/ooodog/">#</a>
    <a class="time" href="2003/02/04/ooodog/">3:13 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 February 03</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/02/03/ooodof/">Unplugging to find a clock again?</a>
      </h2>
    
    <p class="summary">
      Mark Pilgrim is going to unplug for awhile.
Sounds like he's been going through the same woods I trudged through recently, or at least some paths in the same thorny forest.  But, it sounds like he's gotten himself even more inextricably bound up in ties to work then me - so much so that he really needs to unplug even from personal net presence to escape.  Not just to avoid falling to some abstract sheep-farming burn out, but to avoid the immediate reach of The Client.
So, not that I want to assume to much about you and me, but I think many of us are passionate about the things we're lucky enough to get paid to do - so much so that many of us do work-like things for play.  And oftimes, actual work spills into play/personal time.  Sometimes it's heroism, sometimes it starts as fun, but eventually, as Mark also recently observed, there remains no demarcation.  No amount of human passion or personal love for work can survive when the demands of work inevitably grow to consume all available bandwidth.  And y'know, no amount of human sanity can stand for long when one's capacity for effort is described as 'bandwidth'.
Bah.  So how do you strike the balance, and where do you dig in?  How many do you take for the team, and how many times do you shrug it off at five?  The one thing that I saw as positive in the crash of the dot-com age was an anticipation of life-at-net-speed slowing down to something a bit more human, no longer powered by insane sums of money and crack-monkeys of hype.  Are we getting there yet?
Good luck, Mark.  I recommend trips to the zoo, and close observation of cats.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/02/03/ooodof/"
          >329&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/02/03/ooodof/">#</a>
    <a class="time" href="2003/02/03/ooodof/">3:39 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 January 31</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/31/ooodoe/">An end to my referrer abuse</a>
      </h2>
    
    <p class="summary">
      Amen. I’ve always found it irritating that news aggregators insert their URL into the referrer field. ... It would be nice if there was some sort of browser header the aggregator could send to identify itself instead of using the referrer field. Oh, that’s right, there is. It’s called User-Agent. 
The user agent field is designed for browsers, robots, and other user agents to identify themselves to the Web server. You can even add additional information, like a contact URL or email address. I’d like to see aggregators start using it. 




Source:Kalsey Consulting Group: Referral Abuse.




Hmm, being mostly a standards neophyte, I thought this was a great idea, you know, NeatLikeDigitalWatches.  I thought this was more a semi-clever overloading of the referer, rather than outright abuse.  And this, I thought, was reasonably okay since there wasn't, I thought, anywhere else to stick a backlink to myself while consuming RSS feeds.
Well, yeah, now that I read some of the complaints against this use of referers, I agree.  And, yes, now that I read the fine RFC, I see that the User-Agent string is more appropriate for this purpose.
So!  From now on, hits from my copy of AmphetaDesk will leave behind a User-Agent string similar to this:
"AmphetaDesk/0.93 (darwin; http: //www.disobey.com/amphetadesk/; http: //www.decafbad.com/thanks-for-feeding-me.phtml)"
I tack my own personal thanks URL onto the end of the list within the parenthesis.  In addition, I no longer send a referrer string when I download RSS feeds.  How did I do it?  Very simply.
First, I modify my AmphetaDesk/data/mySettings.xml file by hand to supply a blank referer and a new user URL (having some angle-bracket problems, bear with me):


[user]
    ... 
    [http_referer][/http_referer]
    [user_url]http://www.decafbad.com/thanks-for-feeding-me.phtml[/user_url]
    ...
[/user]




Second, I modified AmphetaDesk/lib/AmphetaDesk/Settings.pm to account for the new setting:...
   $SETTINGS{user_http_referer}               = "http://www.disobey.com/amphetadesk/";
   $SETTINGS{user_user_url}                   = "http://www.disobey.com/amphetadesk/";
   $SETTINGS{user_link_target}                = "_blank";
...
Third, I modified the create_ua() subroutine in AmphetaDesk/lib/AmphetaDesk/WWW.pm to actually use the new setting:
sub create_ua {
...
    my $ua = new LWP::UserAgent; $ua->env_proxy();
    $ua->timeout(get_setting("user_request_timeout"));
    my ($app_v, $app_u, $app_o, $user_u) = (get_setting("app_version"),
            get_setting("app_url"), get_setting("app_os"), get_setting("user_user_url"));
    $ua->agent("AmphetaDesk/$app_v ($app_o; $app_u; $user_u)");
...
}

And voila - no more referer abuse.  If you want to discover my thank-you message, examine the User-Agent string.  Seems like this would be a good idea for all news aggregators to pick up.  And if I get ambitious and have spare time today, I'll be sending off a patch to Morbus & friends later today.
Update: Gagh!  This has been the hardest post to try to format correctly within the fancy schmancy auto-formatting widgets I have piped together.  All apologies for content resembling garbage.  I think I'll use this excuse in the future whenever I write something completely daft.  (Which means I'll be using it a lot, most likely.)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/31/ooodoe/"
          >1145&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/31/ooodoe/">#</a>
    <a class="time" href="2003/01/31/ooodoe/">2:50 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 January 30</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/30/ooodod/">INN + blagg + plugin = News Aggregation via NNTP</a>
      </h2>
    
    <p class="summary">
      I couldn't resist a bit of tinkering with NNTP, partly to follow up a little bit myself on RSS to/via NNTP, but mostly in fact to re-acquaint myself with the wonderfully arcane configuration of the  majestic beast that is inn . In addition, there's been talk recently of aggregators moving out of the realms of satellite applications and into the browser itself. The Blagg and Blosxom powered Morning Reading page - my personal (but open) news aggregator - is already web-based, so I thought I'd have a look in the other direction. 

Source:DJ's Weblog: Tinkering with RSS and NNTP .




I've been toying around with doing this with inn for quite some time now, so I'm happy to see someone else actually follow through and give it a whirl.  And, using blagg with a plugin to do the posting seems just the right twist of clever.
Yeah, inn's a beast and meant for Usenet-scale beating, but it's Just There on many Linux installations.  And blagg seems to do a decent job of prying content out of RSS feeds, with just a few regular expression incantations.  DJ didn't have to reinvent an NNTP server, or create a brand new aggregator - just a few tweaks and glue, and two existing apps are joined in a completely new and interestingly complementary way.
Though one thing he says:  "As I saw it, there are two approaches to newsgroup article creation ... Send items from all weblogs to the same newsgroup ... Send items from each weblog to a separate newsgroup."  First thing I was wondering is:  Why not cross-post the articles and have both?
And then there're the ideas for experimentation that come first to mind: "... Combining the various weblog trackbacking mechanisms with NNTP article IDs to link  articles together in a thread; replying (to the newsgroup) to an  article might send a comment to the post at the source weblog."
Kinda retro, kinda nouveau, joining the new distributed RSS net up with the semi-distributed NNTP net.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/30/ooodod/"
          >389&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/30/ooodod/">#</a>
    <a class="time" href="2003/01/30/ooodod/">1:03 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 January 28</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/28/ooodoc/">How to make a multi-platform monster</a>
      </h2>
    
    <p class="summary">
      So I'm thinking that I might prematurely release some code before the week is out, so anyone who's interested can point and laugh at my PersonalWebProxy exploits - this time in Java.
One thing that disturbs me a bit about this thing so far is that, for what I have in mind, I'll have built a mini-OS when all is said and done.  It'll have a web server, a web proxy, telnet-able shell, scripting languages, scheduler, full text search and index engine, persistence & metadata storage, and whatever else I can eventually think to toss in.  There are just so many nice toys for Java, and most are a snap to glue together.  But, I can't really use any of the toys that come with the OS itself.
It's something I've rambled on about before, as has Jon Udell in his old Byte column: Zope Lessons Learned.  If this thing is to run on more than one platform, it can't rely on the facilities of any particular platform.  So, all these lovely things I like OS X for are somewhat off limits.
On the other hand, if I get tired of doing this thing in Java, I could always just finally embrace the platform and go straight for Cocoa.  :)  Yes, that would make for 3 environments tried, but hey - it's still fun for me!
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/28/ooodoc/"
          >435&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/28/ooodoc/">#</a>
    <a class="time" href="2003/01/28/ooodoc/">2:07 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 January 25</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/25/ooodob/">Etiquette with friends &amp; relationships in FOAF?</a>
      </h2>
    
    <p class="summary">
      interestingly, it seems that besides myself there are a goodly number of people wondering about the etiquette surrounding foaf friend declaration. while it's mostly a social and not technical problem, it's precisely the sort of thing that will keep foaf from reaching any kind of critical mass. 

Source:snowdeal.org, ex machina.




I've wondered a bit about this, too.  If I've heard of you, can I list you as a friend?  If I've emailed you once or twice?  How about if I've dated your sister?
However, Eric Vitiello Jr. has an interesting schema for further specifying relationships in FOAF.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/25/ooodob/"
          >283&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/25/ooodob/">#</a>
    <a class="time" href="2003/01/25/ooodob/">4:29 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/25/ooodoa/">Yes, Virginia, there is a Log4Perl.</a>
      </h2>
    
    <p class="summary">
      Log::Log4perl is different. It is a pure Perl port of the widely popular Apache/Jakarta log4j library for Java, a project made public in 1999, which has been actively supported and enhanced by a team around head honcho Ceki Gülcü during the years. 
The comforting facts about log4j are that it's really well thought out, it's the alternative logging standard for Java and it's been in use for years with numerous projects. If you don't like Java, then don't worry, you're not alone -- the Log::Log4perl authors (yours truly among them) are all Perl hardliners who made sure Log::Log4perl is real Perl. 

Source:perl.com: Retire your debugger, log smartly with Log::Log4perl! .




Wow, I hadn't noticed this before.  We've been looking for a Log4J-workalike in for our perl-based web apps at work, and thought CPAN:Log::Agent was where it's at - and it still may be - but CPAN:Log::Log4Perl looks very keen now.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/25/ooodoa/"
          >297&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/25/ooodoa/">#</a>
    <a class="time" href="2003/01/25/ooodoa/">1:35 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 January 24</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/24/ooodoo/">Dive into Premium!</a>
      </h2>
    
    <p class="summary">
      A new and better way to experience the "Dive Into" empire!  For only a few cents a day, you get fast, uncluttered access to your favorite "Dive Into" sites, with premium features available only to subscribers. 

Source:Dive Into Premium .




Finally!  All of those pop-ups, pop-unders, DoubleClick cookies, and epilepsy-inducing banners were really getting to me.  And if Mark Pilgrim can do for full frontal nudity what he did for web accessibility, I'm sure we're seeing the start of something big here.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/24/ooodoo/"
          >176&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/24/ooodoo/">#</a>
    <a class="time" href="2003/01/24/ooodoo/">4:11 am</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/24/ooocii/">Super-lazy link blogging &amp; in-bookmarks RSS aggregation via AppleScript?</a>
      </h2>
    
    <p class="summary">
      And one more post for the night:  I wish Safari gave AppleScript access to read and manipulate bookmarks.  If it does, I can't find it.  I've been playing around with AppleScript folder actions, Matt Webb's link blogging folder hack, and BlogScript.  I've been thinking, for good or bad, I'd like to do more link blogging.  Well, in Safari, I've created a toolbar bookmark folder called "READ/BLOG QUEUE" into which I drop links for later reading and/or blogging.
So...  If I could get at that bookmark folder via AppleScript, I could schedule and generate a templated blog entry for auto-posting every night, listing just the links I've left in that bookmark folder, and clear it out when it's all done.  I could do the same thing with just a Folder Action enabled desktop folder, but it's just so much more convenient to drop things on the toolbar.
And then, there's the other wild idea I'd use scriptable bookmarks for:  RSS aggregation.  Imagine bookmark folders dynamically generated and updated from RSS feeds.  Maybe even one big bookmark folder with RSS items aggregated from many feeds.  This seems somewhat appealing to me.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/24/ooocii/"
          >230&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/24/ooocii/">#</a>
    <a class="time" href="2003/01/24/ooocii/">2:42 am</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/24/ooocih/">BeanShell rocks - and, oh yeah, a personal proxy in Java</a>
      </h2>
    
    <p class="summary">
      Have I mentioned lately that I ♥ BeanShell for Java?
I haven't said much about it lately, but I'm still working on my PersonalWebProxy - only this time I'm playing with Java and all the goodies I was wishing for while in Python.  I've got Jena and Lucene and HSQL and BSF and Quartz and Muffin and...  well, a lot of stuff that feels pretty nice to me.
But, with respect to BeanShell in particular, I've got a lot of the nifty live hackability that I had with the things I was playing with in Python.  With no more than 5 lines of code, I've tossed a live interactive shell into my running proxy, into which I can telnet or access via Java console in a browser.  With this, I can get into the machinery before I take the time composing a UI, inserting/removing plugins at will, tossing together new proxy filters on the fly, composing RDQL queries adhoc, tweaking Lucene searches.
Fun stuff, and so easy.  But, sorry, no further code from me yet.  It's very ugly, and barely works, but it's just a sketchpad at the moment.  I hope to have a little something before the end of the month to pass around, should anyone still be interested.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/24/ooocih/"
          >235&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/24/ooocih/">#</a>
    <a class="time" href="2003/01/24/ooocih/">2:12 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 January 23</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/23/ooocig/">AppleScript and application services in the closet</a>
      </h2>
    
    <p class="summary">
      Apple's Script Editor 2.0 for OS 10.2.3 has support for Application Services . Basically, you can hilight some valid AppleScript text in any supporting application (like Safari, for instance) and 

 execute the script [or] 

 get the result of the script [or] 

 put the text into Script Editor. 




Source:Mac OS X Hints: Run AppleScripts via system services.




Neat!  Now...  can we do something about making access to those services a bit more prominent?  System-wide functions buried in a menu obscurely labeled "Services" under an app-specific menu label doesn't seem very inviting or intuitive.  AppleScript gets insanely better treatment than this.  I'd like to see these services pushed just as far forward, and more easily discoverable.  It's been awhile since I played in Cocoa, but for awhile I was wondering if rearrange things a bit, maybe pull the service items for the currently active app into a menu extra or something.  Or, at least pull the menu up a level, maybe stick it next to the "Script" where appropriate.  And, I'd love to be able to customize the keyboard shortcuts assigned to them - some have shortcuts and I'll rarely use them, while others have no shortcut and I wish I could use them all the time.
It's good stuff, Apple, show it off.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/23/ooocig/"
          >291&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/23/ooocig/">#</a>
    <a class="time" href="2003/01/23/ooocig/">10:40 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/23/ooocif/">Vellum and coffee rings</a>
      </h2>
    
    <p class="summary">
      Vellum is a server-hosted application to run weblogs for you. It's like MovableType or b2, in that it's hosted on your web server. And it's written in Python. 

Source:Vellum: a weblogging system in Python .




Need to check this out, have been itching to revamp this place and rethink what I want to do around here since it's coming up on my 1st full year out here in the blogosphere at large.
Funny thing, too, is that the coffee-ring-like background image on that page looks exactly like some of the first designs I played around with for my site.  Only his looks much better than mine did.  :)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/23/ooocif/"
          >109&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/23/ooocif/">#</a>
    <a class="time" href="2003/01/23/ooocif/">6:49 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/23/ooocie/">Looking for variable row height in your NSOutlineViews and NSTableViews?</a>
      </h2>
    
    <p class="summary">
      Apple's Cocoa library contains two very good table controls, ?NSTableView and it's close relative, ?NSOutlineView . However, both of these controls have one large limitation: All the rows must be the same height. This is an issue when displaying table cells with content that varies in height, such as large amounts of text or images. Luckily, Apple's Cocoa controls were also very well designed, making it possible to add this functionality simply by subclassing the table views. ?RowResizableTableView is an ?NSTableView subclass which allows each row to have variable heights, and ?RowResizableOutlineView is an ?NSOutlineView subclass with the same functionality. 

Source:RowResizableTableView: Variable Row Height Tables and Outlines .




Wow.  Although I think my Arboretum project is very likely asleep for good, it was the want for this particular component that most discouraged me from continuing with my outliner.  Nowadays what keeps me away is the absolute brilliant quality OmniGroup's OmniOutliner and the fact that it supports AppleScript, and furthermore, the fact that AppleScript has its tendrils in abso-freaking-lutely every app that seems to matter to me.  So, I can pretty much have everything I wanted to have out of Arboretum right now.
But I'd still like to come up with a decent project in Cocoa for myself.  It's just so damn comfy to develop with.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/23/ooocie/"
          >216&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/23/ooocie/">#</a>
    <a class="time" href="2003/01/23/ooocie/">6:44 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 January 22</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/22/ooocid/">Python is for superheroes</a>
      </h2>
    
    <p class="summary">
      I've been wasting some of my time playing the superhero role-playing computer game Freedom Force, which turns out to be done in Python. 

Source:The Happiest Geek on Earth: Python for superheroes .




Swanky!  I've been thinking about getting that game, off and on, wondering if my aging 600Mhz desktop PC would run it.  It looks like a hoot - and if it's that nifty under the hood, it should be pretty fun to hack with occasionally.  :)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/22/ooocid/"
          >78&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/22/ooocid/">#</a>
    <a class="time" href="2003/01/22/ooocid/">12:44 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 January 21</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/21/ooocic/">Why Moblog?</a>
      </h2>
    
    <p class="summary">
      It's only day two, yet I have nothing to Moblog today. Yesterday I was bopping around the city from my main office to the Sun testing center to lunch with my wife. Today I'm at the office in front of my computer, where I will probably remain until after dark. I guess I can moblog my lunch... It probably won't be that exciting. 

Source:Russell Beattie Notebook: Moblogging Thoughts .




Is Russell losing the Moblogging faith already?  :)  He raises an interesting, mostly obvious point:  After all the whiz-bang setup and build up - what do you have that's so important that it's worth covering in mobile multimedia splendor?
On one hand, some would say, "Nada mucho," and hang up their camera peripheral.  Me, well, I don't have the hardware yet to deluge my corner of the web with instant snaps and clips of me, my girl, the cats, and co-workers.  (Though I have gotten a start on it.)  But, I find what Russell's posted so far to be fascinating and amusing.  Of course, he's in an exotic locale with respect to me.  Why else, unless he was a photographic genius, would his lunch seem interesting to me?  Then again, I might be in an exotic locale with respect to someone else.
Anyway, after all the fun of connecting various bits together, you always come back to finding a reason to use it if you hadn't had one to begin with.  Sometimes the reason ends up being that it's just fun to play with bits connected together, and that someone somewhere might just find the result interesting.  No one's forcing anyone to look at all the pictures of the world's cats, you know?
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/21/ooocic/"
          >369&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/21/ooocic/">#</a>
    <a class="time" href="2003/01/21/ooocic/">1:03 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/21/ooocib/">RSS as a more generalized message queue for people</a>
      </h2>
    
    <p class="summary">
      It seems that beyond carrying syndication information, RSS is a very useful and flexible way to get all sorts of application data pushed to a user over time. In the same way that a web browser is a universal canvas upon which limitless services and information can be painted, so (in an  albeit much smaller way) an RSS reader/aggregator might also find its  place as an inbox for time-related delivery of all sorts of information. 

Source:DJ's Weblog: The universal canvas and RSS apps .




My thoughts exactly.  Not sure if I've posted here about it, but I know during the whole RSS hubbub this fall, I'd babbled something about RSS being a messaging queue from machines to humans.  Or a transport for timely ephemera to people.  Or something like that.  Basically, I'd like to see RSS, or something like it, used beyond just headlines.  This is why I've leaned toward the RDF-in-RSS camp - I want to see lots of things besides titles and excerpts hung off the individual message events, and RDF seems downright nifty to me for this.
But either way, I like the expanded notion of RSS usage as a timestream-oriented stream of messages targeted at subscribed people.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/21/ooocib/"
          >365&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/21/ooocib/">#</a>
    <a class="time" href="2003/01/21/ooocib/">12:23 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/21/ooocia/">You had 1200 baud?  Sheer luxury!</a>
      </h2>
    
    <p class="summary">
      I used an HP 1200bps external modem.  To connect to BBSes.  When I was in elementary school.  I remember tearing through the latest Focke's BBS list.  It was the definitive guide to DC-metro BBSes.  I'd print it out on my Okidata dot-matrix printer on fan-folded continuous feed paper with the holes on the sides.  Then I'd grab a pen or pencil, mark up some interesting BBSes, fire up Procomm and try to connect. 

Source:postneo: 1200 bps .




Oh yeah?  Well, my first experience with dialing up in Jr. High was with a 300 bps modem on a C=64.  I used to pour over Horst Mann's 313 area code BBS list and sneak in calls to long-distance BBSes throughout Michigan, for which I'd later pay dearly out of my allowance.  :)  I remember coveting my friend's hulking Tandy PC and its 1200 baud modem (nearly a full screen of text at one time when playing BBS games).  Then, I bought a 2400 baud modem with an adapter, and became the envy of everyone - until they all moved up to 2400 and then 14.4K.
I'm sure someone else can give me an oh yeah, too, and we can work up a skit ala Monty Python's "We Were Poor".  ("You were lucky to have a lake! There were 15 of us living in a cardboard box in the middle of the road!")
What I really miss from the BBS days, though, is the local community.  Used to be that far away places were far away, and near places were near, and you had to go through the near places first before you could visit far places.  So, communities formed around BBSes, even as those around be began changing into mere portals onto the internet, and then later to become fledgling dialup ISPs.  Nowadays, the distance between points on the net is measured in terms of interest, attention, and affinity, without regard to physical location.  It's so much harder to get together for a cup of coffee with the people behind the keyboards these days.  :)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/21/ooocia/"
          >444&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/21/ooocia/">#</a>
    <a class="time" href="2003/01/21/ooocia/">11:13 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 January 20</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/20/ooocio/">Automated openness versus the script kiddies</a>
      </h2>
    
    <p class="summary">
      If I did have comments on my weblog it would be like Slashdot, a very low signal to noise ratio. Don't blame me for that, it comes with longevity and flow. The longer the site is around and the higher the flow, the more losers one attracts. I can see where these things work for a lower flow site, but they would never work for Scripting News, I'd have to turn it off quickly because of the low-roaders. 

Source:Dave Winer in comments on Simon Willison's Weblog.




Although I'm too lazy to search for the links at the moment, I've sung the praises to automatic trackback and referrers and friends.  Like Simon, I've also bemoaned the apparent lack of participation Dave has in this self-organizing chaos of blogs auto-discovering each other.
But, Dave's right.  Get too much flow, piss off too many people, say too many controversial or contrary things against too many camps - in other words, assert a strong opinion, right or wrong, and get it read widely enough and do it often enough - and your weblog will turn into a cesspool with all its graciously thrown open doors clogged with trolls.
At present, I'm safe.  My rating is Mostly Harmless, so all my open systems are mostly free from abuse.  But, the first time I really strike a nerve somewhere, I'm a sitting duck.
I've got some pretty pretentious ideas floating in my head about how this relates to an open civilization and culture in general, but I'll save them.  Basically, I don't want to give up my openness, but I want to deflect the barbarians.  Need to think more, but I suspect this may cross streams with the spam crisis, eventually.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/20/ooocio/"
          >303&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/20/ooocio/">#</a>
    <a class="time" href="2003/01/20/ooocio/">4:37 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 January 19</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/19/ooochi/">On OS X, searches are a mere finger twitch away</a>
      </h2>
    
    <p class="summary">
      Oh yeah, and further along the lines of filesystem sacrilege, my most used OS X apps are:



 Searchling



 LaunchBar






Both of these give me lightning fast access with keyboard-shortcut finger twitches to what's on my mind and what I want to do.  I want to find more things like this.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/19/ooochi/"
          >88&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/19/ooochi/">#</a>
    <a class="time" href="2003/01/19/ooochi/">7:34 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/19/ooochh/">Russell Beattie is a sneaky, mobile guy.</a>
      </h2>
    
    <p class="summary">
      Gosh, I've been quiet lately. What could be the reason? 
1) I'm sick of blogging (not likely) 2) I've been having a life away from the computer (not likely) 3) I've been heads down doing something cool that I'll shortly be blogging about? Hmmm.... 




Source:Russell Beattie Notebook: Quiet .




If you're careful and look hard, you'll find what he's teasing about.  Go look - it's not in the quote above.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/19/ooochh/"
          >71&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/19/ooochh/">#</a>
    <a class="time" href="2003/01/19/ooochh/">7:29 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/19/ooochg/">I second that sacrilege</a>
      </h2>
    
    <p class="summary">
      Dear Operating System Vendors. 
I no longer want to know where my files are stored. I no longer care. I have hordes of directories on my various computers called stuff ,downloads and documents , and the effort that it would take to organise them into a proper heirarchy is just not worth it. The heirarchical filesystem is a really wonderful thing for programmers and websites, but it just doesn't cut it for personal use. 
I no longer care where my files are stored. 

Source:The Fishbowl: Filesystem sacrilege.




I'll be burned at the next stake over from Charles when the time comes, for this filesystem heresy.  Just the other night, a co-worker was asking me about how diligent I was in organizing my email.  I told her, "Not at all.  I leave it all in one pile and then run the Find command on it later."  She was shocked that I, alpha geek and info freako, didn't have some intricate taxonomy of folders into which mail was sorted by carefully crafted filters.
Years ago, when I first started using email, I did indeed do this with procmail and other arcane beasties.  Then, I found myself cursing that I couldn't do cross-folder searches very easily.  Also, the filters and folders started making less sense as their structure represented only one possible scheme for finding what I was looking for, and I was needing many possible kinds of schemes over time.  So, eventually it all ended up in one pile, and searches became my way of finding things.
I abandoned bookmarks for Google by the same principle.  Now, my bookmarks consist completely of bookmarklets and a few stray links to local on-disk pages like Python documentation.  In fact, I'm wishing that I could create bookmark folders that are fed by Google API powered persistent searches.
So, now I'm looking balefully upon my filesystem.  I haven't had much chance to play with BeOS, but I've read about the design of the BeOS file system and drooled.  I hear about Microsoft's Longhorn and its WinFS and grind my teeth - I very much dislike Microsoft, but if they pulled this off, I'd have to sing their praises.  Apple?  Do they have any aces up their sleeves in this regard?  Don't let a new fanboy down.  :)
Anyway, that's what I want to see:  Storage without explicit organization, but with super-rich metadata for super-fast searches.  Allow me to create views made from persistent searches - my "project folder" is simply a collection of resources tied together by a common tag, one of many.  And, if I want to form a project hierarchy, make my persistent searches into file objects too.  
The main thing in all this, though, is that it be woven very deeply within the OS.  I don't want a helper app.  I want this to replace the standard metaphor completely.
RDF triples at the inode-level anyone?  Heh, heh.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/19/ooochg/"
          >940&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/19/ooochg/">#</a>
    <a class="time" href="2003/01/19/ooochg/">7:03 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 January 18</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/18/oooche/">Safari: Good riddance to tabs, if there&#39;s something better</a>
      </h2>
    
    <p class="summary">
      I've been thinking about the whole "I need tabs in Safari" issue, and have come to realize that no, in fact, I don't need tabs in Safari. ... What I need is a way to manage multiple open web pages in a single window. ... I've done a quick and dirty mockup of something that approaches what I'm thinking about. 

Source:D'Arcy Norman's Weblog.




So, yeah, not that anyone needs my US$0.02 added to the cacophony around Safari, but here it is anyway.  Go check out D'Arcy's mockup.  I think this is precisely what I want.  I've been keeping myself using Safari since it was released, and I've been disappointed with it very rarely.  Instead of tabs, I've been heavily using the Window menu, wishing for some window navigation shortcuts (ie. prev, next, 0-9 for first ten windows?)
Anyway, I say: tabs can go, but give me a sidebar.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/18/oooche/"
          >350&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/18/oooche/">#</a>
    <a class="time" href="2003/01/18/oooche/">4:10 am</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/18/ooochd/">Kung-Log back with a Cocoanized Vengance</a>
      </h2>
    
    <p class="summary">
      Wow, take a look at The Cocoanization of Kung-Log:During the New Year holiday I started getting acquainted with Cocoa programming by converting my ?AppleScriptStudio Kung-Log app into a Cocoa version. Well, smack my ass and call me Judy, it's done !

It'd been awhile since the last time I checked out Kung-Log - when it was working for me, it was my absolute favorite way to update this site, but then it started breaking in a few places such as recent post retrieval.  So I gave it up.  Then tonight, on a whim, I looked.  And whew, a complete rewrite, apparently release just this night.  Talk about coincidence.
Nice.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/18/ooochd/"
          >143&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/18/ooochd/">#</a>
    <a class="time" href="2003/01/18/ooochd/">3:22 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 January 16</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/16/ooochc/">Folder Actions + AppleScript = Desktop Blogging.  Literally.</a>
      </h2>
    
    <p class="summary">
      Lazy Mac OS X: Weblog links sidebar: ...it's going to be about turning your Mac into a weblogging machine. As easy as the links-and-commentary genre is with all the blogging apps out there, I'm too lazy for the commentary bit, and so I tend to drag-and-drop links to my desktop for later posting -- and then promptly forget about them. Consequently my desktop is a mess, and my blog is stagnating. Bad.
So... what he made, with AppleScript's Folder Actions, is a magic folder on his desktop.  When links are dropped into the folder, a script is triggered which posts the link to a weblog via BloggerAPI.  I've tweaked it a bit to ask me for a link title, quote, and a tiny bit of commentary, but it still needs a bit more work.
I had never heard of Folder Actions before this.  This is very nifty stuff - blogging woven into the OS X desktop itself with AppleScript.  Whew.
What I'd really love is to be able to drop a folder onto my dock, and then drop things onto it there.  I'm thinking of a bunch of "bins" on the dock that shuttle files off to different destinations and through various transformations, right there, always in view.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/16/ooochc/"
          >341&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/16/ooochc/">#</a>
    <a class="time" href="2003/01/16/ooochc/">5:22 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/16/ooochb/">OmniGraffle + AppleScript = RSS news reader</a>
      </h2>
    
    <p class="summary">
      Using OmniGraffle as an RSS News Reader with AppleScript: To learn about the capabilities of a new application in its enhanced AppleScript capabilities, a project is created that turns ?OmniGraffle into an RSS News reader unlike any that are out there.
This rocks.  Been a little quite lately, busy at work, still tinkering with my proxy.  And now I find myself poking around into AppleScript again.  Wheee!
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/16/ooochb/"
          >68&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/16/ooochb/">#</a>
    <a class="time" href="2003/01/16/ooochb/">5:10 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 January 09</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/09/ooocgh/">So, yeah, about that BML thing</a>
      </h2>
    
    <p class="summary">
      Speaking of BML, what ever happened to it?  I first wrote about it back in August and later got a response from Sanjiva Weerawarana, one of the original authors at IBM.  Someone hinted to me that it was supposed to eventually land at Jakarta, and while the Bean Scripting Framework did land there, BML is still off the radar.  Meanwhile, I'm still using it at work, still sitting on some dubiously-gotten source code, and want to use it in more public projects.
Anyone out there in Java-land besides me know about this thing and find it useful?  While it's still very likely that I'm delusioned, I have yet to find something equivalent to what it can do for me.  On the contrary, I've seen other projects rolling their own much less functional versions of BML.  But, I have to assume that I'm not realy a know-it-all, and that I'm likely missing something that makes this not-so-great and relatively unadopted.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/09/ooocgh/"
          >182&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/09/ooocgh/">#</a>
    <a class="time" href="2003/01/09/ooocgh/">3:27 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/09/ooocgg/">Yet another post about that proxy thing</a>
      </h2>
    
    <p class="summary">
      I'm still not entirely sold on Python and Twisted as the foundation for my PersonalWebProxy.  Yeah, I know I just release a bunch of code to that effect, but it's still just a proof of concept.  While there are some impressive things in Twisted and Python, there's also a lot of flux and immaturity there.  Not a bad thing, since the hackers in that camp are doing mad crazy things, but I don't want to focus on mad crazy things in my toolkit - I want to focus on mad crazy things built on top of it.  The thing I've been hoping for is that some of those mad crazy things in the toolkit would enable even madder crazier things down the line for me.  This may be true still - so I'm not tossing anything out, just still experimenting.
So far, this is just playing for me.  For fun, I think I might do the whole thing over again in Java and play in parallel for a little while.  Well, not quite all over, since I think I've found some pretty ready-made components:
Take Muffin, for example.  It's a Java proxy that looks like it's been dormant for quite awhile, but seems ideal on the surface for my needs.  Just today, though, I checked back in the project's CVS repository and it seems that there's new activity and checkins starting up in there.  On the other hand, I've also been poking at Jetty and the proxy classes it comes with.  Seems like there's a lot to work with here, and I have a better vibe about it.
Besides that, Jena seems stronger than rdflib for RDF support, and I'm just biting at the bit to pour damn near everything at Apache Jakarta into this thing.  Also, I suspect I may be able to preserve the quick scripty hackability I want out of the this thing by using BSF and Jython, with some assembly and config in BML.
Hmm.  Still tinkering.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/09/ooocgg/"
          >486&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/09/ooocgg/">#</a>
    <a class="time" href="2003/01/09/ooocgg/">3:19 pm</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 January 08</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/08/ooocgf/">More code toward the personal web proxy</a>
      </h2>
    
    <p class="summary">
      In case anyone's interested, I've been hacking like mad on my toy proxy since New Years'.  Check out PersonalWebProxy for current downloads.  It's got primitive forms of proxy filters, browser-based UI, RDF-based metadata management, logging, config, plugins, and some other goodies.  So far, the major plugins include:

 a noisy logger;

 a content archiver that captures and saves all response headers and content in a directory structure loosely based on the requested URL;

 an initial metadata harvester that fills up the RDF database with triples based on headers and details encountered during browsing







It works, and does stuff, but I'm sure it demonstrates a complete lack of understanding of large portions of the Twisted framework, Python itself, and likely causes forest fires.  So, I hope many people will download it, snicker at it, and maybe set me straight on a few things and contribute a few patches and plugins.
ShareAndEnjoy!
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/08/ooocgf/"
          >433&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/08/ooocgf/">#</a>
    <a class="time" href="2003/01/08/ooocgf/">4:06 am</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/08/ooocge/">About that Apple stuff today</a>
      </h2>
    
    <p class="summary">
      So... yeah.  I watched the keynote, and I'm lusting over the new mini-me ?PowerBook with a plan to purchase in the Spring.  I was aiming at a high end iBook but holding out for something better, and well, this new ?PowerBook is the precisely what I was holding out for.  It appears to be the rightful successor to my formerly beloved Sony Vaio 505TR.
Then there's Safari.  Mark puts it under the microscope, as does Mena.  On the other hand, Ben writes that it's almost-shit.  Oh yeah, and JWZ reports: "Apple says 'fuck you' to Mozilla"  But he's not bitter.
I haven't got the chops to seriously test the thing, so I'll be watching the more spec-wise out there for info.  But, what I do think about it makes me sound like an Apple fanboy:  I think it's great.  
It's not perfect at the moment, but I've got a feeling that this will change.  And fast.  Mozilla's shipped with talkback, but Safari's got a bug submission button right up front.  And the fact that they did snub Mozilla for a dark horse like Konqueror seems a bit provocative (at least in techie / Open Source circles), and after all that talk of innovation I doubt that they're going to let it rest as-is or back down.  I expect lots of movement from here.  Think different and all that.  And, from my minuscule bits of Cocoa dev, I'm looking forward to poking around with ?WebCore and the ?JavaScript framework.  Unless it's a complete disaster, I expect the building blocks of Safari to pop up in projects everywhere.
These things tell me to expect good things from Safari.  I hope Mozilla can keep up.  As for IE, well, I deleted that a long time ago.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/08/ooocge/"
          >332&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/08/ooocge/">#</a>
    <a class="time" href="2003/01/08/ooocge/">2:58 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 January 07</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/07/ooocgd/">Readline support for Python on OS X</a>
      </h2>
    
    <p class="summary">
      I needed and found a little help enabling readline support for Python under Mac OS X.  I love a lazyweb so lazy that solutions to my problems have already been posted.  :)
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/07/ooocgd/"
          >33&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/07/ooocgd/">#</a>
    <a class="time" href="2003/01/07/ooocgd/">4:24 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 January 02</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/02/ooocgc/">Python RDF repository wanted for web proxy metadata harvester</a>
      </h2>
    
    <p class="summary">
      Okay, this is getting close to outstripping my enthusiasm and invoking my laziness:  Does anyone happen to have RDFLib and ZODB working under Mac OS X 10.2.3?  Have also tried compiling Redland and its Python and Java APIs, but that's not been a 100% success.  Or can someone recommend another decent RDF repository to play with under Python?  I've had fun with Jena under Java, love using RDQL, and dig switching between MySQL and BDB stores.
I want an RDF repository I can integrate into my proxy experiments, currently implemented in Python.  I've been very tempted to switch to Java, which I know better and have a better sense of tools available.  But I'm still pulling for Python.  I suppose I could just go with an in-memory repository at first, but I don't want to stick with that.
I'm still finishing up the PersonalWebProxy notes and plan I've been working on, but I've still got an itch to play in code.  The next major thing I want to do is extract as much metadata as I can from every HTML page I visit and load the RDF repository up with statements based on what I harvest.  Examples would include things like HTML title, visitation date, referring url, any meta tags, any autodiscovered RSS and FOAF URLs, and anything else I could eventually dig out.  Then, I want to amass some data and play with it.  I'm thinking this could give me a kind of uber-history with which to work.
Update: Seems like I managed to get Python, RDFLib, and ZODB working, but I started completely from scratch and compiled everything from clean source.  I guess Apple's build of Python has more hiccups in it than just the Makefile thing.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/02/ooocgc/"
          >420&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/02/ooocgc/">#</a>
    <a class="time" href="2003/01/02/ooocgc/">3:13 am</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/02/ooocgb/">Stumbling through compiling Standalone ZODB for Mac OS X</a>
      </h2>
    
    <p class="summary">
      Just in case this wasn't common knowledge, it seems there's a bit of a boo-boo in Jaguar's installation of Python that sticks it head up when one tries to compile extentions (like, oh say, the Standalone ZODB).
Line 62 of /usr/lib/python2.2/config/Makefile reads:
LDFLAGS=        -arch i386 -arch ppc
But, I think should read:
LDFLAGS=        -arch ppc
Making this change appears to have gotten the thing compiling, though it may also cause my iBook to eventually self-format since I barely understand everything involved.
Ugh, though now that everything's compiled without hitch, the test script goes belly up with a bus error.  Time to go back googling to find a solution or somewhere to whine.  I may also swap back into Java, since I like Jena better than anything I've found in Python for RDF support.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/02/ooocgb/"
          >304&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/02/ooocgb/">#</a>
    <a class="time" href="2003/01/02/ooocgb/">1:30 am</a>
    
  </div>
  </li><li class="content-grid date-header">
    <h2 class="date">2003 January 01</h2>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/01/ooocga/">MovableType gets first class treatment for text formatting</a>
      </h2>
    
    <p class="summary">
      Teasing everyone with a solution to something we MovableType users been hacking around with for awhile, Ben Trott writes:We envision Text Formatting options as complete, encapsulated formatters, handling both the formatting of structured text and any desired typographical details (smart quotes, etc), analogous to the way in which Textile handles quote education and its own miniature formatting language.
Plugins will be able to easily add new Text Formatting options to the menu on the New/Edit Entry screen.
Yay!  Text formatting as a first class feature in MovableType - used in previews, as well as in publishing.  No more including plugin tags in every single template ala MTWikiFormatPlugin and friends.  Rock on!  It's a good thing when hacks I write get outmoded by a more elegant treatment.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/01/ooocga/"
          >126&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/01/ooocga/">#</a>
    <a class="time" href="2003/01/01/ooocga/">4:37 pm</a>
    
  </div>
  </li><li class="content-grid post post-type-entry">
    <h2 class="title">
        <a href="/blog.lmorchard.com/2003/01/01/ooocgo/">Sharing my Python proxy experiment</a>
      </h2>
    
    <p class="summary">
      Anthony Eden writes:I was so intrigued by having a proxy agent which would work for me that I wrote a little generic pluggable proxy this morning.
Show us the code! :)  I want to play.
As for my code so far: This is extremely premature, and I'm not even sure if it will work anywhere besides my peculiar iBook, but here's a quick & dirty tarball of my experiments with a PersonalWebProxy (just web, not universal) with a simple plugin API, in Python using Twisted:
dbproxy-20021231.tar.gz
It's poorly commented, doesn't do much useful, but it's a few nights' work by someone just getting acquainted with Twisted - if you're even worse off than me and want to poke at this proxy thing, maybe this will help you.  It does do a few things I thought were nifty, like use Mark Pilgrim's rssfinder script in a thread to dig up RSS feeds for every URL with text/html content you visit.  There's no persistence yet, so they just appear in the log, but figuring out the integration and thread use so far was nifty to me.
Anyway, enjoy.  I'm still tinkering, thinking, and working up a plan.
Oh yeah, and I'm watching Dick Clark and the ball drop with my girlfriend, so this post brings an end to hacking for the night.
      <span class="word-count"
        >[&nbsp;...&nbsp;<a class="link" href="/blog.lmorchard.com/2003/01/01/ooocgo/"
          >379&nbsp;words</a
        >&nbsp;...&nbsp;]</span
      >
    </p>
    <div class="meta">
    <a class="permalink" href="2003/01/01/ooocgo/">#</a>
    <a class="time" href="2003/01/01/ooocgo/">1:53 am</a>
    
  </div>
  </li>
      </ul>
      
    </section></section>

        <footer class="content-grid">
          <div class="left">
            © 2024 Les Orchard &lt;<a href="mailto:me@lmorchard.com"
              >me@lmorchard.com</a
            >&gt;
          </div>
          <img id="growup" src="/blog.lmorchard.com/uploads/growup.jpg" />
          <nav class="right">
            <ul>
              <li>
                <a href="https://lmorchard.github.io/blog.lmorchard.com/index.rss" title="blog.lmorchard.com"
                  ><span class="fa fa-rss"></span> feed</a
                >
              </li>
            </ul>
          </nav>
        </footer>
      </body>
    </html>