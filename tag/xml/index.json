[
  {
    "comments_archived": true,
    "date": "2007-10-17T07:22:47.000Z",
    "layout": "post",
    "tags": [
      "webdev",
      "rss",
      "php",
      "atom",
      "xml",
      "opml",
      "feedmagick",
      "feedmagick2",
      "feeds"
    ],
    "title": "OPML reading lists in FeedMagick2",
    "wordpress_id": 1066,
    "wordpress_slug": "opml-reading-lists-in-feedmagick2",
    "wordpress_url": "http://decafbad.com/blog/2007/10/17/opml-reading-lists-in-feedmagick2",
    "year": "2007",
    "month": "10",
    "day": "17",
    "isDir": false,
    "slug": "opml-reading-lists-in-feedmagick2",
    "postName": "2007-10-17-opml-reading-lists-in-feedmagick2",
    "html": "<p>For anyone who&#39;s interested:  I&#39;ve been hacking a little bit on <a href=\"http://decafbad.com/trac/wiki/FeedMagick\">FeedMagick2</a> again, with the latest addition being an OPML reading list feed blender.  </p>\n<p><a href=\"http://nick.typepad.com/blog/2005/10/reading_lists_f.html\">What&#39;s an OPML reading list?</a>  Basically, it&#39;s the same as as OPML export of a feed reader&#39;s subscription list - only rather than doing a one-time import into another program, the OPML is itself treated as a live feed.  A feed reader that supports OPML reading lists will continually check the list for updates and sync RSS/Atom feed subscriptions with its contents, maybe in a special sub-folder.</p>\n<p>Here&#39;s a quick demo:</p>\n<ul>\n<li><a href=\"http://decafbad.com/2007/04/FeedMagick2/?pipeline=readinglist&amp;url=http%3A%2F%2Fdecafbad.com%2F2007%2F04%2FFeedMagick2%2Fdocs%2Fmaster.opml&amp;format=rss&amp;run=Run+Pipeline\">An RSS feed blended from many of the sites I use daily</a></li>\n<li><a href=\"http://decafbad.com/2007/04/FeedMagick2/docs/master.opml\">The OPML reading list used as input for the above blend</a></li>\n</ul>\n<p>The itch I mean to eventually scratch is to replace the front page of decafbad.com with a live updating aggregation of the stuff I create and capture daily on the web.  It&#39;ll be basically a self-assembling <a href=\"http://en.wikipedia.org/wiki/Tumblelog\">tumblelog</a> pulled from many different services across the web.  It&#39;ll also replace the footer of accumulated crud I&#39;ve got on this very blog - which I thought was a good idea at one point, but now consider <a href=\"http://decafbad.com/twiki/bin/view/Main/NeatLikeDigitalWatches\">NeatLikeDigitalWatches</a>.</p>\n<p>With that in mind, the next thing I plan to develop is an <a href=\"http://microformats.org/wiki/hatom\">hAtom</a> module or XSL transform.  This will turn the blended feed into an XHTML page.  Maybe someday, <a href=\"http://hatomic.org\">hAtomic</a> will launch, and I&#39;ll have a nice pretty style for the page too.  Some time after that, I might work up a module that stows away dated historical archives of the feed and pages.  I have <a href=\"http://decafbad.com/svn/trunk/FeedMagick2/TODO\">further plans and ideas</a>, but I&#39;m trying to focus on the itchy spots first so that I might actually get something done in this round of serial enthusiasm.</p>\n",
    "body": "For anyone who's interested:  I've been hacking a little bit on [FeedMagick2](http://decafbad.com/trac/wiki/FeedMagick) again, with the latest addition being an OPML reading list feed blender.  \r\n\r\n[What's an OPML reading list?](http://nick.typepad.com/blog/2005/10/reading_lists_f.html)  Basically, it's the same as as OPML export of a feed reader's subscription list - only rather than doing a one-time import into another program, the OPML is itself treated as a live feed.  A feed reader that supports OPML reading lists will continually check the list for updates and sync RSS/Atom feed subscriptions with its contents, maybe in a special sub-folder.\r\n\r\nHere's a quick demo:\r\n\r\n* [An RSS feed blended from many of the sites I use daily](http://decafbad.com/2007/04/FeedMagick2/?pipeline=readinglist&url=http%3A%2F%2Fdecafbad.com%2F2007%2F04%2FFeedMagick2%2Fdocs%2Fmaster.opml&format=rss&run=Run+Pipeline)\r\n* [The OPML reading list used as input for the above blend](http://decafbad.com/2007/04/FeedMagick2/docs/master.opml)\r\n\r\nThe itch I mean to eventually scratch is to replace the front page of decafbad.com with a live updating aggregation of the stuff I create and capture daily on the web.  It'll be basically a self-assembling [tumblelog](http://en.wikipedia.org/wiki/Tumblelog) pulled from many different services across the web.  It'll also replace the footer of accumulated crud I've got on this very blog - which I thought was a good idea at one point, but now consider [NeatLikeDigitalWatches](http://decafbad.com/twiki/bin/view/Main/NeatLikeDigitalWatches).\r\n\r\nWith that in mind, the next thing I plan to develop is an [hAtom](http://microformats.org/wiki/hatom) module or XSL transform.  This will turn the blended feed into an XHTML page.  Maybe someday, [hAtomic](http://hatomic.org) will launch, and I'll have a nice pretty style for the page too.  Some time after that, I might work up a module that stows away dated historical archives of the feed and pages.  I have [further plans and ideas](http://decafbad.com/svn/trunk/FeedMagick2/TODO), but I'm trying to focus on the itchy spots first so that I might actually get something done in this round of serial enthusiasm.\r\n",
    "parentPath": "../blog.lmorchard.com/posts/archives/2007",
    "path": "2007/10/17/opml-reading-lists-in-feedmagick2"
  },
  {
    "comments_archived": true,
    "date": "2007-04-30T03:06:32.000Z",
    "layout": "post",
    "tags": [
      "webdev",
      "rss",
      "php",
      "atom",
      "xml",
      "feedmagick",
      "feedmagick2",
      "feeds"
    ],
    "title": "Say hello to FeedMagick2",
    "wordpress_id": 1048,
    "wordpress_slug": "say-hello-to-feedmagick2",
    "wordpress_url": "http://decafbad.com/blog/2007/04/29/say-hello-to-feedmagick2",
    "year": "2007",
    "month": "04",
    "day": "29",
    "isDir": false,
    "slug": "say-hello-to-feedmagick2",
    "postName": "2007-04-29-say-hello-to-feedmagick2",
    "html": "<p>Yeah, things have been basically silent around here thanks to post-work brain fryage and a general lack of things to say.  Really, everyone else around the blogosphere seems to be covering things satisfactorily.  However, I have been idly working on a new project over the past few weeks, namely a total rewrite and redesign of <a href=\"http://decafbad.com/blog/?s=feedmagick\">my format-ignorant feed filtering and munging kit dubbed FeedMagick</a>.</p>\n<p>You can find <a href=\"http://decafbad.com/2007/04/FeedMagick2/\">a demo installation of FeedMagick2 here</a> and find it <a href=\"http://decafbad.com/svn/trunk/FeedMagick2/\">ready for checkout from SVN over here</a>.  It&#39;s basically just a step away from being a proof of concept, but I&#39;m hoping to get around to fleshing out docs and battening down the hatches with tests.  In any case, if my serial enthusiasm holds out, this thing could eventually subsume everything else I&#39;ve done with feeds.</p>\n<p>For now, peek at some of these highlights:</p>\n<ul>\n<li><a href=\"http://decafbad.com/2007/04/FeedMagick2/inspect/masterfeed\">Master Personal Feed</a> - One big feed blended from 10 other personal metadata feeds pulled from various Web-2.0-ish sites.</li>\n<li><a href=\"http://decafbad.com/2007/04/FeedMagick2/inspect/magpiejson\">Feed to JSON via Magpie</a> - Get feed data parsed by way of <a href=\"http://magpierss.sourceforge.net/\">Magpie</a> into JSON data structures</li>\n<li><a href=\"http://decafbad.com/2007/04/FeedMagick2/inspect/flickrfavorites\">Flickr Favorites Feed</a> - Feed of photos marked as favorites by a Flickr user, pulled via the API</li>\n<li><a href=\"http://decafbad.com/2007/04/FeedMagick2/inspect/jbox\">jbox.com scraper</a> - Pipeline composed of <a href=\"http://tidy.sourceforge.net/\">HTML Tidy</a> and XSL to scrape <a href=\"http://jbox.com/\">jbox.com</a> to build an RSS feed of new items for sale.</li>\n</ul>\n<p>Beyond practical examples, there are some things under the hood that seem keen to me.  Apropos of my <a href=\"http://decafbad.com/blog/2007/02/15/thoughts-on-pipes-on-the-web-part-ii\">pipes-via-web ramblings</a> back in February, I&#39;m trying out a few different approaches to pipelining feed content through processor modules.  My original FeedMagick relied on feeding URLs to URLs as parameters.  That, unfortunately, can be mighty cumbersome and inefficient.  So, FeedMagick2 explores a few more approaches:</p>\n<ul>\n<li><p>The first and obvious approach is to chain them together in a single script.  So, I&#39;ve got objects instances that pass content from one to the next.  The thing is, the pipe works in reverse:  The driver script asks the last module in the pipe for content, which then asks the one before it for content, and so on.  At any point along the way, modules can cache the output of previous modules, and refrain from calling up the chain.</p>\n</li>\n<li><p>The second way to chain pipelines together is just like the first FeedMagick:  Some pipelines start with fetching a URL.  That can be an original feed, or a URL leading to the output of an antecedent pipeline.  And, oh yeah, most pipelines are run via parameterized URLs, so there&#39;s that bit of handy recursion.</p>\n</li>\n<li><p>The third way to chain pipelines together is with HTTP POST:  A pipeline can accept feed data via the request body of an HTTP POST, thus allowing antecedent pipelines (or even cURL scripts) to <em>push</em> data into the pipeline rather than getting <em>pulled</em> via URL.  This is kind of like my <a href=\"http://decafbad.com/blog/?s=xmlrpc+pipe\">years-old jiggery pokery</a> with <a href=\"http://www.decafbad.com/twiki/bin/view/Main/XmlRpcFilteringPipe\">pipelines via XML-RPC</a>, only much <em>much</em> simpler.</p>\n</li>\n</ul>\n<p>I&#39;m also poking around at making all of the above available at the command line via PHP-CLI, and I&#39;m having gratuitous fun exploring PEAR to roll my own stripped-down web framework.  I still hate PHP, but I&#39;m at least finding ways to entertain myself while I&#39;m holding my nose.  Of course, I find weird things entertaining.</p>\n<p>And, as a side note, the only reason I&#39;m using PHP is because I&#39;d like to play around with the idea of the de facto WordPress installation requirements standard.  That is:  If you can run WordPress, you can run this.  In reality, I don&#39;t think I&#39;m there, but I&#39;m hoping to get close.  For one, I&#39;m refusing to play with anything older than PHP 5.</p>\n<p>Anyway, play with it, tell me what you think and give me a reason to keep hacking at it.  :)</p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221082761\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://jamesv.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=c82c72ca4f9eab33a80a7bd839c1ae0b&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://jamesv.org\">jamesv</a>\n</div>\n<a href=\"#comment-221082761\" class=\"permalink\"><time datetime=\"2007-04-30T11:39:15\">2007-04-30T11:39:15</time></a>\n</div>\n<div class=\"content\"><p>Aw man, now I've got to port all the code you wrote while you were here over to this new hotness ;) I really like (and appreciate) the single script approach.</p>\n<p>Is caching at a module level done automatically, or is that something I need to flag in my original call? Some installs of the original code base are now aggregating large sections of a pool of around 400 feeds, and eeking out even minor performances gains would be just lovely.</p></div>\n</li>\n<li class=\"comment\" id=\"comment-221082762\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=b309c5a1952afc3d7d81ee90908309af&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"\">dRAUPP</a>\n</div>\n<a href=\"#comment-221082762\" class=\"permalink\"><time datetime=\"2007-04-30T13:40:16\">2007-04-30T13:40:16</time></a>\n</div>\n<div class=\"content\"><p>hawt.</p></div>\n</li>\n<li class=\"comment\" id=\"comment-221082763\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221082763\" class=\"permalink\"><time datetime=\"2007-04-30T14:43:54\">2007-04-30T14:43:54</time></a>\n</div>\n<div class=\"content\"><p>@jamesv: Take a look at the source to this big-ish pipeline, all the way at the end:</p>\n<p>http://decafbad.com/2007/04/FeedMagick2/pipelines/masterfeed</p>\n<p>You can basically slap a Cacher module at the tail-end or even middle of a long string of modules, and it'll cache the results of everything before it.  I've got a cache lifetime set in the conf/config.php, and you can also set the lifetime in the Cacher parameters.  There can multiple Cacher's per pipeline too.</p>\n<p>This thing might not quite yet be even as stable / in working order as the original FeedMagick, but it might be worth poking at for you.  :)</p></div>\n</li>\n<li class=\"comment\" id=\"comment-221082766\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://laughingmeme.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=01457d1a0f0e533062cd0d1033fb4d7a&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://laughingmeme.org\">kellan</a>\n</div>\n<a href=\"#comment-221082766\" class=\"permalink\"><time datetime=\"2007-04-30T16:02:31\">2007-04-30T16:02:31</time></a>\n</div>\n<div class=\"content\"><blockquote>For one, I’m refusing to play with anything older than PHP 5.</blockquote>\n<p>That must be nice.  </p>\n<p>And curse you, this looks interesting, now I've got to find time to look at it.</p></div>\n</li>\n<li class=\"comment\" id=\"comment-221082767\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.jm3.net/\"><img src=\"http://disqus.com/api/users/avatars/jm3.jpg\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.jm3.net/\">John Manoogian III (jm3)</a>\n</div>\n<a href=\"#comment-221082767\" class=\"permalink\"><time datetime=\"2007-04-30T17:53:08\">2007-04-30T17:53:08</time></a>\n</div>\n<div class=\"content\"><p>addendum to README:</p>\nInstallation\n<p>cp conf/config.php-dist conf/config.php\nchmod a+w logs\n- RewriteBase /~lorchard/FeedMagick2\n+ RewriteBase /FeedMagick2</p></div>\n</li>\n<li class=\"comment\" id=\"comment-221082768\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221082768\" class=\"permalink\"><time datetime=\"2007-04-30T17:58:49\">2007-04-30T17:58:49</time></a>\n</div>\n<div class=\"content\"><p>@jm3: Ah!  Good catch.  I really need to eventually installer-ify that kind of stuff.</p></div>\n</li>\n<li class=\"comment\" id=\"comment-221082769\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://xiled.rss-central.net/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=750dbcc9cc192bfad37a3daa4edf139e&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://xiled.rss-central.net/blog\">megalar</a>\n</div>\n<a href=\"#comment-221082769\" class=\"permalink\"><time datetime=\"2007-08-05T12:25:34\">2007-08-05T12:25:34</time></a>\n</div>\n<div class=\"content\"><p>Yesterday my host upgraded to php5 so I ran over to your svn dump and installed feedmagick2.\nAfter editing the $baseurl and rewritebase i tested it and it worked like a charm, so I took a nap.\nUpon waking I was gonna go play with it and see what hacks I could get going with it but something\nwas fubar.\nWarning: fopen(/home/megalar/www/html/feedmagick/logs/feedmagick2-debug-20070805.log) [function.fopen]: failed to open stream: Permission denied in /usr/share/php/Log/file.php on line 216\nare the errors I get as you can see @ <a href=\"http://xiled.rss-central.net/feedmagick/\" rel=\"nofollow\">my site</a>.\nIf it hadn't worked to begin with I would think module problems on my server. To my knowledge, and my host's knowledge, nothing has changed since the upgrade so I'm wondering if it is some sort of bug or a server problem that waited a few hours to reveal itself. The latter doesn't really make much sense to me\nbut I can't rule it out since I'm not r00t on the box and am not 100% certain my host didn't bork something while I slept. </p>\n<pre><code>              anyhoo, your thoughts?\n</code></pre></div>\n</li>\n</ul>\n</div>\n",
    "body": "Yeah, things have been basically silent around here thanks to post-work brain fryage and a general lack of things to say.  Really, everyone else around the blogosphere seems to be covering things satisfactorily.  However, I have been idly working on a new project over the past few weeks, namely a total rewrite and redesign of [my format-ignorant feed filtering and munging kit dubbed FeedMagick](http://decafbad.com/blog/?s=feedmagick).\r\n\r\nYou can find [a demo installation of FeedMagick2 here](http://decafbad.com/2007/04/FeedMagick2/) and find it [ready for checkout from SVN over here](http://decafbad.com/svn/trunk/FeedMagick2/).  It's basically just a step away from being a proof of concept, but I'm hoping to get around to fleshing out docs and battening down the hatches with tests.  In any case, if my serial enthusiasm holds out, this thing could eventually subsume everything else I've done with feeds.\r\n\r\nFor now, peek at some of these highlights:\r\n\r\n   * [Master Personal Feed](http://decafbad.com/2007/04/FeedMagick2/inspect/masterfeed) - One big feed blended from 10 other personal metadata feeds pulled from various Web-2.0-ish sites.\r\n   * [Feed to JSON via Magpie](http://decafbad.com/2007/04/FeedMagick2/inspect/magpiejson) - Get feed data parsed by way of [Magpie](http://magpierss.sourceforge.net/) into JSON data structures\r\n   * [Flickr Favorites Feed](http://decafbad.com/2007/04/FeedMagick2/inspect/flickrfavorites) - Feed of photos marked as favorites by a Flickr user, pulled via the API\r\n   * [jbox.com scraper](http://decafbad.com/2007/04/FeedMagick2/inspect/jbox) - Pipeline composed of [HTML Tidy](http://tidy.sourceforge.net/) and XSL to scrape [jbox.com](http://jbox.com/) to build an RSS feed of new items for sale.\r\n\r\nBeyond practical examples, there are some things under the hood that seem keen to me.  Apropos of my [pipes-via-web ramblings](http://decafbad.com/blog/2007/02/15/thoughts-on-pipes-on-the-web-part-ii) back in February, I'm trying out a few different approaches to pipelining feed content through processor modules.  My original FeedMagick relied on feeding URLs to URLs as parameters.  That, unfortunately, can be mighty cumbersome and inefficient.  So, FeedMagick2 explores a few more approaches:\r\n\r\n   * The first and obvious approach is to chain them together in a single script.  So, I've got objects instances that pass content from one to the next.  The thing is, the pipe works in reverse:  The driver script asks the last module in the pipe for content, which then asks the one before it for content, and so on.  At any point along the way, modules can cache the output of previous modules, and refrain from calling up the chain.\r\n\r\n   * The second way to chain pipelines together is just like the first FeedMagick:  Some pipelines start with fetching a URL.  That can be an original feed, or a URL leading to the output of an antecedent pipeline.  And, oh yeah, most pipelines are run via parameterized URLs, so there's that bit of handy recursion.\r\n\r\n   * The third way to chain pipelines together is with HTTP POST:  A pipeline can accept feed data via the request body of an HTTP POST, thus allowing antecedent pipelines (or even cURL scripts) to *push* data into the pipeline rather than getting *pulled* via URL.  This is kind of like my [years-old jiggery pokery](http://decafbad.com/blog/?s=xmlrpc+pipe) with [pipelines via XML-RPC](http://www.decafbad.com/twiki/bin/view/Main/XmlRpcFilteringPipe), only much *much* simpler.\r\n\r\nI'm also poking around at making all of the above available at the command line via PHP-CLI, and I'm having gratuitous fun exploring PEAR to roll my own stripped-down web framework.  I still hate PHP, but I'm at least finding ways to entertain myself while I'm holding my nose.  Of course, I find weird things entertaining.\r\n\r\nAnd, as a side note, the only reason I'm using PHP is because I'd like to play around with the idea of the de facto WordPress installation requirements standard.  That is:  If you can run WordPress, you can run this.  In reality, I don't think I'm there, but I'm hoping to get close.  For one, I'm refusing to play with anything older than PHP 5.\r\n\r\nAnyway, play with it, tell me what you think and give me a reason to keep hacking at it.  :)\n\n<div id=\"comments\" class=\"comments archived-comments\">\n            <h3>Archived Comments</h3>\n            \n        <ul class=\"comments\">\n            \n        <li class=\"comment\" id=\"comment-221082761\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://jamesv.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=c82c72ca4f9eab33a80a7bd839c1ae0b&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://jamesv.org\">jamesv</a>\n                </div>\n                <a href=\"#comment-221082761\" class=\"permalink\"><time datetime=\"2007-04-30T11:39:15\">2007-04-30T11:39:15</time></a>\n            </div>\n            <div class=\"content\"><p>Aw man, now I've got to port all the code you wrote while you were here over to this new hotness ;) I really like (and appreciate) the single script approach.</p>\n\n<p>Is caching at a module level done automatically, or is that something I need to flag in my original call? Some installs of the original code base are now aggregating large sections of a pool of around 400 feeds, and eeking out even minor performances gains would be just lovely.</p></div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221082762\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=b309c5a1952afc3d7d81ee90908309af&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"\">dRAUPP</a>\n                </div>\n                <a href=\"#comment-221082762\" class=\"permalink\"><time datetime=\"2007-04-30T13:40:16\">2007-04-30T13:40:16</time></a>\n            </div>\n            <div class=\"content\"><p>hawt.</p></div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221082763\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\">l.m.orchard</a>\n                </div>\n                <a href=\"#comment-221082763\" class=\"permalink\"><time datetime=\"2007-04-30T14:43:54\">2007-04-30T14:43:54</time></a>\n            </div>\n            <div class=\"content\"><p>@jamesv: Take a look at the source to this big-ish pipeline, all the way at the end:</p>\n\n<p>http://decafbad.com/2007/04/FeedMagick2/pipelines/masterfeed</p>\n\n<p>You can basically slap a Cacher module at the tail-end or even middle of a long string of modules, and it'll cache the results of everything before it.  I've got a cache lifetime set in the conf/config.php, and you can also set the lifetime in the Cacher parameters.  There can multiple Cacher's per pipeline too.</p>\n\n<p>This thing might not quite yet be even as stable / in working order as the original FeedMagick, but it might be worth poking at for you.  :)</p></div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221082766\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://laughingmeme.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=01457d1a0f0e533062cd0d1033fb4d7a&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://laughingmeme.org\">kellan</a>\n                </div>\n                <a href=\"#comment-221082766\" class=\"permalink\"><time datetime=\"2007-04-30T16:02:31\">2007-04-30T16:02:31</time></a>\n            </div>\n            <div class=\"content\"><blockquote>For one, I’m refusing to play with anything older than PHP 5.</blockquote>\n\n<p>That must be nice.  </p>\n\n<p>And curse you, this looks interesting, now I've got to find time to look at it.</p></div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221082767\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://www.jm3.net/\"><img src=\"http://disqus.com/api/users/avatars/jm3.jpg\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://www.jm3.net/\">John Manoogian III (jm3)</a>\n                </div>\n                <a href=\"#comment-221082767\" class=\"permalink\"><time datetime=\"2007-04-30T17:53:08\">2007-04-30T17:53:08</time></a>\n            </div>\n            <div class=\"content\"><p>addendum to README:</p>\n\nInstallation\n\n<p>cp conf/config.php-dist conf/config.php\n  chmod a+w logs\n- RewriteBase /~lorchard/FeedMagick2\n+ RewriteBase /FeedMagick2</p></div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221082768\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\">l.m.orchard</a>\n                </div>\n                <a href=\"#comment-221082768\" class=\"permalink\"><time datetime=\"2007-04-30T17:58:49\">2007-04-30T17:58:49</time></a>\n            </div>\n            <div class=\"content\"><p>@jm3: Ah!  Good catch.  I really need to eventually installer-ify that kind of stuff.</p></div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221082769\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://xiled.rss-central.net/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=750dbcc9cc192bfad37a3daa4edf139e&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://xiled.rss-central.net/blog\">megalar</a>\n                </div>\n                <a href=\"#comment-221082769\" class=\"permalink\"><time datetime=\"2007-08-05T12:25:34\">2007-08-05T12:25:34</time></a>\n            </div>\n            <div class=\"content\"><p>Yesterday my host upgraded to php5 so I ran over to your svn dump and installed feedmagick2.\nAfter editing the $baseurl and rewritebase i tested it and it worked like a charm, so I took a nap.\nUpon waking I was gonna go play with it and see what hacks I could get going with it but something\n was fubar.\nWarning: fopen(/home/megalar/www/html/feedmagick/logs/feedmagick2-debug-20070805.log) [function.fopen]: failed to open stream: Permission denied in /usr/share/php/Log/file.php on line 216\nare the errors I get as you can see @ <a href=\"http://xiled.rss-central.net/feedmagick/\" rel=\"nofollow\">my site</a>.\nIf it hadn't worked to begin with I would think module problems on my server. To my knowledge, and my host's knowledge, nothing has changed since the upgrade so I'm wondering if it is some sort of bug or a server problem that waited a few hours to reveal itself. The latter doesn't really make much sense to me\nbut I can't rule it out since I'm not r00t on the box and am not 100% certain my host didn't bork something while I slept. </p>\n\n<pre><code>              anyhoo, your thoughts?\n</code></pre></div>\n            \n        </li>\n    \n        </ul>\n    \n        </div>\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2007",
    "path": "2007/04/30/say-hello-to-feedmagick2"
  },
  {
    "comments_archived": true,
    "date": "2006-11-24T06:28:11.000Z",
    "layout": "post",
    "tags": [
      "asides",
      "aggregators",
      "rss",
      "firefox",
      "atom",
      "xsl",
      "xml"
    ],
    "title": "content sniffing sucks",
    "wordpress_id": 1021,
    "wordpress_slug": "content-sniffing-sucks",
    "wordpress_url": "http://decafbad.com/blog/2006/11/24/content-sniffing-sucks",
    "year": "2006",
    "month": "11",
    "day": "24",
    "isDir": false,
    "slug": "content-sniffing-sucks",
    "postName": "2006-11-24-content-sniffing-sucks",
    "html": "<blockquote cite=\"http://www.snellspace.com/wp/?p=530\">If you’re using FF2.0 go <a href=\"http://svn.smedbergs.us/wordpress-atom10/tags/0.6/wp-atom10-comments.php\">here</a> and you’ll see why.<br />No, I don’t want to subscribe to a PHP template used to generate Atom feeds, thank you very much.</blockquote><div class=\"quotesource\">Source: <a href=\"http://www.snellspace.com/wp/?p=530\">snellspace.com » Blog Archive » Content Sniffing Sucks</a></div>\n\n<p>I know this is just taunting <a href=\"http://en.wikipedia.org/wiki/Happy_Fun_Ball\">the Happy Fun Ball</a> I said <a href=\"http://decafbad.com/blog/2006/11/07/firefox-rss-xsl-from-anger-to-apathy\">I was done taunting</a> , but there&#39;s a <a href=\"http://groups.google.com/group/mozilla.dev.apps.firefox/browse_thread/thread/146f70eaf0e1686f/1daec246d79c7dbd#341e610fd279b5fc\">false-positive</a> for ya.  :)</p>\n",
    "body": "<blockquote cite=\"http://www.snellspace.com/wp/?p=530\">If you’re using FF2.0 go <a href=\"http://svn.smedbergs.us/wordpress-atom10/tags/0.6/wp-atom10-comments.php\">here</a> and you’ll see why.<br />No, I don’t want to subscribe to a PHP template used to generate Atom feeds, thank you very much.</blockquote><div class=\"quotesource\">Source: <a href=\"http://www.snellspace.com/wp/?p=530\">snellspace.com » Blog Archive » Content Sniffing Sucks</a></div>\r\n\r\nI know this is just taunting [the Happy Fun Ball](http://en.wikipedia.org/wiki/Happy_Fun_Ball) I said [I was done taunting](http://decafbad.com/blog/2006/11/07/firefox-rss-xsl-from-anger-to-apathy) , but there's a [false-positive](http://groups.google.com/group/mozilla.dev.apps.firefox/browse_thread/thread/146f70eaf0e1686f/1daec246d79c7dbd#341e610fd279b5fc) for ya.  :)\r\n",
    "parentPath": "../blog.lmorchard.com/posts/archives/2006",
    "path": "2006/11/24/content-sniffing-sucks"
  },
  {
    "comments_archived": true,
    "date": "2006-11-15T08:07:12.000Z",
    "layout": "post",
    "tags": [
      "asides",
      "webdev",
      "php",
      "outliners",
      "outlining",
      "xoxooutliner",
      "xsl",
      "xoxo",
      "xml",
      "opml"
    ],
    "title": "XoxoOutliner and further outline addressing adventures",
    "wordpress_id": 1019,
    "wordpress_slug": "xoxooutliner-and-further-outline-addressing-adventures",
    "wordpress_url": "http://decafbad.com/blog/2006/11/15/xoxooutliner-and-further-outline-addressing-adventures",
    "year": "2006",
    "month": "11",
    "day": "15",
    "isDir": false,
    "slug": "xoxooutliner-and-further-outline-addressing-adventures",
    "postName": "2006-11-15-xoxooutliner-and-further-outline-addressing-adventures",
    "html": "<p><a href=\"http://decafbad.com/trac/changeset/779\">Revised the addressing code a bit</a>, adding a few new kinds of addresses and getting ready to support sub-outline <em>updates</em>.  That is, fetch a sub-branch of an outline and then later post a change to that sub-branch using the same address.  Needs more thought - ie. what happens if things move between fetch and update? - but here are a few more samples:</p>\n<ul>\n<li>First is a straight linear index counting down from the top of the outline:<ul>\n<li><a href=\"http://decafbad.com/2006/11/XoxoOutliner/outlines/README;index:4?format=xoxo\">http://decafbad.com/2006/11/XoxoOutliner/outlines/README;index:4?format=xoxo</a></li>\n</ul>\n</li>\n<li>Second is a navigation of outline structure, alternating numbers and letters:<ul>\n<li><a href=\"http://decafbad.com/2006/11/XoxoOutliner/outlines/README;level:3c4?format=xoxo\">http://decafbad.com/2006/11/XoxoOutliner/outlines/README;level:3c4?format=xoxo</a></li>\n</ul>\n</li>\n</ul>\n<p>That&#39;s all for now.  In my next round of enthusiasm, I may try stealing <a href=\"http://blogs.opml.org/tommorris/2006/11/11#opathAToolToPopulariseAConcept\">Tom Morris&#39; Opath idea</a>...</p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221087323\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://vdm.cc/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=a4dae25fe0faeec4f9ff1ad769a52b36&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://vdm.cc/\">Vincent D Murphy</a>\n</div>\n<a href=\"#comment-221087323\" class=\"permalink\"><time datetime=\"2006-11-18T20:52:07\">2006-11-18T20:52:07</time></a>\n</div>\n<div class=\"content\"><p>I think (and said as much on Tom Morris' site) that a fragment identifier would be a better solution, in which case Opath would be a fragment identifier syntax for OPML and XOXO. At least it would be the best solution from a REST/web architecture point of view..</p></div>\n</li>\n<li class=\"comment\" id=\"comment-221087325\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221087325\" class=\"permalink\"><time datetime=\"2006-11-18T21:40:41\">2006-11-18T21:40:41</time></a>\n</div>\n<div class=\"content\"><p>One reason I didn't use the #identifier URI syntax for suboutlines is because some gymnastics need to be done to get the hash through to the server from a browser.  Otherwise, it gets treated as an in-page anchor.  The semicolon syntax seems to work well for a set of path-segment parameters, and follows the standard (if I've read it correctly).  </p>\n<p>In either case, it works for me, and should be just fine in a REST context - the suboutline syntax here should always identify a single parent outline node as a resource, and will eventually work for GET / PUT / POST / DELETE.</p>\n<p>Now I just need to implement a solution for the <a href=\"http://www.w3.org/1999/04/Editing/01\" rel=\"nofollow\">Lost Update Problem</a>.</p></div>\n</li>\n<li class=\"comment\" id=\"comment-221087328\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.dynamiclist.com/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=09eb19f1e84a7aaa63c86bd48c4d0f3d&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.dynamiclist.com/\">Michael Poremba</a>\n</div>\n<a href=\"#comment-221087328\" class=\"permalink\"><time datetime=\"2008-09-18T23:45:56\">2008-09-18T23:45:56</time></a>\n</div>\n<div class=\"content\"><p>Wondering if you ever completed your online outliner? Check out dynamiclist.com, a functioning but incomlete project I launched back in 2001. The editor is rich and works well. Been thinking of reviving now that all major browsers support the contentEditable tag.</p></div>\n</li>\n</ul>\n</div>\n",
    "body": "[Revised the addressing code a bit][rev], adding a few new kinds of addresses and getting ready to support sub-outline *updates*.  That is, fetch a sub-branch of an outline and then later post a change to that sub-branch using the same address.  Needs more thought - ie. what happens if things move between fetch and update? - but here are a few more samples:\r\n\r\n* First is a straight linear index counting down from the top of the outline:\r\n   * [http://decafbad.com/2006/11/XoxoOutliner/outlines/README;index:4?format=xoxo](http://decafbad.com/2006/11/XoxoOutliner/outlines/README;index:4?format=xoxo)\r\n* Second is a navigation of outline structure, alternating numbers and letters:\r\n   * [http://decafbad.com/2006/11/XoxoOutliner/outlines/README;level:3c4?format=xoxo](http://decafbad.com/2006/11/XoxoOutliner/outlines/README;level:3c4?format=xoxo)\r\n\r\nThat's all for now.  In my next round of enthusiasm, I may try stealing [Tom Morris' Opath idea][opath]...\r\n\r\n[rev]: http://decafbad.com/trac/changeset/779\r\n[opath]: http://blogs.opml.org/tommorris/2006/11/11#opathAToolToPopulariseAConcept\n\n<div id=\"comments\" class=\"comments archived-comments\">\n            <h3>Archived Comments</h3>\n            \n        <ul class=\"comments\">\n            \n        <li class=\"comment\" id=\"comment-221087323\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://vdm.cc/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=a4dae25fe0faeec4f9ff1ad769a52b36&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://vdm.cc/\">Vincent D Murphy</a>\n                </div>\n                <a href=\"#comment-221087323\" class=\"permalink\"><time datetime=\"2006-11-18T20:52:07\">2006-11-18T20:52:07</time></a>\n            </div>\n            <div class=\"content\"><p>I think (and said as much on Tom Morris' site) that a fragment identifier would be a better solution, in which case Opath would be a fragment identifier syntax for OPML and XOXO. At least it would be the best solution from a REST/web architecture point of view..</p></div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221087325\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\">l.m.orchard</a>\n                </div>\n                <a href=\"#comment-221087325\" class=\"permalink\"><time datetime=\"2006-11-18T21:40:41\">2006-11-18T21:40:41</time></a>\n            </div>\n            <div class=\"content\"><p>One reason I didn't use the #identifier URI syntax for suboutlines is because some gymnastics need to be done to get the hash through to the server from a browser.  Otherwise, it gets treated as an in-page anchor.  The semicolon syntax seems to work well for a set of path-segment parameters, and follows the standard (if I've read it correctly).  </p>\n\n<p>In either case, it works for me, and should be just fine in a REST context - the suboutline syntax here should always identify a single parent outline node as a resource, and will eventually work for GET / PUT / POST / DELETE.</p>\n\n<p>Now I just need to implement a solution for the <a href=\"http://www.w3.org/1999/04/Editing/01\" rel=\"nofollow\">Lost Update Problem</a>.</p></div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221087328\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://www.dynamiclist.com/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=09eb19f1e84a7aaa63c86bd48c4d0f3d&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://www.dynamiclist.com/\">Michael Poremba</a>\n                </div>\n                <a href=\"#comment-221087328\" class=\"permalink\"><time datetime=\"2008-09-18T23:45:56\">2008-09-18T23:45:56</time></a>\n            </div>\n            <div class=\"content\"><p>Wondering if you ever completed your online outliner? Check out dynamiclist.com, a functioning but incomlete project I launched back in 2001. The editor is rich and works well. Been thinking of reviving now that all major browsers support the contentEditable tag.</p></div>\n            \n        </li>\n    \n        </ul>\n    \n        </div>\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2006",
    "path": "2006/11/15/xoxooutliner-and-further-outline-addressing-adventures"
  },
  {
    "comments_archived": true,
    "date": "2006-11-13T09:34:02.000Z",
    "layout": "post",
    "tags": [
      "asides",
      "webdev",
      "php",
      "outlining",
      "xoxooutliner",
      "xsl",
      "xoxo",
      "xml"
    ],
    "title": "XoxoOutliner and suboutline addressing",
    "wordpress_id": 1018,
    "wordpress_slug": "xoxooutliner-and-suboutline-addressing",
    "wordpress_url": "http://decafbad.com/blog/2006/11/13/xoxooutliner-and-suboutline-addressing",
    "year": "2006",
    "month": "11",
    "day": "13",
    "isDir": false,
    "slug": "xoxooutliner-and-suboutline-addressing",
    "postName": "2006-11-13-xoxooutliner-and-suboutline-addressing",
    "html": "<p>Here&#39;s a feature I <a href=\"http://decafbad.com/trac/changeset/776\">just hacked together</a> for <a href=\"http://decafbad.com/trac/wiki/XoxoOutliner\">XoxoOutliner</a> and plan to refine further:</p>\n<ul>\n<li><a href=\"http://decafbad.com/2006/11/XoxoOutliner/outlines/README;text:Features?format=xoxo\">http://decafbad.com/2006/11/XoxoOutliner/outlines/README;text:Features?format=xoxo</a></li>\n<li><a href=\"http://decafbad.com/2006/11/XoxoOutliner/outlines/README;id:native?format=xoxo\">http://decafbad.com/2006/11/XoxoOutliner/outlines/README;id:native?format=xoxo</a></li>\n<li><a href=\"http://decafbad.com/2006/11/XoxoOutliner/outlines/README;contains:Implement?format=xoxo\">http://decafbad.com/2006/11/XoxoOutliner/outlines/README;contains:Implement?format=xoxo</a></li>\n</ul>\n<p>Not entirely sure that this is how I want this to work, but these three URLs demonstrate the ability to address and fetch subsets of outlines.  I&#39;m hoping this will be a basis for selective transclusion in other outlines, or maybe even in a sidebar of a blog.  (Which, depending on the blog software, might be built from outlines anyway.)</p>\n",
    "body": "Here's a feature I [just hacked together][ha] for [XoxoOutliner][xo] and plan to refine further:\r\n\r\n[ha]: http://decafbad.com/trac/changeset/776\r\n[xo]: http://decafbad.com/trac/wiki/XoxoOutliner\r\n\r\n* [http://decafbad.com/2006/11/XoxoOutliner/outlines/README;text:Features?format=xoxo](http://decafbad.com/2006/11/XoxoOutliner/outlines/README;text:Features?format=xoxo)\r\n* [http://decafbad.com/2006/11/XoxoOutliner/outlines/README;id:native?format=xoxo](http://decafbad.com/2006/11/XoxoOutliner/outlines/README;id:native?format=xoxo)\r\n* [http://decafbad.com/2006/11/XoxoOutliner/outlines/README;contains:Implement?format=xoxo](http://decafbad.com/2006/11/XoxoOutliner/outlines/README;contains:Implement?format=xoxo)\r\n\r\nNot entirely sure that this is how I want this to work, but these three URLs demonstrate the ability to address and fetch subsets of outlines.  I'm hoping this will be a basis for selective transclusion in other outlines, or maybe even in a sidebar of a blog.  (Which, depending on the blog software, might be built from outlines anyway.)\n",
    "parentPath": "../blog.lmorchard.com/posts/archives/2006",
    "path": "2006/11/13/xoxooutliner-and-suboutline-addressing"
  },
  {
    "comments_archived": true,
    "date": "2005-12-19T23:15:03.000Z",
    "layout": "post",
    "tags": [
      "asides",
      "xml",
      "feedmagick",
      "lazyweb",
      "syndcation",
      "facepalm"
    ],
    "title": "Sometimes the lazyweb delivers with a deluge",
    "wordpress_id": 806,
    "wordpress_slug": "sometimes-the-lazyweb-delivers-with-a-deluge",
    "wordpress_url": "http://decafbad.com/blog/?p=806",
    "year": "2005",
    "month": "12",
    "day": "19",
    "isDir": false,
    "slug": "sometimes-the-lazyweb-delivers-with-a-deluge",
    "postName": "2005-12-19-sometimes-the-lazyweb-delivers-with-a-deluge",
    "html": "<blockquote>\n<p><a href=\"http://decafbad.com/blog/2005/12/19/feedburner-feeds-give-heartburn-to-php-xml-parsers#comment-3200\">Kellan</a>: &quot; &#39;… and that’s not my code.&#39; ouch&quot;</p>\n<p><a href=\"http://decafbad.com/blog/2005/12/19/feedburner-feeds-give-heartburn-to-php-xml-parsers#comment-3204\">Eric</a>: &quot;Right now, the only thing we have special for Magpie RSS is that we don’t serve Atom to that user-agent if the version is 0.5.&quot;</p>\n<p><a href=\"http://decafbad.com/blog/2005/12/19/feedburner-feeds-give-heartburn-to-php-xml-parsers#comment-3209\">Rasmus</a>: &quot;I wrote a simple little PHP 5.1-based RSS parser a while back and it doesn’t have any problems with that ... feed.&quot;</p>\n</blockquote>\n<p><small style=\"text-align:right; display:block\">Source: <a href=\"http://decafbad.com/blog/2005/12/19/feedburner-feeds-give-heartburn-to-php-xml-parsers\">Comments on my previous post</a></small></p>\n<p><a href=\"http://www.google.com/search?q=facepalm&amp;start=0&amp;ie=utf-8&amp;oe=utf-8&amp;client=firefox-a&amp;rls=org.mozilla:en-US:official\">Facepalm</a>, <a href=\"http://www.urbandictionary.com/define.php?term=headdesk\">headdesk</a>.  As it turns out, the issue I was having with my PHP XML parsing was that I was trying to cram raw gzip streams down its throat, caused by some odd things I was trying to do with HTTP headers copied cargo-cult style from <a href=\"http://decafbad.com/trac/browser/trunk/FeedMagick/includes/HTTPCache.php\">a Python module I&#39;ve tried reinventing in PHP</a>.  </p>\n<p>In other words, completely braindead work by someone who should know better, even though he&#39;s relatively new to PHP—where <em>he</em> is defined as <strong><em>me</em></strong>.</p>\n<p>But, kudos to the people of the lazyweb for taking the time to triangulate me and remove all doubt within scant hours of my post.  Not counting a half-dozen private emails, I got very quick responses from <a href=\"http://decafbad.com/blog/2005/12/19/feedburner-feeds-give-heartburn-to-php-xml-parsers#comment-3200\">the author of MagpieRSS</a>, <a href=\"http://decafbad.com/blog/2005/12/19/feedburner-feeds-give-heartburn-to-php-xml-parsers#comment-3204\">the CTO of FeedBurner</a>, and <a href=\"http://decafbad.com/blog/2005/12/19/feedburner-feeds-give-heartburn-to-php-xml-parsers#comment-3209\">the creator of PHP himself</a>—each very nicely, clearly, and rightly saying: </p>\n<p><strong>&quot;...and that&#39;s not <em>my</em> code.&quot;</strong></p>\n<p>Be careful when you attempt to invoke the lazyweb, because it might just respond!</p>\n",
    "body": "> [Kellan][k]: \" '… and that’s not my code.' ouch\"\r\n>\r\n> [Eric][e]: \"Right now, the only thing we have special for Magpie RSS is that we don’t serve Atom to that user-agent if the version is 0.5.\"\r\n>\r\n> [Rasmus][r]: \"I wrote a simple little PHP 5.1-based RSS parser a while back and it doesn’t have any problems with that ... feed.\"\r\n\r\n<small style=\"text-align:right; display:block\">Source: <a href=\"http://decafbad.com/blog/2005/12/19/feedburner-feeds-give-heartburn-to-php-xml-parsers\">Comments on my previous post</a></small>\r\n\r\n[Facepalm][fp], [headdesk][hd].  As it turns out, the issue I was having with my PHP XML parsing was that I was trying to cram raw gzip streams down its throat, caused by some odd things I was trying to do with HTTP headers copied cargo-cult style from [a Python module I've tried reinventing in PHP][htc].  \r\n\r\nIn other words, completely braindead work by someone who should know better, even though he's relatively new to PHP—where *he* is defined as ***me***.\r\n\r\nBut, kudos to the people of the lazyweb for taking the time to triangulate me and remove all doubt within scant hours of my post.  Not counting a half-dozen private emails, I got very quick responses from [the author of MagpieRSS][k], [the CTO of FeedBurner][e], and [the creator of PHP himself][r]—each very nicely, clearly, and rightly saying: \r\n\r\n**\"...and that's not *my* code.\"**\r\n\r\nBe careful when you attempt to invoke the lazyweb, because it might just respond!\r\n\r\n[htc]: http://decafbad.com/trac/browser/trunk/FeedMagick/includes/HTTPCache.php\r\n[hd]: http://www.urbandictionary.com/define.php?term=headdesk\r\n[fp]: http://www.google.com/search?q=facepalm&start=0&ie=utf-8&oe=utf-8&client=firefox-a&rls=org.mozilla:en-US:official\r\n[k]: http://decafbad.com/blog/2005/12/19/feedburner-feeds-give-heartburn-to-php-xml-parsers#comment-3200\r\n[e]: http://decafbad.com/blog/2005/12/19/feedburner-feeds-give-heartburn-to-php-xml-parsers#comment-3204\r\n[r]: http://decafbad.com/blog/2005/12/19/feedburner-feeds-give-heartburn-to-php-xml-parsers#comment-3209\n",
    "parentPath": "../blog.lmorchard.com/posts/archives/2005",
    "path": "2005/12/19/sometimes-the-lazyweb-delivers-with-a-deluge"
  },
  {
    "comments_archived": true,
    "date": "2005-12-19T04:17:55.000Z",
    "layout": "post",
    "tags": [
      "asides",
      "ajax",
      "json",
      "webdev",
      "xml"
    ],
    "title": "Okay, okay, JSON is pretty hot",
    "wordpress_id": 802,
    "wordpress_slug": "okay-okay-json-is-pretty-hot",
    "wordpress_url": "http://decafbad.com/blog/?p=802",
    "year": "2005",
    "month": "12",
    "day": "18",
    "isDir": false,
    "slug": "okay-okay-json-is-pretty-hot",
    "postName": "2005-12-18-okay-okay-json-is-pretty-hot",
    "html": "<p>The XML <strike>purist</strike> fanboy in me has had me <em>pshaw</em>&#39;ing at JSON.  But, now that <a href=\"http://ws1.inf.scd.yahoo.com/common/json.html\">the recent JSON release from Yahoo!</a> reminded me of its existence and I <a href=\"http://decafbad.com/2005/12/FeedMagick/docs/json-demo.html\">gave it a shot</a> myself, I have to admit that it&#39;s pretty hot—if only for the cross-domain bridging capabilities and the no-fuss parsing.</p>\n<p>Although, I do worry about running into a poisoned payload someday that raids my cookie jar. </p>\n<!-- tags: webdev ajax json xml -->\n\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221082692\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://beesbuzz.biz/\"><img src=\"http://disqus.com/api/users/avatars/plaidfluff.jpg\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://beesbuzz.biz/\">fluffy</a>\n</div>\n<a href=\"#comment-221082692\" class=\"permalink\"><time datetime=\"2005-12-19T06:50:57\">2005-12-19T06:50:57</time></a>\n</div>\n<div class=\"content\"><p>JSON is currently the big Hot Thing at work.  It's very good for some things, but IMO it's not nearly as robust as XML as far as generic interchange goes.  Its big drawback is that it's not nearly as flexible, and since elements are either unordered or stored in an array, you have to agree upon the actual structure of the document before you send it across the wire (which isn't so much the case with XML where often all you care about is the nesting order which you can handle with XPath or similar).</p>\n<p>It's GREAT for AJAX though, as long as you can trust the server of course.</p></div>\n</li>\n<li class=\"comment\" id=\"comment-221082695\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.whump.com/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=152a649080e99c313ecae9a34c60d11d&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.whump.com/\">Bill Humphries</a>\n</div>\n<a href=\"#comment-221082695\" class=\"permalink\"><time datetime=\"2005-12-19T07:26:09\">2005-12-19T07:26:09</time></a>\n</div>\n<div class=\"content\"><p>I thought <a href=\"http://microformats.org/wiki/rest/ahah\" rel=\"nofollow\">AHAH</a> was the current big thing. Just send HTML to the client and use <code>Element.innerHTML</code>.</p></div>\n</li>\n</ul>\n</div>\n",
    "body": "The XML <strike>purist</strike> fanboy in me has had me *pshaw*'ing at JSON.  But, now that [the recent JSON release from Yahoo!][yj] reminded me of its existence and I [gave it a shot][gs] myself, I have to admit that it's pretty hot—if only for the cross-domain bridging capabilities and the no-fuss parsing.\r\n\r\nAlthough, I do worry about running into a poisoned payload someday that raids my cookie jar. \r\n\r\n<!-- tags: webdev ajax json xml -->\r\n\r\n[yj]: http://ws1.inf.scd.yahoo.com/common/json.html\r\n[gs]: http://decafbad.com/2005/12/FeedMagick/docs/json-demo.html\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221082692\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://beesbuzz.biz/\"><img src=\"http://disqus.com/api/users/avatars/plaidfluff.jpg\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://beesbuzz.biz/\">fluffy</a>\r\n                </div>\r\n                <a href=\"#comment-221082692\" class=\"permalink\"><time datetime=\"2005-12-19T06:50:57\">2005-12-19T06:50:57</time></a>\r\n            </div>\r\n            <div class=\"content\"><p>JSON is currently the big Hot Thing at work.  It's very good for some things, but IMO it's not nearly as robust as XML as far as generic interchange goes.  Its big drawback is that it's not nearly as flexible, and since elements are either unordered or stored in an array, you have to agree upon the actual structure of the document before you send it across the wire (which isn't so much the case with XML where often all you care about is the nesting order which you can handle with XPath or similar).</p>\r\n\r\n<p>It's GREAT for AJAX though, as long as you can trust the server of course.</p></div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221082695\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.whump.com/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=152a649080e99c313ecae9a34c60d11d&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.whump.com/\">Bill Humphries</a>\r\n                </div>\r\n                <a href=\"#comment-221082695\" class=\"permalink\"><time datetime=\"2005-12-19T07:26:09\">2005-12-19T07:26:09</time></a>\r\n            </div>\r\n            <div class=\"content\"><p>I thought <a href=\"http://microformats.org/wiki/rest/ahah\" rel=\"nofollow\">AHAH</a> was the current big thing. Just send HTML to the client and use <code>Element.innerHTML</code>.</p></div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2005",
    "path": "2005/12/19/okay-okay-json-is-pretty-hot"
  },
  {
    "comments_archived": true,
    "date": "2005-09-26T01:12:46.000Z",
    "layout": "post",
    "tags": [
      "webdev",
      "rss",
      "syndication",
      "webservices",
      "atom",
      "xml"
    ],
    "title": "Templates:  Good or Evil?",
    "wordpress_id": 689,
    "wordpress_slug": "templates-good-or-evil",
    "wordpress_url": "http://decafbad.com/blog/?p=689",
    "year": "2005",
    "month": "09",
    "day": "25",
    "isDir": false,
    "slug": "templates-good-or-evil",
    "postName": "2005-09-25-templates-good-or-evil",
    "html": "<blockquote cite=\"http://lachy.id.au/log/2005/04/xhtml-future#comment-271\">This cry and whine that draconian handling will break your page and make your users suffer for you if you have a single error is just another legacy of HTML we’ve gotten used to: our toolchains tend to be of the “glue strings together” (aka templates) variety. ... There should never be any part of your publishing toolchain just gluing strings together. Ever.</blockquote><span style=\"float:right; font-size: 0.75em; width:75%\">Source: <a href=\"http://lachy.id.au/log/2005/04/xhtml-future#comment-271\">Aristotle Pagaltzis in a comment on \"The Future: HTML or XHTML\"</a></span><br style=\"clear:both\" /><blockquote cite=\"http://lesscode.org/2005/09/24/web-services-infrastructure-kid/\">There’s no rule that says templates must only be used to generate HTML. Indeed, many of the RSS and Atom feeds in the wild are generated from some form of template. They are never automatically-generated-behind-the-scenes using language bindings and are very rarely generated using some kind of DOM/SAX API.</blockquote><span style=\"float:right; font-size: 0.75em; width:75%\">Source: <a href=\"http://lesscode.org/2005/09/24/web-services-infrastructure-kid/\">Web Services Infrastructure: Kid Templating  </a></span><br style=\"clear:both\" />\n\n<p>I&#39;ve been meaning to write about this for some time now, though I&#39;ve never had my thoughts together to any degree to mount a decent case for either side.  Problem is, I haven&#39;t gotten much closer now, but I figured I&#39;d at least post a few thoughts and conjure up a vague sketch of the issue.</p>\n<p>You see, I think it all goes back to <a href=\"http://decafbad.com/blog/2002/12/13/oooced\">thoughts about which I posted almost three years ago</a>.  On the one hand, producing something like XML using &quot;proper&quot; DOM invocations and handwavings seems like the &quot;correct&quot; thing to do.  Yet, on the other hand, using a templating system lets me get down to business much more quickly and with much more clarity and succinct code.  </p>\n<p>Yeah, templates provide a range of flexibility sufficient to aim the barrel at your own toes, while an API like the XML DOM keeps everything on the rails--but sometimes you know where you&#39;re going and don&#39;t need the rails to get you there.  Furthermore, isn&#39;t it possible to make a template system that Does The Right Thing?</p>\n<p>Anyway, it&#39;s rather apparent that I&#39;m solidly in favor of templates:  After all, a book of mine just hit the shelves which is just rife with template-based generation of RSS and Atom feeds.  </p>\n<p>My only issue, really, is that I feel vaguely guilty about it.</p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221084924\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=821395fe70906c8290df7f18ac4ac6cf&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"\">rick</a>\n</div>\n<a href=\"#comment-221084924\" class=\"permalink\"><time datetime=\"2005-09-26T02:27:37\">2005-09-26T02:27:37</time></a>\n</div>\n<div class=\"content\">Ruby has the nice Builder module for this (http://builder.rubyforge.org/).  Ruby on Rails uses it for it's rxml templates.  So, you still get the speed of templates, but you don't have to worry about those pesky xml rules.\nHere's a sample Atom 1.0 template used by Typo, a rails weblogging system: http://typo.leetsoft.com/trac/file/trunk/app/views/xml/atom10_feed.rxml</div>\n</li>\n<li class=\"comment\" id=\"comment-221084925\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://plasmasturm.org/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=e17949267bbfe21a0fadf1bbf00592b4&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://plasmasturm.org/\">Aristotle Pagaltzis</a>\n</div>\n<a href=\"#comment-221084925\" class=\"permalink\"><time datetime=\"2005-09-26T03:52:50\">2005-09-26T03:52:50</time></a>\n</div>\n<div class=\"content\">Using the DOM to build documents is awfully awkward. Don&#8217;t do that.\nCheck <a href=\"http://hsivonen.iki.fi/\" rel=\"nofollow\">Henri Sivonen</a>&#8217;s suggestions just published in his <a href=\"http://hsivonen.iki.fi/producing-xml/\" rel=\"nofollow\">HOWTO Avoid Being Called a Bozo When Producing XML</a>. Instead of building a DOM, generate SAX events, using the program structure to ensure proper nesting &#8211; or instead of generating the SAX events all manually, generate them by parsing a static XML document and using certain interesting points in the stream (such as Processing Instructions) as hooks for inserting payload.\nThe emission of synthesised SAX events can be generalised by writing a datastructure-to-SAX serialiser, so that you can build your data within your language&#8217;s native datastructures prior to outputting it, for maximum comfort. (Of course you serialise piecemeal too, f.ex. by outputting the head of a feed manually, then for each item, building the data structure and immediately serialising it, then emitting the final events to complete the document.)\nDepending on the complexity of the output, you could directly emit the otuput format or feed the events into to an XSLT transform that generates the full-blown thing from an easy to generate document structure. In both cases this can be done with or without the involvement of a serialiser as middle man.\nThere are plenty of ways to make sure that the entire toolchain from one end to the other consists only of steps that conserve well-formedness, and they need not be any less convenient than using templates.</div>\n</li>\n<li class=\"comment\" id=\"comment-221084926\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221084926\" class=\"permalink\"><time datetime=\"2005-09-26T04:16:35\">2005-09-26T04:16:35</time></a>\n</div>\n<div class=\"content\"><blockquote>or instead of generating the SAX events all manually, generate them by parsing a static XML document and using certain interesting points in the stream (such as Processing Instructions) as hooks for inserting payload.</blockquote>\nAristotle:  Now here's where I think certain templating technologies get interesting, and may Do the Right Thing.  My so-far-favorite templating kit, ZPT, wants well-formed XML as templates--although I think that restriction is unfortunately relaxed as a nod to HTML.  On the other hand, my possibly-new-favorite templating kit, Kid, [demands well-formed XML as templates](http://lesscode.org/projects/kid/wiki/KidFaq#must-templates-be-well-formed-xml).\nIn case you haven't played with them, these two template languages center around the idea that certain attributes on elements define where content provided in a data structure should be inserted / swapped in by the template engine.  The engine handles character encodings and such to ensure that the well-formed template results in a well-formed document.\nDoes this match up with what you say up there?</div>\n</li>\n<li class=\"comment\" id=\"comment-221084928\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221084928\" class=\"permalink\"><time datetime=\"2005-09-26T04:28:49\">2005-09-26T04:28:49</time></a>\n</div>\n<div class=\"content\">I guess the other thing that bugs me about constructing documents via DOM or via generating SAX events—which I'd first discovered in <a href=\"http://www.xml.com/pub/a/2003/03/12/py-xml.html\" rel=\"nofollow\">this XML.com article by Uche Ogbuji</a>—is how awkward and removed it is from the view-source XML I've gotten used to hacking around with.  Of course, my distaste for programmatically generating things like this goes back to <a href=\"http://perldoc.perl.org/CGI.html#CREATING-STANDARD-HTML-ELEMENTS%3a\" rel=\"nofollow\">CGI.pm</a> in my perl-hacking days.\nWhen I start writing <i>code</i> to generate <i>data</i> that could be mostly done with a template, it strikes me as tangling Model/View/Controller elements and introducing weird context shifts.  (ie. h1() vs &lt;h1 /&gt;)  Not sure if that made sense...</div>\n</li>\n<li class=\"comment\" id=\"comment-221084929\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.sporkmonger.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=56ee28134dd0776825445e3551979b14&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.sporkmonger.com\">Bob Aman</a>\n</div>\n<a href=\"#comment-221084929\" class=\"permalink\"><time datetime=\"2005-09-26T05:40:24\">2005-09-26T05:40:24</time></a>\n</div>\n<div class=\"content\">Yeah, I was gonna say, Builder for Ruby solves most of the issues with using templates and xml.  For RSS and Atom, there's also my Ruby FeedTools library, which makes it even more rediculously easy to get a valid feed up and running.\nI'm also very tempted to play around with Kid and see how I like it, and perhaps port it to Ruby.  From what I've seen so far, it looks like perhaps the nicest templating system yet.</div>\n</li>\n<li class=\"comment\" id=\"comment-221084930\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://plasmasturm.org/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=e17949267bbfe21a0fadf1bbf00592b4&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://plasmasturm.org/\">Aristotle Pagaltzis</a>\n</div>\n<a href=\"#comment-221084930\" class=\"permalink\"><time datetime=\"2005-09-26T05:59:08\">2005-09-26T05:59:08</time></a>\n</div>\n<div class=\"content\">It does. I confess I actually kind of liked <a href=\"http://search.cpan.org/dist/CGI.pm/\" rel=\"nofollow\">CGI.pm</a> &#8211; because nesting is automatically taken care of without so much typing of end tags, and you can seamlessly weave <code>map</code>s into the code for output loops.\nI have to note though that I used it as a sort of template language in its own right &#8211; I never littered <code>print</code>s all over my code, I kept all the calls in a single place, in fact, usually a single expression. That is also why I find it strange that people create template languages for PHP, which was itself born as a template language. What matters is that the output generation is separate from the processing logic, whether or not the template and the code are in different languages.\nAnyway, I digress.\nWhat I wanted to say is, no, I hadn&#8217;t seen either ZPT or Kid. I had put off reading the lesscode.org article you quoted and went back to it after responding here. Now that I&#8217;ve read it, I admit I&#8217;m intrigued. I&#8217;ll have to look into Kid; it sounds like an interesting take.</div>\n</li>\n<li class=\"comment\" id=\"comment-221084931\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221084931\" class=\"permalink\"><time datetime=\"2005-09-26T13:39:00\">2005-09-26T13:39:00</time></a>\n</div>\n<div class=\"content\"><blockquote>What matters is that the output generation is separate from the processing logic, whether or not the template and the code are in different languages.</blockquote>\nAh hah, yeah, that's what I was fumbling toward with the sleepy tail-end of my comment.  Logic and presentation in separate blocks / files / etc.  And then, my take is that if you're going to have your presentation/view separate from the logic/controller, you may as well code the presentation in a form as close to the goal as possible (ie. in XML or HTML, not in s-expressions or the logic implementation idiom)—especially since oftimes you've got separate people or teams working primarily on each.\nI suspect, however, that a templating system like Kid goes quite a ways toward solving the problem of \"gluing strings together\".  I almost wish it had been further along / I'd been more aware of it before I'd reinvented my own wheels for my book using Python string templates and funky map classes.</div>\n</li>\n<li class=\"comment\" id=\"comment-221084932\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://naeblis.cx/rtomayko/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=abfc88b96ae18c85ba7aac3bded2ec5e&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://naeblis.cx/rtomayko/\">Ryan Tomayko</a>\n</div>\n<a href=\"#comment-221084932\" class=\"permalink\"><time datetime=\"2005-09-26T19:00:44\">2005-09-26T19:00:44</time></a>\n</div>\n<div class=\"content\"><blockquote>I suspect, however, that a templating system like Kid goes quite a ways toward solving the problem of “gluing strings together”.</blockquote>\nThat's the idea. The correctness of DOM/SAX based contruction with the ease-of-use of templating. The future of Kid is somewhat uncertain. I'm hoping to wrap up 1.0 and stabalize it for Kevin and TurboGears but what I'd personally really love to see is the general concept of \"structured templating\" reach a wider audience.</div>\n</li>\n<li class=\"comment\" id=\"comment-221084933\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://naeblis.cx/rtomayko/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=abfc88b96ae18c85ba7aac3bded2ec5e&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://naeblis.cx/rtomayko/\">Ryan Tomayko</a>\n</div>\n<a href=\"#comment-221084933\" class=\"permalink\"><time datetime=\"2005-09-26T19:02:17\">2005-09-26T19:02:17</time></a>\n</div>\n<div class=\"content\">Oops. Sorry about the rough formatting. For some reason I thought comments were in markdown. Edit away, Leslie.</div>\n</li>\n<li class=\"comment\" id=\"comment-221084934\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221084934\" class=\"permalink\"><time datetime=\"2005-09-26T19:11:20\">2005-09-26T19:11:20</time></a>\n</div>\n<div class=\"content\">Ryan:  Grr.  Funny you should mention that—I thought comments around here allowed markdown, too.  I think I need to fix that *and* display some copy explaining markdown availablility, since I think that was something about which Aristotle expressed some confusion/surprise before as well.</div>\n</li>\n<li class=\"comment\" id=\"comment-221084935\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://plasmasturm.org/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=e17949267bbfe21a0fadf1bbf00592b4&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://plasmasturm.org/\">Aristotle Pagaltzis</a>\n</div>\n<a href=\"#comment-221084935\" class=\"permalink\"><time datetime=\"2005-09-26T20:29:12\">2005-09-26T20:29:12</time></a>\n</div>\n<div class=\"content\"><blockquote>if you&#8217;re going to have your presentation/view separate from the logic/controller, you may as well code the presentation in a form as close to the goal as possible</blockquote>\nOh, I don&#8217;t disagree at all.\nI have been annoyed at the state of XML generation at large, myself. Kid looks very nice, except I have no use for it, being that I&#8217;m still a Perlista. (Python just doesn&#8217;t feel right to me &#8211; like wearing a badly fitting tuxedo.)\nI&#8217;m wondering how much work it would be to port it or a close copy to Perl&#8230;\n<blockquote>I think that was something about which Aristotle expressed some confusion/surprise before as well.</blockquote>\nHeh, yeah. Your MT installation permitted Markdown but no literal tags, which caught me off guard once or twice until I noticed. But thankfully it had a preview button, so I could figure it out. I <strong><em>hate</em></strong> how WordPress does not ship with preview button available and enabled by default, and the default configuration doesn't even mention the expected formatting anywhere either.\nI just suspected that your WordPress was vanilla and used HTML on that hunch &#8211; and it worked. Phew. Maybe you can install the gagdget that Ryan uses on lesscode.org? I love that.</div>\n</li>\n<li class=\"comment\" id=\"comment-221084936\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221084936\" class=\"permalink\"><time datetime=\"2005-09-26T21:38:08\">2005-09-26T21:38:08</time></a>\n</div>\n<div class=\"content\"><blockquote>\n<p>I just suspected that your WordPress was vanilla and used HTML on that hunch – and it worked. Phew. Maybe you can install the gagdget that Ryan uses on lesscode.org? I love that.</p>\n</blockquote>\n<p>Your wish is my command.  At least, in this instance.  I pawed through Ryan's HTML source and got sufficient clues to install this thing and shamelessly steal a snippet or two.  Let's see if this preview works and if it accurately reflects what this will look like when I post...</p></div>\n</li>\n<li class=\"comment\" id=\"comment-221084937\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.emacswiki.org/alex/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=73d2617de46d85c306dbdf533b72fded&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.emacswiki.org/alex/\">Alex Schröder</a>\n</div>\n<a href=\"#comment-221084937\" class=\"permalink\"><time datetime=\"2005-09-27T11:22:06\">2005-09-27T11:22:06</time></a>\n</div>\n<div class=\"content\"><p>I maintain Oddmuse, a wiki engine written in Perl, using CGI.pm to generate the HTML.  Often people want me to switch to templates.  At the moment, when you want to radically change the HTML for the stuff that is not the wiki content, ie. headers and footers, you need to override the Perl subs that I provide.  Somehow that strikes me as natural and easy, but many of my users seem to disagree, preferring to learn a templating system instead of learning to write Perl code.  I'm still undecided about the issue.  At the moment I'm still sticking to the \"write Perl code instead of templating\" because being able to write Perl code will make so many other task easy.</p></div>\n</li>\n<li class=\"comment\" id=\"comment-221084938\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221084938\" class=\"permalink\"><time datetime=\"2005-09-27T11:31:23\">2005-09-27T11:31:23</time></a>\n</div>\n<div class=\"content\"><p>Alex:  Well, from my perspective, I've worked on a lot of teams where you've essentially got two roles—software engineer (SE) and interface engineer (IE).  Depending on the company and the team, the SE might understand Perl/Python/Java/SQL while the IE might understand HTML/CSS/Javascript/Flash.  There's usually overlap, of course, but these are the roles on paper at least.</p>\n<p>When you're trying to come up with an overarching framework which accomodates collaboration between these two sorts of people and their respective skill sets, it helps to have a bridge between the logic and the presentation which can keep the Perl out of the HTML and the HTML out of the Perl.</p>\n<p>On the other hand...  A project like Oddmuse likely has an entirely different user and developer base than the projects I work on at my day job :)</p></div>\n</li>\n</ul>\n</div>\n",
    "body": "<blockquote cite=\"http://lachy.id.au/log/2005/04/xhtml-future#comment-271\">This cry and whine that draconian handling will break your page and make your users suffer for you if you have a single error is just another legacy of HTML we’ve gotten used to: our toolchains tend to be of the “glue strings together” (aka templates) variety. ... There should never be any part of your publishing toolchain just gluing strings together. Ever.</blockquote><span style=\"float:right; font-size: 0.75em; width:75%\">Source: <a href=\"http://lachy.id.au/log/2005/04/xhtml-future#comment-271\">Aristotle Pagaltzis in a comment on \"The Future: HTML or XHTML\"</a></span><br style=\"clear:both\" /><blockquote cite=\"http://lesscode.org/2005/09/24/web-services-infrastructure-kid/\">There’s no rule that says templates must only be used to generate HTML. Indeed, many of the RSS and Atom feeds in the wild are generated from some form of template. They are never automatically-generated-behind-the-scenes using language bindings and are very rarely generated using some kind of DOM/SAX API.</blockquote><span style=\"float:right; font-size: 0.75em; width:75%\">Source: <a href=\"http://lesscode.org/2005/09/24/web-services-infrastructure-kid/\">Web Services Infrastructure: Kid Templating  </a></span><br style=\"clear:both\" />\r\n\r\nI've been meaning to write about this for some time now, though I've never had my thoughts together to any degree to mount a decent case for either side.  Problem is, I haven't gotten much closer now, but I figured I'd at least post a few thoughts and conjure up a vague sketch of the issue.\r\n\r\nYou see, I think it all goes back to [thoughts about which I posted almost three years ago][lazy].  On the one hand, producing something like XML using \"proper\" DOM invocations and handwavings seems like the \"correct\" thing to do.  Yet, on the other hand, using a templating system lets me get down to business much more quickly and with much more clarity and succinct code.  \r\n\r\nYeah, templates provide a range of flexibility sufficient to aim the barrel at your own toes, while an API like the XML DOM keeps everything on the rails--but sometimes you know where you're going and don't need the rails to get you there.  Furthermore, isn't it possible to make a template system that Does The Right Thing?\r\n\r\nAnyway, it's rather apparent that I'm solidly in favor of templates:  After all, a book of mine just hit the shelves which is just rife with template-based generation of RSS and Atom feeds.  \r\n\r\nMy only issue, really, is that I feel vaguely guilty about it.\r\n\r\n[lazy]: http://decafbad.com/blog/2002/12/13/oooced\n\n<div id=\"comments\" class=\"comments archived-comments\">\n            <h3>Archived Comments</h3>\n            \n        <ul class=\"comments\">\n            \n        <li class=\"comment\" id=\"comment-221084924\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=821395fe70906c8290df7f18ac4ac6cf&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"\">rick</a>\n                </div>\n                <a href=\"#comment-221084924\" class=\"permalink\"><time datetime=\"2005-09-26T02:27:37\">2005-09-26T02:27:37</time></a>\n            </div>\n            <div class=\"content\">Ruby has the nice Builder module for this (http://builder.rubyforge.org/).  Ruby on Rails uses it for it's rxml templates.  So, you still get the speed of templates, but you don't have to worry about those pesky xml rules.\n\nHere's a sample Atom 1.0 template used by Typo, a rails weblogging system: http://typo.leetsoft.com/trac/file/trunk/app/views/xml/atom10_feed.rxml</div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221084925\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://plasmasturm.org/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=e17949267bbfe21a0fadf1bbf00592b4&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://plasmasturm.org/\">Aristotle Pagaltzis</a>\n                </div>\n                <a href=\"#comment-221084925\" class=\"permalink\"><time datetime=\"2005-09-26T03:52:50\">2005-09-26T03:52:50</time></a>\n            </div>\n            <div class=\"content\">Using the DOM to build documents is awfully awkward. Don&#8217;t do that.\n\nCheck <a href=\"http://hsivonen.iki.fi/\" rel=\"nofollow\">Henri Sivonen</a>&#8217;s suggestions just published in his <a href=\"http://hsivonen.iki.fi/producing-xml/\" rel=\"nofollow\">HOWTO Avoid Being Called a Bozo When Producing XML</a>. Instead of building a DOM, generate SAX events, using the program structure to ensure proper nesting &#8211; or instead of generating the SAX events all manually, generate them by parsing a static XML document and using certain interesting points in the stream (such as Processing Instructions) as hooks for inserting payload.\n\nThe emission of synthesised SAX events can be generalised by writing a datastructure-to-SAX serialiser, so that you can build your data within your language&#8217;s native datastructures prior to outputting it, for maximum comfort. (Of course you serialise piecemeal too, f.ex. by outputting the head of a feed manually, then for each item, building the data structure and immediately serialising it, then emitting the final events to complete the document.)\n\nDepending on the complexity of the output, you could directly emit the otuput format or feed the events into to an XSLT transform that generates the full-blown thing from an easy to generate document structure. In both cases this can be done with or without the involvement of a serialiser as middle man.\n\nThere are plenty of ways to make sure that the entire toolchain from one end to the other consists only of steps that conserve well-formedness, and they need not be any less convenient than using templates.</div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221084926\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\">l.m.orchard</a>\n                </div>\n                <a href=\"#comment-221084926\" class=\"permalink\"><time datetime=\"2005-09-26T04:16:35\">2005-09-26T04:16:35</time></a>\n            </div>\n            <div class=\"content\"><blockquote>or instead of generating the SAX events all manually, generate them by parsing a static XML document and using certain interesting points in the stream (such as Processing Instructions) as hooks for inserting payload.</blockquote>\nAristotle:  Now here's where I think certain templating technologies get interesting, and may Do the Right Thing.  My so-far-favorite templating kit, ZPT, wants well-formed XML as templates--although I think that restriction is unfortunately relaxed as a nod to HTML.  On the other hand, my possibly-new-favorite templating kit, Kid, [demands well-formed XML as templates](http://lesscode.org/projects/kid/wiki/KidFaq#must-templates-be-well-formed-xml).\n\nIn case you haven't played with them, these two template languages center around the idea that certain attributes on elements define where content provided in a data structure should be inserted / swapped in by the template engine.  The engine handles character encodings and such to ensure that the well-formed template results in a well-formed document.\n\nDoes this match up with what you say up there?</div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221084928\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\">l.m.orchard</a>\n                </div>\n                <a href=\"#comment-221084928\" class=\"permalink\"><time datetime=\"2005-09-26T04:28:49\">2005-09-26T04:28:49</time></a>\n            </div>\n            <div class=\"content\">I guess the other thing that bugs me about constructing documents via DOM or via generating SAX events—which I'd first discovered in <a href=\"http://www.xml.com/pub/a/2003/03/12/py-xml.html\" rel=\"nofollow\">this XML.com article by Uche Ogbuji</a>—is how awkward and removed it is from the view-source XML I've gotten used to hacking around with.  Of course, my distaste for programmatically generating things like this goes back to <a href=\"http://perldoc.perl.org/CGI.html#CREATING-STANDARD-HTML-ELEMENTS%3a\" rel=\"nofollow\">CGI.pm</a> in my perl-hacking days.\n\nWhen I start writing <i>code</i> to generate <i>data</i> that could be mostly done with a template, it strikes me as tangling Model/View/Controller elements and introducing weird context shifts.  (ie. h1() vs &lt;h1 /&gt;)  Not sure if that made sense...</div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221084929\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://www.sporkmonger.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=56ee28134dd0776825445e3551979b14&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://www.sporkmonger.com\">Bob Aman</a>\n                </div>\n                <a href=\"#comment-221084929\" class=\"permalink\"><time datetime=\"2005-09-26T05:40:24\">2005-09-26T05:40:24</time></a>\n            </div>\n            <div class=\"content\">Yeah, I was gonna say, Builder for Ruby solves most of the issues with using templates and xml.  For RSS and Atom, there's also my Ruby FeedTools library, which makes it even more rediculously easy to get a valid feed up and running.\n\nI'm also very tempted to play around with Kid and see how I like it, and perhaps port it to Ruby.  From what I've seen so far, it looks like perhaps the nicest templating system yet.</div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221084930\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://plasmasturm.org/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=e17949267bbfe21a0fadf1bbf00592b4&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://plasmasturm.org/\">Aristotle Pagaltzis</a>\n                </div>\n                <a href=\"#comment-221084930\" class=\"permalink\"><time datetime=\"2005-09-26T05:59:08\">2005-09-26T05:59:08</time></a>\n            </div>\n            <div class=\"content\">It does. I confess I actually kind of liked <a href=\"http://search.cpan.org/dist/CGI.pm/\" rel=\"nofollow\">CGI.pm</a> &#8211; because nesting is automatically taken care of without so much typing of end tags, and you can seamlessly weave <code>map</code>s into the code for output loops.\n\nI have to note though that I used it as a sort of template language in its own right &#8211; I never littered <code>print</code>s all over my code, I kept all the calls in a single place, in fact, usually a single expression. That is also why I find it strange that people create template languages for PHP, which was itself born as a template language. What matters is that the output generation is separate from the processing logic, whether or not the template and the code are in different languages.\n\nAnyway, I digress.\n\nWhat I wanted to say is, no, I hadn&#8217;t seen either ZPT or Kid. I had put off reading the lesscode.org article you quoted and went back to it after responding here. Now that I&#8217;ve read it, I admit I&#8217;m intrigued. I&#8217;ll have to look into Kid; it sounds like an interesting take.</div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221084931\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\">l.m.orchard</a>\n                </div>\n                <a href=\"#comment-221084931\" class=\"permalink\"><time datetime=\"2005-09-26T13:39:00\">2005-09-26T13:39:00</time></a>\n            </div>\n            <div class=\"content\"><blockquote>What matters is that the output generation is separate from the processing logic, whether or not the template and the code are in different languages.</blockquote>\n\nAh hah, yeah, that's what I was fumbling toward with the sleepy tail-end of my comment.  Logic and presentation in separate blocks / files / etc.  And then, my take is that if you're going to have your presentation/view separate from the logic/controller, you may as well code the presentation in a form as close to the goal as possible (ie. in XML or HTML, not in s-expressions or the logic implementation idiom)—especially since oftimes you've got separate people or teams working primarily on each.\n\nI suspect, however, that a templating system like Kid goes quite a ways toward solving the problem of \"gluing strings together\".  I almost wish it had been further along / I'd been more aware of it before I'd reinvented my own wheels for my book using Python string templates and funky map classes.</div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221084932\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://naeblis.cx/rtomayko/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=abfc88b96ae18c85ba7aac3bded2ec5e&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://naeblis.cx/rtomayko/\">Ryan Tomayko</a>\n                </div>\n                <a href=\"#comment-221084932\" class=\"permalink\"><time datetime=\"2005-09-26T19:00:44\">2005-09-26T19:00:44</time></a>\n            </div>\n            <div class=\"content\"><blockquote>I suspect, however, that a templating system like Kid goes quite a ways toward solving the problem of “gluing strings together”.</blockquote>\n\nThat's the idea. The correctness of DOM/SAX based contruction with the ease-of-use of templating. The future of Kid is somewhat uncertain. I'm hoping to wrap up 1.0 and stabalize it for Kevin and TurboGears but what I'd personally really love to see is the general concept of \"structured templating\" reach a wider audience.</div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221084933\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://naeblis.cx/rtomayko/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=abfc88b96ae18c85ba7aac3bded2ec5e&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://naeblis.cx/rtomayko/\">Ryan Tomayko</a>\n                </div>\n                <a href=\"#comment-221084933\" class=\"permalink\"><time datetime=\"2005-09-26T19:02:17\">2005-09-26T19:02:17</time></a>\n            </div>\n            <div class=\"content\">Oops. Sorry about the rough formatting. For some reason I thought comments were in markdown. Edit away, Leslie.</div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221084934\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\">l.m.orchard</a>\n                </div>\n                <a href=\"#comment-221084934\" class=\"permalink\"><time datetime=\"2005-09-26T19:11:20\">2005-09-26T19:11:20</time></a>\n            </div>\n            <div class=\"content\">Ryan:  Grr.  Funny you should mention that—I thought comments around here allowed markdown, too.  I think I need to fix that *and* display some copy explaining markdown availablility, since I think that was something about which Aristotle expressed some confusion/surprise before as well.</div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221084935\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://plasmasturm.org/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=e17949267bbfe21a0fadf1bbf00592b4&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://plasmasturm.org/\">Aristotle Pagaltzis</a>\n                </div>\n                <a href=\"#comment-221084935\" class=\"permalink\"><time datetime=\"2005-09-26T20:29:12\">2005-09-26T20:29:12</time></a>\n            </div>\n            <div class=\"content\"><blockquote>if you&#8217;re going to have your presentation/view separate from the logic/controller, you may as well code the presentation in a form as close to the goal as possible</blockquote>\n\nOh, I don&#8217;t disagree at all.\n\nI have been annoyed at the state of XML generation at large, myself. Kid looks very nice, except I have no use for it, being that I&#8217;m still a Perlista. (Python just doesn&#8217;t feel right to me &#8211; like wearing a badly fitting tuxedo.)\n\nI&#8217;m wondering how much work it would be to port it or a close copy to Perl&#8230;\n\n<blockquote>I think that was something about which Aristotle expressed some confusion/surprise before as well.</blockquote>\n\nHeh, yeah. Your MT installation permitted Markdown but no literal tags, which caught me off guard once or twice until I noticed. But thankfully it had a preview button, so I could figure it out. I <strong><em>hate</em></strong> how WordPress does not ship with preview button available and enabled by default, and the default configuration doesn't even mention the expected formatting anywhere either.\n\nI just suspected that your WordPress was vanilla and used HTML on that hunch &#8211; and it worked. Phew. Maybe you can install the gagdget that Ryan uses on lesscode.org? I love that.</div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221084936\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\">l.m.orchard</a>\n                </div>\n                <a href=\"#comment-221084936\" class=\"permalink\"><time datetime=\"2005-09-26T21:38:08\">2005-09-26T21:38:08</time></a>\n            </div>\n            <div class=\"content\"><blockquote>\n  <p>I just suspected that your WordPress was vanilla and used HTML on that hunch – and it worked. Phew. Maybe you can install the gagdget that Ryan uses on lesscode.org? I love that.</p>\n</blockquote>\n\n<p>Your wish is my command.  At least, in this instance.  I pawed through Ryan's HTML source and got sufficient clues to install this thing and shamelessly steal a snippet or two.  Let's see if this preview works and if it accurately reflects what this will look like when I post...</p></div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221084937\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://www.emacswiki.org/alex/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=73d2617de46d85c306dbdf533b72fded&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://www.emacswiki.org/alex/\">Alex Schröder</a>\n                </div>\n                <a href=\"#comment-221084937\" class=\"permalink\"><time datetime=\"2005-09-27T11:22:06\">2005-09-27T11:22:06</time></a>\n            </div>\n            <div class=\"content\"><p>I maintain Oddmuse, a wiki engine written in Perl, using CGI.pm to generate the HTML.  Often people want me to switch to templates.  At the moment, when you want to radically change the HTML for the stuff that is not the wiki content, ie. headers and footers, you need to override the Perl subs that I provide.  Somehow that strikes me as natural and easy, but many of my users seem to disagree, preferring to learn a templating system instead of learning to write Perl code.  I'm still undecided about the issue.  At the moment I'm still sticking to the \"write Perl code instead of templating\" because being able to write Perl code will make so many other task easy.</p></div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221084938\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\">l.m.orchard</a>\n                </div>\n                <a href=\"#comment-221084938\" class=\"permalink\"><time datetime=\"2005-09-27T11:31:23\">2005-09-27T11:31:23</time></a>\n            </div>\n            <div class=\"content\"><p>Alex:  Well, from my perspective, I've worked on a lot of teams where you've essentially got two roles—software engineer (SE) and interface engineer (IE).  Depending on the company and the team, the SE might understand Perl/Python/Java/SQL while the IE might understand HTML/CSS/Javascript/Flash.  There's usually overlap, of course, but these are the roles on paper at least.</p>\n\n<p>When you're trying to come up with an overarching framework which accomodates collaboration between these two sorts of people and their respective skill sets, it helps to have a bridge between the logic and the presentation which can keep the Perl out of the HTML and the HTML out of the Perl.</p>\n\n<p>On the other hand...  A project like Oddmuse likely has an entirely different user and developer base than the projects I work on at my day job :)</p></div>\n            \n        </li>\n    \n        </ul>\n    \n        </div>\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2005",
    "path": "2005/09/26/templates-good-or-evil"
  },
  {
    "comments_archived": true,
    "date": "2005-09-13T23:45:47.000Z",
    "layout": "post",
    "tags": [
      "rss",
      "syndication",
      "writing",
      "atom",
      "xml",
      "books",
      "hackingrssandatom"
    ],
    "title": "Hacking RSS and Atom is out!",
    "wordpress_id": 680,
    "wordpress_slug": "hacking-rss-and-atom-is-out",
    "wordpress_url": "http://www.decafbad.com/blog/?p=680",
    "year": "2005",
    "month": "09",
    "day": "13",
    "isDir": false,
    "slug": "hacking-rss-and-atom-is-out",
    "postName": "2005-09-13-hacking-rss-and-atom-is-out",
    "html": "<p>If you&#39;ve been following along with me these past months, you might&#39;ve gotten the gist that <a href=\"http://www.decafbad.com/blog/2005/04/25/hacking-rss-and-atom-is-a-real-book\">I&#39;ve been working on a book</a>.  Well, lookee what landed on my doorstep late Friday afternoon--my author copies!</p>\n<p>\n<a href=\"http://www.decafbad.com/blog_attachments/IMG_3554-1.JPG\" onclick=\"window.open('http://www.decafbad.com/blog_attachments/IMG_3554-1.JPG','popup','width=1024,height=768,scrollbars=no,resizable=yes,toolbar=no,directories=no,location=no,menubar=no,status=yes,left=0,top=0');return false\"><img src=\"http://www.decafbad.com/blog_attachments/IMG_3554-1-tm.jpg\" height=\"253\" width=\"337\" border=\"1\" align=\"middle\" hspace=\"4\" vspace=\"4\" alt=\"Cue the angelic chorus\" title=\"Cue the angelic chorus\" /></a>\n</p>\n\n<p>This package was actually supposed to have been delivered on Thursday.  But, much to my consternation, I wasn&#39;t present to sign for the package.  But now, I&#39;ve got the surreal experience of holding a bound volume of around 600 pages with my name on the cover.  And inside?  There&#39;s all this stuff that once appeared on my PowerBook screen in MS Word and Terminal windows.  (Oh yeah, and there&#39;re a few photos of my iPod thrown in for good measure.)</p>\n<p>Funny thing is, this process started for me back in late <a href=\"http://www.decafbad.com/blog/2004/12/\">December 2004</a>.  But, you&#39;d barely know it, because--for whatever reason--I started off pretty cagey about the whole thing, and then plunged headlong into the effort.  I did manage to make <a href=\"http://www.decafbad.com/blog/2005/01/07/belated-happy-new-year\">a quick announcement of authorship</a>, but thereafter only managed to emerge for a few <a href=\"http://www.decafbad.com/blog/2005/02/19/writing-no-things-of-epic-import\">quick thought dumps</a>.</p>\n<p>I think part of my silence about things stemmed from a reticence to talk about or promise anything before I&#39;d written it--and also because this has been my first time doing anything like this and I didn&#39;t want to flub anything up along the way.  How I might&#39;ve done that, who knows?  But, I got a bit too busy to really worry about superstitions as the deadlines rolled on.</p>\n<p>But now, it&#39;s out!  And <a href=\"http://www.amazon.com/exec/obidos/ASIN/0764597582/0xdecafbad01-20?creative=327641&amp;camp=14573&amp;link_code=as1\">you should buy it!</a>  Lookee, lookee:  It&#39;s already got a 5-star review from someone I don&#39;t even know!</p>\n<p>For the moment, I&#39;m going to wrap up this post, finish my dinner, and go for a walk with the girl--but, when we get back, I think I might post a few more details on what you&#39;ll find in my book debut. </p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221082500\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://monkey.org/~jose/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=d74863ca9c7785cd396379766095036c&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://monkey.org/~jose/\">jose</a>\n</div>\n<a href=\"#comment-221082500\" class=\"permalink\"><time datetime=\"2005-09-14T01:03:36\">2005-09-14T01:03:36</time></a>\n</div>\n<div class=\"content\">congrats, les, if anyone should have written that book it's you. i'm glad to see it's hit the shelves .. now to go find a copy and look it over :)</div>\n</li>\n<li class=\"comment\" id=\"comment-221082501\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://stingthebee.nu\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=0c6c4240507baf594a95fd3b25b975d2&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://stingthebee.nu\">Jim Renaud</a>\n</div>\n<a href=\"#comment-221082501\" class=\"permalink\"><time datetime=\"2005-09-14T01:54:39\">2005-09-14T01:54:39</time></a>\n</div>\n<div class=\"content\">Congrats Les. I am gonna need you to autograph mine!!! New site design, new box, new CMS... The world is your oyster!!! It's Les' world, we just live in it!!!</div>\n</li>\n<li class=\"comment\" id=\"comment-221082503\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.livejournal.com/users/blackcustard/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=96dd5db5ebd7a91a5df453707ffa8d8d&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.livejournal.com/users/blackcustard/\">Matt Blackcustard</a>\n</div>\n<a href=\"#comment-221082503\" class=\"permalink\"><time datetime=\"2005-09-14T02:52:08\">2005-09-14T02:52:08</time></a>\n</div>\n<div class=\"content\">Hell yeah!</div>\n</li>\n<li class=\"comment\" id=\"comment-221082505\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.8dot3.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2d870e8df3af0d62fa636b336b17cd60&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.8dot3.com\">Nick</a>\n</div>\n<a href=\"#comment-221082505\" class=\"permalink\"><time datetime=\"2005-09-14T04:15:22\">2005-09-14T04:15:22</time></a>\n</div>\n<div class=\"content\">Just ordered mine...whens the book signing?..\nCongrats man..</div>\n</li>\n<li class=\"comment\" id=\"comment-221082507\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://10500bc.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=00ceff438a69a964d580f8384debcc0e&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://10500bc.org\">nf0</a>\n</div>\n<a href=\"#comment-221082507\" class=\"permalink\"><time datetime=\"2005-09-19T21:41:49\">2005-09-19T21:41:49</time></a>\n</div>\n<div class=\"content\">I got my copy over the weekend. Some really good work!</div>\n</li>\n<li class=\"comment\" id=\"comment-221082508\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221082508\" class=\"permalink\"><time datetime=\"2005-09-19T22:50:23\">2005-09-19T22:50:23</time></a>\n</div>\n<div class=\"content\">nf0: Hooray!  Thanks for the kudos :)</div>\n</li>\n</ul>\n</div>\n",
    "body": "If you've been following along with me these past months, you might've gotten the gist that [I've been working on a book][book].  Well, lookee what landed on my doorstep late Friday afternoon--my author copies!\r\n\r\n<p>\r\n<a href=\"http://www.decafbad.com/blog_attachments/IMG_3554-1.JPG\" onclick=\"window.open('http://www.decafbad.com/blog_attachments/IMG_3554-1.JPG','popup','width=1024,height=768,scrollbars=no,resizable=yes,toolbar=no,directories=no,location=no,menubar=no,status=yes,left=0,top=0');return false\"><img src=\"http://www.decafbad.com/blog_attachments/IMG_3554-1-tm.jpg\" height=\"253\" width=\"337\" border=\"1\" align=\"middle\" hspace=\"4\" vspace=\"4\" alt=\"Cue the angelic chorus\" title=\"Cue the angelic chorus\" /></a>\r\n</p>\r\n\r\nThis package was actually supposed to have been delivered on Thursday.  But, much to my consternation, I wasn't present to sign for the package.  But now, I've got the surreal experience of holding a bound volume of around 600 pages with my name on the cover.  And inside?  There's all this stuff that once appeared on my PowerBook screen in MS Word and Terminal windows.  (Oh yeah, and there're a few photos of my iPod thrown in for good measure.)\r\n\r\nFunny thing is, this process started for me back in late [December 2004][dec04].  But, you'd barely know it, because--for whatever reason--I started off pretty cagey about the whole thing, and then plunged headlong into the effort.  I did manage to make [a quick announcement of authorship][announce], but thereafter only managed to emerge for a few [quick thought dumps][quick].\r\n\r\nI think part of my silence about things stemmed from a reticence to talk about or promise anything before I'd written it--and also because this has been my first time doing anything like this and I didn't want to flub anything up along the way.  How I might've done that, who knows?  But, I got a bit too busy to really worry about superstitions as the deadlines rolled on.\r\n\r\nBut now, it's out!  And [you should buy it!][buy]  Lookee, lookee:  It's already got a 5-star review from someone I don't even know!\r\n\r\nFor the moment, I'm going to wrap up this post, finish my dinner, and go for a walk with the girl--but, when we get back, I think I might post a few more details on what you'll find in my book debut. \r\n\r\n[buy]: http://www.amazon.com/exec/obidos/ASIN/0764597582/0xdecafbad01-20?creative=327641&camp=14573&link_code=as1\r\n[announce]: http://www.decafbad.com/blog/2005/01/07/belated-happy-new-year\r\n[quick]: http://www.decafbad.com/blog/2005/02/19/writing-no-things-of-epic-import\r\n[dec04]: http://www.decafbad.com/blog/2004/12/\r\n[book]: http://www.decafbad.com/blog/2005/04/25/hacking-rss-and-atom-is-a-real-book\n\n<div id=\"comments\" class=\"comments archived-comments\">\n            <h3>Archived Comments</h3>\n            \n        <ul class=\"comments\">\n            \n        <li class=\"comment\" id=\"comment-221082500\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://monkey.org/~jose/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=d74863ca9c7785cd396379766095036c&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://monkey.org/~jose/\">jose</a>\n                </div>\n                <a href=\"#comment-221082500\" class=\"permalink\"><time datetime=\"2005-09-14T01:03:36\">2005-09-14T01:03:36</time></a>\n            </div>\n            <div class=\"content\">congrats, les, if anyone should have written that book it's you. i'm glad to see it's hit the shelves .. now to go find a copy and look it over :)</div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221082501\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://stingthebee.nu\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=0c6c4240507baf594a95fd3b25b975d2&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://stingthebee.nu\">Jim Renaud</a>\n                </div>\n                <a href=\"#comment-221082501\" class=\"permalink\"><time datetime=\"2005-09-14T01:54:39\">2005-09-14T01:54:39</time></a>\n            </div>\n            <div class=\"content\">Congrats Les. I am gonna need you to autograph mine!!! New site design, new box, new CMS... The world is your oyster!!! It's Les' world, we just live in it!!!</div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221082503\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://www.livejournal.com/users/blackcustard/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=96dd5db5ebd7a91a5df453707ffa8d8d&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://www.livejournal.com/users/blackcustard/\">Matt Blackcustard</a>\n                </div>\n                <a href=\"#comment-221082503\" class=\"permalink\"><time datetime=\"2005-09-14T02:52:08\">2005-09-14T02:52:08</time></a>\n            </div>\n            <div class=\"content\">Hell yeah!</div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221082505\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://www.8dot3.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2d870e8df3af0d62fa636b336b17cd60&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://www.8dot3.com\">Nick</a>\n                </div>\n                <a href=\"#comment-221082505\" class=\"permalink\"><time datetime=\"2005-09-14T04:15:22\">2005-09-14T04:15:22</time></a>\n            </div>\n            <div class=\"content\">Just ordered mine...whens the book signing?..\n\nCongrats man..</div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221082507\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://10500bc.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=00ceff438a69a964d580f8384debcc0e&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://10500bc.org\">nf0</a>\n                </div>\n                <a href=\"#comment-221082507\" class=\"permalink\"><time datetime=\"2005-09-19T21:41:49\">2005-09-19T21:41:49</time></a>\n            </div>\n            <div class=\"content\">I got my copy over the weekend. Some really good work!</div>\n            \n        </li>\n    \n        <li class=\"comment\" id=\"comment-221082508\">\n            <div class=\"meta\">\n                <div class=\"author\">\n                    <a class=\"avatar image\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n                    <a class=\"avatar name\" rel=\"nofollow\" \n                       href=\"http://www.decafbad.com\">l.m.orchard</a>\n                </div>\n                <a href=\"#comment-221082508\" class=\"permalink\"><time datetime=\"2005-09-19T22:50:23\">2005-09-19T22:50:23</time></a>\n            </div>\n            <div class=\"content\">nf0: Hooray!  Thanks for the kudos :)</div>\n            \n        </li>\n    \n        </ul>\n    \n        </div>\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2005",
    "path": "2005/09/13/hacking-rss-and-atom-is-out",
    "thumbnail": "http://www.decafbad.com/blog_attachments/IMG_3554-1-tm.jpg"
  },
  {
    "comments_archived": true,
    "date": "2004-12-23T05:58:41.000Z",
    "excerpt": "So, in the spirit of pico-projects, I've started building that address book application I mentioned awhile ago and I want to start writing about it as I go.",
    "layout": "post",
    "tags": [
      "hacks",
      "xml"
    ],
    "title": "Building an Address Book as a Modern Web App",
    "wordpress_id": 580,
    "wordpress_slug": "abook1",
    "wordpress_url": "http://www.decafbad.com/blog/?p=580",
    "year": "2004",
    "month": "12",
    "day": "23",
    "isDir": false,
    "slug": "abook1",
    "postName": "2004-12-23-abook1",
    "html": "<img src=\"http://www.decafbad.com/2004/12/abook-architecture.jpg\" align=\"right\" />\n\n<p>So, in the spirit of <a href=\"http://www.decafbad.com/blog/2004/11/30/picoprojects_and_trepanation\">pico-projects</a>, I&#39;ve started building <a href=\"http://www.decafbad.com/blog/2004/11/30/nextgenwebapps\">that address book application</a> I mentioned awhile ago and I want to start writing about it as I go.</p>\n<p>First off, hopefully you&#39;ll notice the quick diagram I threw together in OmniGraffle.  This is a sort of rough sketch of the loosely-joined architecture I want to explore with this thing.  </p>\n<ul>\n<li><em>Data</em>: This is where address book entries live.</li>\n<li><em>Model</em>: A set of objects encapsulating the data, this is how address book entries will be accessed.</li>\n<li><em>REST API</em>: Model objects exposed as resources identified by URI, serialized and deserialized as XML, and manipulated by GET / PUT / POST / DELETE methods.</li>\n<li><em>XSLT Filter</em>: XML data produced by REST API calls can be first passed through XSL at a given URL before being served up as a response.  </li>\n<li><em>HTML, CSS, JavaScript</em>: Thanks to the XSLT filter layer, the XML vocabulary used to describe address book entries can be transformed into user interface presentation.</li>\n<li><em>HTTP</em>: Everything happens via HTTP...</li>\n<li><em>Web Browser Client</em>: ...and everything is viewed in a web browser.</li>\n</ul>\n<p>Now, I call this a loosely-joined architecture because I want to stress that you should be able to swap out just about any part of this whenever you want.  </p>\n<p>Want the <em>Data</em> to be in MySQL?  Fine.  Want it to be in flat files?  Fine.  Just make sure the <em>Model</em> can cope while maintaining a consistent interface for the <em>REST API*.  Want to change the user interface in the browser?  Great-- ideally, all you have to do is change some XSLT files.  I&#39;m writing everything from the *XSLT Filter</em> down to the <em>Model</em> in Python.  Don&#39;t like that?  Fine.  Rewrite it all in Perl, and hopefully everything from the XSLT up to the browser will still be useful to you.</p>\n<p>At some point, you might even want to ditch the browser for a native desktop client.  Fabulous! Just ignore everything past the <em>REST API</em> and <em>HTTP</em>, don&#39;t use any XSLT in the <em>Filter</em>, and use the API and XML directly.</p>\n<p>I don&#39;t think any of this is particularly revolutionary-- although I thought it was when I first saw Amazon Web Services doing some of this, and I hope to throw a little GMail in as well.  I hope that this will all be useful as I muddle through explaining what I&#39;m doing.  In the meantime, you can see me getting the stage set as I start checking things into my Subversion repository over here:</p>\n<ul>\n<li><a href=\"http://www.decafbad.com/svn/trunk/hacks/abook/\">http://www.decafbad.com/svn/trunk/hacks/abook/</a><!--more-->\nshortname=abook1</li>\n</ul>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221085892\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://trikuare.cx/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=7d3d1e46aae8ca19855a6026d404b91d&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://trikuare.cx/\">fluffy</a>\n</div>\n<a href=\"#comment-221085892\" class=\"permalink\"><time datetime=\"2004-12-23T07:35:40\">2004-12-23T07:35:40</time></a>\n</div>\n<div class=\"content\">Don't forget that with XSLT you could also rewrite it to SyncML and vCard and so on, so you could also sync it with external devices and iSync (assuming Apple finally opens up a third-party conduit system in Tiger, preferably one which doesn't require .Mac to function).</div>\n</li>\n<li class=\"comment\" id=\"comment-221085894\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://eliot.landrum.cx\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8b8f5370253bd0e0030154baa15785ed&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://eliot.landrum.cx\">eliot</a>\n</div>\n<a href=\"#comment-221085894\" class=\"permalink\"><time datetime=\"2004-12-23T09:12:34\">2004-12-23T09:12:34</time></a>\n</div>\n<div class=\"content\">I'm looking forward to what becomes of this little app. Address book apps seem to all be severely lacking (with the possible exception of OS X's app) and need some fresh thinking. Making the components flexible could be a great way for some change to come about. \nKeep us posted!</div>\n</li>\n<li class=\"comment\" id=\"comment-221085895\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221085895\" class=\"permalink\"><time datetime=\"2004-12-23T12:41:13\">2004-12-23T12:41:13</time></a>\n</div>\n<div class=\"content\">Well, hopefully it's not too disappointing, but this address book app will be pretty anemic in terms of use as a serious app.  Implementing an address book is just an excuse to run through the various technologies involved.\nHowever, there's nothing stopping anyone (including me) from enhancing the thing when I'm done and making it into a serious offering with vCard support and such.</div>\n</li>\n<li class=\"comment\" id=\"comment-221085896\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://webseitz.fluxent.com/wiki\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8157a5907b244071cda98ba5aa7a9635&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://webseitz.fluxent.com/wiki\">Bill Seitz</a>\n</div>\n<a href=\"#comment-221085896\" class=\"permalink\"><time datetime=\"2004-12-27T12:23:46\">2004-12-27T12:23:46</time></a>\n</div>\n<div class=\"content\">(Hmm, posted last week but it never showed up...)\nWhat are you thinking in terms of having this data store actually used by, say, your email client?\nMake it look like an LDAP server, maybe?</div>\n</li>\n<li class=\"comment\" id=\"comment-221085898\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.chuckknows.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=6cede7ba6ff803837ba2da9cc6e466b6&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.chuckknows.com\">Chuck Conway</a>\n</div>\n<a href=\"#comment-221085898\" class=\"permalink\"><time datetime=\"2005-01-02T20:37:00\">2005-01-02T20:37:00</time></a>\n</div>\n<div class=\"content\">How Funny! I've been thinking about doing the same thing.\nThe only difference is I was thinking about doing address book, bookmarks and my RSS feeds. \nThose are the things I miss the most when I am away.</div>\n</li>\n<li class=\"comment\" id=\"comment-221085900\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.worldwide-sources.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=73de6d1640f8cae902843f4a753bcaee&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.worldwide-sources.com\">William</a>\n</div>\n<a href=\"#comment-221085900\" class=\"permalink\"><time datetime=\"2005-03-05T05:16:08\">2005-03-05T05:16:08</time></a>\n</div>\n<div class=\"content\">I'm curious to see where this little app is going its still needs more work</div>\n</li>\n<li class=\"comment\" id=\"comment-221085903\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://webseitz.fluxent.com/wiki\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8157a5907b244071cda98ba5aa7a9635&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://webseitz.fluxent.com/wiki\">Bill Seitz</a>\n</div>\n<a href=\"#comment-221085903\" class=\"permalink\"><time datetime=\"2006-08-26T13:37:35\">2006-08-26T13:37:35</time></a>\n</div>\n<div class=\"content\"><p>I see you working with Tarawa in there. Did you like it? Is it being worked on at all?</p></div>\n</li>\n</ul>\n</div>\n",
    "body": "<img src=\"http://www.decafbad.com/2004/12/abook-architecture.jpg\" align=\"right\" />\r\n\r\nSo, in the spirit of [pico-projects][pp], I've started building [that address book application][ab] I mentioned awhile ago and I want to start writing about it as I go.\r\n\r\n[pp]: http://www.decafbad.com/blog/2004/11/30/picoprojects_and_trepanation\r\n[ab]: http://www.decafbad.com/blog/2004/11/30/nextgenwebapps\r\n\r\nFirst off, hopefully you'll notice the quick diagram I threw together in OmniGraffle.  This is a sort of rough sketch of the loosely-joined architecture I want to explore with this thing.  \r\n\r\n* *Data*: This is where address book entries live.\r\n* *Model*: A set of objects encapsulating the data, this is how address book entries will be accessed.\r\n* *REST API*: Model objects exposed as resources identified by URI, serialized and deserialized as XML, and manipulated by GET / PUT / POST / DELETE methods.\r\n* *XSLT Filter*: XML data produced by REST API calls can be first passed through XSL at a given URL before being served up as a response.  \r\n* *HTML, CSS, JavaScript*: Thanks to the XSLT filter layer, the XML vocabulary used to describe address book entries can be transformed into user interface presentation.\r\n* *HTTP*: Everything happens via HTTP...\r\n* *Web Browser Client*: ...and everything is viewed in a web browser.\r\n\r\nNow, I call this a loosely-joined architecture because I want to stress that you should be able to swap out just about any part of this whenever you want.  \r\n\r\nWant the *Data* to be in MySQL?  Fine.  Want it to be in flat files?  Fine.  Just make sure the *Model* can cope while maintaining a consistent interface for the *REST API*.  Want to change the user interface in the browser?  Great-- ideally, all you have to do is change some XSLT files.  I'm writing everything from the *XSLT Filter* down to the *Model* in Python.  Don't like that?  Fine.  Rewrite it all in Perl, and hopefully everything from the XSLT up to the browser will still be useful to you.\r\n\r\nAt some point, you might even want to ditch the browser for a native desktop client.  Fabulous! Just ignore everything past the *REST API* and *HTTP*, don't use any XSLT in the *Filter*, and use the API and XML directly.\r\n\r\nI don't think any of this is particularly revolutionary-- although I thought it was when I first saw Amazon Web Services doing some of this, and I hope to throw a little GMail in as well.  I hope that this will all be useful as I muddle through explaining what I'm doing.  In the meantime, you can see me getting the stage set as I start checking things into my Subversion repository over here:\r\n\r\n* [http://www.decafbad.com/svn/trunk/hacks/abook/](http://www.decafbad.com/svn/trunk/hacks/abook/)\r\n<!--more-->\r\nshortname=abook1\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221085892\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://trikuare.cx/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=7d3d1e46aae8ca19855a6026d404b91d&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://trikuare.cx/\">fluffy</a>\r\n                </div>\r\n                <a href=\"#comment-221085892\" class=\"permalink\"><time datetime=\"2004-12-23T07:35:40\">2004-12-23T07:35:40</time></a>\r\n            </div>\r\n            <div class=\"content\">Don't forget that with XSLT you could also rewrite it to SyncML and vCard and so on, so you could also sync it with external devices and iSync (assuming Apple finally opens up a third-party conduit system in Tiger, preferably one which doesn't require .Mac to function).</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221085894\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://eliot.landrum.cx\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8b8f5370253bd0e0030154baa15785ed&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://eliot.landrum.cx\">eliot</a>\r\n                </div>\r\n                <a href=\"#comment-221085894\" class=\"permalink\"><time datetime=\"2004-12-23T09:12:34\">2004-12-23T09:12:34</time></a>\r\n            </div>\r\n            <div class=\"content\">I'm looking forward to what becomes of this little app. Address book apps seem to all be severely lacking (with the possible exception of OS X's app) and need some fresh thinking. Making the components flexible could be a great way for some change to come about. \r\n\r\nKeep us posted!</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221085895\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2377f34a68801b861c3e54e1301f0dce&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/\">l.m.orchard</a>\r\n                </div>\r\n                <a href=\"#comment-221085895\" class=\"permalink\"><time datetime=\"2004-12-23T12:41:13\">2004-12-23T12:41:13</time></a>\r\n            </div>\r\n            <div class=\"content\">Well, hopefully it's not too disappointing, but this address book app will be pretty anemic in terms of use as a serious app.  Implementing an address book is just an excuse to run through the various technologies involved.\r\n\r\nHowever, there's nothing stopping anyone (including me) from enhancing the thing when I'm done and making it into a serious offering with vCard support and such.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221085896\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://webseitz.fluxent.com/wiki\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8157a5907b244071cda98ba5aa7a9635&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://webseitz.fluxent.com/wiki\">Bill Seitz</a>\r\n                </div>\r\n                <a href=\"#comment-221085896\" class=\"permalink\"><time datetime=\"2004-12-27T12:23:46\">2004-12-27T12:23:46</time></a>\r\n            </div>\r\n            <div class=\"content\">(Hmm, posted last week but it never showed up...)\r\n\r\nWhat are you thinking in terms of having this data store actually used by, say, your email client?\r\n\r\nMake it look like an LDAP server, maybe?</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221085898\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.chuckknows.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=6cede7ba6ff803837ba2da9cc6e466b6&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.chuckknows.com\">Chuck Conway</a>\r\n                </div>\r\n                <a href=\"#comment-221085898\" class=\"permalink\"><time datetime=\"2005-01-02T20:37:00\">2005-01-02T20:37:00</time></a>\r\n            </div>\r\n            <div class=\"content\">How Funny! I've been thinking about doing the same thing.\r\n\r\nThe only difference is I was thinking about doing address book, bookmarks and my RSS feeds. \r\n\r\nThose are the things I miss the most when I am away.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221085900\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.worldwide-sources.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=73de6d1640f8cae902843f4a753bcaee&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.worldwide-sources.com\">William</a>\r\n                </div>\r\n                <a href=\"#comment-221085900\" class=\"permalink\"><time datetime=\"2005-03-05T05:16:08\">2005-03-05T05:16:08</time></a>\r\n            </div>\r\n            <div class=\"content\">I'm curious to see where this little app is going its still needs more work</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221085903\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://webseitz.fluxent.com/wiki\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8157a5907b244071cda98ba5aa7a9635&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://webseitz.fluxent.com/wiki\">Bill Seitz</a>\r\n                </div>\r\n                <a href=\"#comment-221085903\" class=\"permalink\"><time datetime=\"2006-08-26T13:37:35\">2006-08-26T13:37:35</time></a>\r\n            </div>\r\n            <div class=\"content\"><p>I see you working with Tarawa in there. Did you like it? Is it being worked on at all?</p></div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2004",
    "path": "2004/12/23/abook1",
    "thumbnail": "http://www.decafbad.com/2004/12/abook-architecture.jpg",
    "summary": "<img src=\"http://www.decafbad.com/2004/12/abook-architecture.jpg\" align=\"right\">\n\n<p>So, in the spirit of <a href=\"http://www.decafbad.com/blog/2004/11/30/picoprojects_and_trepanation\">pico-projects</a>, I&apos;ve started building <a href=\"http://www.decafbad.com/blog/2004/11/30/nextgenwebapps\">that address book application</a> I mentioned awhile ago and I want to start writing about it as I go.</p>\n<p>First off, hopefully you&apos;ll notice the quick diagram I threw together in OmniGraffle.  This is a sort of rough sketch of the loosely-joined architecture I want to explore with this thing.  </p>\n<ul>\n<li><em>Data</em>: This is where address book entries live.</li>\n<li><em>Model</em>: A set of objects encapsulating the data, this is how address book entries will be accessed.</li>\n<li><em>REST API</em>: Model objects exposed as resources identified by URI, serialized and deserialized as XML, and manipulated by GET / PUT / POST / DELETE methods.</li>\n<li><em>XSLT Filter</em>: XML data produced by REST API calls can be first passed through XSL at a given URL before being served up as a response.  </li>\n<li><em>HTML, CSS, JavaScript</em>: Thanks to the XSLT filter layer, the XML vocabulary used to describe address book entries can be transformed into user interface presentation.</li>\n<li><em>HTTP</em>: Everything happens via HTTP...</li>\n<li><em>Web Browser Client</em>: ...and everything is viewed in a web browser.</li>\n</ul>\n<p>Now, I call this a loosely-joined architecture because I want to stress that you should be able to swap out just about any part of this whenever you want.  </p>\n<p>Want the <em>Data</em> to be in MySQL?  Fine.  Want it to be in flat files?  Fine.  Just make sure the <em>Model</em> can cope while maintaining a consistent interface for the <em>REST API*.  Want to change the user interface in the browser?  Great-- ideally, all you have to do is change some XSLT files.  I&apos;m writing everything from the *XSLT Filter</em> down to the <em>Model</em> in Python.  Don&apos;t like that?  Fine.  Rewrite it all in Perl, and hopefully everything from the XSLT up to the browser will still be useful to you.</p>\n<p>At some point, you might even want to ditch the browser for a native desktop client.  Fabulous! Just ignore everything past the <em>REST API</em> and <em>HTTP</em>, don&apos;t use any XSLT in the <em>Filter</em>, and use the API and XML directly.</p>\n<p>I don&apos;t think any of this is particularly revolutionary-- although I thought it was when I first saw Amazon Web Services doing some of this, and I hope to throw a little GMail in as well.  I hope that this will all be useful as I muddle through explaining what I&apos;m doing.  In the meantime, you can see me getting the stage set as I start checking things into my Subversion repository over here:</p>\n<ul>\n<li><a href=\"http://www.decafbad.com/svn/trunk/hacks/abook/\">http://www.decafbad.com/svn/trunk/hacks/abook/</a></li></ul>"
  },
  {
    "comments_archived": true,
    "date": "2004-12-03T01:15:52.000Z",
    "excerpt": "Both ZPT and XSLT very different technologies, but they are often used in similar contexts.  More than once, I've wished that XSLT was as simple as ZPT (i.e. less verbose and intrusive, more document centered), and I've wished that ZPT had some of the features of XSLT (i.e. ability to be used as a transforming filter).",
    "layout": "post",
    "tags": [
      "xml",
      "python"
    ],
    "title": "Cross-breeding XSLT and ZPT",
    "wordpress_id": 570,
    "wordpress_slug": "crossbreedingxsltzpt",
    "wordpress_url": "http://www.decafbad.com/blog/?p=570",
    "year": "2004",
    "month": "12",
    "day": "02",
    "isDir": false,
    "slug": "crossbreedingxsltzpt",
    "postName": "2004-12-02-crossbreedingxsltzpt",
    "html": "<p>I&#39;ve recently been doing some side work involving Zope and, along with the rest of the suite of technologies it offers, I&#39;ve been happy to be working with <a href=\"http://dev.zope.org/Wikis/DevSite/Projects/ZPT/FrontPage\">Zope Page Templates</a> again.  I dabbled with them a bit when they first came out, and a Zope-free implementation named <a href=\"http://www.owlfish.com/software/simpleTAL/\">SimpleTAL</a> was one of the core components of the iteration of my news aggregator which came before FeedReactor.</p>\n<p>Out of all the templating and content generation approaches I&#39;ve used, Zope Page Templates are my favorite yet.  Pretty expressive, yet unobtrusive; nicely powerful, yet not quite something with which you&#39;d want to write an entire application (<a href=\"http://naeblis.cx/rtomayko/2004/12/02/a-note-on-template-design\">and that&#39;s a feature, not a bug</a>).  </p>\n<p>I&#39;ve yet to be in a work-a-day team that uses ZPT-- but I can see where a lot of production, delegation, and integration issues would have gone much smoother had I used ZPT instead of <a href=\"http://www.template-toolkit.org/\">Template Toolkit</a> for the web app framework I created at a previous company.  (Though I do have to say TT2 is <em>very</em> nicely done!)  And where I am now, I spend most of my days trying to pummel ASP 3.0 pages into some semblance of logic/presentation separation-- I would certainly dive at the chance to dump VBScript and <code>&lt;% cruft %&gt;</code> for a bit of Python and ZPT.  (But, you know, <em>it&#39;s a living</em>.)</p>\n<p>A close second favorite is XSLT.  I&#39;ve really been hot on it lately, having worked it into the core of FeedReactor in place of SimpleTAL.  And in <a href=\"http://www.decafbad.com/blog/2003/09/02/xsl_scraper\">other</a> <a href=\"http://www.decafbad.com/blog/2004/06/16/wishofthemonthclub1\">hacks</a>, I&#39;ve really come to appreciate it&#39;s role as a filter segment in pipelines between REST web services and <a href=\"http://udell.roninhouse.com/bytecols/2001-08-15.html\">URL-as-command-line</a> invocations.</p>\n<p>Granted, both ZPT and XSLT very different technologies, but they are often used in similar contexts.  More than once, I&#39;ve wished that XSLT was as simple as ZPT (i.e. less verbose and intrusive, more document centered), and I&#39;ve wished that ZPT had some of the features of XSLT (i.e. ability to be used as a transforming filter).</p>\n<p>Reading <a href=\"http://naeblis.cx/rtomayko/2004/11/30/pythonic-xml-based-templating-language\">Ryan Tomayko&#39;s description of Kid</a> got me thinking, and googling.  One thing I turned up from a mailing list archive asked about an &#8220;<a href=\"http://mail.zope.org/pipermail/zpt/2002-January/002651.html\">XSL implementation of TAL?</a>&#8221;  It struck me as a tad nutty at first, but then I started having inklings that just maybe it could be done.  (Whether it <em>should</em> be done, well...)  But the kernel of the idea grabbed me: Instead of using <a href=\"http://zope.org/Wikis/DevSite/Projects/ZPT/TALES%20Specification%201.3\">TALES path expressions</a> to look up values in Pythonic space, why not use XPath expressions to look up values from a supplied XML document?</p>\n<p>This strikes me as such an obvious idea that someone has to already have done it and possibly rejected it for good reason.  On the other hand, maybe this is the sort of thing Ryan&#39;s thinking about-- I wonder how hard it would be to hack this into Kid?  It would give only a subset of XSLT&#39;s capabilities in trade for simplicity, and would only offer the &#8220;<a href=\"http://www.dpawson.co.uk/xsl/sect2/pushpull.html\">pull</a>&#8221; approach, but it would give XML-pipelining to a ZPT-ish technology.</p>\n<p>I think this is something I want to look into a bit further at some point.</p>\n<!--more-->\n<p>shortname=crossbreedingxsltzpt</p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221087930\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://blog.ianbicking.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=cc8334869c9d2a9e603017f2da805eb3&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://blog.ianbicking.org\">Ian Bicking</a>\n</div>\n<a href=\"#comment-221087930\" class=\"permalink\"><time datetime=\"2004-12-04T17:16:09\">2004-12-04T17:16:09</time></a>\n</div>\n<div class=\"content\">I've been meaning to write about this on my blog, as I've done something similar.\nInstead of using XSLT, I've used ZPT for the transformations.  It was an application where the user created a document in a WYSIWYG editor, then we wanted to pull information out of the content -- like a table of contents, or a title.\nTo do this I parsed the content into a DOM, then put some objects in the ZPT namespace that manipulated it.  For instance, the ToC object took a tag name (through getitem) and returned a list of the content and id of those tags (it created ids if necessary, modifying the content).  Then you could easily create a ToC by looking through and creating anchor tags from, say, all the  tags in the document.  It should be easy to expand with other transformations (all coded in Python, of course).  The actual code was only like 20 lines of Python, maybe less, and easy to understand from both sides (ZPT and Python).</div>\n</li>\n<li class=\"comment\" id=\"comment-221087932\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=14076d6ce3d0e8a0fd751a36d9912df5&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"\">Petri Savolainen</a>\n</div>\n<a href=\"#comment-221087932\" class=\"permalink\"><time datetime=\"2004-12-13T05:21:41\">2004-12-13T05:21:41</time></a>\n</div>\n<div class=\"content\">See http://zope.org/Members/DaddyGravity/PT_XPath\nIt would be great to have that in SimpleTAL, too.</div>\n</li>\n<li class=\"comment\" id=\"comment-221087935\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://blog.ianbicking.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=cc8334869c9d2a9e603017f2da805eb3&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://blog.ianbicking.org\">Ian Bicking</a>\n</div>\n<a href=\"#comment-221087935\" class=\"permalink\"><time datetime=\"2004-12-13T11:43:33\">2004-12-13T11:43:33</time></a>\n</div>\n<div class=\"content\">Another thing you might want to look at: in the last few days there's been discussion on the ZPT mailing list about an extension to stylesheets (TERSE) for ZPT that introduces transformations.</div>\n</li>\n<li class=\"comment\" id=\"comment-221087937\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://codeconsult.ch/bertrand\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=d244e495717742bd0776b715a45877eb&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://codeconsult.ch/bertrand\">Bertrand Delacretaz</a>\n</div>\n<a href=\"#comment-221087937\" class=\"permalink\"><time datetime=\"2004-12-13T15:15:55\">2004-12-13T15:15:55</time></a>\n</div>\n<div class=\"content\">FYI, people from the Apache Cocoon and BXE projects are working on similar stuff, in the opposite direction: we're taking TAL-like templates and converting them to XSLT, adding simple \"match\" templates for declarative rules. It's only prototypes and experiments for now, but the results look promising.\nMore info at\nhttp://wiki.apache.org/cocoon/HtmlToXsltExperiments\nand\nhttp://blog.bitflux.ch/archive/further-improvements-on-xsl-tal.html</div>\n</li>\n<li class=\"comment\" id=\"comment-221087939\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.manuzhai.nl/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=d62bb8855d45ab52fd5a414f0ca47703&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.manuzhai.nl/\">Manuzhai</a>\n</div>\n<a href=\"#comment-221087939\" class=\"permalink\"><time datetime=\"2004-12-13T16:07:54\">2004-12-13T16:07:54</time></a>\n</div>\n<div class=\"content\">I like XSLT a lot, myself, and I have advocated it in the past on my weblog, but it just doesn't seem to be very wide-spread. Which is a pity, I think the world would be much easier if more people used this *standard* way of templating.\nOne of the bigger problems with it seems to be the verbosity, so I've been thinking of a more compact syntax, kind of like RELAX NG has the .rnc compact stuff. I don't know if it's very feasible, but it seems like that would be not very hard; just have some compact syntax which maps onto a real XSLT-sheet (it could be \"compiled\" and cached, if need be).</div>\n</li>\n<li class=\"comment\" id=\"comment-221087942\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.owlfish.com/weblog/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=377cef4245e0fcbf76e021d9cd253e35&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.owlfish.com/weblog/\">Colin Stewart</a>\n</div>\n<a href=\"#comment-221087942\" class=\"permalink\"><time datetime=\"2004-12-13T23:47:18\">2004-12-13T23:47:18</time></a>\n</div>\n<div class=\"content\">Integrating an XPATH implementation into SimpleTAL shouldn't be too hard as the TALES and TAL implementations share a fairly simple interface.  There are 6 methods you'd have to provide to the simpleTAL module and that's about it.\nI don't know if XPATH is the right approach though - how would things like tal:define work if the paths were pure XPATH instead of TALES?  Being able to mix XPATH and TALES would work better I think.\nA more promising approach would be to integrate ElementTree so that the 'find*' methods were usable from within TALES.  Making it so that '/mydoc/root/find/.//searchElement' works would be fairly easy, but getting '/mydoc/root/find/.//searchElement/attrib/firstAtt' to work would require more co-operation between ElemenTree and SimpleTAL.\nI'll have a think about this though as it sounds like a promising approach.</div>\n</li>\n<li class=\"comment\" id=\"comment-221087946\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=d67eea2ce18dd70f4642cb971c2c5ad2&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"\">Paul Everitt</a>\n</div>\n<a href=\"#comment-221087946\" class=\"permalink\"><time datetime=\"2004-12-14T00:45:18\">2004-12-14T00:45:18</time></a>\n</div>\n<div class=\"content\">Chapter 11 of Jeni Tennison's \"XSLT and XPath On The Edge\" book has a section called \"Using Page Templates\".  It includes an example of using substitution points.\nLike some of the others in this thread, playing with doing merges using DOM IDs and other patterns.  This lets you write \"themes\" that are simpler than even ZPT, as they contain no non-XHTML namespace elements.\nThanks for the article, which also seems to have brought out some interesting comments and URLs!</div>\n</li>\n<li class=\"comment\" id=\"comment-221087948\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://webseitz.fluxent.com/wiki\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8157a5907b244071cda98ba5aa7a9635&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://webseitz.fluxent.com/wiki\">Bill Seitz</a>\n</div>\n<a href=\"#comment-221087948\" class=\"permalink\"><time datetime=\"2004-12-14T20:23:08\">2004-12-14T20:23:08</time></a>\n</div>\n<div class=\"content\">Don't forget you can run Python within IIS/ASP!\nhttp://webseitz.fluxent.com/articles/PythonViaIis</div>\n</li>\n<li class=\"comment\" id=\"comment-221087950\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.owlfish.com/weblog/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=377cef4245e0fcbf76e021d9cd253e35&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.owlfish.com/weblog/\">Colin Stewart</a>\n</div>\n<a href=\"#comment-221087950\" class=\"permalink\"><time datetime=\"2004-12-15T22:49:30\">2004-12-15T22:49:30</time></a>\n</div>\n<div class=\"content\">I've put together an experimental build of SimpleTAL that integrates ElementTree to provide some of the XPATH syntax.  It's just an experiment, but see what you think.\n(More detail here: http://www.owlfish.com/weblog/2004/12/15122004.html#20:59:59)</div>\n</li>\n</ul>\n</div>\n",
    "body": "I've recently been doing some side work involving Zope and, along with the rest of the suite of technologies it offers, I've been happy to be working with [Zope Page Templates](http://dev.zope.org/Wikis/DevSite/Projects/ZPT/FrontPage) again.  I dabbled with them a bit when they first came out, and a Zope-free implementation named [SimpleTAL](http://www.owlfish.com/software/simpleTAL/) was one of the core components of the iteration of my news aggregator which came before FeedReactor.\r\n\r\nOut of all the templating and content generation approaches I've used, Zope Page Templates are my favorite yet.  Pretty expressive, yet unobtrusive; nicely powerful, yet not quite something with which you'd want to write an entire application ([and that's a feature, not a bug](http://naeblis.cx/rtomayko/2004/12/02/a-note-on-template-design)).  \r\n  \r\nI've yet to be in a work-a-day team that uses ZPT-- but I can see where a lot of production, delegation, and integration issues would have gone much smoother had I used ZPT instead of [Template Toolkit](http://www.template-toolkit.org/) for the web app framework I created at a previous company.  (Though I do have to say TT2 is *very* nicely done!)  And where I am now, I spend most of my days trying to pummel ASP 3.0 pages into some semblance of logic/presentation separation-- I would certainly dive at the chance to dump VBScript and `<% cruft %>` for a bit of Python and ZPT.  (But, you know, *it's a living*.)\r\n   \r\nA close second favorite is XSLT.  I've really been hot on it lately, having worked it into the core of FeedReactor in place of SimpleTAL.  And in [other](http://www.decafbad.com/blog/2003/09/02/xsl_scraper) [hacks](http://www.decafbad.com/blog/2004/06/16/wishofthemonthclub1), I've really come to appreciate it's role as a filter segment in pipelines between REST web services and [URL-as-command-line](http://udell.roninhouse.com/bytecols/2001-08-15.html) invocations.\r\n\r\nGranted, both ZPT and XSLT very different technologies, but they are often used in similar contexts.  More than once, I've wished that XSLT was as simple as ZPT (i.e. less verbose and intrusive, more document centered), and I've wished that ZPT had some of the features of XSLT (i.e. ability to be used as a transforming filter).\r\n\r\nReading [Ryan Tomayko's description of Kid](http://naeblis.cx/rtomayko/2004/11/30/pythonic-xml-based-templating-language) got me thinking, and googling.  One thing I turned up from a mailing list archive asked about an &#8220;[XSL implementation of TAL?](http://mail.zope.org/pipermail/zpt/2002-January/002651.html)&#8221;  It struck me as a tad nutty at first, but then I started having inklings that just maybe it could be done.  (Whether it *should* be done, well...)  But the kernel of the idea grabbed me: Instead of using [TALES path expressions](http://zope.org/Wikis/DevSite/Projects/ZPT/TALES%20Specification%201.3) to look up values in Pythonic space, why not use XPath expressions to look up values from a supplied XML document?\r\n\r\nThis strikes me as such an obvious idea that someone has to already have done it and possibly rejected it for good reason.  On the other hand, maybe this is the sort of thing Ryan's thinking about-- I wonder how hard it would be to hack this into Kid?  It would give only a subset of XSLT's capabilities in trade for simplicity, and would only offer the &#8220;[pull](http://www.dpawson.co.uk/xsl/sect2/pushpull.html)&#8221; approach, but it would give XML-pipelining to a ZPT-ish technology.\r\n\r\nI think this is something I want to look into a bit further at some point.\r\n<!--more-->\r\nshortname=crossbreedingxsltzpt\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221087930\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://blog.ianbicking.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=cc8334869c9d2a9e603017f2da805eb3&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://blog.ianbicking.org\">Ian Bicking</a>\r\n                </div>\r\n                <a href=\"#comment-221087930\" class=\"permalink\"><time datetime=\"2004-12-04T17:16:09\">2004-12-04T17:16:09</time></a>\r\n            </div>\r\n            <div class=\"content\">I've been meaning to write about this on my blog, as I've done something similar.\r\n\r\nInstead of using XSLT, I've used ZPT for the transformations.  It was an application where the user created a document in a WYSIWYG editor, then we wanted to pull information out of the content -- like a table of contents, or a title.\r\n\r\nTo do this I parsed the content into a DOM, then put some objects in the ZPT namespace that manipulated it.  For instance, the ToC object took a tag name (through getitem) and returned a list of the content and id of those tags (it created ids if necessary, modifying the content).  Then you could easily create a ToC by looking through and creating anchor tags from, say, all the  tags in the document.  It should be easy to expand with other transformations (all coded in Python, of course).  The actual code was only like 20 lines of Python, maybe less, and easy to understand from both sides (ZPT and Python).</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221087932\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=14076d6ce3d0e8a0fd751a36d9912df5&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"\">Petri Savolainen</a>\r\n                </div>\r\n                <a href=\"#comment-221087932\" class=\"permalink\"><time datetime=\"2004-12-13T05:21:41\">2004-12-13T05:21:41</time></a>\r\n            </div>\r\n            <div class=\"content\">See http://zope.org/Members/DaddyGravity/PT_XPath\r\n\r\nIt would be great to have that in SimpleTAL, too.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221087935\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://blog.ianbicking.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=cc8334869c9d2a9e603017f2da805eb3&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://blog.ianbicking.org\">Ian Bicking</a>\r\n                </div>\r\n                <a href=\"#comment-221087935\" class=\"permalink\"><time datetime=\"2004-12-13T11:43:33\">2004-12-13T11:43:33</time></a>\r\n            </div>\r\n            <div class=\"content\">Another thing you might want to look at: in the last few days there's been discussion on the ZPT mailing list about an extension to stylesheets (TERSE) for ZPT that introduces transformations.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221087937\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://codeconsult.ch/bertrand\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=d244e495717742bd0776b715a45877eb&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://codeconsult.ch/bertrand\">Bertrand Delacretaz</a>\r\n                </div>\r\n                <a href=\"#comment-221087937\" class=\"permalink\"><time datetime=\"2004-12-13T15:15:55\">2004-12-13T15:15:55</time></a>\r\n            </div>\r\n            <div class=\"content\">FYI, people from the Apache Cocoon and BXE projects are working on similar stuff, in the opposite direction: we're taking TAL-like templates and converting them to XSLT, adding simple \"match\" templates for declarative rules. It's only prototypes and experiments for now, but the results look promising.\r\n\r\nMore info at\r\nhttp://wiki.apache.org/cocoon/HtmlToXsltExperiments\r\nand\r\nhttp://blog.bitflux.ch/archive/further-improvements-on-xsl-tal.html</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221087939\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.manuzhai.nl/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=d62bb8855d45ab52fd5a414f0ca47703&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.manuzhai.nl/\">Manuzhai</a>\r\n                </div>\r\n                <a href=\"#comment-221087939\" class=\"permalink\"><time datetime=\"2004-12-13T16:07:54\">2004-12-13T16:07:54</time></a>\r\n            </div>\r\n            <div class=\"content\">I like XSLT a lot, myself, and I have advocated it in the past on my weblog, but it just doesn't seem to be very wide-spread. Which is a pity, I think the world would be much easier if more people used this *standard* way of templating.\r\n\r\nOne of the bigger problems with it seems to be the verbosity, so I've been thinking of a more compact syntax, kind of like RELAX NG has the .rnc compact stuff. I don't know if it's very feasible, but it seems like that would be not very hard; just have some compact syntax which maps onto a real XSLT-sheet (it could be \"compiled\" and cached, if need be).</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221087942\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.owlfish.com/weblog/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=377cef4245e0fcbf76e021d9cd253e35&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.owlfish.com/weblog/\">Colin Stewart</a>\r\n                </div>\r\n                <a href=\"#comment-221087942\" class=\"permalink\"><time datetime=\"2004-12-13T23:47:18\">2004-12-13T23:47:18</time></a>\r\n            </div>\r\n            <div class=\"content\">Integrating an XPATH implementation into SimpleTAL shouldn't be too hard as the TALES and TAL implementations share a fairly simple interface.  There are 6 methods you'd have to provide to the simpleTAL module and that's about it.\r\n\r\nI don't know if XPATH is the right approach though - how would things like tal:define work if the paths were pure XPATH instead of TALES?  Being able to mix XPATH and TALES would work better I think.\r\n\r\nA more promising approach would be to integrate ElementTree so that the 'find*' methods were usable from within TALES.  Making it so that '/mydoc/root/find/.//searchElement' works would be fairly easy, but getting '/mydoc/root/find/.//searchElement/attrib/firstAtt' to work would require more co-operation between ElemenTree and SimpleTAL.\r\n\r\nI'll have a think about this though as it sounds like a promising approach.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221087946\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=d67eea2ce18dd70f4642cb971c2c5ad2&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"\">Paul Everitt</a>\r\n                </div>\r\n                <a href=\"#comment-221087946\" class=\"permalink\"><time datetime=\"2004-12-14T00:45:18\">2004-12-14T00:45:18</time></a>\r\n            </div>\r\n            <div class=\"content\">Chapter 11 of Jeni Tennison's \"XSLT and XPath On The Edge\" book has a section called \"Using Page Templates\".  It includes an example of using substitution points.\r\n\r\nLike some of the others in this thread, playing with doing merges using DOM IDs and other patterns.  This lets you write \"themes\" that are simpler than even ZPT, as they contain no non-XHTML namespace elements.\r\n\r\nThanks for the article, which also seems to have brought out some interesting comments and URLs!</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221087948\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://webseitz.fluxent.com/wiki\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8157a5907b244071cda98ba5aa7a9635&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://webseitz.fluxent.com/wiki\">Bill Seitz</a>\r\n                </div>\r\n                <a href=\"#comment-221087948\" class=\"permalink\"><time datetime=\"2004-12-14T20:23:08\">2004-12-14T20:23:08</time></a>\r\n            </div>\r\n            <div class=\"content\">Don't forget you can run Python within IIS/ASP!\r\n\r\nhttp://webseitz.fluxent.com/articles/PythonViaIis</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221087950\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.owlfish.com/weblog/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=377cef4245e0fcbf76e021d9cd253e35&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.owlfish.com/weblog/\">Colin Stewart</a>\r\n                </div>\r\n                <a href=\"#comment-221087950\" class=\"permalink\"><time datetime=\"2004-12-15T22:49:30\">2004-12-15T22:49:30</time></a>\r\n            </div>\r\n            <div class=\"content\">I've put together an experimental build of SimpleTAL that integrates ElementTree to provide some of the XPATH syntax.  It's just an experiment, but see what you think.\r\n\r\n(More detail here: http://www.owlfish.com/weblog/2004/12/15122004.html#20:59:59)</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2004",
    "path": "2004/12/03/crossbreedingxsltzpt",
    "summary": "<p>I&apos;ve recently been doing some side work involving Zope and, along with the rest of the suite of technologies it offers, I&apos;ve been happy to be working with <a href=\"http://dev.zope.org/Wikis/DevSite/Projects/ZPT/FrontPage\">Zope Page Templates</a> again.  I dabbled with them a bit when they first came out, and a Zope-free implementation named <a href=\"http://www.owlfish.com/software/simpleTAL/\">SimpleTAL</a> was one of the core components of the iteration of my news aggregator which came before FeedReactor.</p>\n<p>Out of all the templating and content generation approaches I&apos;ve used, Zope Page Templates are my favorite yet.  Pretty expressive, yet unobtrusive; nicely powerful, yet not quite something with which you&apos;d want to write an entire application (<a href=\"http://naeblis.cx/rtomayko/2004/12/02/a-note-on-template-design\">and that&apos;s a feature, not a bug</a>).  </p>\n<p>I&apos;ve yet to be in a work-a-day team that uses ZPT-- but I can see where a lot of production, delegation, and integration issues would have gone much smoother had I used ZPT instead of <a href=\"http://www.template-toolkit.org/\">Template Toolkit</a> for the web app framework I created at a previous company.  (Though I do have to say TT2 is <em>very</em> nicely done!)  And where I am now, I spend most of my days trying to pummel ASP 3.0 pages into some semblance of logic/presentation separation-- I would certainly dive at the chance to dump VBScript and <code>&lt;% cruft %&gt;</code> for a bit of Python and ZPT.  (But, you know, <em>it&apos;s a living</em>.)</p>\n<p>A close second favorite is XSLT.  I&apos;ve really been hot on it lately, having worked it into the core of FeedReactor in place of SimpleTAL.  And in <a href=\"http://www.decafbad.com/blog/2003/09/02/xsl_scraper\">other</a> <a href=\"http://www.decafbad.com/blog/2004/06/16/wishofthemonthclub1\">hacks</a>, I&apos;ve really come to appreciate it&apos;s role as a filter segment in pipelines between REST web services and <a href=\"http://udell.roninhouse.com/bytecols/2001-08-15.html\">URL-as-command-line</a> invocations.</p>\n<p>Granted, both ZPT and XSLT very different technologies, but they are often used in similar contexts.  More than once, I&apos;ve wished that XSLT was as simple as ZPT (i.e. less verbose and intrusive, more document centered), and I&apos;ve wished that ZPT had some of the features of XSLT (i.e. ability to be used as a transforming filter).</p>\n<p>Reading <a href=\"http://naeblis.cx/rtomayko/2004/11/30/pythonic-xml-based-templating-language\">Ryan Tomayko&apos;s description of Kid</a> got me thinking, and googling.  One thing I turned up from a mailing list archive asked about an &#x201C;<a href=\"http://mail.zope.org/pipermail/zpt/2002-January/002651.html\">XSL implementation of TAL?</a>&#x201D;  It struck me as a tad nutty at first, but then I started having inklings that just maybe it could be done.  (Whether it <em>should</em> be done, well...)  But the kernel of the idea grabbed me: Instead of using <a href=\"http://zope.org/Wikis/DevSite/Projects/ZPT/TALES%20Specification%201.3\">TALES path expressions</a> to look up values in Pythonic space, why not use XPath expressions to look up values from a supplied XML document?</p>\n<p>This strikes me as such an obvious idea that someone has to already have done it and possibly rejected it for good reason.  On the other hand, maybe this is the sort of thing Ryan&apos;s thinking about-- I wonder how hard it would be to hack this into Kid?  It would give only a subset of XSLT&apos;s capabilities in trade for simplicity, and would only offer the &#x201C;<a href=\"http://www.dpawson.co.uk/xsl/sect2/pushpull.html\">pull</a>&#x201D; approach, but it would give XML-pipelining to a ZPT-ish technology.</p>\n<p>I think this is something I want to look into a bit further at some point.</p>\n"
  },
  {
    "comments_archived": true,
    "date": "2004-11-30T21:53:35.000Z",
    "excerpt": "This has been where most of my private hacking sessions have been taking me over the past year or so:  combining HTML, CSS, DOM, JavaScript, XML, XSLT, and REST to build what I consider to be a next-generation web app.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "Next generation web apps using REST, XML, XSLT, and XmlHTTPRequest",
    "wordpress_id": 568,
    "wordpress_slug": "nextgenwebapps",
    "wordpress_url": "http://www.decafbad.com/blog/?p=568",
    "year": "2004",
    "month": "11",
    "day": "30",
    "isDir": false,
    "slug": "nextgenwebapps",
    "postName": "2004-11-30-nextgenwebapps",
    "html": "<p>So, like I was saying:  I&#39;ve been working on <a href=\"http://www.decafbad.com/kwiki?FeedReactor\">FeedReactor</a> and have been doing some things with it that I find rather interesting, independent of news aggregation.  </p>\n<p>One of the core goals I have for FeedReactor is to explore what it takes to build a web app that exploits <a href=\"http://www.xfront.com/REST-Web-Services.html\">principles of REST architecture</a>.  Having already <a href=\"http://www.decafbad.com/blog/tech/old/oooccb\">sung the praises</a> of XML-RPC, I wanted to get immersed in REST and see what all the hubbub was about.  I&#39;ve got some ways to go, but I think I understand the major concepts now, and it&#39;s a pretty nifty frame within which to work.</p>\n<p>But, two other things I&#39;ve added to my mix have really made things interesting for me:  </p>\n<ol>\n<li>XSLT filtering</li>\n<li>The XmlHTTPRequest object</li>\n</ol>\n<p>XSLT and REST make a really good pair, as <a href=\"http://www.decafbad.com/blog/2004/06/16/wishofthemonthclub1\">Amazon Web Services already demonstrate</a>.  Inspired by that API (<a href=\"http://www.decafbad.com/blog/2003/09/02/xsl_scraper\">and earlier experiments</a>), I use XML for all the input and output formats in my API and accept a query string parameter that contains the path to an XSLT file.  When this parameter is supplied, the XML output by the API is first processed using the given XSLT.  (Think of it like piping API output through <code>xsltproc</code>.)</p>\n<p>So, with a properly constructed collection of XSLT, I can present a browser-viewable HTML user interface served up directly from REST API calls.  Links, frame sets, and iframes present in the HTML lead the user from that call to the next XSLT-wrapped REST API call. </p>\n<p>But, once the initial HTML-and-JavaScript payload reaches the browser, it gets better (<a href=\"http://www.infoworld.com/article/04/10/22/43OPstrategic_1.html\">ala Gmail</a>):  </p>\n<p>On older browsers (if I happen to care about them), I can make new HTTP requests back to the server <a href=\"http://developer.apple.com/internet/webcontent/iframe.html\">from JavaScript using iframes</a>.  In this case, XSLT filtering lets me retrofit the API&#39;s responses to the HTML-and-JavaScript crud I need to serve up to make things happen back in the browser client.  Unfortunately, passing data <em>to</em> the API (which expects XML, not form submissions) is still a bit wonky and requires some hacks and exceptions involving hidden forms and such.</p>\n<p>However, on the newer browsers, it&#39;s all about the <a href=\"http://developer.apple.com/internet/webcontent/xmlhttpreq.html\">XmlHTTPRequest object</a>.  With this facility, I can make clean asynchronous requests back to the REST API, including XML data in the request body if I feel like it.  Responses are handled by JavaScript callbacks, which twiddle the browser DOM to update the user interface in response.  </p>\n<p>So, after the major initial contact with the API to supply the browser with HTML by way of XSLT, most future interactions take place in the form of direct calls to the REST API using XML.  Although for some things, it&#39;s easier to just reload a page of HTML, it&#39;s nicer for most interactions to be handled via DOM manipulations in-place.  I&#39;ve been amazed at the Gmail-like responsiveness I get from FeedReactor when I&#39;m skimming through news items, marking some as seen or flagged, and popping open the descriptions on others.  </p>\n<p>I suppose I <em>shouldn&#39;t</em> be amazed at the responsiveness, since I&#39;m using some of the same techniques as Gmail.  However, my daily-use installation of FeedReactor is presently running on an old 300Mhz Debian Linux PC at home, and it&#39;s taking me through the daily produce of 600 subscribed feeds faster than any desktop aggregator has yet.  Of course, this is partly a product of my familiarity with the UI I&#39;ve cobbled together, but... <em>the server&#39;s running on a 300Mhz PC with 256MB of RAM!</em>  And the client is my 867Mhz G4 PowerBook, running Firefox or Safari, depending on my mood.</p>\n<p>Although I can&#39;t see when I&#39;ll have time for it, I really want to explore this approach further using desktop apps on OS X and accessing the API from Flash movies (maybe using <a href=\"http://openlaszlo.org/\">Laszlo</a>).  I&#39;d also like to see how far I can go toward adapting the interface toward mobile devices like my Treo 600.</p>\n<p>So anyway, this has been where most of my private hacking sessions have been taking me over the past year or so:  combining HTML, CSS, DOM, JavaScript, XML, XSLT, and REST to build what I consider to be a next-generation web app.  </p>\n<p>Now, although I use FeedReactor on a daily basis to keep up with all my feeds, it&#39;s nowhere near any state suitable for public consumption.  I add new subscriptions from a command-line script and still fiddle with the database directly for some operations.  I&#39;d like to have a personal-server version of it ready for use by some alpha geeks before or not long into the new year, but I&#39;d like to share some of the things I&#39;ve been doing with it before then.</p>\n<p>With that in mind, I think I&#39;ll wrap up this entry and think about putting together a quick tutorial pico-project to demonstrate some of the concepts.  Maybe an address book, or something equally simple-yet-useful.  </p>\n<p>Stay tuned.</p>\n<!--more-->\n<p>shortname=nextgenwebapps</p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221089601\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.ricebridge.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=a57fe535201a5daca9590abd68d490c7&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.ricebridge.com\">Richard Rodger</a>\n</div>\n<a href=\"#comment-221089601\" class=\"permalink\"><time datetime=\"2004-12-01T08:14:39\">2004-12-01T08:14:39</time></a>\n</div>\n<div class=\"content\">You should take a look at http://www.json.org which provides a really nice JavaScript-native way to exchange data using XMLHttpRequest.</div>\n</li>\n<li class=\"comment\" id=\"comment-221089609\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://fiftyfly.mine.nu\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=c1e58f891708437e94407f573639094c&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://fiftyfly.mine.nu\">mike</a>\n</div>\n<a href=\"#comment-221089609\" class=\"permalink\"><time datetime=\"2004-12-01T14:23:44\">2004-12-01T14:23:44</time></a>\n</div>\n<div class=\"content\">This is def a powerful set of techniques. I hadn't worked with a lot of javascript in several years but recently I'd wanted to put a cleaner face on my proof of concept request icecast station: http://fiftyfly.mine.nu/RFM . An off hand comment somone had made regarding XMLHTTPRequest sounded so interesting I had to give it some thought. The result can be found here: http://fiftyfly.mine.nu/RFMamp.html . Faster, cleaner, far more flexible - this excercise has made me think about web services in a way I hadn't previously. Consider my eyes opened ;)</div>\n</li>\n</ul>\n</div>\n",
    "body": "So, like I was saying:  I've been working on [FeedReactor](http://www.decafbad.com/kwiki?FeedReactor) and have been doing some things with it that I find rather interesting, independent of news aggregation.  \r\n\r\nOne of the core goals I have for FeedReactor is to explore what it takes to build a web app that exploits [principles of REST architecture](http://www.xfront.com/REST-Web-Services.html).  Having already [sung the praises](http://www.decafbad.com/blog/tech/old/oooccb) of XML-RPC, I wanted to get immersed in REST and see what all the hubbub was about.  I've got some ways to go, but I think I understand the major concepts now, and it's a pretty nifty frame within which to work.\r\n\r\nBut, two other things I've added to my mix have really made things interesting for me:  \r\n\r\n1. XSLT filtering\r\n2. The XmlHTTPRequest object\r\n\r\nXSLT and REST make a really good pair, as [Amazon Web Services already demonstrate](http://www.decafbad.com/blog/2004/06/16/wishofthemonthclub1).  Inspired by that API ([and earlier experiments](http://www.decafbad.com/blog/2003/09/02/xsl_scraper)), I use XML for all the input and output formats in my API and accept a query string parameter that contains the path to an XSLT file.  When this parameter is supplied, the XML output by the API is first processed using the given XSLT.  (Think of it like piping API output through `xsltproc`.)\r\n\r\nSo, with a properly constructed collection of XSLT, I can present a browser-viewable HTML user interface served up directly from REST API calls.  Links, frame sets, and iframes present in the HTML lead the user from that call to the next XSLT-wrapped REST API call. \r\n\r\nBut, once the initial HTML-and-JavaScript payload reaches the browser, it gets better ([ala Gmail](http://www.infoworld.com/article/04/10/22/43OPstrategic_1.html)):  \r\n\r\nOn older browsers (if I happen to care about them), I can make new HTTP requests back to the server [from JavaScript using iframes](http://developer.apple.com/internet/webcontent/iframe.html).  In this case, XSLT filtering lets me retrofit the API's responses to the HTML-and-JavaScript crud I need to serve up to make things happen back in the browser client.  Unfortunately, passing data *to* the API (which expects XML, not form submissions) is still a bit wonky and requires some hacks and exceptions involving hidden forms and such.\r\n\r\nHowever, on the newer browsers, it's all about the [XmlHTTPRequest object](http://developer.apple.com/internet/webcontent/xmlhttpreq.html).  With this facility, I can make clean asynchronous requests back to the REST API, including XML data in the request body if I feel like it.  Responses are handled by JavaScript callbacks, which twiddle the browser DOM to update the user interface in response.  \r\n\r\nSo, after the major initial contact with the API to supply the browser with HTML by way of XSLT, most future interactions take place in the form of direct calls to the REST API using XML.  Although for some things, it's easier to just reload a page of HTML, it's nicer for most interactions to be handled via DOM manipulations in-place.  I've been amazed at the Gmail-like responsiveness I get from FeedReactor when I'm skimming through news items, marking some as seen or flagged, and popping open the descriptions on others.  \r\n\r\nI suppose I *shouldn't* be amazed at the responsiveness, since I'm using some of the same techniques as Gmail.  However, my daily-use installation of FeedReactor is presently running on an old 300Mhz Debian Linux PC at home, and it's taking me through the daily produce of 600 subscribed feeds faster than any desktop aggregator has yet.  Of course, this is partly a product of my familiarity with the UI I've cobbled together, but... *the server's running on a 300Mhz PC with 256MB of RAM!*  And the client is my 867Mhz G4 PowerBook, running Firefox or Safari, depending on my mood.\r\n\r\nAlthough I can't see when I'll have time for it, I really want to explore this approach further using desktop apps on OS X and accessing the API from Flash movies (maybe using [Laszlo](http://openlaszlo.org/)).  I'd also like to see how far I can go toward adapting the interface toward mobile devices like my Treo 600.\r\n\r\nSo anyway, this has been where most of my private hacking sessions have been taking me over the past year or so:  combining HTML, CSS, DOM, JavaScript, XML, XSLT, and REST to build what I consider to be a next-generation web app.  \r\n\r\nNow, although I use FeedReactor on a daily basis to keep up with all my feeds, it's nowhere near any state suitable for public consumption.  I add new subscriptions from a command-line script and still fiddle with the database directly for some operations.  I'd like to have a personal-server version of it ready for use by some alpha geeks before or not long into the new year, but I'd like to share some of the things I've been doing with it before then.\r\n\r\nWith that in mind, I think I'll wrap up this entry and think about putting together a quick tutorial pico-project to demonstrate some of the concepts.  Maybe an address book, or something equally simple-yet-useful.  \r\n\r\nStay tuned.\r\n<!--more-->\r\nshortname=nextgenwebapps\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221089601\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.ricebridge.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=a57fe535201a5daca9590abd68d490c7&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.ricebridge.com\">Richard Rodger</a>\r\n                </div>\r\n                <a href=\"#comment-221089601\" class=\"permalink\"><time datetime=\"2004-12-01T08:14:39\">2004-12-01T08:14:39</time></a>\r\n            </div>\r\n            <div class=\"content\">You should take a look at http://www.json.org which provides a really nice JavaScript-native way to exchange data using XMLHttpRequest.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221089609\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://fiftyfly.mine.nu\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=c1e58f891708437e94407f573639094c&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://fiftyfly.mine.nu\">mike</a>\r\n                </div>\r\n                <a href=\"#comment-221089609\" class=\"permalink\"><time datetime=\"2004-12-01T14:23:44\">2004-12-01T14:23:44</time></a>\r\n            </div>\r\n            <div class=\"content\">This is def a powerful set of techniques. I hadn't worked with a lot of javascript in several years but recently I'd wanted to put a cleaner face on my proof of concept request icecast station: http://fiftyfly.mine.nu/RFM . An off hand comment somone had made regarding XMLHTTPRequest sounded so interesting I had to give it some thought. The result can be found here: http://fiftyfly.mine.nu/RFMamp.html . Faster, cleaner, far more flexible - this excercise has made me think about web services in a way I hadn't previously. Consider my eyes opened ;)</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2004",
    "path": "2004/11/30/nextgenwebapps",
    "summary": "<p>So, like I was saying:  I&apos;ve been working on <a href=\"http://www.decafbad.com/kwiki?FeedReactor\">FeedReactor</a> and have been doing some things with it that I find rather interesting, independent of news aggregation.  </p>\n<p>One of the core goals I have for FeedReactor is to explore what it takes to build a web app that exploits <a href=\"http://www.xfront.com/REST-Web-Services.html\">principles of REST architecture</a>.  Having already <a href=\"http://www.decafbad.com/blog/tech/old/oooccb\">sung the praises</a> of XML-RPC, I wanted to get immersed in REST and see what all the hubbub was about.  I&apos;ve got some ways to go, but I think I understand the major concepts now, and it&apos;s a pretty nifty frame within which to work.</p>\n<p>But, two other things I&apos;ve added to my mix have really made things interesting for me:  </p>\n<ol>\n<li>XSLT filtering</li>\n<li>The XmlHTTPRequest object</li>\n</ol>\n<p>XSLT and REST make a really good pair, as <a href=\"http://www.decafbad.com/blog/2004/06/16/wishofthemonthclub1\">Amazon Web Services already demonstrate</a>.  Inspired by that API (<a href=\"http://www.decafbad.com/blog/2003/09/02/xsl_scraper\">and earlier experiments</a>), I use XML for all the input and output formats in my API and accept a query string parameter that contains the path to an XSLT file.  When this parameter is supplied, the XML output by the API is first processed using the given XSLT.  (Think of it like piping API output through <code>xsltproc</code>.)</p>\n<p>So, with a properly constructed collection of XSLT, I can present a browser-viewable HTML user interface served up directly from REST API calls.  Links, frame sets, and iframes present in the HTML lead the user from that call to the next XSLT-wrapped REST API call. </p>\n<p>But, once the initial HTML-and-JavaScript payload reaches the browser, it gets better (<a href=\"http://www.infoworld.com/article/04/10/22/43OPstrategic_1.html\">ala Gmail</a>):  </p>\n<p>On older browsers (if I happen to care about them), I can make new HTTP requests back to the server <a href=\"http://developer.apple.com/internet/webcontent/iframe.html\">from JavaScript using iframes</a>.  In this case, XSLT filtering lets me retrofit the API&apos;s responses to the HTML-and-JavaScript crud I need to serve up to make things happen back in the browser client.  Unfortunately, passing data <em>to</em> the API (which expects XML, not form submissions) is still a bit wonky and requires some hacks and exceptions involving hidden forms and such.</p>\n<p>However, on the newer browsers, it&apos;s all about the <a href=\"http://developer.apple.com/internet/webcontent/xmlhttpreq.html\">XmlHTTPRequest object</a>.  With this facility, I can make clean asynchronous requests back to the REST API, including XML data in the request body if I feel like it.  Responses are handled by JavaScript callbacks, which twiddle the browser DOM to update the user interface in response.  </p>\n<p>So, after the major initial contact with the API to supply the browser with HTML by way of XSLT, most future interactions take place in the form of direct calls to the REST API using XML.  Although for some things, it&apos;s easier to just reload a page of HTML, it&apos;s nicer for most interactions to be handled via DOM manipulations in-place.  I&apos;ve been amazed at the Gmail-like responsiveness I get from FeedReactor when I&apos;m skimming through news items, marking some as seen or flagged, and popping open the descriptions on others.  </p>\n<p>I suppose I <em>shouldn&apos;t</em> be amazed at the responsiveness, since I&apos;m using some of the same techniques as Gmail.  However, my daily-use installation of FeedReactor is presently running on an old 300Mhz Debian Linux PC at home, and it&apos;s taking me through the daily produce of 600 subscribed feeds faster than any desktop aggregator has yet.  Of course, this is partly a product of my familiarity with the UI I&apos;ve cobbled together, but... <em>the server&apos;s running on a 300Mhz PC with 256MB of RAM!</em>  And the client is my 867Mhz G4 PowerBook, running Firefox or Safari, depending on my mood.</p>\n<p>Although I can&apos;t see when I&apos;ll have time for it, I really want to explore this approach further using desktop apps on OS X and accessing the API from Flash movies (maybe using <a href=\"http://openlaszlo.org/\">Laszlo</a>).  I&apos;d also like to see how far I can go toward adapting the interface toward mobile devices like my Treo 600.</p>\n<p>So anyway, this has been where most of my private hacking sessions have been taking me over the past year or so:  combining HTML, CSS, DOM, JavaScript, XML, XSLT, and REST to build what I consider to be a next-generation web app.  </p>\n<p>Now, although I use FeedReactor on a daily basis to keep up with all my feeds, it&apos;s nowhere near any state suitable for public consumption.  I add new subscriptions from a command-line script and still fiddle with the database directly for some operations.  I&apos;d like to have a personal-server version of it ready for use by some alpha geeks before or not long into the new year, but I&apos;d like to share some of the things I&apos;ve been doing with it before then.</p>\n<p>With that in mind, I think I&apos;ll wrap up this entry and think about putting together a quick tutorial pico-project to demonstrate some of the concepts.  Maybe an address book, or something equally simple-yet-useful.  </p>\n<p>Stay tuned.</p>\n"
  },
  {
    "comments_archived": true,
    "date": "2004-10-08T17:07:49.000Z",
    "excerpt": "So I had an idea for a quick podcasting listening hack on the way into work this morning.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "Using iTunes as a podcast aggregator, with a little help from XSLT",
    "wordpress_id": 561,
    "wordpress_slug": "itunesxslt",
    "wordpress_url": "http://www.decafbad.com/blog/?p=561",
    "year": "2004",
    "month": "10",
    "day": "08",
    "isDir": false,
    "slug": "itunesxslt",
    "postName": "2004-10-08-itunesxslt",
    "html": "<p>So I had an idea for a quick podcasting listening hack on the way into work this morning. Check it out:</p>\n<ul>\n<li>Take one <a href=\"http://www.decafbad.com/2004/10/podcasts.opml\">list of RSS feeds in OPML</a>.</li>\n<li>Throw in <a href=\"http://www.decafbad.com/2004/10/opml-to-playlist.xsl\">a bit of XSLT</a>.</li>\n<li>Combine using <code>xsltproc</code> to make <a href=\"http://www.decafbad.com/2004/10/podcasts.pls\">a playlist</a> that works in iTunes.</li>\n</ul>\n<p>And, oh yeah, I just happen to have an <code>xsltproc</code> web service laying around, so:</p>\n<ul>\n<li>Supply a URL to your OPML in <a href=\"http://www.decafbad.com/2004/10/xsltproc.cgi?xsl=http%3A%2F%2Fwww.decafbad.com%2F2004%2F10%2Fopml-to-playlist.xsl\">this form</a>.</li>\n<li>Get a <a href=\"http://www.decafbad.com/2004/10/xsltproc.cgi?xsl=http%3A%2F%2Fwww.decafbad.com%2F2004%2F10%2Fopml-to-playlist.xsl&#38;xml=http%3A%2F%2Fwww.decafbad.com%2F2004%2F10%2Fpodcasts.opml\">freshly-built playlist</a>.</li>\n</ul>\n<p>Now, this has been barely tested and is the product of a ten-minute hacking session.  There are likely an enormous number of things wrong with this.  That said, iTunes does seem to open the playlist happily, and it looks like only new streams are added with repeated openings of the playlist.</p>\n<p>You will want to be careful to ensure that your OPML is valid XML (mine wasn&#39;t, on initial export from iPodderX - escape those freaking ampersands in URLs already!), and I have no idea what would happen if any of the RSS feeds in your subscriptions turn up invalid.  </p>\n<p>Have I mentioned that, despite their unforgiving and sometimes fragile nature, I love XML technologies?</p>\n<p>If this looks useful, maybe I&#39;ll work it over a bit more and pair it up with some python to handle actually downloading the MP3s and torrents.</p>\n<p><strong>Update:</strong> Oh yeah, and I&#39;m expecting this will be useful with an iTunes smart playlist crafted along these lines:</p>\n<ul>\n<li>Date Added in the last 1 days</li>\n<li>Play Count is less than 1</li>\n</ul>\n<p><strong>Update #2:</strong> Another use I just found for this playlist, is on my <a href=\"http://www.xboxmediacenter.com/\">Xbox Media Center</a>.  I generate this playlist via cronjob every few hours, and store it on an SMB share accessible to the XBMC.  Voila!  Listening to podcasts on my stereo system via the Xbox.  Yeah, nothing big, just kind of nifty.</p>\n<!--more-->\n<p>shortname=itunesxslt</p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221090734\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=a5cae412b649470abb8827c85ef2d4c8&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"\">Kevin</a>\n</div>\n<a href=\"#comment-221090734\" class=\"permalink\"><time datetime=\"2004-10-21T10:32:55\">2004-10-21T10:32:55</time></a>\n</div>\n<div class=\"content\">This is a great idea...  My playlist seems to be formated all wrong, so i need to work on it.  Any advancements on this one?</div>\n</li>\n</ul>\n</div>\n",
    "body": "So I had an idea for a quick podcasting listening hack on the way into work this morning. Check it out:\r\n\r\n* Take one [list of RSS feeds in OPML](http://www.decafbad.com/2004/10/podcasts.opml).\r\n* Throw in [a bit of XSLT](http://www.decafbad.com/2004/10/opml-to-playlist.xsl).\r\n* Combine using `xsltproc` to make [a playlist](http://www.decafbad.com/2004/10/podcasts.pls) that works in iTunes.\r\n\r\nAnd, oh yeah, I just happen to have an `xsltproc` web service laying around, so:\r\n\r\n* Supply a URL to your OPML in [this form](http://www.decafbad.com/2004/10/xsltproc.cgi?xsl=http%3A%2F%2Fwww.decafbad.com%2F2004%2F10%2Fopml-to-playlist.xsl).\r\n* Get a [freshly-built playlist](http://www.decafbad.com/2004/10/xsltproc.cgi?xsl=http%3A%2F%2Fwww.decafbad.com%2F2004%2F10%2Fopml-to-playlist.xsl&#38;xml=http%3A%2F%2Fwww.decafbad.com%2F2004%2F10%2Fpodcasts.opml).\r\n\r\nNow, this has been barely tested and is the product of a ten-minute hacking session.  There are likely an enormous number of things wrong with this.  That said, iTunes does seem to open the playlist happily, and it looks like only new streams are added with repeated openings of the playlist.\r\n\r\nYou will want to be careful to ensure that your OPML is valid XML (mine wasn't, on initial export from iPodderX - escape those freaking ampersands in URLs already!), and I have no idea what would happen if any of the RSS feeds in your subscriptions turn up invalid.  \r\n\r\nHave I mentioned that, despite their unforgiving and sometimes fragile nature, I love XML technologies?\r\n\r\nIf this looks useful, maybe I'll work it over a bit more and pair it up with some python to handle actually downloading the MP3s and torrents.\r\n\r\n**Update:** Oh yeah, and I'm expecting this will be useful with an iTunes smart playlist crafted along these lines:\r\n\r\n* Date Added in the last 1 days\r\n* Play Count is less than 1\r\n\r\n**Update #2:** Another use I just found for this playlist, is on my [Xbox Media Center](http://www.xboxmediacenter.com/).  I generate this playlist via cronjob every few hours, and store it on an SMB share accessible to the XBMC.  Voila!  Listening to podcasts on my stereo system via the Xbox.  Yeah, nothing big, just kind of nifty.\r\n<!--more-->\r\nshortname=itunesxslt\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221090734\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=a5cae412b649470abb8827c85ef2d4c8&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"\">Kevin</a>\r\n                </div>\r\n                <a href=\"#comment-221090734\" class=\"permalink\"><time datetime=\"2004-10-21T10:32:55\">2004-10-21T10:32:55</time></a>\r\n            </div>\r\n            <div class=\"content\">This is a great idea...  My playlist seems to be formated all wrong, so i need to work on it.  Any advancements on this one?</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2004",
    "path": "2004/10/08/itunesxslt",
    "summary": "<p>So I had an idea for a quick podcasting listening hack on the way into work this morning. Check it out:</p>\n<ul>\n<li>Take one <a href=\"http://www.decafbad.com/2004/10/podcasts.opml\">list of RSS feeds in OPML</a>.</li>\n<li>Throw in <a href=\"http://www.decafbad.com/2004/10/opml-to-playlist.xsl\">a bit of XSLT</a>.</li>\n<li>Combine using <code>xsltproc</code> to make <a href=\"http://www.decafbad.com/2004/10/podcasts.pls\">a playlist</a> that works in iTunes.</li>\n</ul>\n<p>And, oh yeah, I just happen to have an <code>xsltproc</code> web service laying around, so:</p>\n<ul>\n<li>Supply a URL to your OPML in <a href=\"http://www.decafbad.com/2004/10/xsltproc.cgi?xsl=http%3A%2F%2Fwww.decafbad.com%2F2004%2F10%2Fopml-to-playlist.xsl\">this form</a>.</li>\n<li>Get a <a href=\"http://www.decafbad.com/2004/10/xsltproc.cgi?xsl=http%3A%2F%2Fwww.decafbad.com%2F2004%2F10%2Fopml-to-playlist.xsl&amp;xml=http%3A%2F%2Fwww.decafbad.com%2F2004%2F10%2Fpodcasts.opml\">freshly-built playlist</a>.</li>\n</ul>\n<p>Now, this has been barely tested and is the product of a ten-minute hacking session.  There are likely an enormous number of things wrong with this.  That said, iTunes does seem to open the playlist happily, and it looks like only new streams are added with repeated openings of the playlist.</p>\n<p>You will want to be careful to ensure that your OPML is valid XML (mine wasn&apos;t, on initial export from iPodderX - escape those freaking ampersands in URLs already!), and I have no idea what would happen if any of the RSS feeds in your subscriptions turn up invalid.  </p>\n<p>Have I mentioned that, despite their unforgiving and sometimes fragile nature, I love XML technologies?</p>\n<p>If this looks useful, maybe I&apos;ll work it over a bit more and pair it up with some python to handle actually downloading the MP3s and torrents.</p>\n<p><strong>Update:</strong> Oh yeah, and I&apos;m expecting this will be useful with an iTunes smart playlist crafted along these lines:</p>\n<ul>\n<li>Date Added in the last 1 days</li>\n<li>Play Count is less than 1</li>\n</ul>\n<p><strong>Update #2:</strong> Another use I just found for this playlist, is on my <a href=\"http://www.xboxmediacenter.com/\">Xbox Media Center</a>.  I generate this playlist via cronjob every few hours, and store it on an SMB share accessible to the XBMC.  Voila!  Listening to podcasts on my stereo system via the Xbox.  Yeah, nothing big, just kind of nifty.</p>\n"
  },
  {
    "comments_archived": true,
    "date": "2004-09-17T13:32:30.000Z",
    "excerpt": "Wow.  So it looks like there are some people starting to follow to what I'm doing with dbagg3, and they're showing me how woefully prepared I am for the attention from tinkerers who are actually trying to, you know, run my code.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "dbagg3: Please excuse the mess",
    "wordpress_id": 549,
    "wordpress_slug": "dbagg3mess",
    "wordpress_url": "http://www.decafbad.com/blog/?p=549",
    "year": "2004",
    "month": "09",
    "day": "17",
    "isDir": false,
    "slug": "dbagg3mess",
    "postName": "2004-09-17-dbagg3mess",
    "html": "<p>Wow.  So it looks like there are some people starting to follow to what I&#39;m doing with <code>dbagg3</code>, and they&#39;re showing me how woefully prepared I am for the attention from tinkerers who are actually trying to, you know, <strong>run</strong> my code.  Things have been crazy busy for me at work, so I haven&#39;t been getting done what I&#39;ve planned.  But, I do need to pull a few things together and clean a few things up.  I&#39;ll soon be answering the smattering of email I&#39;ve gotten so far, but until then, a few quick thoughts:</p>\n<ul>\n<li><p>My source control is a bit of a mess at the moment.  Not only have I <a href=\"http://www.decafbad.com/blog/2004/09/16/moving_time_from_cvs_to_subversion\">switched from CVS to SVN</a>-- but even if you followed me in that migration, I&#39;ve not kept committed code in working order.  I already know that this is a horrible habit, but since no one&#39;s really been looking, I haven&#39;t been called on it until now.  (Heh, heh--d&#39;oh.)  Planning this weekend (but hopefully today) to resolve this, so that moving forward, svn trunk will be (as far as possible) in a working state at any given moment.</p>\n</li>\n<li><p>I&#39;ve hacked one of my dependencies, SQLObject, by applying <a href=\"http://sourceforge.net/mailarchive/message.php?msg_id=9122066\">a patch</a> to support SELECT DISTINCT queries.  This has understandably caused problems for some people who have no idea what I did.  This patch has turned out to be essential, though I don&#39;t know if/when it will or would be included in a release of SQLObject.  So...  I wonder if I should dump my working copy of SQLObject into source control?  Otherwise, applying the DISTINCT patch to your SQLObject install should work.</p>\n</li>\n<li><p>At some point very soon, I want to change the name of this thing to <strong>feedReactor</strong>.  Yes, I know there&#39;s already a <em>feedparser</em>, and a <em>feeddemon</em>, and a <em>feedburner</em>, and someone&#39;s probably got a <em>feedkitchensink</em> in the works, but I like this name and want to run with it.</p>\n</li>\n</ul>\n<p>So, in the meantime while I straighten some things out, please excuse the mess and thanks for bearing with me!</p>\n<!--more-->\n<p>shortname=dbagg3mess</p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221083379\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=1229fe3e2959517f522393889bedbf61&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"\">Christian Henz</a>\n</div>\n<a href=\"#comment-221083379\" class=\"permalink\"><time datetime=\"2004-09-18T06:25:13\">2004-09-18T06:25:13</time></a>\n</div>\n<div class=\"content\">I think having a copy of your SQLObject tree would be most helpful.\nFirst of all, that patch applies (or at least _did_ apply a few weeks ago) to their development version, while you're using the 0.5 Version, right? \nI also 'back-ported' the patch to 0.5.2 (only the distinct part though), but I'm still getting errors...\ncheers,\nChristian</div>\n</li>\n<li class=\"comment\" id=\"comment-221083380\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=1229fe3e2959517f522393889bedbf61&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"\">Christian Henz</a>\n</div>\n<a href=\"#comment-221083380\" class=\"permalink\"><time datetime=\"2004-09-18T07:28:15\">2004-09-18T07:28:15</time></a>\n</div>\n<div class=\"content\">Woops, just tried it again with a fresh svn-upped dbagg3 and it seems to work now.\nGood stuff :-)\ncheers,\nChristian</div>\n</li>\n</ul>\n</div>\n",
    "body": "Wow.  So it looks like there are some people starting to follow to what I'm doing with `dbagg3`, and they're showing me how woefully prepared I am for the attention from tinkerers who are actually trying to, you know, **run** my code.  Things have been crazy busy for me at work, so I haven't been getting done what I've planned.  But, I do need to pull a few things together and clean a few things up.  I'll soon be answering the smattering of email I've gotten so far, but until then, a few quick thoughts:\r\n\r\n* My source control is a bit of a mess at the moment.  Not only have I [switched from CVS to SVN][svnswitch]-- but even if you followed me in that migration, I've not kept committed code in working order.  I already know that this is a horrible habit, but since no one's really been looking, I haven't been called on it until now.  (Heh, heh--d'oh.)  Planning this weekend (but hopefully today) to resolve this, so that moving forward, svn trunk will be (as far as possible) in a working state at any given moment.\r\n\r\n* I've hacked one of my dependencies, SQLObject, by applying [a patch][sodistinct] to support SELECT DISTINCT queries.  This has understandably caused problems for some people who have no idea what I did.  This patch has turned out to be essential, though I don't know if/when it will or would be included in a release of SQLObject.  So...  I wonder if I should dump my working copy of SQLObject into source control?  Otherwise, applying the DISTINCT patch to your SQLObject install should work.\r\n\r\n* At some point very soon, I want to change the name of this thing to **feedReactor**.  Yes, I know there's already a *feedparser*, and a *feeddemon*, and a *feedburner*, and someone's probably got a *feedkitchensink* in the works, but I like this name and want to run with it.\r\n\r\nSo, in the meantime while I straighten some things out, please excuse the mess and thanks for bearing with me!\r\n\r\n[sodistinct]: http://sourceforge.net/mailarchive/message.php?msg_id=9122066\r\n[svnswitch]: http://www.decafbad.com/blog/2004/09/16/moving_time_from_cvs_to_subversion\r\n<!--more-->\r\nshortname=dbagg3mess\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221083379\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=1229fe3e2959517f522393889bedbf61&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"\">Christian Henz</a>\r\n                </div>\r\n                <a href=\"#comment-221083379\" class=\"permalink\"><time datetime=\"2004-09-18T06:25:13\">2004-09-18T06:25:13</time></a>\r\n            </div>\r\n            <div class=\"content\">I think having a copy of your SQLObject tree would be most helpful.\r\n\r\nFirst of all, that patch applies (or at least _did_ apply a few weeks ago) to their development version, while you're using the 0.5 Version, right? \r\n\r\nI also 'back-ported' the patch to 0.5.2 (only the distinct part though), but I'm still getting errors...\r\n\r\n\r\ncheers,\r\nChristian</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221083380\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=1229fe3e2959517f522393889bedbf61&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"\">Christian Henz</a>\r\n                </div>\r\n                <a href=\"#comment-221083380\" class=\"permalink\"><time datetime=\"2004-09-18T07:28:15\">2004-09-18T07:28:15</time></a>\r\n            </div>\r\n            <div class=\"content\">Woops, just tried it again with a fresh svn-upped dbagg3 and it seems to work now.\r\n\r\nGood stuff :-)\r\n\r\ncheers,\r\nChristian</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2004",
    "path": "2004/09/17/dbagg3mess",
    "summary": "<p>Wow.  So it looks like there are some people starting to follow to what I&apos;m doing with <code>dbagg3</code>, and they&apos;re showing me how woefully prepared I am for the attention from tinkerers who are actually trying to, you know, <strong>run</strong> my code.  Things have been crazy busy for me at work, so I haven&apos;t been getting done what I&apos;ve planned.  But, I do need to pull a few things together and clean a few things up.  I&apos;ll soon be answering the smattering of email I&apos;ve gotten so far, but until then, a few quick thoughts:</p>\n<ul>\n<li><p>My source control is a bit of a mess at the moment.  Not only have I <a href=\"http://www.decafbad.com/blog/2004/09/16/moving_time_from_cvs_to_subversion\">switched from CVS to SVN</a>-- but even if you followed me in that migration, I&apos;ve not kept committed code in working order.  I already know that this is a horrible habit, but since no one&apos;s really been looking, I haven&apos;t been called on it until now.  (Heh, heh--d&apos;oh.)  Planning this weekend (but hopefully today) to resolve this, so that moving forward, svn trunk will be (as far as possible) in a working state at any given moment.</p>\n</li>\n<li><p>I&apos;ve hacked one of my dependencies, SQLObject, by applying <a href=\"http://sourceforge.net/mailarchive/message.php?msg_id=9122066\">a patch</a> to support SELECT DISTINCT queries.  This has understandably caused problems for some people who have no idea what I did.  This patch has turned out to be essential, though I don&apos;t know if/when it will or would be included in a release of SQLObject.  So...  I wonder if I should dump my working copy of SQLObject into source control?  Otherwise, applying the DISTINCT patch to your SQLObject install should work.</p>\n</li>\n<li><p>At some point very soon, I want to change the name of this thing to <strong>feedReactor</strong>.  Yes, I know there&apos;s already a <em>feedparser</em>, and a <em>feeddemon</em>, and a <em>feedburner</em>, and someone&apos;s probably got a <em>feedkitchensink</em> in the works, but I like this name and want to run with it.</p>\n</li>\n</ul>\n<p>So, in the meantime while I straighten some things out, please excuse the mess and thanks for bearing with me!</p>\n"
  },
  {
    "comments_archived": true,
    "date": "2004-09-16T15:29:04.000Z",
    "excerpt": "So, I'm waiting for the other shoe to drop.  After making sure things seemed reasonably stable post-server-move, I migrated my CVS repository here to Subversion.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "Moving time: From CVS to Subversion",
    "wordpress_id": 548,
    "wordpress_slug": "moving-time-from-cvs-to-subversion",
    "wordpress_url": "http://www.decafbad.com/blog/?p=548",
    "year": "2004",
    "month": "09",
    "day": "16",
    "isDir": false,
    "slug": "moving-time-from-cvs-to-subversion",
    "postName": "2004-09-16-moving-time-from-cvs-to-subversion",
    "html": "<p>So, I&#39;m waiting for the other shoe to drop.  After making sure things seemed reasonably stable post-server-move, I migrated my CVS repository here to <a href=\"http://subversion.tigris.org/\">Subversion</a>.  There were one or two tiny bumps in the road-- such as a default setting in Apache to deny access to anything starting with .ht (ie. .htaccess)-- but so far, so good.  <a href=\"http://viewcvs.sourceforge.net/\">ViewCVS</a> appears to support Subversion, and I&#39;ve also discovered an alternate frontend called <a href=\"http://websvn.tigris.org/\">WebSVN</a>.  I like ViewCVS better, but WebSVN offers RSS feeds on commits.</p>\n<p>One consequence to this move is that soon, when I take down everything related to CVS, I&#39;ll have plenty of broken links (since I frequently link to ViewCVS pages for my projects).  So, I think my next step will be to set up some redirects to a reasonable number of things for continuity&#39;s sake.</p>\n<p>So, anyway... if you&#39;ve been keeping up with <code>dbagg3</code>, the action&#39;s not in CVS anymore.  It&#39;s here:</p>\n<ul>\n<li><a href=\"http://www.decafbad.com/svn/trunk/dbagg3/\">http://www.decafbad.com/svn/trunk/dbagg3/</a></li>\n</ul>\n<p>Alternately, you can also peek at things here:</p>\n<ul>\n<li><a href=\"http://www.decafbad.com/svn-view/trunk/dbagg3/\">http://www.decafbad.com/svn-view/trunk/dbagg3/</a></li>\n<li><a href=\"http://www.decafbad.com/websvn/listing.php?repname=0xDECAFBAD%20projects&#38;path=%2Ftrunk%2Fdbagg3%2F&#38;rev=0&#38;sc=0\">WebSVN</a></li>\n</ul>\n<p>(Can you see one reason why I like ViewCVS so much better?)</p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221085325\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.unix-girl.com/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=dec4418e2a8f2b2a11408df7cf343bcc&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.unix-girl.com/blog\">kasia</a>\n</div>\n<a href=\"#comment-221085325\" class=\"permalink\"><time datetime=\"2004-09-16T11:53:06\">2004-09-16T11:53:06</time></a>\n</div>\n<div class=\"content\">ViewCVS is much better than WebSVN, you could create RSS feeds with a relatively simple post-commit hook, or even just modify the email changes post-commit hook to also generate RSS feeds..</div>\n</li>\n<li class=\"comment\" id=\"comment-221085328\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://blog.ianbicking.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=cc8334869c9d2a9e603017f2da805eb3&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://blog.ianbicking.org\">Ian Bicking</a>\n</div>\n<a href=\"#comment-221085328\" class=\"permalink\"><time datetime=\"2004-09-16T12:50:14\">2004-09-16T12:50:14</time></a>\n</div>\n<div class=\"content\">One PITA with ViewCVS is that it has to have write access to the repository, and having multiple users access the repository can cause the permissions to get out of wack and make the repository unavailable.  I don't know if WebSVN uses the client svn libraries (i.e., accesses the repository through the server, instead of accessing repository files directly), but if it does then I would probably stick with it.  Though if you are using Apache, I suppose it's all being accessed as the same user, so it shouldn't be too much of a problem.</div>\n</li>\n<li class=\"comment\" id=\"comment-221085330\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://simon.incutio.com/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=02ecb4f56e961dd226352c4dd51eff26&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://simon.incutio.com/\">Simon Willison</a>\n</div>\n<a href=\"#comment-221085330\" class=\"permalink\"><time datetime=\"2004-09-16T13:19:41\">2004-09-16T13:19:41</time></a>\n</div>\n<div class=\"content\">Have you looked at Trac? http://projects.edgewall.com/trac\nsvn browser, bug tracker and wiki rolled in to one. It's very sexy.</div>\n</li>\n<li class=\"comment\" id=\"comment-221085331\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=d6c17175cba2c2d27483fe5f4ed8ee27&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"\">Ben Weekes</a>\n</div>\n<a href=\"#comment-221085331\" class=\"permalink\"><time datetime=\"2004-09-16T13:19:45\">2004-09-16T13:19:45</time></a>\n</div>\n<div class=\"content\">I suggest that if you want to avoid breaking URLs again in future you take the \"svn\" out of those URLs.\nI generally prefer WebSVN; it seems to fit the \"Subversion Way\" a lot better than ViewCVS, which bends it to a CVS way of thinking about things to some extent. Mostly, though, they're essentially the same thing. WebSVN's theme and UI needs a little work, but other than that I find it good. Providing both is nice, though!\nI'm guessing you're picking on WebSVN's horrible URLs... and I agree with you on that. It has been an intention of mine for a while to take a look at it and see if I can't use some mod_rewrite magic to make it nicer. I don't much like PHP, though, so I've not got around to it yet.</div>\n</li>\n</ul>\n</div>\n",
    "body": "So, I'm waiting for the other shoe to drop.  After making sure things seemed reasonably stable post-server-move, I migrated my CVS repository here to [Subversion][subversion].  There were one or two tiny bumps in the road-- such as a default setting in Apache to deny access to anything starting with .ht (ie. .htaccess)-- but so far, so good.  [ViewCVS][viewcvs] appears to support Subversion, and I've also discovered an alternate frontend called [WebSVN][websvn].  I like ViewCVS better, but WebSVN offers RSS feeds on commits.\r\n\r\nOne consequence to this move is that soon, when I take down everything related to CVS, I'll have plenty of broken links (since I frequently link to ViewCVS pages for my projects).  So, I think my next step will be to set up some redirects to a reasonable number of things for continuity's sake.\r\n\r\nSo, anyway... if you've been keeping up with `dbagg3`, the action's not in CVS anymore.  It's here:\r\n\r\n* <http://www.decafbad.com/svn/trunk/dbagg3/>\r\n\r\nAlternately, you can also peek at things here:\r\n\r\n* <http://www.decafbad.com/svn-view/trunk/dbagg3/>\r\n* [WebSVN](http://www.decafbad.com/websvn/listing.php?repname=0xDECAFBAD%20projects&#38;path=%2Ftrunk%2Fdbagg3%2F&#38;rev=0&#38;sc=0)\r\n\r\n(Can you see one reason why I like ViewCVS so much better?)\r\n\r\n[viewcvs]: http://viewcvs.sourceforge.net/\r\n[subversion]: http://subversion.tigris.org/\r\n[websvn]: http://websvn.tigris.org/\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221085325\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.unix-girl.com/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=dec4418e2a8f2b2a11408df7cf343bcc&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.unix-girl.com/blog\">kasia</a>\r\n                </div>\r\n                <a href=\"#comment-221085325\" class=\"permalink\"><time datetime=\"2004-09-16T11:53:06\">2004-09-16T11:53:06</time></a>\r\n            </div>\r\n            <div class=\"content\">ViewCVS is much better than WebSVN, you could create RSS feeds with a relatively simple post-commit hook, or even just modify the email changes post-commit hook to also generate RSS feeds..</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221085328\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://blog.ianbicking.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=cc8334869c9d2a9e603017f2da805eb3&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://blog.ianbicking.org\">Ian Bicking</a>\r\n                </div>\r\n                <a href=\"#comment-221085328\" class=\"permalink\"><time datetime=\"2004-09-16T12:50:14\">2004-09-16T12:50:14</time></a>\r\n            </div>\r\n            <div class=\"content\">One PITA with ViewCVS is that it has to have write access to the repository, and having multiple users access the repository can cause the permissions to get out of wack and make the repository unavailable.  I don't know if WebSVN uses the client svn libraries (i.e., accesses the repository through the server, instead of accessing repository files directly), but if it does then I would probably stick with it.  Though if you are using Apache, I suppose it's all being accessed as the same user, so it shouldn't be too much of a problem.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221085330\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://simon.incutio.com/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=02ecb4f56e961dd226352c4dd51eff26&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://simon.incutio.com/\">Simon Willison</a>\r\n                </div>\r\n                <a href=\"#comment-221085330\" class=\"permalink\"><time datetime=\"2004-09-16T13:19:41\">2004-09-16T13:19:41</time></a>\r\n            </div>\r\n            <div class=\"content\">Have you looked at Trac? http://projects.edgewall.com/trac\r\n\r\nsvn browser, bug tracker and wiki rolled in to one. It's very sexy.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221085331\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=d6c17175cba2c2d27483fe5f4ed8ee27&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"\">Ben Weekes</a>\r\n                </div>\r\n                <a href=\"#comment-221085331\" class=\"permalink\"><time datetime=\"2004-09-16T13:19:45\">2004-09-16T13:19:45</time></a>\r\n            </div>\r\n            <div class=\"content\">I suggest that if you want to avoid breaking URLs again in future you take the \"svn\" out of those URLs.\r\n\r\nI generally prefer WebSVN; it seems to fit the \"Subversion Way\" a lot better than ViewCVS, which bends it to a CVS way of thinking about things to some extent. Mostly, though, they're essentially the same thing. WebSVN's theme and UI needs a little work, but other than that I find it good. Providing both is nice, though!\r\n\r\nI'm guessing you're picking on WebSVN's horrible URLs... and I agree with you on that. It has been an intention of mine for a while to take a look at it and see if I can't use some mod_rewrite magic to make it nicer. I don't much like PHP, though, so I've not got around to it yet.</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2004",
    "path": "2004/09/16/moving-time-from-cvs-to-subversion"
  },
  {
    "comments_archived": true,
    "date": "2004-09-15T18:48:53.000Z",
    "excerpt": "So... am I missing a more elegant RESTful way of doing this which doesn't result in a quadrillion HTTP requests?",
    "layout": "post",
    "tags": [
      "xml"
    ],
    "title": "Manipulating aggregate resources in a REST API?",
    "wordpress_id": 547,
    "wordpress_slug": "manipulating-aggregate-resources-in-a-rest-api",
    "wordpress_url": "http://www.decafbad.com/blog/?p=547",
    "year": "2004",
    "month": "09",
    "day": "15",
    "isDir": false,
    "slug": "manipulating-aggregate-resources-in-a-rest-api",
    "postName": "2004-09-15-manipulating-aggregate-resources-in-a-rest-api",
    "html": "<p>Here&#39;s a tiny bit of a REST-ian quandary:  I&#39;m working through this API for <code>dbagg3</code>.  The major resources involved include <strong>subscriptions</strong> and <strong>entries</strong>.  Quite often, while working on the UI, I find a need to manipulate ranges and collections of these resources-- things like: &#8220;mark these 12 entries as read&#8221; and &#8220;give me an aggregate of the new entries for these 6 subscriptions&#8221;.</p>\n<p>So, I have been using URLs like the following:</p>\n<ul>\n<li><code>POST /subscriptions/523/entries/12322,12326,12325,12388,12412/notes/</code></li>\n<li><code>GET /subscriptions/312,443,523/now-12.xml</code></li>\n</ul>\n<p>Doing things this way is terribly convenient with regard to stuffing many things into one HTTP request.  Problem is, with respect to REST, these URLs no longer refer to individual resources--  they&#39;re aggregate references.</p>\n<p>I&#39;ve been thinking about this apparent break with the REST philosophy, and was reminded of it after skimming through <a href=\"http://www.markbaker.ca/Talks/2004-xmlself/all.htm\">Mark Baker&#39;s notes on a talk</a> today.  </p>\n<p>So... am I missing a more elegant RESTful way of doing this which doesn&#39;t result in a quadrillion HTTP requests?</p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221090514\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://trevor.smith.name/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=e873edb1d1943ea7087468439ce64d37&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://trevor.smith.name/\">Trevor F. Smith</a>\n</div>\n<a href=\"#comment-221090514\" class=\"permalink\"><time datetime=\"2004-09-15T16:29:16\">2004-09-15T16:29:16</time></a>\n</div>\n<div class=\"content\">Even the most stringent of REST advocates will break down and use reasonable parameters for adjectives, adverbs and unusual qualifiers.  Leave the path for nouns and verbs.</div>\n</li>\n<li class=\"comment\" id=\"comment-221090515\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=ad3bec4560b1c5d0ffddddc497c8b1e0&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"\">Jeremy Dunck</a>\n</div>\n<a href=\"#comment-221090515\" class=\"permalink\"><time datetime=\"2004-09-15T17:06:44\">2004-09-15T17:06:44</time></a>\n</div>\n<div class=\"content\">PUT /aggregates/312,443,523\n1\n---\nGET /aggregates/1/now-12.xml</div>\n</li>\n<li class=\"comment\" id=\"comment-221090516\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://franklinmint.fm\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=b9ed774661a22ff8797a1e0e24f0baf3&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://franklinmint.fm\">Robert Sayre</a>\n</div>\n<a href=\"#comment-221090516\" class=\"permalink\"><time datetime=\"2004-09-15T18:08:17\">2004-09-15T18:08:17</time></a>\n</div>\n<div class=\"content\">Lessons from WebDAV</div>\n</li>\n<li class=\"comment\" id=\"comment-221090517\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.shearersoftware.com/personal/weblog/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=4654316e8388b2e83af98a3118d976bb&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.shearersoftware.com/personal/weblog/\">Andrew Shearer</a>\n</div>\n<a href=\"#comment-221090517\" class=\"permalink\"><time datetime=\"2004-09-15T18:43:59\">2004-09-15T18:43:59</time></a>\n</div>\n<div class=\"content\">Interesting method, Jeremy.\nThe revised GET request looks closer to the REST philosophy to me than the original. The thing that worries me is that now you're generating state on the server (a new \"aggregate resource\" with its own identifier), and it's not clear that it's needed. How long does the server have to keep the list around? Could other clients access it if they guessed the ID?\nIt's the PUT request that causes the problems. It's a high price to pay for a modest improvement in the GET request.\nOn second thought, I don't see much wrong with the original. URLs can be algorithmic, and this one just happens to refer to a list of things. The thing that throws it into a different mental category for me is probably the combinatorial explosion. But does it really matter that now, for practical purposes, the REST service could no longer be fully indexed by search engines?</div>\n</li>\n<li class=\"comment\" id=\"comment-221090519\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.scifihifi.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=266511c4b3124a981ccd3b1716e0bb0b&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.scifihifi.com\">Buzz Andersen</a>\n</div>\n<a href=\"#comment-221090519\" class=\"permalink\"><time datetime=\"2004-09-15T19:57:21\">2004-09-15T19:57:21</time></a>\n</div>\n<div class=\"content\">I've wondered about this in the context of an application I'm designing that allows wildcard queries (e.g. /id/1*/details.html) as part of the URL path.  To me, it seems OK to do that, from REST's \"document-centric\" viewpoint, since it seems reasonable that I could actually have an actual document with that path.  Your original GET request seems like the same thing to me.\nI could be completely wrong though--I'd be the first to admit that I still find REST a bit difficult to pin down.  It seems like it's a lot like the old saw about pornography: I can't define it, but I know it when I see it :-).</div>\n</li>\n<li class=\"comment\" id=\"comment-221090520\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.scifihifi.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=266511c4b3124a981ccd3b1716e0bb0b&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.scifihifi.com\">Buzz Andersen</a>\n</div>\n<a href=\"#comment-221090520\" class=\"permalink\"><time datetime=\"2004-09-15T20:55:05\">2004-09-15T20:55:05</time></a>\n</div>\n<div class=\"content\">Upon further reading: isn't Jeremy's method wrong per Paul Prescod's \"Common REST Mistakes\" (http://www.prescod.net/rest/mistakes/)?  In particular:\n\"Do not invent proprietary object  identifiers.\"\nAnd...\n\"If you use URI syntax with UUIDs or something like that then you  get half of the benefit of URIs. You get a standardized syntax but have no standardized dereferencing capability.\"\nEssentially, only the client that did the post and stored the ID in Jeremy's example would have a way of referencing that set.\nAm I wrong?</div>\n</li>\n<li class=\"comment\" id=\"comment-221090521\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://blog.ianbicking.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=cc8334869c9d2a9e603017f2da805eb3&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://blog.ianbicking.org\">Ian Bicking</a>\n</div>\n<a href=\"#comment-221090521\" class=\"permalink\"><time datetime=\"2004-09-16T11:12:56\">2004-09-16T11:12:56</time></a>\n</div>\n<div class=\"content\">To expand on WebDAV, certain WebDAV operations produce compound requests and responses, all packaged in XML.  I can't remember what they look like, but it's really nothing more than several HTTP requests packaged in XML.  They use it for doing atomic operations on several files/resources.  It's kind of REST, kind of anti-REST.\nOtherwise, of course, the query string is reasonably unordered and allows multiple pieces of data, i.e., /subscriptions/now-12.xml?id=1&id=2&id=3\nAnother option is to somehow define sets.  E.g., something like POST /createset (request body contains the IDs) and then the server responds with an identifier for that set, and then you work with that identifier.</div>\n</li>\n<li class=\"comment\" id=\"comment-221090522\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=d0d0148e03ff9f1639cab8b35bf625db&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"\">Ken Meltsner</a>\n</div>\n<a href=\"#comment-221090522\" class=\"permalink\"><time datetime=\"2004-09-16T15:31:28\">2004-09-16T15:31:28</time></a>\n</div>\n<div class=\"content\">You could have the system return an existing identifier as the response to sending it a set of identifiers, if that set has already been defined.\nThat is, treat the GET as more of a \"return existing or create a new one\" operation.  And if you want to be really consistent, allow sets to include other sets.\nPerhaps something like:\nGET /setID/entries/12322,12326,12325,12388,12412\nwould return \n912345678\nthe first time and all following times, and then 912345678 could be used from then on.\nI think this would be idempotent, cache-friendly, etc.</div>\n</li>\n<li class=\"comment\" id=\"comment-221090523\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.markbaker.ca\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=05a5272a087ce9a44bd5f050932d7a28&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.markbaker.ca\">Mark Baker</a>\n</div>\n<a href=\"#comment-221090523\" class=\"permalink\"><time datetime=\"2004-09-26T14:03:39\">2004-09-26T14:03:39</time></a>\n</div>\n<div class=\"content\">Yah, REST isn't ideal for dealing with sets of resources since most operations on sets are specific to sets and therefore not uniform.  Consider the equivalent of a \"FILL\" operation, which would be a PUT on everything in a set of resources, where the set was identified by the HTTP Request-URI.\nWebDAV can help with its collections stuff, but sometimes that's overkill.  When I've encountered this, I've simply created a resource for the set and a POST on it changes the state of all the members of the set.  Not RESTful, but so long as you understand the architectural consequences, that's ok.</div>\n</li>\n<li class=\"comment\" id=\"comment-221090524\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=ad3bec4560b1c5d0ffddddc497c8b1e0&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"\">Jeremy Dunck</a>\n</div>\n<a href=\"#comment-221090524\" class=\"permalink\"><time datetime=\"2004-10-05T15:17:52\">2004-10-05T15:17:52</time></a>\n</div>\n<div class=\"content\">I'm not a well-experienced, RESTian.  Thanks for the pointer to Prescod's piece.\nI was thinking what Ken later said (Sep 16 @ 3:31PM).</div>\n</li>\n</ul>\n</div>\n",
    "body": "Here's a tiny bit of a REST-ian quandary:  I'm working through this API for `dbagg3`.  The major resources involved include **subscriptions** and **entries**.  Quite often, while working on the UI, I find a need to manipulate ranges and collections of these resources-- things like: &#8220;mark these 12 entries as read&#8221; and &#8220;give me an aggregate of the new entries for these 6 subscriptions&#8221;.\r\n\r\nSo, I have been using URLs like the following:\r\n\r\n* `POST /subscriptions/523/entries/12322,12326,12325,12388,12412/notes/`\r\n* `GET /subscriptions/312,443,523/now-12.xml`\r\n\r\nDoing things this way is terribly convenient with regard to stuffing many things into one HTTP request.  Problem is, with respect to REST, these URLs no longer refer to individual resources--  they're aggregate references.\r\n\r\nI've been thinking about this apparent break with the REST philosophy, and was reminded of it after skimming through [Mark Baker's notes on a talk][mbakerrest] today.  \r\n\r\nSo... am I missing a more elegant RESTful way of doing this which doesn't result in a quadrillion HTTP requests?\r\n\r\n[mbakerrest]: http://www.markbaker.ca/Talks/2004-xmlself/all.htm\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221090514\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://trevor.smith.name/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=e873edb1d1943ea7087468439ce64d37&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://trevor.smith.name/\">Trevor F. Smith</a>\r\n                </div>\r\n                <a href=\"#comment-221090514\" class=\"permalink\"><time datetime=\"2004-09-15T16:29:16\">2004-09-15T16:29:16</time></a>\r\n            </div>\r\n            <div class=\"content\">Even the most stringent of REST advocates will break down and use reasonable parameters for adjectives, adverbs and unusual qualifiers.  Leave the path for nouns and verbs.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221090515\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=ad3bec4560b1c5d0ffddddc497c8b1e0&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"\">Jeremy Dunck</a>\r\n                </div>\r\n                <a href=\"#comment-221090515\" class=\"permalink\"><time datetime=\"2004-09-15T17:06:44\">2004-09-15T17:06:44</time></a>\r\n            </div>\r\n            <div class=\"content\">PUT /aggregates/312,443,523\r\n\r\n1\r\n\r\n---\r\n\r\nGET /aggregates/1/now-12.xml</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221090516\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://franklinmint.fm\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=b9ed774661a22ff8797a1e0e24f0baf3&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://franklinmint.fm\">Robert Sayre</a>\r\n                </div>\r\n                <a href=\"#comment-221090516\" class=\"permalink\"><time datetime=\"2004-09-15T18:08:17\">2004-09-15T18:08:17</time></a>\r\n            </div>\r\n            <div class=\"content\">Lessons from WebDAV</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221090517\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.shearersoftware.com/personal/weblog/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=4654316e8388b2e83af98a3118d976bb&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.shearersoftware.com/personal/weblog/\">Andrew Shearer</a>\r\n                </div>\r\n                <a href=\"#comment-221090517\" class=\"permalink\"><time datetime=\"2004-09-15T18:43:59\">2004-09-15T18:43:59</time></a>\r\n            </div>\r\n            <div class=\"content\">Interesting method, Jeremy.\r\n\r\nThe revised GET request looks closer to the REST philosophy to me than the original. The thing that worries me is that now you're generating state on the server (a new \"aggregate resource\" with its own identifier), and it's not clear that it's needed. How long does the server have to keep the list around? Could other clients access it if they guessed the ID?\r\n\r\nIt's the PUT request that causes the problems. It's a high price to pay for a modest improvement in the GET request.\r\n\r\nOn second thought, I don't see much wrong with the original. URLs can be algorithmic, and this one just happens to refer to a list of things. The thing that throws it into a different mental category for me is probably the combinatorial explosion. But does it really matter that now, for practical purposes, the REST service could no longer be fully indexed by search engines?</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221090519\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.scifihifi.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=266511c4b3124a981ccd3b1716e0bb0b&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.scifihifi.com\">Buzz Andersen</a>\r\n                </div>\r\n                <a href=\"#comment-221090519\" class=\"permalink\"><time datetime=\"2004-09-15T19:57:21\">2004-09-15T19:57:21</time></a>\r\n            </div>\r\n            <div class=\"content\">I've wondered about this in the context of an application I'm designing that allows wildcard queries (e.g. /id/1*/details.html) as part of the URL path.  To me, it seems OK to do that, from REST's \"document-centric\" viewpoint, since it seems reasonable that I could actually have an actual document with that path.  Your original GET request seems like the same thing to me.\r\n\r\nI could be completely wrong though--I'd be the first to admit that I still find REST a bit difficult to pin down.  It seems like it's a lot like the old saw about pornography: I can't define it, but I know it when I see it :-).</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221090520\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.scifihifi.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=266511c4b3124a981ccd3b1716e0bb0b&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.scifihifi.com\">Buzz Andersen</a>\r\n                </div>\r\n                <a href=\"#comment-221090520\" class=\"permalink\"><time datetime=\"2004-09-15T20:55:05\">2004-09-15T20:55:05</time></a>\r\n            </div>\r\n            <div class=\"content\">Upon further reading: isn't Jeremy's method wrong per Paul Prescod's \"Common REST Mistakes\" (http://www.prescod.net/rest/mistakes/)?  In particular:\r\n\r\n\"Do not invent proprietary object  identifiers.\"\r\n\r\nAnd...\r\n\r\n\"If you use URI syntax with UUIDs or something like that then you  get half of the benefit of URIs. You get a standardized syntax but have no standardized dereferencing capability.\"\r\n\r\nEssentially, only the client that did the post and stored the ID in Jeremy's example would have a way of referencing that set.\r\n\r\nAm I wrong?</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221090521\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://blog.ianbicking.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=cc8334869c9d2a9e603017f2da805eb3&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://blog.ianbicking.org\">Ian Bicking</a>\r\n                </div>\r\n                <a href=\"#comment-221090521\" class=\"permalink\"><time datetime=\"2004-09-16T11:12:56\">2004-09-16T11:12:56</time></a>\r\n            </div>\r\n            <div class=\"content\">To expand on WebDAV, certain WebDAV operations produce compound requests and responses, all packaged in XML.  I can't remember what they look like, but it's really nothing more than several HTTP requests packaged in XML.  They use it for doing atomic operations on several files/resources.  It's kind of REST, kind of anti-REST.\r\n\r\nOtherwise, of course, the query string is reasonably unordered and allows multiple pieces of data, i.e., /subscriptions/now-12.xml?id=1&id=2&id=3\r\n\r\nAnother option is to somehow define sets.  E.g., something like POST /createset (request body contains the IDs) and then the server responds with an identifier for that set, and then you work with that identifier.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221090522\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=d0d0148e03ff9f1639cab8b35bf625db&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"\">Ken Meltsner</a>\r\n                </div>\r\n                <a href=\"#comment-221090522\" class=\"permalink\"><time datetime=\"2004-09-16T15:31:28\">2004-09-16T15:31:28</time></a>\r\n            </div>\r\n            <div class=\"content\">You could have the system return an existing identifier as the response to sending it a set of identifiers, if that set has already been defined.\r\n\r\nThat is, treat the GET as more of a \"return existing or create a new one\" operation.  And if you want to be really consistent, allow sets to include other sets.\r\n\r\n\r\nPerhaps something like:\r\n\r\nGET /setID/entries/12322,12326,12325,12388,12412\r\n\r\nwould return \r\n\r\n912345678\r\n\r\nthe first time and all following times, and then 912345678 could be used from then on.\r\n\r\nI think this would be idempotent, cache-friendly, etc.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221090523\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.markbaker.ca\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=05a5272a087ce9a44bd5f050932d7a28&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.markbaker.ca\">Mark Baker</a>\r\n                </div>\r\n                <a href=\"#comment-221090523\" class=\"permalink\"><time datetime=\"2004-09-26T14:03:39\">2004-09-26T14:03:39</time></a>\r\n            </div>\r\n            <div class=\"content\">Yah, REST isn't ideal for dealing with sets of resources since most operations on sets are specific to sets and therefore not uniform.  Consider the equivalent of a \"FILL\" operation, which would be a PUT on everything in a set of resources, where the set was identified by the HTTP Request-URI.\r\n\r\nWebDAV can help with its collections stuff, but sometimes that's overkill.  When I've encountered this, I've simply created a resource for the set and a POST on it changes the state of all the members of the set.  Not RESTful, but so long as you understand the architectural consequences, that's ok.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221090524\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=ad3bec4560b1c5d0ffddddc497c8b1e0&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"\">Jeremy Dunck</a>\r\n                </div>\r\n                <a href=\"#comment-221090524\" class=\"permalink\"><time datetime=\"2004-10-05T15:17:52\">2004-10-05T15:17:52</time></a>\r\n            </div>\r\n            <div class=\"content\">I'm not a well-experienced, RESTian.  Thanks for the pointer to Prescod's piece.\r\n\r\nI was thinking what Ken later said (Sep 16 @ 3:31PM).</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2004",
    "path": "2004/09/15/manipulating-aggregate-resources-in-a-rest-api"
  },
  {
    "comments_archived": true,
    "date": "2004-09-13T22:11:41.000Z",
    "excerpt": "So at this point, it's all URLs and barely working HTML, but it's exciting to me at least.  And it's dogfood for me, since I'm using this crud to get my daily (hourly?) fix.  Pretty soon, I'll be diving into wrapping more of a proper usable web app around this, with user management and stuff that works in MSIE.  Until then, maybe someone else will see this and catch a buzz from it.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "Early dbagg3 demo is alive and kicking",
    "wordpress_id": 546,
    "wordpress_slug": "dbagg3alive",
    "wordpress_url": "http://www.decafbad.com/blog/?p=546",
    "year": "2004",
    "month": "09",
    "day": "13",
    "isDir": false,
    "slug": "dbagg3alive",
    "postName": "2004-09-13-dbagg3alive",
    "html": "<p>Got some very good work in this weekend on switching servers and getting <a href=\"http://www.decafbad.com/cvs/dbagg3/\"><code>dbagg3</code></a> in some semblance of working order somewhere other than on my overworked and decidedly non-publicly-demonstrable laptop.</p>\n<p>This stuff is so this side of premature, that I&#39;m probably about to cause <a href=\"http://www.johncompanies.com\">JohnCompanies</a> to send hit-men out to cancel <strong>me</strong>, along with my hosting account (have I said that I <em>really</em> appreciate the help so far?).  But I just have to get this out: I&#39;m easily excited by shiny code and gadgets, but it&#39;s so much easier to get excited when I can see something in working condition before taking a screwdriver to it.  So... remember <a href=\"http://www.decafbad.com/blog/2004/08/30/dbagg3_makingprogress\">when I mentioned all those URLs</a>?  They&#39;re working out nicely.</p>\n<p>First, check out a simple two-pane view of news items, ala <a href=\"http://www.bloglines.com/\">Bloglines</a>:</p>\n<ul>\n<li><a href=\"http://feeds.decafbad.com/api/users/demo.xml?xsl=xsl/two-pane/index.xsl&#38;content-type=text/html\" target=\"new\">http://feeds.decafbad.com/api/users/demo.xml?xsl=xsl/two-pane/index.xsl&#38;content-type=text/html</a></li>\n</ul>\n<p>Taking this apart, you can see:</p>\n<ul>\n<li>A user account: <a href=\"http://feeds.decafbad.com/api/users/demo.xml\">http://feeds.decafbad.com/api/users/demo.xml</a></li>\n<li>Some XSL: <a href=\"http://feeds.decafbad.com/xsl/two-pane/index.xsl\">http://feeds.decafbad.com/xsl/two-pane/index.xsl</a></li>\n<li>... and a specified content type (text/html)</li>\n</ul>\n<p>If your curiosity is piqued by this, view source and pay attention to link URLs.  It&#39;s more of the same:  XML produced by a REST API, passed through XSL, delivered as HTML.</p>\n<p>Here, take a look at another view on this demo user&#39;s aggregated items:</p>\n<ul>\n<li><a href=\"http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/outliner/index.xsl&#38;content-type=text/html\" target=\"new\">http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/outliner/index.xsl&#38;content-type=text/html</a></li>\n</ul>\n<p>Unfortunately, this only seems to be working decently with Firefox and Safari.  MSIE seems to be balking at the dynamic stuff, though I&#39;ve had it working there in a previous incarnation of this code.  So hopefully this will be fixed soon.</p>\n<p>At any rate, what you should see is a single-pane outliner-style display of feed entries.  This is the style of aggregator UI I&#39;ve been using for almost 3 years now.  Disclosure triangles open entries up to show summaries and further content.  &#8220;[seen]&#8221; links hide the entries, while &#8220;[queue]&#8221; hides an entry while tossing it into a queue for viewing later.</p>\n<p>Speaking of that, you can see what&#39;s in the queue right now:</p>\n<ul>\n<li><a href=\"http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&#38;content-type=text/html&#38;show_queued=1\" target=\"new\">http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&#38;content-type=text/html&#38;show_queued=1</a></li>\n</ul>\n<p>Here is a display of queued entries, with another stylesheet applied that shows everything in a flat and open blog-like template.  It&#39;s not reverse-chronological, but that&#39;s not hard to accomplish with a flag or a tweak to an &lt;xsl:sort&gt; tag.  </p>\n<p>So that&#39;s just the start of things.  Remember <a href=\"http://www.decafbad.com/blog/2004/08/23/slicing_and_dicing_to_make_atom_soup_in_dbagg3\">when I was rambling on about XML storage and query</a>?  A URL like this is one product of that:</p>\n<ul>\n<li><a href=\"http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&#38;content-type=text/html&#38;entry_xpath=//entry/title[contains(text(),'OS%20X')]\" target=\"new\">http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&#38;content-type=text/html&#38;entry_xpath=//entry/title[contains(text(),&#39;OS%20X&#39;)]</a></li>\n</ul>\n<p>This should show you a flat listing of all entries whose titles contain &#8220;OS X&#8221;.  This is far from perfect, but it&#39;s very exciting to me-- it&#39;s got a lot of promise, stuff that first caught my eye when I saw <a href=\"http://webservices.xml.com/pub/a/ws/2003/04/15/semanticblog.html\">Jon Udell playing</a> <a href=\"http://webservices.xml.com/pub/a/ws/2003/06/10/xpathsearch.html?page=1\">awhile back</a>.</p>\n<p>Now, something that you might not notice until doing a bit more digging, is that all these attributes like &#8220;seen&#8221; and &#8220;query&#8221; are annotations made by the user on entries.  If you take a peek at <a href=\"http://feeds.decafbad.com/js/agg.js\">some of the Javascript</a> under the hood, you might notice some XmlHTTPRequest code going on.  To mark something as &#8220;seen&#8221; or &#8220;queued&#8221;, I POST XML to a URL like this:</p>\n<ul>\n<li><a href=\"http://feeds.decafbad.com/api/users/demo/subscriptions/638/entries/60567/notes/\">http://feeds.decafbad.com/api/users/demo/subscriptions/638/entries/60567/notes/</a></li>\n</ul>\n<p>The upshot of this is that these attributes are not limited to &#8220;seen&#8221; or &#8220;queued&#8221; flags-- in fact, these annotations can (well, in theory) be any pairing of arbitrary XML and a name.  This annotation then gets injected into the entry, when viewed by the user who owns the annotation, like so:</p>\n<ul>\n<li><a href=\"http://feeds.decafbad.com/api/users/demo/subscriptions/638/entries/60567.xml\">http://feeds.decafbad.com/api/users/demo/subscriptions/638/entries/60567.xml</a></li>\n</ul>\n<p>In fact, you could invent a new annotation called &#39;tags&#39; and filter for entries with this annotation with a URL like this:</p>\n<ul>\n<li><a href=\"http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&#38;content-type=text/html&#38;entry%5C_notes%5C_xpath=//dbagg3:note%5B@name=&#39;tags&#39;\">http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&#38;content-type=text/html&#38;entry\\_notes\\_xpath=//dbagg3:note[@name=&#39;tags&#39;</a> and contains(text(),&#39;#food#&#39;) and contains(text(),&#39;#odd#&#39;)]</li>\n</ul>\n<p>Eventually, what I&#39;d <em>really</em> like to see this start doing is something akin to del.icio.us-style tagging while you&#39;re reading.  Then, you can have public queries that pull feeds based on your (and others&#39;) tags and spit things back out as feeds again with the proper XSL stylings.</p>\n<p>So at this point, it&#39;s all URLs and barely working HTML, but it&#39;s exciting to me at least.  And it&#39;s dogfood for me, since I&#39;m using this crud to get my daily (hourly?) fix.  Pretty soon, I&#39;ll be diving into wrapping more of a proper usable web app around this, with user management and stuff that works in MSIE.  Until then, maybe someone else will see this and catch a buzz from it.</p>\n<p>Stay tuned.</p>\n<!--more-->\n<p>shortname=dbagg3alive</p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221090566\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=e1cc8e7103bb0f77a7d7abf91b1a961b&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"\">Christopher</a>\n</div>\n<a href=\"#comment-221090566\" class=\"permalink\"><time datetime=\"2004-09-14T09:40:02\">2004-09-14T09:40:02</time></a>\n</div>\n<div class=\"content\">Very cool! Keep this up. I'm looking forward to your final version :)</div>\n</li>\n<li class=\"comment\" id=\"comment-221090567\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://notizen.typepad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=005509858f6bec19f23d989ff9228724&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://notizen.typepad.com\">Markus Breuer</a>\n</div>\n<a href=\"#comment-221090567\" class=\"permalink\"><time datetime=\"2004-09-15T12:48:19\">2004-09-15T12:48:19</time></a>\n</div>\n<div class=\"content\">Could not find the Trackback-URL. So here my two-cents-worth as a comment:\nLeslie Michael Orchard (of Decafbad) did it again. He has a demo of his latest projekt online: Dbagg3 (a.k.a . FeedReactor?) I am very impressed. It is still in its embryonic state but show great promise. \nThe current demo may look unimpressing to the uninitiated but actually implements already a lot of functionality in a rather light package. All this functionality can be accessed elegantly through the REST-API.\n[...]\nI am looking into integrating dbagg3 into my own feedbox-project (see here). I hope Leslie aggrees with us doing some tinkering around ...\n... in more detail \nLINK: http://notizen.typepad.com/aus_der_provinz/2004/09/cool_new_embryo.html</div>\n</li>\n</ul>\n</div>\n",
    "body": "Got some very good work in this weekend on switching servers and getting [`dbagg3`][dbagg3] in some semblance of working order somewhere other than on my overworked and decidedly non-publicly-demonstrable laptop.\r\n\r\nThis stuff is so this side of premature, that I'm probably about to cause [JohnCompanies][johncompanies] to send hit-men out to cancel **me**, along with my hosting account (have I said that I *really* appreciate the help so far?).  But I just have to get this out: I'm easily excited by shiny code and gadgets, but it's so much easier to get excited when I can see something in working condition before taking a screwdriver to it.  So... remember [when I mentioned all those URLs][dbagg3urls]?  They're working out nicely.\r\n\r\nFirst, check out a simple two-pane view of news items, ala [Bloglines][bloglines]:\r\n\r\n* <a href=\"http://feeds.decafbad.com/api/users/demo.xml?xsl=xsl/two-pane/index.xsl&#38;content-type=text/html\" target=\"new\">http://feeds.decafbad.com/api/users/demo.xml?xsl=xsl/two-pane/index.xsl&#38;content-type=text/html</a>\r\n\r\nTaking this apart, you can see:\r\n\r\n* A user account: <http://feeds.decafbad.com/api/users/demo.xml>\r\n* Some XSL: <http://feeds.decafbad.com/xsl/two-pane/index.xsl>\r\n* ... and a specified content type (text/html)\r\n\r\nIf your curiosity is piqued by this, view source and pay attention to link URLs.  It's more of the same:  XML produced by a REST API, passed through XSL, delivered as HTML.\r\n\r\nHere, take a look at another view on this demo user's aggregated items:\r\n\r\n* <a href=\"http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/outliner/index.xsl&#38;content-type=text/html\" target=\"new\">http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/outliner/index.xsl&#38;content-type=text/html</a>\r\n\r\nUnfortunately, this only seems to be working decently with Firefox and Safari.  MSIE seems to be balking at the dynamic stuff, though I've had it working there in a previous incarnation of this code.  So hopefully this will be fixed soon.\r\n\r\nAt any rate, what you should see is a single-pane outliner-style display of feed entries.  This is the style of aggregator UI I've been using for almost 3 years now.  Disclosure triangles open entries up to show summaries and further content.  &#8220;[seen]&#8221; links hide the entries, while &#8220;[queue]&#8221; hides an entry while tossing it into a queue for viewing later.\r\n\r\nSpeaking of that, you can see what's in the queue right now:\r\n\r\n* <a href=\"http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&#38;content-type=text/html&#38;show_queued=1\" target=\"new\">http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&#38;content-type=text/html&#38;show_queued=1</a>\r\n\r\nHere is a display of queued entries, with another stylesheet applied that shows everything in a flat and open blog-like template.  It's not reverse-chronological, but that's not hard to accomplish with a flag or a tweak to an &lt;xsl:sort&gt; tag.  \r\n\r\nSo that's just the start of things.  Remember [when I was rambling on about XML storage and query][dbagg3storage]?  A URL like this is one product of that:\r\n\r\n* <a href=\"http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&#38;content-type=text/html&#38;entry_xpath=//entry/title[contains(text(),'OS%20X')]\" target=\"new\">http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&#38;content-type=text/html&#38;entry_xpath=//entry/title[contains(text(),'OS%20X')]</a>\r\n\r\nThis should show you a flat listing of all entries whose titles contain &#8220;OS X&#8221;.  This is far from perfect, but it's very exciting to me-- it's got a lot of promise, stuff that first caught my eye when I saw [Jon Udell playing][xpathquery] [awhile back][xpathquery2].\r\n\r\nNow, something that you might not notice until doing a bit more digging, is that all these attributes like &#8220;seen&#8221; and &#8220;query&#8221; are annotations made by the user on entries.  If you take a peek at [some of the Javascript][js] under the hood, you might notice some XmlHTTPRequest code going on.  To mark something as &#8220;seen&#8221; or &#8220;queued&#8221;, I POST XML to a URL like this:\r\n\r\n* http://feeds.decafbad.com/api/users/demo/subscriptions/638/entries/60567/notes/\r\n\r\nThe upshot of this is that these attributes are not limited to &#8220;seen&#8221; or &#8220;queued&#8221; flags-- in fact, these annotations can (well, in theory) be any pairing of arbitrary XML and a name.  This annotation then gets injected into the entry, when viewed by the user who owns the annotation, like so:\r\n\r\n* http://feeds.decafbad.com/api/users/demo/subscriptions/638/entries/60567.xml\r\n\r\nIn fact, you could invent a new annotation called 'tags' and filter for entries with this annotation with a URL like this:\r\n\r\n* http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&#38;content-type=text/html&#38;entry\\_notes\\_xpath=//dbagg3:note[@name='tags' and contains(text(),'#food#') and contains(text(),'#odd#')]\r\n\r\nEventually, what I'd *really* like to see this start doing is something akin to del.icio.us-style tagging while you're reading.  Then, you can have public queries that pull feeds based on your (and others') tags and spit things back out as feeds again with the proper XSL stylings.\r\n\r\nSo at this point, it's all URLs and barely working HTML, but it's exciting to me at least.  And it's dogfood for me, since I'm using this crud to get my daily (hourly?) fix.  Pretty soon, I'll be diving into wrapping more of a proper usable web app around this, with user management and stuff that works in MSIE.  Until then, maybe someone else will see this and catch a buzz from it.\r\n\r\nStay tuned.\r\n\r\n[js]: http://feeds.decafbad.com/js/agg.js\r\n[xpathquery2]: http://webservices.xml.com/pub/a/ws/2003/06/10/xpathsearch.html?page=1\r\n[xpathquery]: http://webservices.xml.com/pub/a/ws/2003/04/15/semanticblog.html\r\n[johncompanies]: http://www.johncompanies.com\r\n[dbagg3storage]: http://www.decafbad.com/blog/2004/08/23/slicing_and_dicing_to_make_atom_soup_in_dbagg3\r\n[dbagg3urls]: http://www.decafbad.com/blog/2004/08/30/dbagg3_makingprogress\r\n[dbagg3]: http://www.decafbad.com/cvs/dbagg3/\r\n[bloglines]: http://www.bloglines.com/\r\n<!--more-->\r\nshortname=dbagg3alive\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221090566\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=e1cc8e7103bb0f77a7d7abf91b1a961b&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"\">Christopher</a>\r\n                </div>\r\n                <a href=\"#comment-221090566\" class=\"permalink\"><time datetime=\"2004-09-14T09:40:02\">2004-09-14T09:40:02</time></a>\r\n            </div>\r\n            <div class=\"content\">Very cool! Keep this up. I'm looking forward to your final version :)</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221090567\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://notizen.typepad.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=005509858f6bec19f23d989ff9228724&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://notizen.typepad.com\">Markus Breuer</a>\r\n                </div>\r\n                <a href=\"#comment-221090567\" class=\"permalink\"><time datetime=\"2004-09-15T12:48:19\">2004-09-15T12:48:19</time></a>\r\n            </div>\r\n            <div class=\"content\">Could not find the Trackback-URL. So here my two-cents-worth as a comment:\r\n\r\nLeslie Michael Orchard (of Decafbad) did it again. He has a demo of his latest projekt online: Dbagg3 (a.k.a . FeedReactor?) I am very impressed. It is still in its embryonic state but show great promise. \r\n\r\nThe current demo may look unimpressing to the uninitiated but actually implements already a lot of functionality in a rather light package. All this functionality can be accessed elegantly through the REST-API.\r\n\r\n[...]\r\n\r\nI am looking into integrating dbagg3 into my own feedbox-project (see here). I hope Leslie aggrees with us doing some tinkering around ...\r\n\r\n... in more detail \r\nLINK: http://notizen.typepad.com/aus_der_provinz/2004/09/cool_new_embryo.html</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2004",
    "path": "2004/09/13/dbagg3alive",
    "summary": "<p>Got some very good work in this weekend on switching servers and getting <a href=\"http://www.decafbad.com/cvs/dbagg3/\"><code>dbagg3</code></a> in some semblance of working order somewhere other than on my overworked and decidedly non-publicly-demonstrable laptop.</p>\n<p>This stuff is so this side of premature, that I&apos;m probably about to cause <a href=\"http://www.johncompanies.com\">JohnCompanies</a> to send hit-men out to cancel <strong>me</strong>, along with my hosting account (have I said that I <em>really</em> appreciate the help so far?).  But I just have to get this out: I&apos;m easily excited by shiny code and gadgets, but it&apos;s so much easier to get excited when I can see something in working condition before taking a screwdriver to it.  So... remember <a href=\"http://www.decafbad.com/blog/2004/08/30/dbagg3_makingprogress\">when I mentioned all those URLs</a>?  They&apos;re working out nicely.</p>\n<p>First, check out a simple two-pane view of news items, ala <a href=\"http://www.bloglines.com/\">Bloglines</a>:</p>\n<ul>\n<li><a href=\"http://feeds.decafbad.com/api/users/demo.xml?xsl=xsl/two-pane/index.xsl&amp;content-type=text/html\" target=\"new\">http://feeds.decafbad.com/api/users/demo.xml?xsl=xsl/two-pane/index.xsl&amp;content-type=text/html</a></li>\n</ul>\n<p>Taking this apart, you can see:</p>\n<ul>\n<li>A user account: <a href=\"http://feeds.decafbad.com/api/users/demo.xml\">http://feeds.decafbad.com/api/users/demo.xml</a></li>\n<li>Some XSL: <a href=\"http://feeds.decafbad.com/xsl/two-pane/index.xsl\">http://feeds.decafbad.com/xsl/two-pane/index.xsl</a></li>\n<li>... and a specified content type (text/html)</li>\n</ul>\n<p>If your curiosity is piqued by this, view source and pay attention to link URLs.  It&apos;s more of the same:  XML produced by a REST API, passed through XSL, delivered as HTML.</p>\n<p>Here, take a look at another view on this demo user&apos;s aggregated items:</p>\n<ul>\n<li><a href=\"http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/outliner/index.xsl&amp;content-type=text/html\" target=\"new\">http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/outliner/index.xsl&amp;content-type=text/html</a></li>\n</ul>\n<p>Unfortunately, this only seems to be working decently with Firefox and Safari.  MSIE seems to be balking at the dynamic stuff, though I&apos;ve had it working there in a previous incarnation of this code.  So hopefully this will be fixed soon.</p>\n<p>At any rate, what you should see is a single-pane outliner-style display of feed entries.  This is the style of aggregator UI I&apos;ve been using for almost 3 years now.  Disclosure triangles open entries up to show summaries and further content.  &#x201C;[seen]&#x201D; links hide the entries, while &#x201C;[queue]&#x201D; hides an entry while tossing it into a queue for viewing later.</p>\n<p>Speaking of that, you can see what&apos;s in the queue right now:</p>\n<ul>\n<li><a href=\"http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&amp;content-type=text/html&amp;show_queued=1\" target=\"new\">http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&amp;content-type=text/html&amp;show_queued=1</a></li>\n</ul>\n<p>Here is a display of queued entries, with another stylesheet applied that shows everything in a flat and open blog-like template.  It&apos;s not reverse-chronological, but that&apos;s not hard to accomplish with a flag or a tweak to an &lt;xsl:sort&gt; tag.  </p>\n<p>So that&apos;s just the start of things.  Remember <a href=\"http://www.decafbad.com/blog/2004/08/23/slicing_and_dicing_to_make_atom_soup_in_dbagg3\">when I was rambling on about XML storage and query</a>?  A URL like this is one product of that:</p>\n<ul>\n<li><a href=\"http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&amp;content-type=text/html&amp;entry_xpath=//entry/title[contains(text(),&apos;OS%20X&apos;)]\" target=\"new\">http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&amp;content-type=text/html&amp;entry_xpath=//entry/title[contains(text(),&apos;OS%20X&apos;)]</a></li>\n</ul>\n<p>This should show you a flat listing of all entries whose titles contain &#x201C;OS X&#x201D;.  This is far from perfect, but it&apos;s very exciting to me-- it&apos;s got a lot of promise, stuff that first caught my eye when I saw <a href=\"http://webservices.xml.com/pub/a/ws/2003/04/15/semanticblog.html\">Jon Udell playing</a> <a href=\"http://webservices.xml.com/pub/a/ws/2003/06/10/xpathsearch.html?page=1\">awhile back</a>.</p>\n<p>Now, something that you might not notice until doing a bit more digging, is that all these attributes like &#x201C;seen&#x201D; and &#x201C;query&#x201D; are annotations made by the user on entries.  If you take a peek at <a href=\"http://feeds.decafbad.com/js/agg.js\">some of the Javascript</a> under the hood, you might notice some XmlHTTPRequest code going on.  To mark something as &#x201C;seen&#x201D; or &#x201C;queued&#x201D;, I POST XML to a URL like this:</p>\n<ul>\n<li><a href=\"http://feeds.decafbad.com/api/users/demo/subscriptions/638/entries/60567/notes/\">http://feeds.decafbad.com/api/users/demo/subscriptions/638/entries/60567/notes/</a></li>\n</ul>\n<p>The upshot of this is that these attributes are not limited to &#x201C;seen&#x201D; or &#x201C;queued&#x201D; flags-- in fact, these annotations can (well, in theory) be any pairing of arbitrary XML and a name.  This annotation then gets injected into the entry, when viewed by the user who owns the annotation, like so:</p>\n<ul>\n<li><a href=\"http://feeds.decafbad.com/api/users/demo/subscriptions/638/entries/60567.xml\">http://feeds.decafbad.com/api/users/demo/subscriptions/638/entries/60567.xml</a></li>\n</ul>\n<p>In fact, you could invent a new annotation called &apos;tags&apos; and filter for entries with this annotation with a URL like this:</p>\n<ul>\n<li><a href=\"http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&amp;content-type=text/html&amp;entry%5C_notes%5C_xpath=//dbagg3:note%5B@name=&apos;tags&apos;\">http://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&amp;content-type=text/html&amp;entry\\_notes\\_xpath=//dbagg3:note[@name=&apos;tags&apos;</a> and contains(text(),&apos;#food#&apos;) and contains(text(),&apos;#odd#&apos;)]</li>\n</ul>\n<p>Eventually, what I&apos;d <em>really</em> like to see this start doing is something akin to del.icio.us-style tagging while you&apos;re reading.  Then, you can have public queries that pull feeds based on your (and others&apos;) tags and spit things back out as feeds again with the proper XSL stylings.</p>\n<p>So at this point, it&apos;s all URLs and barely working HTML, but it&apos;s exciting to me at least.  And it&apos;s dogfood for me, since I&apos;m using this crud to get my daily (hourly?) fix.  Pretty soon, I&apos;ll be diving into wrapping more of a proper usable web app around this, with user management and stuff that works in MSIE.  Until then, maybe someone else will see this and catch a buzz from it.</p>\n<p>Stay tuned.</p>\n"
  },
  {
    "comments_archived": true,
    "date": "2004-09-01T10:47:41.000Z",
    "excerpt": "But, while I'm in the process of wheel reinvention, how about I borrow Kimbro's idea?  I just threw together a quick class called XPathDict, based on libxml2.",
    "layout": "post",
    "tags": [
      "hacks",
      "xml"
    ],
    "title": "XPath based Python dictionaries, on loan",
    "wordpress_id": 544,
    "wordpress_slug": "xpath-based-python-dictionaries-on-loan",
    "wordpress_url": "http://www.decafbad.com/blog/?p=544",
    "year": "2004",
    "month": "09",
    "day": "01",
    "isDir": false,
    "slug": "xpath-based-python-dictionaries-on-loan",
    "postName": "2004-09-01-xpath-based-python-dictionaries-on-loan",
    "html": "<p>So <a href=\"http://www.xmldatabases.org/WK/blog\">Kimbro Staken</a> posted this nifty idea to build <a href=\"http://www.xmldatabases.org/WK/blog/1964_XPath_based_Python_Dictionaries.item\">XPath based Python dictionaries</a> to access XML data as a part of his incredibly nifty <a href=\"http://www.syncato.org/\">Syncato</a> microcontent management system.  Eventually, I&#39;ve really got to break down and get that thing built and running on my server and my laptop-- it really seems like I&#39;m reinventing so many wheels by not basing <a href=\"http://www.decafbad.com/cvs/dbagg3/\"><code>dbagg3</code></a> on it.</p>\n<p>But, while I&#39;m in the process of wheel reinvention, how about I borrow Kimbro&#39;s idea?  I just threw together <a href=\"http://www.decafbad.com/cvs/*checkout*/dbagg3/lib/dbagg3/xmlutils.py\">a quick class called XPathDict</a>, based on <a href=\"http://www.xmlsoft.org/\">libxml2</a>.  It works a little something like this:</p>\n<pre><code>feed_xd = XPathDict(file=&quot;sample-atom.xml&quot;)\nfor entry_node in feed_xd.nodes(&quot;//atom:entry&quot;):\n    entry = XPathDict(doc=entry_node.doc, node=entry_node)\n    print &quot;Title: &quot; % entry[&#39;atom:title&#39;]\n    if &#39;atom:author&#39; in entry:\n        print &quot;Author: &quot; % entry[&#39;atom:author/atom:name&#39;]\n\nxml = &quot;&quot;&quot;\n   &lt;dbagg3:user xmlns=&quot;http://purl.org/atom/ns#&quot; \n            xmlns:dbagg3=&quot;http://decafbad.com/2004/07/dbagg3/&quot;&gt;\n        &lt;name&gt;deusx&lt;/name&gt;\n        &lt;email&gt;deus_x@pobox.com&lt;/email&gt;\n        &lt;url&gt;http://www.decafbad.com/&lt;/url&gt;\n        &lt;dbagg3:prefs&gt;\n            &lt;dbagg3:pref name=&quot;foo&quot;&gt;bar&lt;/dbagg3:pref&gt;\n        &lt;/dbagg3:prefs&gt;\n   &lt;/dbagg3:author&gt;\n&quot;&quot;&quot;\n\nmap = (\n    (&#39;userName&#39;,  &#39;a:name&#39;),\n    (&#39;userEmail&#39;, &#39;a:email&#39;),\n    (&#39;fooPref&#39;,   &quot;dbagg3:prefs/dbagg3:pref[@name=&#39;foo&#39;]&quot;)\n)\n\nxd = XPathDict(xml=xml)\nxd.cd(&quot;/dbagg3:user&quot;)\nprint xd.extract(map)\n\n#    {&#39;userName&#39;  : &#39;deusx&#39;, \n#     &#39;userEmail&#39; : &#39;deus_x@pobox.com&#39;, \n#     &#39;fooPref&#39;   : &#39;bar&#39;}</code></pre>\n<p>There isn&#39;t any spectacular code behind all this, and the idea <em>was</em> Kimbro&#39;s, but it&#39;s working.  It&#39;s also incredibly convenient, especially with the little XML-to-dict extraction map method I whipped up.  This would take a bit more work to pry it out of its current context, such as turning the hardcoded namespaces into an option, among other things.  But, <a href=\"http://www.decafbad.com/cvs/*checkout*/dbagg3/lib/dbagg3/xmlutils.py\">here&#39;s the code</a> for you to peruse.</p>\n<p>(I got hooked early on subverting in-built language constructs from perl&#39;s <code>tie</code> facilities, and C++&#39;s operator overloading.  Now I&#39;m loving Python&#39;s <a href=\"http://diveintopython.org/object_oriented_framework/special_class_methods2.html\">special class methods</a>.  Someday, maybe, I&#39;ll actually get down to doing some work in LISP and wrap my head around some <em>real</em> language subversion.)</p>\n<p>Anyway, while this is neither quite <a href=\"http://dev2dev.bea.com/products/wlworkshop/articles/JSchneider_XML.jsp\">Native XML Scripting</a> nor XML as <a href=\"http://www.xmldatabases.org/WK/blog/663?t=item\">a native language construct</a>, it&#39;s getting there.</p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221090556\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://naeblis.cx\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=abfc88b96ae18c85ba7aac3bded2ec5e&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://naeblis.cx\">Ryan Tomayko</a>\n</div>\n<a href=\"#comment-221090556\" class=\"permalink\"><time datetime=\"2004-09-01T17:29:27\">2004-09-01T17:29:27</time></a>\n</div>\n<div class=\"content\">Funny that. I also have one that has survived a couple of failed apps. I have a hard time dropping it to be honest and just keep lugging it around to each new project. \nhttp://naeblis.cx/cvs/percolator/xb/lib/xpdm.py?rev=HEAD&content-type=text/vnd.viewcvs-markup\nIt has some pretty big issues. Among other things, creating nodes with namespace support is a little.. ermmm.. not there. But it does a lot of things well like garbage collecting xmlDoc instances (freeDoc), copying nodesets between documents, encoding things when they need to be, etc.\nAnyway, I wonder if maybe we all might benefit by teaming up on this and try to define what a complete xpathish wrapper atop libxml2 should look like. And really, why limit it to libxml2? I'm of the opinion that the value here is an interface that embraces xpath. The fact that it's running on top of the blazingly fast libxml2 is nice but coding against the XMLTRAMP like interface is the value for me.\nSo let me see if I can get some time together to whip up a quick comparison of the three implementations. I'll shoot that over to you and Kimbro and we can go from there. If these seem to work best as backyard APIs we like to keep close to us, we'll drop it. However, I think there's a good chance that we can all benefit by combining our efforts.</div>\n</li>\n</ul>\n</div>\n",
    "body": "So [Kimbro Staken][kimbro] posted this nifty idea to build [XPath based Python dictionaries][xpathdict] to access XML data as a part of his incredibly nifty [Syncato][syncato] microcontent management system.  Eventually, I've really got to break down and get that thing built and running on my server and my laptop-- it really seems like I'm reinventing so many wheels by not basing [`dbagg3`][dbagg3] on it.\r\n\r\nBut, while I'm in the process of wheel reinvention, how about I borrow Kimbro's idea?  I just threw together [a quick class called XPathDict][myxdict], based on [libxml2][libxml2].  It works a little something like this:\r\n\r\n    feed_xd = XPathDict(file=\"sample-atom.xml\")\r\n    for entry_node in feed_xd.nodes(\"//atom:entry\"):\r\n        entry = XPathDict(doc=entry_node.doc, node=entry_node)\r\n        print \"Title: \" % entry['atom:title']\r\n        if 'atom:author' in entry:\r\n            print \"Author: \" % entry['atom:author/atom:name']\r\n\r\n    xml = \"\"\"\r\n       <dbagg3:user xmlns=\"http://purl.org/atom/ns#\" \r\n                xmlns:dbagg3=\"http://decafbad.com/2004/07/dbagg3/\">\r\n            <name>deusx</name>\r\n            <email>deus_x@pobox.com</email>\r\n            <url>http://www.decafbad.com/</url>\r\n            <dbagg3:prefs>\r\n                <dbagg3:pref name=\"foo\">bar</dbagg3:pref>\r\n            </dbagg3:prefs>\r\n       </dbagg3:author>\r\n    \"\"\"\r\n\r\n    map = (\r\n        ('userName',  'a:name'),\r\n        ('userEmail', 'a:email'),\r\n        ('fooPref',   \"dbagg3:prefs/dbagg3:pref[@name='foo']\")\r\n    )\r\n\r\n    xd = XPathDict(xml=xml)\r\n    xd.cd(\"/dbagg3:user\")\r\n    print xd.extract(map)\r\n\r\n    #    {'userName'  : 'deusx', \r\n    #     'userEmail' : 'deus_x@pobox.com', \r\n    #     'fooPref'   : 'bar'}\r\n\r\nThere isn't any spectacular code behind all this, and the idea *was* Kimbro's, but it's working.  It's also incredibly convenient, especially with the little XML-to-dict extraction map method I whipped up.  This would take a bit more work to pry it out of its current context, such as turning the hardcoded namespaces into an option, among other things.  But, [here's the code][myxdict] for you to peruse.\r\n\r\n(I got hooked early on subverting in-built language constructs from perl's `tie` facilities, and C++'s operator overloading.  Now I'm loving Python's [special class methods][methods].  Someday, maybe, I'll actually get down to doing some work in LISP and wrap my head around some *real* language subversion.)\r\n\r\nAnyway, while this is neither quite [Native XML Scripting][nativexml] nor XML as [a native language construct][nativeconstruct], it's getting there.\r\n\r\n[methods]: http://diveintopython.org/object_oriented_framework/special_class_methods2.html\r\n[nativeconstruct]: http://www.xmldatabases.org/WK/blog/663?t=item\r\n[nativexml]: http://dev2dev.bea.com/products/wlworkshop/articles/JSchneider_XML.jsp\r\n[libxml2]: http://www.xmlsoft.org/\r\n[myxdict]: http://www.decafbad.com/cvs/*checkout*/dbagg3/lib/dbagg3/xmlutils.py\r\n[dbagg3]: http://www.decafbad.com/cvs/dbagg3/\r\n[syncato]: http://www.syncato.org/\r\n[kimbro]: http://www.xmldatabases.org/WK/blog\r\n[xpathdict]: http://www.xmldatabases.org/WK/blog/1964_XPath_based_Python_Dictionaries.item\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221090556\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://naeblis.cx\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=abfc88b96ae18c85ba7aac3bded2ec5e&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://naeblis.cx\">Ryan Tomayko</a>\r\n                </div>\r\n                <a href=\"#comment-221090556\" class=\"permalink\"><time datetime=\"2004-09-01T17:29:27\">2004-09-01T17:29:27</time></a>\r\n            </div>\r\n            <div class=\"content\">Funny that. I also have one that has survived a couple of failed apps. I have a hard time dropping it to be honest and just keep lugging it around to each new project. \r\n\r\nhttp://naeblis.cx/cvs/percolator/xb/lib/xpdm.py?rev=HEAD&content-type=text/vnd.viewcvs-markup\r\n\r\nIt has some pretty big issues. Among other things, creating nodes with namespace support is a little.. ermmm.. not there. But it does a lot of things well like garbage collecting xmlDoc instances (freeDoc), copying nodesets between documents, encoding things when they need to be, etc.\r\n \r\nAnyway, I wonder if maybe we all might benefit by teaming up on this and try to define what a complete xpathish wrapper atop libxml2 should look like. And really, why limit it to libxml2? I'm of the opinion that the value here is an interface that embraces xpath. The fact that it's running on top of the blazingly fast libxml2 is nice but coding against the XMLTRAMP like interface is the value for me.\r\n\r\nSo let me see if I can get some time together to whip up a quick comparison of the three implementations. I'll shoot that over to you and Kimbro and we can go from there. If these seem to work best as backyard APIs we like to keep close to us, we'll drop it. However, I think there's a good chance that we can all benefit by combining our efforts.</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2004",
    "path": "2004/09/01/xpath-based-python-dictionaries-on-loan"
  },
  {
    "comments_archived": true,
    "date": "2004-08-31T01:37:42.000Z",
    "excerpt": "Work has been insanely busy lately, but I have made some more progress with [`dbagg3`][dbagg3].  The code is all in CVS, so feel free to take a gander-- I don't have a ton of time for a proper write up, but I do want to spew a little bit.",
    "layout": "post",
    "tags": [
      "hacks",
      "syndication",
      "xml"
    ],
    "title": "Making progress on dbagg3",
    "wordpress_id": 543,
    "wordpress_slug": "dbagg3-makingprogress",
    "wordpress_url": "http://www.decafbad.com/blog/?p=543",
    "year": "2004",
    "month": "08",
    "day": "30",
    "isDir": false,
    "slug": "dbagg3-makingprogress",
    "postName": "2004-08-30-dbagg3-makingprogress",
    "html": "<p>Work has been insanely busy lately, but I have made some more progress with <a href=\"http://www.decafbad.com/cvs/dbagg3/\"><code>dbagg3</code></a>.  The code is all in CVS, so feel free to take a gander-- I don&#39;t have a ton of time for a proper write up, but I do want to spew a little bit. </p>\n<p>As per my <a href=\"http://www.decafbad.com/blog/2004/08/23/slicing_and_dicing_to_make_atom_soup_in_dbagg3\">previous musings on XML in a SQL database</a>, I revamped the database.  Now things are sliced up by feed and entry tables, rows in each containing a few metadata columns and then one big column for an XML dump.  This lets me index on  date and parent feed and such, meanwhile punting on the issue of dicing things like authors or content up further.  And, as extension elements start to show up, this handling is dumb enough to simply store things it doesn&#39;t know about without mangling them.  This is a very good thing and one of my big goals for this beast.</p>\n<p>The other thing that I&#39;m getting excited about is the REST API built atop the Atom store.  Rather than spend time on proper documentation, here&#39;s a quick dump from the <a href=\"http://www.decafbad.com/cvs/*checkout*/dbagg3/lib/dbagg3/rest.py\">appropriate module</a>:</p>\n<pre><code>URL: GET /feeds/\nURL: GET /feeds/{id}.xml\nURL: GET /feeds/{id}/{yyyy}/{mm}/{dd}/{hstart}-{hend}.xml\nURL: GET /feeds/{id}/{yyyy}/{mm}/{dd}/{hh}.xml\nURL: GET /feeds/{id}/{yyyy}/{mm}/{dd}.xml\nURL: GET /feeds/{id}/{yyyy}/{mm}.xml\nURL: GET /feeds/{id}/now-{nowoff}.xml\nURL: GET /feeds/{fid}/entries/{eid}.xml\nURL: GET /users/\nURL: GET /users/{uname}.xml\nURL: POST /users/\nURL: DELETE /users/{uname}.xml\nURL: PUT /users/{uname}.xml\nURL: GET /users/{uname}/prefs.xml\nURL: GET /users/{uname}/prefs/\nURL: POST /users/{uname}/prefs/{pname}.{type}\nURL: PUT /users/{uname}/prefs/{pname}.{type}\nURL: GET /users/{uname}/prefs/{pname}.{type}\nURL: DELETE /users/{uname}/prefs/{pname}.{type}\nURL: GET /users/{uname}/subscriptions.{type}\nURL: GET /users/{uname}/subscriptions/\nURL: POST /users/{uname}/subscriptions/\nURL: DELETE /users/{uname}/subscriptions/{id}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}/{dd}/{hstart}-{hend}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}/{dd}/{hh}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}/{dd}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/now-{hours}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/now.xml\nURL: GET /users/{uname}/subscriptions/{yyyy}/{mm}/{dd}/{hstart}-{hend}.xml\nURL: GET /users/{uname}/subscriptions/{yyyy}/{mm}/{dd}/{hh}.xml\nURL: GET /users/{uname}/subscriptions/{yyyy}/{mm}/{dd}.xml\nURL: GET /users/{uname}/subscriptions/{yyyy}/{mm}.xml\nURL: GET /users/{uname}/subscriptions/now-{hours}.xml\nURL: GET /users/{uname}/subscriptions/now.xml\nURL: GET /users/{uname}/subscriptions/{sid}/entries/{eid}.xml</code></pre>\n<p>Hopefully, the structure of these URL patterns make a little bit of sense.  The too-clever thing about these is that they&#39;re both documentation in the module&#39;s docstrings, and parsed out to register methods with automagically-generated regexes applied to incoming URL requests.  (I may eventually realize just how stupid an idea this is, but not yet.)  </p>\n<p>This list is nowhere near complete or final or even all that well thought out yet.  But, it seems to be working out pretty well so far, and it&#39;s so easy to tinker with the API to sketch out ideas in working code.  Eating my own dogfood, my first browser window of the day tends to open on this URL:</p>\n<pre><code>http://localhost/~deusx/dbagg3.5/api/users/default/subscriptions/\nnow-12.xml?xsl=xsl/full.xsl&amp;#38;content-type=text/html</code></pre>\n<p>This grabs the last 12 hours&#39; worth of items from <code>default</code>&#39;s subscriptions, passing them through the XSL at <code>xsl/full.xsl</code> on the way to my browser with a content type of <code>text/html</code>.  This tends to produce about 1000-1500 entries in about 15 seconds on my PowerBook, which is better than I&#39;d expected.  </p>\n<p>Pretty soon, I&#39;ll be implementing the ability to post metadata onto feed entries under subscriptions.  Then, I can mark items as seen, attach categories, tags, and notes.  From there, I can exclude seen items from queries, produce new aggregate feeds based on my tagging or notes, among a few other ideas I&#39;ve got stewing.</p>\n<p>A little more work, and I think I&#39;ll be able to throw together the beginnings of a <a href=\"http://www.bloglines.com\">Bloglines</a>-style three-pane browser interface, as well as improving the functionality of my own outliner-style display with <a href=\"http://developer.apple.com/internet/webcontent/xmlhttpreq.html\">XmlHTTPRequest</a>-based calls to the API to enable refresh-free interaction.  From there, I have some ideas for desktop apps and maybe even some <a href=\"http://www.decafbad.com/blog/2003/06/19/flash_agg\">tinkering in Flash</a>.  (Wow... has it really been over a year since I was writing about Flash &#38; REST?)</p>\n<p>And <em>then</em>, I want to implement the Atom API and allow users to create feeds to which they can post their own items and share read-only with others (or share writing with a group).  From there, this thing can turn into a read/write Atom storage tank, serving both as an aggregator and a blog publishing engine, given the appropriate XSL work.</p>\n<p>Lots of ideas stewing.  Now I just have to get the time and possibly a new web server, since I&#39;d like to eventually open up an installation of this to fellow tinkerers, but this poor little box can barely take what it&#39;s tasked with at present...</p>\n<p>Oh yeah, and one other thing:  I&#39;ve been thinking about names better than <code>dbagg3</code>.  The one that&#39;s sticking around in my head so far is <strong>feedReactor</strong>.  What do you think?</p>\n<!--more-->\n<p>shortname=dbagg3_makingprogress</p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221086277\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=26343060da04d2f84c3fbd726c1158b6&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"\">Alan</a>\n</div>\n<a href=\"#comment-221086277\" class=\"permalink\"><time datetime=\"2004-09-01T03:39:10\">2004-09-01T03:39:10</time></a>\n</div>\n<div class=\"content\">I prefer the dbagg title to feed_anything_. There's feedster, feedburner, feedreader and I'm sure there will be a whole slew more. This needs an original name. It seems similiar to Urchin, which you earlier posted a link to, how about Starfish or maybe Seahorse. ;)</div>\n</li>\n</ul>\n</div>\n",
    "body": "Work has been insanely busy lately, but I have made some more progress with [`dbagg3`][dbagg3].  The code is all in CVS, so feel free to take a gander-- I don't have a ton of time for a proper write up, but I do want to spew a little bit. \r\n\r\nAs per my [previous musings on XML in a SQL database][soup], I revamped the database.  Now things are sliced up by feed and entry tables, rows in each containing a few metadata columns and then one big column for an XML dump.  This lets me index on  date and parent feed and such, meanwhile punting on the issue of dicing things like authors or content up further.  And, as extension elements start to show up, this handling is dumb enough to simply store things it doesn't know about without mangling them.  This is a very good thing and one of my big goals for this beast.\r\n\r\nThe other thing that I'm getting excited about is the REST API built atop the Atom store.  Rather than spend time on proper documentation, here's a quick dump from the [appropriate module][restapi]:\r\n\r\n    URL: GET /feeds/\r\n    URL: GET /feeds/{id}.xml\r\n    URL: GET /feeds/{id}/{yyyy}/{mm}/{dd}/{hstart}-{hend}.xml\r\n    URL: GET /feeds/{id}/{yyyy}/{mm}/{dd}/{hh}.xml\r\n    URL: GET /feeds/{id}/{yyyy}/{mm}/{dd}.xml\r\n    URL: GET /feeds/{id}/{yyyy}/{mm}.xml\r\n    URL: GET /feeds/{id}/now-{nowoff}.xml\r\n    URL: GET /feeds/{fid}/entries/{eid}.xml\r\n    URL: GET /users/\r\n    URL: GET /users/{uname}.xml\r\n    URL: POST /users/\r\n    URL: DELETE /users/{uname}.xml\r\n    URL: PUT /users/{uname}.xml\r\n    URL: GET /users/{uname}/prefs.xml\r\n    URL: GET /users/{uname}/prefs/\r\n    URL: POST /users/{uname}/prefs/{pname}.{type}\r\n    URL: PUT /users/{uname}/prefs/{pname}.{type}\r\n    URL: GET /users/{uname}/prefs/{pname}.{type}\r\n    URL: DELETE /users/{uname}/prefs/{pname}.{type}\r\n    URL: GET /users/{uname}/subscriptions.{type}\r\n    URL: GET /users/{uname}/subscriptions/\r\n    URL: POST /users/{uname}/subscriptions/\r\n    URL: DELETE /users/{uname}/subscriptions/{id}.xml\r\n    URL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}/{dd}/{hstart}-{hend}.xml\r\n    URL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}/{dd}/{hh}.xml\r\n    URL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}/{dd}.xml\r\n    URL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}.xml\r\n    URL: GET /users/{uname}/subscriptions/{sid}/now-{hours}.xml\r\n    URL: GET /users/{uname}/subscriptions/{sid}/now.xml\r\n    URL: GET /users/{uname}/subscriptions/{yyyy}/{mm}/{dd}/{hstart}-{hend}.xml\r\n    URL: GET /users/{uname}/subscriptions/{yyyy}/{mm}/{dd}/{hh}.xml\r\n    URL: GET /users/{uname}/subscriptions/{yyyy}/{mm}/{dd}.xml\r\n    URL: GET /users/{uname}/subscriptions/{yyyy}/{mm}.xml\r\n    URL: GET /users/{uname}/subscriptions/now-{hours}.xml\r\n    URL: GET /users/{uname}/subscriptions/now.xml\r\n    URL: GET /users/{uname}/subscriptions/{sid}/entries/{eid}.xml\r\n\r\nHopefully, the structure of these URL patterns make a little bit of sense.  The too-clever thing about these is that they're both documentation in the module's docstrings, and parsed out to register methods with automagically-generated regexes applied to incoming URL requests.  (I may eventually realize just how stupid an idea this is, but not yet.)  \r\n\r\nThis list is nowhere near complete or final or even all that well thought out yet.  But, it seems to be working out pretty well so far, and it's so easy to tinker with the API to sketch out ideas in working code.  Eating my own dogfood, my first browser window of the day tends to open on this URL:\r\n\r\n    http://localhost/~deusx/dbagg3.5/api/users/default/subscriptions/\r\n    now-12.xml?xsl=xsl/full.xsl&#38;content-type=text/html\r\n\r\nThis grabs the last 12 hours' worth of items from `default`'s subscriptions, passing them through the XSL at `xsl/full.xsl` on the way to my browser with a content type of `text/html`.  This tends to produce about 1000-1500 entries in about 15 seconds on my PowerBook, which is better than I'd expected.  \r\n\r\nPretty soon, I'll be implementing the ability to post metadata onto feed entries under subscriptions.  Then, I can mark items as seen, attach categories, tags, and notes.  From there, I can exclude seen items from queries, produce new aggregate feeds based on my tagging or notes, among a few other ideas I've got stewing.\r\n\r\nA little more work, and I think I'll be able to throw together the beginnings of a [Bloglines][bloglines]-style three-pane browser interface, as well as improving the functionality of my own outliner-style display with [XmlHTTPRequest][xmlhttp]-based calls to the API to enable refresh-free interaction.  From there, I have some ideas for desktop apps and maybe even some [tinkering in Flash][flash].  (Wow... has it really been over a year since I was writing about Flash &#38; REST?)\r\n\r\nAnd *then*, I want to implement the Atom API and allow users to create feeds to which they can post their own items and share read-only with others (or share writing with a group).  From there, this thing can turn into a read/write Atom storage tank, serving both as an aggregator and a blog publishing engine, given the appropriate XSL work.\r\n\r\nLots of ideas stewing.  Now I just have to get the time and possibly a new web server, since I'd like to eventually open up an installation of this to fellow tinkerers, but this poor little box can barely take what it's tasked with at present...\r\n\r\nOh yeah, and one other thing:  I've been thinking about names better than `dbagg3`.  The one that's sticking around in my head so far is **feedReactor**.  What do you think?\r\n\r\n[flash]: http://www.decafbad.com/blog/2003/06/19/flash_agg\r\n[xmlhttp]: http://developer.apple.com/internet/webcontent/xmlhttpreq.html\r\n[bloglines]: http://www.bloglines.com\r\n[restapi]: http://www.decafbad.com/cvs/*checkout*/dbagg3/lib/dbagg3/rest.py\r\n[dbagg3]: http://www.decafbad.com/cvs/dbagg3/\r\n[soup]: http://www.decafbad.com/blog/2004/08/23/slicing_and_dicing_to_make_atom_soup_in_dbagg3\r\n<!--more-->\r\nshortname=dbagg3_makingprogress\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221086277\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=26343060da04d2f84c3fbd726c1158b6&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"\">Alan</a>\r\n                </div>\r\n                <a href=\"#comment-221086277\" class=\"permalink\"><time datetime=\"2004-09-01T03:39:10\">2004-09-01T03:39:10</time></a>\r\n            </div>\r\n            <div class=\"content\">I prefer the dbagg title to feed_anything_. There's feedster, feedburner, feedreader and I'm sure there will be a whole slew more. This needs an original name. It seems similiar to Urchin, which you earlier posted a link to, how about Starfish or maybe Seahorse. ;)</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2004",
    "path": "2004/08/31/dbagg3-makingprogress",
    "summary": "<p>Work has been insanely busy lately, but I have made some more progress with <a href=\"http://www.decafbad.com/cvs/dbagg3/\"><code>dbagg3</code></a>.  The code is all in CVS, so feel free to take a gander-- I don&apos;t have a ton of time for a proper write up, but I do want to spew a little bit. </p>\n<p>As per my <a href=\"http://www.decafbad.com/blog/2004/08/23/slicing_and_dicing_to_make_atom_soup_in_dbagg3\">previous musings on XML in a SQL database</a>, I revamped the database.  Now things are sliced up by feed and entry tables, rows in each containing a few metadata columns and then one big column for an XML dump.  This lets me index on  date and parent feed and such, meanwhile punting on the issue of dicing things like authors or content up further.  And, as extension elements start to show up, this handling is dumb enough to simply store things it doesn&apos;t know about without mangling them.  This is a very good thing and one of my big goals for this beast.</p>\n<p>The other thing that I&apos;m getting excited about is the REST API built atop the Atom store.  Rather than spend time on proper documentation, here&apos;s a quick dump from the <a href=\"http://www.decafbad.com/cvs/*checkout*/dbagg3/lib/dbagg3/rest.py\">appropriate module</a>:</p>\n<pre><code>URL: GET /feeds/\nURL: GET /feeds/{id}.xml\nURL: GET /feeds/{id}/{yyyy}/{mm}/{dd}/{hstart}-{hend}.xml\nURL: GET /feeds/{id}/{yyyy}/{mm}/{dd}/{hh}.xml\nURL: GET /feeds/{id}/{yyyy}/{mm}/{dd}.xml\nURL: GET /feeds/{id}/{yyyy}/{mm}.xml\nURL: GET /feeds/{id}/now-{nowoff}.xml\nURL: GET /feeds/{fid}/entries/{eid}.xml\nURL: GET /users/\nURL: GET /users/{uname}.xml\nURL: POST /users/\nURL: DELETE /users/{uname}.xml\nURL: PUT /users/{uname}.xml\nURL: GET /users/{uname}/prefs.xml\nURL: GET /users/{uname}/prefs/\nURL: POST /users/{uname}/prefs/{pname}.{type}\nURL: PUT /users/{uname}/prefs/{pname}.{type}\nURL: GET /users/{uname}/prefs/{pname}.{type}\nURL: DELETE /users/{uname}/prefs/{pname}.{type}\nURL: GET /users/{uname}/subscriptions.{type}\nURL: GET /users/{uname}/subscriptions/\nURL: POST /users/{uname}/subscriptions/\nURL: DELETE /users/{uname}/subscriptions/{id}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}/{dd}/{hstart}-{hend}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}/{dd}/{hh}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}/{dd}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/now-{hours}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/now.xml\nURL: GET /users/{uname}/subscriptions/{yyyy}/{mm}/{dd}/{hstart}-{hend}.xml\nURL: GET /users/{uname}/subscriptions/{yyyy}/{mm}/{dd}/{hh}.xml\nURL: GET /users/{uname}/subscriptions/{yyyy}/{mm}/{dd}.xml\nURL: GET /users/{uname}/subscriptions/{yyyy}/{mm}.xml\nURL: GET /users/{uname}/subscriptions/now-{hours}.xml\nURL: GET /users/{uname}/subscriptions/now.xml\nURL: GET /users/{uname}/subscriptions/{sid}/entries/{eid}.xml</code></pre>\n<p>Hopefully, the structure of these URL patterns make a little bit of sense.  The too-clever thing about these is that they&apos;re both documentation in the module&apos;s docstrings, and parsed out to register methods with automagically-generated regexes applied to incoming URL requests.  (I may eventually realize just how stupid an idea this is, but not yet.)  </p>\n<p>This list is nowhere near complete or final or even all that well thought out yet.  But, it seems to be working out pretty well so far, and it&apos;s so easy to tinker with the API to sketch out ideas in working code.  Eating my own dogfood, my first browser window of the day tends to open on this URL:</p>\n<pre><code>http://localhost/~deusx/dbagg3.5/api/users/default/subscriptions/\nnow-12.xml?xsl=xsl/full.xsl&amp;#38;content-type=text/html</code></pre>\n<p>This grabs the last 12 hours&apos; worth of items from <code>default</code>&apos;s subscriptions, passing them through the XSL at <code>xsl/full.xsl</code> on the way to my browser with a content type of <code>text/html</code>.  This tends to produce about 1000-1500 entries in about 15 seconds on my PowerBook, which is better than I&apos;d expected.  </p>\n<p>Pretty soon, I&apos;ll be implementing the ability to post metadata onto feed entries under subscriptions.  Then, I can mark items as seen, attach categories, tags, and notes.  From there, I can exclude seen items from queries, produce new aggregate feeds based on my tagging or notes, among a few other ideas I&apos;ve got stewing.</p>\n<p>A little more work, and I think I&apos;ll be able to throw together the beginnings of a <a href=\"http://www.bloglines.com\">Bloglines</a>-style three-pane browser interface, as well as improving the functionality of my own outliner-style display with <a href=\"http://developer.apple.com/internet/webcontent/xmlhttpreq.html\">XmlHTTPRequest</a>-based calls to the API to enable refresh-free interaction.  From there, I have some ideas for desktop apps and maybe even some <a href=\"http://www.decafbad.com/blog/2003/06/19/flash_agg\">tinkering in Flash</a>.  (Wow... has it really been over a year since I was writing about Flash &amp; REST?)</p>\n<p>And <em>then</em>, I want to implement the Atom API and allow users to create feeds to which they can post their own items and share read-only with others (or share writing with a group).  From there, this thing can turn into a read/write Atom storage tank, serving both as an aggregator and a blog publishing engine, given the appropriate XSL work.</p>\n<p>Lots of ideas stewing.  Now I just have to get the time and possibly a new web server, since I&apos;d like to eventually open up an installation of this to fellow tinkerers, but this poor little box can barely take what it&apos;s tasked with at present...</p>\n<p>Oh yeah, and one other thing:  I&apos;ve been thinking about names better than <code>dbagg3</code>.  The one that&apos;s sticking around in my head so far is <strong>feedReactor</strong>.  What do you think?</p>\n"
  },
  {
    "comments_archived": true,
    "date": "2004-08-24T03:14:40.000Z",
    "excerpt": "I tell ya, this is an idea that's catching.  Feeds go into a searchable stew, come back out as new synthetic feeds.  What comes out looks like what goes in, and there's a well-defined spec behind it.  Sprinkle in the elegance of loosely coupled UNIX pipelines and filters, REST interfaces, and XML tech like XSLT for munging, and you've got the makings of the next generation of syndication and XML feeds.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "More Cooks in the Feed Stew Kitchen",
    "wordpress_id": 540,
    "wordpress_slug": "more-cooks-in-the-feed-stew-kitchen",
    "wordpress_url": "http://www.decafbad.com/blog/?p=540",
    "year": "2004",
    "month": "08",
    "day": "23",
    "isDir": false,
    "slug": "more-cooks-in-the-feed-stew-kitchen",
    "postName": "2004-08-23-more-cooks-in-the-feed-stew-kitchen",
    "html": "<blockquote>\n<p>\nI've talked before about why I like Atom. It's because it's the fixed point around which all the rest can crystallise...</p>\n\n</blockquote>\n<div class=\"credit\" align=\"right\"><small>Source: <cite><a href=\n\"http://interconnected.org/home/2004/08/24/diego_dovals_atomflow\">diego dovals atomflow (24 August 2004, Interconnected)</a></cite></small></div>\n\n<blockquote>\n<p>\nOne, that by using Atom as input format, you could simplify entry into this black-box system and use it, for example, on the receiving end of a UNIX pipe. Content on the source could be either straight Atom or come in some other form that would require transforming it into Atom, but that'd be easy to do, since transforming XML is pretty easy these days.\n</p><p>\n Two, that by using Atom as the output format you'd have the same flexibility. To generate a feed if you wanted, or transform it into something else, say, a weblog.\n</p>\n</blockquote>\n<div class=\"credit\" align=\"right\"><small>Source: <cite><a href=\n\"http://www.dynamicobjects.com/d2r/archives/002885.html\">d2r: atomflow</a></cite></small></div>\n\n<p>So, first I discover <a href=\"http://urchin.sourceforge.net/\">Urchin</a>, and now I read <a href=\"http://interconnected.org/home/\">this</a>.  I tell ya, this is an idea that&#39;s catching.  Granted, Urchin&#39;s all about RSS, and <a href=\"http://www.dynamicobjects.com/d2r/archives/002885.html\">atomflow</a> and <a href=\"http://www.decafbad.com/cvs/dbagg3/\">dbagg3</a> are all about Atom, but the spirit&#39;s the same:  </p>\n<p>Feeds go into a searchable stew, come back out as new synthetic feeds.  What comes out looks like what goes in, and there&#39;s a well-defined spec behind it.  Sprinkle in the elegance of loosely coupled UNIX pipelines and filters, REST interfaces, and XML tech like XSLT for munging, and you&#39;ve got the makings of the next generation of syndication and XML feeds.</p>\n<p>I guess maybe I should start checking into this Java stuff again, since smart guys like <a href=\"http://www.dynamicobjects.com/d2r/\">Diego</a> and <a href=\"http://interconnected.org/home/\">Matt</a> are making noises I like, over in that sandbox.  Well, at least I&#39;ll have things like <a href=\"http://www.jython.org/\">Jython</a>, <a href=\"http://www.beanshell.org/\">Beanshell</a>, and <a href=\"http://groovy.codehaus.org/\">Groovy</a> to toy with over there.  And it&#39;s not like I haven&#39;t <a href=\"http://www.decafbad.com/cvs/AgentFrank/\">played with Java</a> before.</p>\n<p>So who else has something like this brewing?</p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221082710\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://franklinmint.fm\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=b9ed774661a22ff8797a1e0e24f0baf3&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://franklinmint.fm\">Robert Sayre</a>\n</div>\n<a href=\"#comment-221082710\" class=\"permalink\"><time datetime=\"2004-08-23T23:54:50\">2004-08-23T23:54:50</time></a>\n</div>\n<div class=\"content\">The Jabber folks!\nhot off the press:\nhttp://www.ietf.org/internet-drafts/draft-saintandre-atompub-notify-00.txt</div>\n</li>\n<li class=\"comment\" id=\"comment-221082711\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8a5273f79cfe7579ad46023f93377aa8&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.decafbad.com/blog/\">l.m.orchard</a>\n</div>\n<a href=\"#comment-221082711\" class=\"permalink\"><time datetime=\"2004-08-24T00:28:51\">2004-08-24T00:28:51</time></a>\n</div>\n<div class=\"content\">Wow, this feels like a lot of wouldn't-it-be-nice-if's all coming together.  :)</div>\n</li>\n<li class=\"comment\" id=\"comment-221082712\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://mah.everybody.org/weblog/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=a6d8be203bb9da491bbdce177fea43eb&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://mah.everybody.org/weblog/\">Mark A. Hershberger</a>\n</div>\n<a href=\"#comment-221082712\" class=\"permalink\"><time datetime=\"2004-08-24T08:53:07\">2004-08-24T08:53:07</time></a>\n</div>\n<div class=\"content\">Check out what Simon Cozens has been up to: \nhttp://blog.simon-cozens.org/bryar.cgi/id_6786\nhttp://blog.simon-cozens.org/bryar.cgi/id_6787\nhttp://blog.simon-cozens.org/bryar.cgi/id_6788</div>\n</li>\n<li class=\"comment\" id=\"comment-221082713\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://dannyayers.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=b66023720241dc4e8791dfe9fb9cfcdc&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://dannyayers.com\">Danny</a>\n</div>\n<a href=\"#comment-221082713\" class=\"permalink\"><time datetime=\"2004-08-27T15:27:29\">2004-08-27T15:27:29</time></a>\n</div>\n<div class=\"content\">I'm working on a book on it, does that count?\n(Well, I'm taking a very component-oriented approach, with the aim of enabling this kind of stuff)</div>\n</li>\n<li class=\"comment\" id=\"comment-221082715\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://notizen.typepad.com/aus_der_provinz/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=005509858f6bec19f23d989ff9228724&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://notizen.typepad.com/aus_der_provinz/\">Markus Breuer</a>\n</div>\n<a href=\"#comment-221082715\" class=\"permalink\"><time datetime=\"2004-08-30T18:07:09\">2004-08-30T18:07:09</time></a>\n</div>\n<div class=\"content\">AtomFlow really sound like an nice proof of concept to me. Interestingly (talk of synchronicity) Kottkes \"Noodlings\" (http://www.kottke.org/04/08/web-platform) inspired me to a similar concept, which I'm trying to demo together with a few friends. We would very much appreciate your suggestions/comments on the concept especially because dbagg looks like a nice \"persistent storage\" for aggregating feeds and - together with the tools you showed in the post \"Introducing dbagg3, an Atom-powered client/server aggregator\" should also be usable as a kind of debugger for feed-munching tools ...\nPlease have a look: (the link was not accepted here because of the underscores in the url; but you can find it on the homepage of my webblog \"A simple (but universal) toolbox for building Blogs (and Websites) from RSS-Feeds\")</div>\n</li>\n</ul>\n</div>\n",
    "body": "<blockquote>\r\n<p>\r\nI've talked before about why I like Atom. It's because it's the fixed point around which all the rest can crystallise...</p>\r\n\r\n</blockquote>\r\n<div class=\"credit\" align=\"right\"><small>Source: <cite><a href=\r\n\"http://interconnected.org/home/2004/08/24/diego_dovals_atomflow\">diego dovals atomflow (24 August 2004, Interconnected)</a></cite></small></div>\r\n\r\n<blockquote>\r\n<p>\r\nOne, that by using Atom as input format, you could simplify entry into this black-box system and use it, for example, on the receiving end of a UNIX pipe. Content on the source could be either straight Atom or come in some other form that would require transforming it into Atom, but that'd be easy to do, since transforming XML is pretty easy these days.\r\n</p><p>\r\n Two, that by using Atom as the output format you'd have the same flexibility. To generate a feed if you wanted, or transform it into something else, say, a weblog.\r\n</p>\r\n</blockquote>\r\n<div class=\"credit\" align=\"right\"><small>Source: <cite><a href=\r\n\"http://www.dynamicobjects.com/d2r/archives/002885.html\">d2r: atomflow</a></cite></small></div>\r\n\r\nSo, first I discover [Urchin][urchin], and now I read [this][matt].  I tell ya, this is an idea that's catching.  Granted, Urchin's all about RSS, and [atomflow][atomflow] and [dbagg3][dbagg3] are all about Atom, but the spirit's the same:  \r\n\r\nFeeds go into a searchable stew, come back out as new synthetic feeds.  What comes out looks like what goes in, and there's a well-defined spec behind it.  Sprinkle in the elegance of loosely coupled UNIX pipelines and filters, REST interfaces, and XML tech like XSLT for munging, and you've got the makings of the next generation of syndication and XML feeds.\r\n\r\nI guess maybe I should start checking into this Java stuff again, since smart guys like [Diego][diego] and [Matt][matt] are making noises I like, over in that sandbox.  Well, at least I'll have things like [Jython][jython], [Beanshell][beanshell], and [Groovy][groovy] to toy with over there.  And it's not like I haven't [played with Java][agentfrank] before.\r\n\r\nSo who else has something like this brewing?\r\n\r\n[agentfrank]: http://www.decafbad.com/cvs/AgentFrank/\r\n[groovy]: http://groovy.codehaus.org/\r\n[beanshell]: http://www.beanshell.org/\r\n[jython]: http://www.jython.org/\r\n[matt]: http://interconnected.org/home/\r\n[diego]: http://www.dynamicobjects.com/d2r/\r\n[dbagg3]: http://www.decafbad.com/cvs/dbagg3/\r\n[atomflow]: http://www.dynamicobjects.com/d2r/archives/002885.html\r\n[matt]: http://interconnected.org/home/2004/08/24/diego_dovals_atomflow\r\n[urchin]: http://urchin.sourceforge.net/\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221082710\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://franklinmint.fm\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=b9ed774661a22ff8797a1e0e24f0baf3&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://franklinmint.fm\">Robert Sayre</a>\r\n                </div>\r\n                <a href=\"#comment-221082710\" class=\"permalink\"><time datetime=\"2004-08-23T23:54:50\">2004-08-23T23:54:50</time></a>\r\n            </div>\r\n            <div class=\"content\">The Jabber folks!\r\n\r\nhot off the press:\r\n\r\nhttp://www.ietf.org/internet-drafts/draft-saintandre-atompub-notify-00.txt</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221082711\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8a5273f79cfe7579ad46023f93377aa8&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.decafbad.com/blog/\">l.m.orchard</a>\r\n                </div>\r\n                <a href=\"#comment-221082711\" class=\"permalink\"><time datetime=\"2004-08-24T00:28:51\">2004-08-24T00:28:51</time></a>\r\n            </div>\r\n            <div class=\"content\">Wow, this feels like a lot of wouldn't-it-be-nice-if's all coming together.  :)</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221082712\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://mah.everybody.org/weblog/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=a6d8be203bb9da491bbdce177fea43eb&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://mah.everybody.org/weblog/\">Mark A. Hershberger</a>\r\n                </div>\r\n                <a href=\"#comment-221082712\" class=\"permalink\"><time datetime=\"2004-08-24T08:53:07\">2004-08-24T08:53:07</time></a>\r\n            </div>\r\n            <div class=\"content\">Check out what Simon Cozens has been up to: \r\n\r\nhttp://blog.simon-cozens.org/bryar.cgi/id_6786\r\nhttp://blog.simon-cozens.org/bryar.cgi/id_6787\r\nhttp://blog.simon-cozens.org/bryar.cgi/id_6788</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221082713\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://dannyayers.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=b66023720241dc4e8791dfe9fb9cfcdc&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://dannyayers.com\">Danny</a>\r\n                </div>\r\n                <a href=\"#comment-221082713\" class=\"permalink\"><time datetime=\"2004-08-27T15:27:29\">2004-08-27T15:27:29</time></a>\r\n            </div>\r\n            <div class=\"content\">I'm working on a book on it, does that count?\r\n\r\n(Well, I'm taking a very component-oriented approach, with the aim of enabling this kind of stuff)</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221082715\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://notizen.typepad.com/aus_der_provinz/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=005509858f6bec19f23d989ff9228724&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://notizen.typepad.com/aus_der_provinz/\">Markus Breuer</a>\r\n                </div>\r\n                <a href=\"#comment-221082715\" class=\"permalink\"><time datetime=\"2004-08-30T18:07:09\">2004-08-30T18:07:09</time></a>\r\n            </div>\r\n            <div class=\"content\">AtomFlow really sound like an nice proof of concept to me. Interestingly (talk of synchronicity) Kottkes \"Noodlings\" (http://www.kottke.org/04/08/web-platform) inspired me to a similar concept, which I'm trying to demo together with a few friends. We would very much appreciate your suggestions/comments on the concept especially because dbagg looks like a nice \"persistent storage\" for aggregating feeds and - together with the tools you showed in the post \"Introducing dbagg3, an Atom-powered client/server aggregator\" should also be usable as a kind of debugger for feed-munching tools ...\r\n\r\nPlease have a look: (the link was not accepted here because of the underscores in the url; but you can find it on the homepage of my webblog \"A simple (but universal) toolbox for building Blogs (and Websites) from RSS-Feeds\")</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2004",
    "path": "2004/08/24/more-cooks-in-the-feed-stew-kitchen"
  },
  {
    "comments_archived": true,
    "date": "2004-08-23T22:52:06.000Z",
    "excerpt": "I've been putting more work into dbagg3, but I'm getting hung up on the database.  Well, actually I'm getting hung up on the subject of XML storage, query, and retrieval in general-- but at present, I'm trying to cram all this data into MySQL and SQLite databases.  But, my tendencies as an abstraction astronaut and my lack of database savvy are tying me (and my data) in knots.  I kept meaning to write a bit Atom (and XML in general) with regard to database storage and query, so maybe now's the time.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "Slicing and Dicing to Make Atom Soup in dbagg3",
    "wordpress_id": 539,
    "wordpress_slug": "slicing-and-dicing-to-make-atom-soup-in-dbagg3",
    "wordpress_url": "http://www.decafbad.com/blog/?p=539",
    "year": "2004",
    "month": "08",
    "day": "23",
    "isDir": false,
    "slug": "slicing-and-dicing-to-make-atom-soup-in-dbagg3",
    "postName": "2004-08-23-slicing-and-dicing-to-make-atom-soup-in-dbagg3",
    "html": "<p>I&#39;ve been putting more work into <a href=\"http://www.decafbad.com/cvs/dbagg3/\"><code>dbagg3</code></a>, but I&#39;m getting hung up on the database.  Well, actually I&#39;m getting hung up on the subject of XML storage, query, and retrieval in general-- but at present, I&#39;m trying to cram all this data into MySQL and SQLite databases.  But, my tendencies as an abstraction astronaut and my lack of database savvy are tying me (and my data) in knots.  I kept meaning to write a bit Atom (and XML in general) with regard to database storage and query, so maybe now&#39;s the time.</p>\n<h3 id=\"xml-databases\">XML databases</h3>\n<p>I&#39;m aware of XML-native databases like <a href=\"http://exist.sourceforge.net/\">eXist</a>, <a href=\"http://xml.apache.org/xindice/\">Xindice</a>, and <a href=\"http://www.sleepycat.com/products/xml.shtml\">Berkeley DB XML</a>-- but I don&#39;t want to work in Java right now, and I can&#39;t get the Berkeley XML DB compiled and running without segfault under OS X.  This bugs me, though, since the most elegant solution to me is to use something XML-native to store and query piles of Atom feeds and entries.  I&#39;d really like to have <a href=\"http://webservices.xml.com/pub/a/ws/2003/04/15/semanticblog.html\">XPath available as a query tool</a>.  And then, though I haven&#39;t heard a ton about it lately, there&#39;s XQuery.</p>\n<p>And, oh yeah, I know there are some commercial solutions (like <a href=\"http://virtuoso.openlinksw.com/\">Virtuoso</a>), but umm... no.</p>\n<h3 id=\"rdf-databases\">RDF databases</h3>\n<p>I suppose I could also switch to tossing RDF around internally, maybe use RSS 1.0 under the hood.  This seems to be what the much-similar <a href=\"http://urchin.sourceforge.net/\">Urchin RSS aggregator</a> is doing.  (Maybe I should just dump <code>dbagg3</code> and pitch in with Urchin.)  But, I don&#39;t know the state of RDF art well enough to know whether there&#39;s a database available that can handle 10,000 Atom/RSS entries a week or more for a year without gagging.  (My previous database was up to 500,000 entries when I started working on <code>dbagg3</code>, and I think that was since last November.)</p>\n<h3 id=\"sql-databases\">SQL databases</h3>\n<p>So, I&#39;m screwing around with SQL databases-- MySQL and SQLite in particular.  As compared to XML and RDF databases, I know and understand and trust SQL databases so much more with regards to performance and gotchas and general techniques.  </p>\n<p>In previous incarnations of my aggregator, MySQL and SQLite served me well with pretty simple data models.  But this time around, I want to play with much richer data: I want to include everything in the Atom spec, and try to take in some metadata from extensions.  So I threw together what I thought was a pretty decent relational model onto which I could map Atom XML data.  (If you&#39;re curious, you can check out <a href=\"http://www.decafbad.com/2004/08/dbagg3.sql\">a recent schema dump</a>.)</p>\n<p>The problem is, with the XML sliced and diced and sprinkled into all these separate tables, it&#39;s a <strong>fun</strong> time reassembling the pieces.  I&#39;ve run into this problem many times before, when trying to map object hierarchies into relational databases, and usually things degrade into nasty self-joins and an explosive number of queries.  This kind of inelegance smells really bad, oily like melting plastic caused by the friction of a square peg being driven into a round hole by my forehead as a hammer.</p>\n<p>In the end, what I&#39;ve usually ended up doing is to forget about mapping from objects to the relational model: tables become a set of indices to objects, the objects themselves packed up as BLOBs via some language-dependant pickling or freezing scheme.  Nasty, ugly, fragile, and completely inelegant.  There&#39;s some of that in <code>dbagg3</code> <em>right now</em>, and I want it out.  Though I used to think it was as clever and neat as a digital watch, this smells even worse than melting plastic.</p>\n<h3 id=\"xml-in-sql-databases\">XML in SQL databases</h3>\n<p>My latest thoughts, then, are to accept some bad smells (I <em>do</em> like the smell of burning plastic, actually) and simplify my database:  Instead of pickled binary objects, I&#39;ll store XML in a column (at least that isn&#39;t implementation-tied), and other tables will give me indices to this XML.  Thinking hard about my use cases, I think I can cover 80% of what I need with being able to look things up by feed, by subscription, by user, by date, and a few other useful aspects.  Once I&#39;ve gotten a pile of data out of the database in XML form, I can then attack it with XSL.</p>\n<p>However, what gives me even further enthusiasm for this approach is <a href=\"http://www.throwingbeans.org/tech/postgresql_and_xml.html\">this little XPath extension to PostgreSQL</a>.  This gives you a set of functions to apply XPath to XML-containing columns in SQL queries.  So, you can pull out nodes in a select, or search on the results in a WHERE clause, among other things.  I haven&#39;t tried it yet, but it gives me ideas.</p>\n<p>One idea is that, through <a href=\"http://pysqlite.sourceforge.net/old/documentation/pysqlite/node10.html\">PySQLite&#39;s API additions</a>, I can easily add new SQL functions at will-- oh like, say, some XPath functions using libxml2 under python.</p>\n<p>Granted, there are no indices backing these XPath searches, and using these python functions added to SQLite comes with overhead, the availability of XPath in SQL could give me the 20% I&#39;m missing with simple tables.  It might be worth the price and the smells.</p>\n<h3 id=\"so-anyway\">So Anyway...</h3>\n<p>That&#39;s where I&#39;m at right now.  I think I&#39;ve written a bunch, and all this text could use some code examples and some diagrams.  But, I figured I&#39;d think out loud a bit and see if anyone could step in and smack me for being a complete twink.  </p>\n<p>I want to slurp in Atom XML data, with arbitrary extensions, and be able to attack it with some reasonable set of queries to recombine this data into new feeds.</p>\n<p>I know I&#39;m not the only person thinking about this stuff, and I&#39;ve got to assume that I&#39;m nowhere near the smartest about it.  I&#39;m still working on this aggregator thing, and making what I think is some fun progress with a <a href=\"http://www.decafbad.com/cvs/*checkout*/dbagg3/lib/dbagg3/web/api.py?rev=HEAD&#38;content-type=text/x-python\">REST interface</a>, but this data stuff has me stalled.</p>\n<p>So... what do you think?</p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221082837\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://franklinmint.fm\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=b9ed774661a22ff8797a1e0e24f0baf3&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://franklinmint.fm\">Robert Sayre</a>\n</div>\n<a href=\"#comment-221082837\" class=\"permalink\"><time datetime=\"2004-08-23T19:23:19\">2004-08-23T19:23:19</time></a>\n</div>\n<div class=\"content\">FYI: Apple's upcoming SafariRSS uses XQuery to parse feeds. The Tiger version of NSXML includes XQuery as well.</div>\n</li>\n<li class=\"comment\" id=\"comment-221082838\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=719ad7cfa24c00bbcaa8030427dd8743&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"\">bear</a>\n</div>\n<a href=\"#comment-221082838\" class=\"permalink\"><time datetime=\"2004-08-23T21:16:42\">2004-08-23T21:16:42</time></a>\n</div>\n<div class=\"content\">Not knowing what errors you are getting during the dbxml build means my comment will be generic but I hope it is still useful.\nThe OSAF people are using dbxml as their back-end data store and their build process works on os/x (what I use) - I can forward the makefile or just compare notes if that is useful to you.\nthanks for your great writing</div>\n</li>\n<li class=\"comment\" id=\"comment-221082839\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://randomthoughts.vandorp.ca/WK/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=0a9028b800da9db6932c2f026d50847b&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://randomthoughts.vandorp.ca/WK/blog\">Darryl</a>\n</div>\n<a href=\"#comment-221082839\" class=\"permalink\"><time datetime=\"2004-08-24T04:27:51\">2004-08-24T04:27:51</time></a>\n</div>\n<div class=\"content\">Try a recipe by Kimbro Staken \nhttp://www.xmldatabases.org/movabletype/archives/000267.html</div>\n</li>\n<li class=\"comment\" id=\"comment-221082840\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://simon.incutio.com/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=02ecb4f56e961dd226352c4dd51eff26&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://simon.incutio.com/\">Simon Willison</a>\n</div>\n<a href=\"#comment-221082840\" class=\"permalink\"><time datetime=\"2004-08-24T18:27:33\">2004-08-24T18:27:33</time></a>\n</div>\n<div class=\"content\">Unfortunately, the XPath extension for PostgreSQL seems to be vapourware. As far as I know it exists only as a mention in the blog entry you linked to - the guy never released it. I'd love to be proved wrong - I'd really like to use it for a whole bunch of different things.</div>\n</li>\n<li class=\"comment\" id=\"comment-221082841\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.throwingbeans.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=96bc90c98bc78316eda53f6d1dbfa0f6&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.throwingbeans.org\">Tom Dyson</a>\n</div>\n<a href=\"#comment-221082841\" class=\"permalink\"><time datetime=\"2004-08-25T21:10:17\">2004-08-25T21:10:17</time></a>\n</div>\n<div class=\"content\">The XPath extensions for Postgres are certainly not vapourware: we're using them in a content management environment for several high-profile websites. The extensions are available as part of the Postgres 8 beta download, where you'll find them in source code form in the contrib/xml directory. If you need help installing the functions, let me know - we have compiled them successfully on Debian, RedHat, OS X and Windows.</div>\n</li>\n<li class=\"comment\" id=\"comment-221082842\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://dannyayers.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=7028f422ca6da0180de6c9d922a3228f&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://dannyayers.com\">Danny</a>\n</div>\n<a href=\"#comment-221082842\" class=\"permalink\"><time datetime=\"2004-09-08T22:03:05\">2004-09-08T22:03:05</time></a>\n</div>\n<div class=\"content\">I've not tried that kind of data size with RDF either, though am assured kit like Kowari can handle it.\nA possible compromise approach might be to use SQL storage directly for core syndication stuff, with RDF at the side. \nVaguely relevant blogged stuff:\nhttp://dannyayers.com/archives/2004/08/10/extending-the-capabilities-of-content-management-systems-with-rdf/\nanother possibility is using a triplestore on top of SQL, you end up with views/queries like this:\nhttp://dannyayers.com/archives/2004/07/14/all-in-a-days-work/</div>\n</li>\n<li class=\"comment\" id=\"comment-221082843\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://netapps.muohio.edu/blogs/darcusb/darcusb/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8043a49e7e80eef7672fa2be09b51473&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://netapps.muohio.edu/blogs/darcusb/darcusb/\">Bruce</a>\n</div>\n<a href=\"#comment-221082843\" class=\"permalink\"><time datetime=\"2005-02-24T03:16:48\">2005-02-24T03:16:48</time></a>\n</div>\n<div class=\"content\">You might take a look at BDB XML again.  I recall having problems compiling v1 on Mac OS X too, but had no such problems with v2.  And it addds XQuery to the mix.</div>\n</li>\n</ul>\n</div>\n",
    "body": "I've been putting more work into [`dbagg3`][dbagg3], but I'm getting hung up on the database.  Well, actually I'm getting hung up on the subject of XML storage, query, and retrieval in general-- but at present, I'm trying to cram all this data into MySQL and SQLite databases.  But, my tendencies as an abstraction astronaut and my lack of database savvy are tying me (and my data) in knots.  I kept meaning to write a bit Atom (and XML in general) with regard to database storage and query, so maybe now's the time.\r\n\r\n### XML databases\r\n\r\nI'm aware of XML-native databases like [eXist][exist], [Xindice][xindice], and [Berkeley DB XML][bdbxml]-- but I don't want to work in Java right now, and I can't get the Berkeley XML DB compiled and running without segfault under OS X.  This bugs me, though, since the most elegant solution to me is to use something XML-native to store and query piles of Atom feeds and entries.  I'd really like to have [XPath available as a query tool][xpathudell].  And then, though I haven't heard a ton about it lately, there's XQuery.\r\n\r\nAnd, oh yeah, I know there are some commercial solutions (like [Virtuoso][virtuoso]), but umm... no.\r\n\r\n### RDF databases\r\n\r\nI suppose I could also switch to tossing RDF around internally, maybe use RSS 1.0 under the hood.  This seems to be what the much-similar [Urchin RSS aggregator][urchin] is doing.  (Maybe I should just dump `dbagg3` and pitch in with Urchin.)  But, I don't know the state of RDF art well enough to know whether there's a database available that can handle 10,000 Atom/RSS entries a week or more for a year without gagging.  (My previous database was up to 500,000 entries when I started working on `dbagg3`, and I think that was since last November.)\r\n\r\n### SQL databases\r\n\r\nSo, I'm screwing around with SQL databases-- MySQL and SQLite in particular.  As compared to XML and RDF databases, I know and understand and trust SQL databases so much more with regards to performance and gotchas and general techniques.  \r\n\r\nIn previous incarnations of my aggregator, MySQL and SQLite served me well with pretty simple data models.  But this time around, I want to play with much richer data: I want to include everything in the Atom spec, and try to take in some metadata from extensions.  So I threw together what I thought was a pretty decent relational model onto which I could map Atom XML data.  (If you're curious, you can check out [a recent schema dump][dbagg3_sql].)\r\n\r\nThe problem is, with the XML sliced and diced and sprinkled into all these separate tables, it's a **fun** time reassembling the pieces.  I've run into this problem many times before, when trying to map object hierarchies into relational databases, and usually things degrade into nasty self-joins and an explosive number of queries.  This kind of inelegance smells really bad, oily like melting plastic caused by the friction of a square peg being driven into a round hole by my forehead as a hammer.\r\n\r\nIn the end, what I've usually ended up doing is to forget about mapping from objects to the relational model: tables become a set of indices to objects, the objects themselves packed up as BLOBs via some language-dependant pickling or freezing scheme.  Nasty, ugly, fragile, and completely inelegant.  There's some of that in `dbagg3` *right now*, and I want it out.  Though I used to think it was as clever and neat as a digital watch, this smells even worse than melting plastic.\r\n\r\n### XML in SQL databases\r\n\r\nMy latest thoughts, then, are to accept some bad smells (I *do* like the smell of burning plastic, actually) and simplify my database:  Instead of pickled binary objects, I'll store XML in a column (at least that isn't implementation-tied), and other tables will give me indices to this XML.  Thinking hard about my use cases, I think I can cover 80% of what I need with being able to look things up by feed, by subscription, by user, by date, and a few other useful aspects.  Once I've gotten a pile of data out of the database in XML form, I can then attack it with XSL.\r\n\r\nHowever, what gives me even further enthusiasm for this approach is [this little XPath extension to PostgreSQL][postxml].  This gives you a set of functions to apply XPath to XML-containing columns in SQL queries.  So, you can pull out nodes in a select, or search on the results in a WHERE clause, among other things.  I haven't tried it yet, but it gives me ideas.\r\n\r\nOne idea is that, through [PySQLite's API additions][pysqliteapi], I can easily add new SQL functions at will-- oh like, say, some XPath functions using libxml2 under python.\r\n\r\nGranted, there are no indices backing these XPath searches, and using these python functions added to SQLite comes with overhead, the availability of XPath in SQL could give me the 20% I'm missing with simple tables.  It might be worth the price and the smells.\r\n\r\n### So Anyway...\r\n\r\nThat's where I'm at right now.  I think I've written a bunch, and all this text could use some code examples and some diagrams.  But, I figured I'd think out loud a bit and see if anyone could step in and smack me for being a complete twink.  \r\n\r\nI want to slurp in Atom XML data, with arbitrary extensions, and be able to attack it with some reasonable set of queries to recombine this data into new feeds.\r\n\r\nI know I'm not the only person thinking about this stuff, and I've got to assume that I'm nowhere near the smartest about it.  I'm still working on this aggregator thing, and making what I think is some fun progress with a [REST interface][dbagg3_api], but this data stuff has me stalled.\r\n\r\nSo... what do you think?\r\n\r\n[virtuoso]: http://virtuoso.openlinksw.com/\r\n[dbagg3_api]: http://www.decafbad.com/cvs/*checkout*/dbagg3/lib/dbagg3/web/api.py?rev=HEAD&#38;content-type=text/x-python\r\n[pysqliteapi]: http://pysqlite.sourceforge.net/old/documentation/pysqlite/node10.html\r\n[postxml]: http://www.throwingbeans.org/tech/postgresql_and_xml.html\r\n[exist]: http://exist.sourceforge.net/\r\n[xindice]: http://xml.apache.org/xindice/\r\n[bdbxml]: http://www.sleepycat.com/products/xml.shtml\r\n[urchin]: http://urchin.sourceforge.net/\r\n[dbagg3]: http://www.decafbad.com/cvs/dbagg3/\r\n[dbagg3_sql]: http://www.decafbad.com/2004/08/dbagg3.sql\r\n[xpathudell]: http://webservices.xml.com/pub/a/ws/2003/04/15/semanticblog.html\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221082837\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://franklinmint.fm\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=b9ed774661a22ff8797a1e0e24f0baf3&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://franklinmint.fm\">Robert Sayre</a>\r\n                </div>\r\n                <a href=\"#comment-221082837\" class=\"permalink\"><time datetime=\"2004-08-23T19:23:19\">2004-08-23T19:23:19</time></a>\r\n            </div>\r\n            <div class=\"content\">FYI: Apple's upcoming SafariRSS uses XQuery to parse feeds. The Tiger version of NSXML includes XQuery as well.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221082838\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=719ad7cfa24c00bbcaa8030427dd8743&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"\">bear</a>\r\n                </div>\r\n                <a href=\"#comment-221082838\" class=\"permalink\"><time datetime=\"2004-08-23T21:16:42\">2004-08-23T21:16:42</time></a>\r\n            </div>\r\n            <div class=\"content\">Not knowing what errors you are getting during the dbxml build means my comment will be generic but I hope it is still useful.\r\n\r\nThe OSAF people are using dbxml as their back-end data store and their build process works on os/x (what I use) - I can forward the makefile or just compare notes if that is useful to you.\r\n\r\nthanks for your great writing</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221082839\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://randomthoughts.vandorp.ca/WK/blog\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=0a9028b800da9db6932c2f026d50847b&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://randomthoughts.vandorp.ca/WK/blog\">Darryl</a>\r\n                </div>\r\n                <a href=\"#comment-221082839\" class=\"permalink\"><time datetime=\"2004-08-24T04:27:51\">2004-08-24T04:27:51</time></a>\r\n            </div>\r\n            <div class=\"content\">Try a recipe by Kimbro Staken \r\nhttp://www.xmldatabases.org/movabletype/archives/000267.html</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221082840\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://simon.incutio.com/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=02ecb4f56e961dd226352c4dd51eff26&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://simon.incutio.com/\">Simon Willison</a>\r\n                </div>\r\n                <a href=\"#comment-221082840\" class=\"permalink\"><time datetime=\"2004-08-24T18:27:33\">2004-08-24T18:27:33</time></a>\r\n            </div>\r\n            <div class=\"content\">Unfortunately, the XPath extension for PostgreSQL seems to be vapourware. As far as I know it exists only as a mention in the blog entry you linked to - the guy never released it. I'd love to be proved wrong - I'd really like to use it for a whole bunch of different things.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221082841\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.throwingbeans.org\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=96bc90c98bc78316eda53f6d1dbfa0f6&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.throwingbeans.org\">Tom Dyson</a>\r\n                </div>\r\n                <a href=\"#comment-221082841\" class=\"permalink\"><time datetime=\"2004-08-25T21:10:17\">2004-08-25T21:10:17</time></a>\r\n            </div>\r\n            <div class=\"content\">The XPath extensions for Postgres are certainly not vapourware: we're using them in a content management environment for several high-profile websites. The extensions are available as part of the Postgres 8 beta download, where you'll find them in source code form in the contrib/xml directory. If you need help installing the functions, let me know - we have compiled them successfully on Debian, RedHat, OS X and Windows.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221082842\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://dannyayers.com\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=7028f422ca6da0180de6c9d922a3228f&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://dannyayers.com\">Danny</a>\r\n                </div>\r\n                <a href=\"#comment-221082842\" class=\"permalink\"><time datetime=\"2004-09-08T22:03:05\">2004-09-08T22:03:05</time></a>\r\n            </div>\r\n            <div class=\"content\">I've not tried that kind of data size with RDF either, though am assured kit like Kowari can handle it.\r\n\r\nA possible compromise approach might be to use SQL storage directly for core syndication stuff, with RDF at the side. \r\n\r\nVaguely relevant blogged stuff:\r\n\r\nhttp://dannyayers.com/archives/2004/08/10/extending-the-capabilities-of-content-management-systems-with-rdf/\r\n\r\nanother possibility is using a triplestore on top of SQL, you end up with views/queries like this:\r\n\r\nhttp://dannyayers.com/archives/2004/07/14/all-in-a-days-work/</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221082843\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://netapps.muohio.edu/blogs/darcusb/darcusb/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=8043a49e7e80eef7672fa2be09b51473&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://netapps.muohio.edu/blogs/darcusb/darcusb/\">Bruce</a>\r\n                </div>\r\n                <a href=\"#comment-221082843\" class=\"permalink\"><time datetime=\"2005-02-24T03:16:48\">2005-02-24T03:16:48</time></a>\r\n            </div>\r\n            <div class=\"content\">You might take a look at BDB XML again.  I recall having problems compiling v1 on Mac OS X too, but had no such problems with v2.  And it addds XQuery to the mix.</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2004",
    "path": "2004/08/23/slicing-and-dicing-to-make-atom-soup-in-dbagg3"
  },
  {
    "comments_archived": true,
    "date": "2004-08-23T05:09:51.000Z",
    "excerpt": "So...  How many of you have ever used mysql -X?",
    "layout": "post",
    "tags": [
      "hacks",
      "xml"
    ],
    "title": "mysql and XML output",
    "wordpress_id": 538,
    "wordpress_slug": "mysql-and-xml-output",
    "wordpress_url": "http://www.decafbad.com/blog/?p=538",
    "year": "2004",
    "month": "08",
    "day": "23",
    "isDir": false,
    "slug": "mysql-and-xml-output",
    "postName": "2004-08-23-mysql-and-xml-output",
    "html": "<p>So...  How many of you have ever used <code>mysql -X</code>?</p>\n<p>I just discovered it today, while screwing around with dumping database queries into Atom.  While I&#39;m not entirely sure it&#39;s what I need to use, this is pretty nifty:</p>\n<pre><code>$ mysql -Xp -udbagg3 dbagg3 -e &#39;\n&gt; select id, title, modified \n&gt; from feed\n&gt; order by modified \n&gt; limit 4&#39; \nEnter password:\n\n&lt;?xml version=&quot;1.0&quot;?&gt;\n\n&lt;resultset statement=&quot;select id, title, modified \n        from feed order by modified limit 4&quot;&gt;\n  &lt;row&gt;\n    &lt;id&gt;527&lt;/id&gt;\n    &lt;title&gt;Channel Dean&lt;/title&gt;\n    &lt;modified&gt;2004-03-04 15:56:54&lt;/modified&gt;\n  &lt;/row&gt;\n\n  &lt;row&gt;\n    &lt;id&gt;31&lt;/id&gt;\n    &lt;title&gt;chocolate and vodka&lt;/title&gt;\n    &lt;modified&gt;2004-07-21 21:30:08&lt;/modified&gt;\n  &lt;/row&gt;\n\n  &lt;row&gt;\n    &lt;id&gt;183&lt;/id&gt;\n    &lt;title&gt;floating atoll&lt;/title&gt;\n    &lt;modified&gt;2004-07-31 14:09:27&lt;/modified&gt;\n  &lt;/row&gt;\n\n  &lt;row&gt;\n    &lt;id&gt;24&lt;/id&gt;\n    &lt;title&gt;What&#39;s Your Brand Mantra?&lt;/title&gt;\n    &lt;modified&gt;2004-08-02 03:15:03&lt;/modified&gt;\n  &lt;/row&gt;\n&lt;/resultset&gt;    </code></pre>\n<p>Now, while I don&#39;t think that using this for <code>dbagg3</code> is all that great an idea, it&#39;s something I need to remember for future shell and XSLT hacks...</p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221087588\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=365087c6a73a2ee5fa90760c2f9d9ca8&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"\">iamsure</a>\n</div>\n<a href=\"#comment-221087588\" class=\"permalink\"><time datetime=\"2004-08-23T03:47:12\">2004-08-23T03:47:12</time></a>\n</div>\n<div class=\"content\">Is there a way to do so without the commandline option, ie, via a select call, etc?</div>\n</li>\n<li class=\"comment\" id=\"comment-221087591\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=34b6089110a6bfc86b6351ba400ae8fa&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"\">bosshoff</a>\n</div>\n<a href=\"#comment-221087591\" class=\"permalink\"><time datetime=\"2005-04-20T12:22:15\">2005-04-20T12:22:15</time></a>\n</div>\n<div class=\"content\">There is a better way, using mysqldump, explained here: http://insight.zdnet.co.uk/software/developer/0,39020469,2112200,00.htm</div>\n</li>\n<li class=\"comment\" id=\"comment-221087595\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=4c32c5992ac6744d2f14712d280e3834&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"\">Rededog027</a>\n</div>\n<a href=\"#comment-221087595\" class=\"permalink\"><time datetime=\"2007-07-19T23:51:15\">2007-07-19T23:51:15</time></a>\n</div>\n<div class=\"content\"><p>That is awesome I haven't used it before but it is extreamly useful for  creating changelogs from svn and bugzilla :)</p></div>\n</li>\n</ul>\n</div>\n",
    "body": "So...  How many of you have ever used `mysql -X`?\r\n\r\nI just discovered it today, while screwing around with dumping database queries into Atom.  While I'm not entirely sure it's what I need to use, this is pretty nifty:\r\n\r\n    $ mysql -Xp -udbagg3 dbagg3 -e '\r\n    > select id, title, modified \r\n    > from feed\r\n    > order by modified \r\n    > limit 4' \r\n    Enter password:\r\n \r\n    <?xml version=\"1.0\"?>\r\n\r\n    <resultset statement=\"select id, title, modified \r\n            from feed order by modified limit 4\">\r\n      <row>\r\n        <id>527</id>\r\n        <title>Channel Dean</title>\r\n        <modified>2004-03-04 15:56:54</modified>\r\n      </row>\r\n\r\n      <row>\r\n        <id>31</id>\r\n        <title>chocolate and vodka</title>\r\n        <modified>2004-07-21 21:30:08</modified>\r\n      </row>\r\n\r\n      <row>\r\n        <id>183</id>\r\n        <title>floating atoll</title>\r\n        <modified>2004-07-31 14:09:27</modified>\r\n      </row>\r\n \r\n      <row>\r\n        <id>24</id>\r\n        <title>What's Your Brand Mantra?</title>\r\n        <modified>2004-08-02 03:15:03</modified>\r\n      </row>\r\n    </resultset>    \r\n\r\nNow, while I don't think that using this for `dbagg3` is all that great an idea, it's something I need to remember for future shell and XSLT hacks...\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221087588\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=365087c6a73a2ee5fa90760c2f9d9ca8&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"\">iamsure</a>\r\n                </div>\r\n                <a href=\"#comment-221087588\" class=\"permalink\"><time datetime=\"2004-08-23T03:47:12\">2004-08-23T03:47:12</time></a>\r\n            </div>\r\n            <div class=\"content\">Is there a way to do so without the commandline option, ie, via a select call, etc?</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221087591\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=34b6089110a6bfc86b6351ba400ae8fa&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"\">bosshoff</a>\r\n                </div>\r\n                <a href=\"#comment-221087591\" class=\"permalink\"><time datetime=\"2005-04-20T12:22:15\">2005-04-20T12:22:15</time></a>\r\n            </div>\r\n            <div class=\"content\">There is a better way, using mysqldump, explained here: http://insight.zdnet.co.uk/software/developer/0,39020469,2112200,00.htm</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221087595\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=4c32c5992ac6744d2f14712d280e3834&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"\">Rededog027</a>\r\n                </div>\r\n                <a href=\"#comment-221087595\" class=\"permalink\"><time datetime=\"2007-07-19T23:51:15\">2007-07-19T23:51:15</time></a>\r\n            </div>\r\n            <div class=\"content\"><p>That is awesome I haven't used it before but it is extreamly useful for  creating changelogs from svn and bugzilla :)</p></div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2004",
    "path": "2004/08/23/mysql-and-xml-output"
  },
  {
    "comments_archived": true,
    "date": "2004-07-06T21:05:45.000Z",
    "excerpt": "This is the exciting conclusion of the Wish-of-the-Month Club.  Before continuing on, you may want to catch up with parts one and two.",
    "layout": "post",
    "tags": [
      "hacks",
      "xml"
    ],
    "title": "Wish-of-the-Month Club, Part 3 of 3",
    "wordpress_id": 532,
    "wordpress_slug": "wishofthemonthclub3",
    "wordpress_url": "http://www.decafbad.com/blog/?p=532",
    "year": "2004",
    "month": "07",
    "day": "06",
    "isDir": false,
    "slug": "wishofthemonthclub3",
    "postName": "2004-07-06-wishofthemonthclub3",
    "html": "<p><i>This is the exciting conclusion of the Wish-of-the-Month Club.  Before continuing on, you may want to catch up with parts <a href=\"http://www.decafbad.com/blog/2004/06/16/wishofthemonthclub1\">one</a> and <a href=\"http://www.decafbad.com/blog/2004/06/27/wishofthemonthclub2\">two</a>.</i></p>\n<h3 id=\"presenting-the-results\">Presenting the Results</h3>\n<p>Some ready-made files are available for this section:</p>\n<ul>\n<li><a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex5.xsl\"><code>wishes-ex5.xsl</code></a>: The fifth iteration of the stylesheet in development.</li>\n<li><a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.html\"><code>wishes.html</code></a>: Sample output in HTML</li>\n</ul>\n<p>We&#39;ve finally gotten together all the bits of information we need--wishlists have been queried; random items have been selected; and a shopping cart has been prepared.  Now we just have to present the selections and a link to check out with the shopping cart.</p>\n<p>First, locate the following line toward the end of the stylesheet as we left it in the last section:</p>\n<pre><code>    &lt;xsl:copy-of select=&quot;$shopping_cart&quot; /&gt;</code></pre>\n<p>Delete this, and let&#39;s replace it by building some HTML:</p>\n<pre><code>    &lt;xsl:variable name=&quot;shopping_cart_purchase_url&quot; \n                  select=&quot;exsl:node-set($shopping_cart)//PurchaseUrl&quot; /&gt;\n\n    &lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;\n      &lt;head&gt;&lt;title&gt;Wishlist Shopping Cart&lt;/title&gt;\\&lt;/head&gt;\n      &lt;body&gt;\n        &lt;p class=&quot;title&quot;&gt;\n          Here are your wishlist items\n          &lt;a href=&quot;{$shopping_cart_purchase_url}&quot;&gt;\n            &lt;img src=&quot;http://g-images.amazon.com/images/G/01/detail/shoppingcart-header-02.gif&quot; /&gt;\n          &lt;/a&gt; \n          items:\n        &lt;/p&gt;</code></pre>\n<p>We&#39;re using the <code>exsl:note-set</code> function again to access the contents of <code>$shopping_cart</code> with an XPath expression.  We pluck out the value of the <code>PurchaseUrl</code> in the shopping cart and place it in the variable <code>shopping_cart_purchase_url</code>.  Then, after a bit of HTML preamble, we borrow a shopping cart icon from Amazon itself to construct a link to which we can browse later to purchase the selected items.  This HTML is very simple so far; it&#39;s likely too simple, so eventually you may like to toss some CSS in here to improve the looks of things.  But, I&#39;ll leave that as an exercise for the reader.  </p>\n<p>Next, let&#39;s build a display of the items selected by iterating first through the wishlists:</p>\n<pre><code>        &lt;xsl:for-each select=&quot;exsl:node-set($random_products)/wishes:wishitem&quot;&gt;\n          &lt;div class=&quot;Detail&quot;&gt;\n\n            &lt;p class=&quot;wishlistLabel&quot;&gt;\n              &lt;xsl:value-of select=&quot;wishes:wishlist/@label&quot; /&gt;\n            &lt;/p&gt;</code></pre>\n<p>This begins a block for each wishlist, starting off with a paragraph containing the label we gave each wishlist.  Next, let&#39;s include a few details about the product chosen.  Again, all of the bits of data included for each product are described in the AWS documentation in the <em>Overview</em> under <em>Amazon Web Services Data Model</em>.  Checking that out, we can see that the data includes a URL to images of several sizes representing the product.  Let&#39;s include the medium-sized image as a link to the product&#39;s detail page:</p>\n<pre><code>            &lt;p class=&quot;Product&quot;&gt;\n              &lt;a href=&quot;{Details/@url}&quot;&gt;\n                &lt;img src=&quot;{Details/ImageUrlMedium}&quot; /&gt;\n              &lt;/a&gt;\n              &lt;br /&gt;</code></pre>\n<p>We can also include the product&#39;s name as a link:</p>\n<pre><code>              &lt;span class=&quot;ProductName&quot;&gt;\n                &lt;a href=&quot;{Details/@url}&quot;&gt;\n                  &lt;xsl:value-of select=&quot;Details/ProductName&quot; /&gt;\n                &lt;/a&gt;\n              &lt;/span&gt;\n              &lt;br /&gt;</code></pre>\n<p>And, it would be nice to provide a listing of people involved in creating the product (ie. the artists and/or authors):</p>\n<pre><code>          &lt;xsl:for-each select=&quot;./Details/Artists/Artist | \n                                ./Details/Authors/Author&quot;&gt;\n            &lt;span class=&quot;Author&quot;&gt;by &lt;xsl:value-of select=&quot;.&quot; /&gt;&lt;/span&gt;&lt;br /&gt;\n          &lt;/xsl:for-each&gt;</code></pre>\n<p>Note that here, the XPath selecting the data is just a bit more involved, since this information can be found in both <code>Artist</code> and <code>Author</code> elements.  In another case, we might care to make a distinction, but it really isn&#39;t all that important for this project.  The data model also provides an indication of from which catalog this product came, as well as its date of release.  Let&#39;s include that for good measure:</p>\n<pre><code>          (\n          &lt;xsl:value-of select=&quot;Details/Catalog&quot; /&gt; -\n          &lt;span class=&quot;ReleaseDate&quot;&gt;\n            &lt;xsl:value-of select=&quot;Details/ReleaseDate&quot; /&gt;\n          &lt;/span&gt;\n          )\n          &lt;br /&gt;\n        &lt;/p&gt;</code></pre>\n<p>Another thing that would be nice to know is how much this thing costs--we&#39;ve got this information provided in the XML data as well, so let&#39;s include it:</p>\n<pre><code>        &lt;p&gt;\n          &lt;span class=&quot;PriceLabel&quot;&gt;List Price:&lt;/span&gt; \n          &lt;span class=&quot;ListPrice&quot;&gt;\n            &lt;xsl:value-of select=&quot;Details/ListPrice&quot; /&gt;\n          &lt;/span&gt;\n          &lt;br /&gt;\n\n          &lt;span class=&quot;PriceLabel&quot;&gt;Our Price:&lt;/span&gt;\n          &lt;span class=&quot;OurPrice&quot;&gt;\n            &lt;xsl:value-of select=&quot;Details/OurPrice&quot; /&gt;\n          &lt;/span&gt;\n          &lt;br /&gt;\n\n          &lt;span class=&quot;PriceLabel&quot;&gt;Used Price:&lt;/span&gt; \n          &lt;span class=&quot;UsedPrice&quot;&gt;\n            &lt;xsl:value-of select=&quot;Details/UsedPrice&quot; /&gt;\n          &lt;/span&gt;\n          &lt;br /&gt;\n        &lt;/p&gt;</code></pre>\n<p>Something to note about these prices, too, is that although the used price is listed, the shopping cart will contain new items from Amazon&#39;s shelves.  You might want to compare these prices though, and make a change to the shopping cart when you get there, if a used item is acceptable.  (Another good reason for manual intervention in our Wish-of-the-Month club.)</p>\n<p>Oh yeah, and we should include one other bit of information:</p>\n<pre><code>        &lt;p&gt;(&lt;xsl:value-of select=&quot;Details/Availability&quot; /&gt;)&lt;/p&gt;</code></pre>\n<p>This tells us whether or not this item can actually be bought, at present.  Although we used this data earlier to try to filter out unavailable items, we should still display this information just in case we missed something.</p>\n<p>Finally, let&#39;s clean up and finish the HTML:</p>\n<pre><code>      &lt;/div&gt;\n    &lt;/xsl:for-each&gt;\n\n  &lt;/body&gt;\n&lt;/html&gt;</code></pre>\n<p>Running this stylesheet (<a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex5.xsl\">wishes-ex5.xsl</a>) should give you a page that looks something like this in a browser:</p>\n<p><img src=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.jpg\" alt=\"Wishlist HTML screenshot\"></p>\n<h3 id=\"scheduling-monthly-emails\">Scheduling Monthly Emails</h3>\n<p>Some ready-made files are available for this section:</p>\n<ul>\n<li><a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex6.xsl\"><code>wishes-ex6.xsl</code></a>: The sixth (and final) iteration of the stylesheet in development.</li>\n</ul>\n<p>That HTML we&#39;re producing is fine, but what we really want to do is get it delivered to us.  We could set up a scheduled run that would periodically generate a page for us to visit, but the whole point of this is laziness.  How about firing off an email with this content?  There are two things to help us with this: <a href=\"http://www.faqs.org/rfcs/rfc1521.html\" title=\"RFC 1521\">RFC 1521</a> shows us how to construct email messages with a variety of content types; and <a href=\"http://www.hmug.org/man/8/sendmail.html\" title=\"man: sendmail\"><code>sendmail</code></a> will let us send these messages out.  And then, with the help of <code>cron</code>, we can fire up this process every month.</p>\n<p>Along with producing XML, XSLT can also construct plain text output--which is just what we need to create MIME email messages.  <a href=\"http://www.faqs.org/rfcs/rfc1521.html\" title=\"RFC 1521\">RFC 1521</a> doesn&#39;t make for the most thrilling reading, but there are a few articles to be found that summarize things (such as <a href=\"http://www.abiglime.com/webmaster/articles/cgi/010698.htm\" title=\"How to encapsulate HTML in an email message\">this article</a> and <a href=\"http://www.wilsonweb.com/wmt5/html-email-multi.htm\" title=\"Sending HTML and Plain Text E-Mail Simultaneously\">this article</a>).   To make a long story short, a basic shell for an email message using MIME to include an HTML part and a plain text part looks something like this:</p>\n<pre><code>To: someone@example.org\nSubject: Some useful email subject\nMIME-Version: 1.0\nContent-Type: multipart/alternative; boundary=&quot;theBoundaryString&quot;\n\n--theBoundaryString\nContent-Type: text/plain\n\nSome plain text representation goes here...\n\n--theBoundaryString\nContent-Type: text/html\nContent-Transfer-Encoding: 7bit\nContent-Disposition: inline\nContent-Base: &quot;http://www.decafbad.com/&quot;\n\n&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;\n    &lt;p&gt;Some HTML representation goes here...&lt;/p&gt;\n&lt;/html&gt;\n\n--theBoundaryString--</code></pre>\n<p>I&#39;ve snuck in the idea of providing both an HTML version (which we&#39;ve already done) and a new plain text version.  Depending on your email program and your preferences, one type might be more useful than the other.  In any case, it&#39;s not all that hard to offer both here.  To start sending these email messages, though, we&#39;ll need an email address.  So, add that as an element in <a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.xml\">wishes.xml</a>:</p>\n<pre><code>&lt;wishes xmlns=&quot;http://www.decafbad.com/2004/05/wishes&quot;&gt;\n  &lt;email&gt;deus_x@pobox.com&lt;/email&gt;\n  &lt;maxprice&gt;15.00&lt;/maxprice&gt;\n  &lt;associate&gt;0xdecafbad-20&lt;/associate&gt;\n  &lt;devtoken&gt;D8HVH869XA0NP&lt;/devtoken&gt;\n  &lt;wishlists&gt;\n    &lt;wishlist label=&quot;Me&quot;&gt;1QWYI6P2JF3Q5&lt;/wishlist&gt;\n    &lt;wishlist label=&quot;The Girl&quot;&gt;35OIOYWQ9XQAE&lt;/wishlist&gt;\n  &lt;/wishlists&gt;\n&lt;/wishes&gt;</code></pre>\n<p>Let&#39;s extract this data into a global variable near the start of the stylesheet:</p>\n<pre><code>  &lt;xsl:variable name=&quot;email_to&quot;  select=&quot;/wishes:wishes/wishes:email&quot; /&gt;</code></pre>\n<p>Start editing the final template of the stylesheet, inserting before the start of HTML content:</p>\n<pre><code>    &lt;!-- Eat all the line breaks generated so far --&gt;\n    &lt;xsl:text&gt;To: &lt;/xsl:text&gt;&lt;xsl:value-of select=&quot;$email_to&quot; /&gt;   \nSubject: 0xDECAFBAD&#39;s Amazon Wish-of-the-Month Club\nMIME-Version: 1.0\nContent-Type: multipart/alternative; boundary=&quot;theBoundaryString&quot;</code></pre>\n<p>This is the header for the email.  Up until now, we&#39;ve been generating XML with the stylesheet and haven&#39;t cared very much about any extra whitespace or line breaks which might sneak into the output.  However, in an email header, whitespace is important since a blank line is what&#39;s used to separate the headers from the body of the email message.  So, any stray blank lines will cause what we might have meant to be headers to be interpreted as part of the message instead.  Producing the first header in the email with <code>xsl:text</code> tags causes the XSL processor to throw away any leading whitespace which would have appeared before the first header.</p>\n<p>Other than this little twist, the email header looks pretty much like the shell.  We fill in the <code>To</code> address from the global variable <code>$email_to</code> and define a <code>Subject</code> line.  The <code>MIME-Version</code> and <code>Content-Type</code> headers are what enable us to include both text and HTML versions in one email.</p>\n<p>Now we can start into one of the parts:</p>\n<pre><code>--theBoundaryString\nContent-Type: text/plain</code></pre>\n<p>This begins the plain text section of the email, using the <em>boundary string</em> as defined in the headers to delinieate the section&#39;s beginning.  The section can also have its own set of headers, of which we use only one: <code>Content-Type</code>.  Moving along, let&#39;s work on the text content itself.</p>\n<pre><code>Here are your wishlist items:\n\n&lt;xsl:value-of select=&quot;$shopping_cart_purchase_url&quot; /&gt;&lt;xsl:text&gt;\n&lt;/xsl:text&gt;</code></pre>\n<p>No shopping cart image here, but this includes the human-viewable URL which leads to a shopping cart on Amazon.com.  The usage of <code>xsl:text</code> here forces a line break where there otherwise wouldn&#39;t have been one with the usage of <code>xsl:value-of</code>.  Now, let&#39;s iterate through each of the wishlists and list out the product details:</p>\n<pre><code>&lt;xsl:for-each select=&quot;exsl:node-set($random_products)/wishes:wishitem&quot;&gt;\n---------------------------------------------------------------------------\n&lt;xsl:value-of select=&quot;wishes:wishlist/@label&quot; \n       disable-output-escaping=&quot;yes&quot; /&gt;\n---------------------------------------------------------------------------\n\n&lt;xsl:value-of select=&quot;Details/ProductName&quot; \n       disable-output-escaping=&quot;yes&quot; /&gt;\n\n&lt;xsl:for-each select=&quot;./Details/Artists/Artist | \n                      ./Details/Authors/Author&quot;&gt;\nby &lt;xsl:value-of select=&quot;.&quot;  \n   disable-output-escaping=&quot;yes&quot;/&gt;\n&lt;/xsl:for-each&gt;\n\nCatalog:      &lt;xsl:value-of select=&quot;Details/Catalog&quot; \n   disable-output-escaping=&quot;yes&quot; /&gt;\nReleased:     &lt;xsl:value-of select=&quot;Details/ReleaseDate&quot; \n   disable-output-escaping=&quot;yes&quot; /&gt;\n\nList Price:   &lt;xsl:value-of select=&quot;Details/ListPrice&quot;  \n     disable-output-escaping=&quot;yes&quot;/&gt; \nOur  Price:   &lt;xsl:value-of select=&quot;Details/UsedPrice&quot;  \n     disable-output-escaping=&quot;yes&quot;/&gt; \nUsed Price:   &lt;xsl:value-of select=&quot;Details/OurPrice&quot;  \n     disable-output-escaping=&quot;yes&quot;/&gt; \n\nAvailability: &lt;xsl:value-of select=&quot;Details/Availability&quot;  \n       disable-output-escaping=&quot;yes&quot;/&gt;\n&lt;xsl:text&gt;\n\n&lt;/xsl:text&gt;\n&lt;xsl:value-of select=&quot;Details/@url&quot;  \n       disable-output-escaping=&quot;yes&quot;/&gt;\n&lt;xsl:text&gt;\n&lt;/xsl:text&gt;\n\n&lt;/xsl:for-each&gt;</code></pre>\n<p>Most everything in this stretch should look very similar to the HTML version we just finished.  The biggest difference is that every bit of information pulled in using <code>xsl:value-of</code> is done using the <code>disable-output-escaping</code> option.  When this is <code>yes</code>, things like ampersands are no longer escaped for valid XML output.  Since this bit of the email is plain text, we don&#39;t want to see <code>&amp;amp;</code> in album titles, so this will cause ampersands to appear unmolested.</p>\n<p>That&#39;s the plain text version finished.  Now let&#39;s create the HTML version:</p>\n<pre><code>--theBoundaryString\nContent-Type: text/html\nContent-Transfer-Encoding: 7bit\nContent-Disposition: inline\nContent-Base: &quot;http://www.decafbad.com/2004/05/wishes&quot;</code></pre>\n<p>The boundary string appears again, signifying the end of the plain text section and the start of the HTML section.  Headers appear here which specify that what follows is HTML; that it&#39;s encoded in 7-bit characters; that it should be included in the message display itself (rather than presented as an attachment to be saved); and that all relative URLs which might appear in the HTML should be treated as having a base URL as specified.  This last part allows HTML in email to refer to images and other pages on another site without making all the URLs absolute.</p>\n<p>We don&#39;t need to make any modifications to the HTML as we built it in the last iteration of the stylesheet, so we can just include it unchanged:</p>\n<pre><code>&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;\n...\n&lt;/html&gt;\n\n--theBoundaryString--</code></pre>\n<p>This final appearance of the boundary string is bracketed on both sides by dashes, which indicates the end of the final section of the document.  We should be ready to try this in combination with <code>sendmail</code> in a shell:</p>\n<pre><code>$ xsltproc wishes-ex6.xsl wishes.xml | sendmail -it</code></pre>\n<p>If everything has worked correctly, there should be an email arriving in your mailbox sometime soon.  (Or in my inbox, if you followed the directions literally and didn&#39;t supply your own email address.)  The options supplied to <code>sendmail</code> are fairly basic: </p>\n<ul>\n<li><code>-i</code> causes lines consisting solely of <code>.</code> <em>not</em> to be treated as an end-of-input signal.</li>\n<li><code>-t</code> causes <code>sendmail</code> to look in the message headers (ie. <code>To:</code>) for a list of recipients.</li>\n</ul>\n<p>If you don&#39;t happen to have have <code>sendmail</code> available, you might want to look into what local mail programs you have available which can accept the output from the stylesheet.</p>\n<p>Once you have this working, the final task is to schedule its monthly execution with your local <code>cron</code> installation.  If you haven&#39;t played with <code>cron</code> before, there are many resources and tutorials available (<a href=\"http://www.lysator.liu.se/~forsberg/linux/cron.html\" title=\"Doing things periodically - Using CRON\">here&#39;s one</a> and <a href=\"http://www.itworld.com/Comp/2378/swol-0825-unix101/\" title=\"Using cron basics\">here&#39;s another</a>).  You should add something like the following to your user account&#39;s <code>crontab</code>:</p>\n<pre><code>0 0 * 1 *  (cd /your/working/path; xsltproc wishes.xsl wishes.xml | sendmail -it)</code></pre>\n<p>The &quot;<code>0 0 * 1 *</code>&quot; indicates to <code>cron</code> that this set of commands should be run at midnight on the first of every months.  Note also that <code>/your/working/path</code> should be replaced by the path to where you&#39;ve been working during this project.  And finally, I&#39;ve renamed the final iteration of the stylesheet file to simply <code>wishes.xsl</code>.</p>\n<h3 id=\"conclusion\">Conclusion</h3>\n<p>So that&#39;s it--we have an XSL stylesheet which queries Amazon Web Services for products contained in multiple wishlists; selects a random item from each; prepares a shopping cart containing those items; and finally generates an email message containing both plain text and HTML presentations of the shopping cart and selected items.</p>\n<p>Though this implementation serves the purpose I wrote about at the start of this article, there are definitely many areas where this can be improved upon or expanded:</p>\n<ul>\n<li><p>Many people think Amazon is an evil company for their use of patents.  I can&#39;t say that I&#39;m entirely happy with them for this myself, but their AWS offering is just too nice to resist tinkering with.  It might be interesting to investigate other retailers&#39; wishlist offerings, where they exist, and to see how this idea might be made to work with other (or even multiple) retailers.  Even better, come up with your own wishlist system, and a cross-retailer shopping cart.</p>\n</li>\n<li><p>I chose XSLT as the implementation technology because I thought it would be more natural to deal with Amazon&#39;s XML this way.  There are, admittedly, a few awkward parts in the resulting stylesheet however.  Sometimes it&#39;s good to see a project like this through, just to get a sense for where things do go awkward with a technology or my understanding of it.  It could be interesting to transliterate this into a scripting language like Python or Perl, perhaps using the <a href=\"http://xmlsoft.org/python.html\">libxml bindings</a> to do so.</p>\n</li>\n<li><p>The error and failure handling in this implementation are all but non-existent.  Should anything unexpected happen while dealing with Amazon Web Services, the results aren&#39;t likely to be very pretty.  You may want to consider improving in this area.  One instance I identified was to report when the sanity limit was hit in looping through wishlist pages, versus an actual end of pages.</p>\n</li>\n<li><p>If you play around with making more wishlist queries using the techniques here, you might want to consider caching the full set of data pulled in by the multiple-page calls to AWS, in order to prevent hammering Amazon&#39;s servers with repeated requests for the same data, likely unchanged.</p>\n</li>\n<li><p>I still don&#39;t know why <code>exsl:random</code> doesn&#39;t work for me.  Although I thought using a web service for random numbers was intereting, it would be very nice if I didn&#39;t have to use it.</p>\n</li>\n<li><p>The HTML presentation could certainly use some good CSS to make it more attractive.</p>\n</li>\n</ul>\n<p>Feel free to send me any suggestions, criticisms, or complaints related to this article!</p>\n<!--more-->\n<p>shortname=wishofthemonthclub3</p>\n",
    "body": "<i>This is the exciting conclusion of the Wish-of-the-Month Club.  Before continuing on, you may want to catch up with parts [one][part1] and [two][part2].</i>\r\n\r\n### Presenting the Results\r\n\r\nSome ready-made files are available for this section:\r\n* [`wishes-ex5.xsl`][wishes-ex5.xsl]: The fifth iteration of the stylesheet in development.\r\n* [`wishes.html`][wishes.html]: Sample output in HTML\r\n\r\nWe've finally gotten together all the bits of information we need--wishlists have been queried; random items have been selected; and a shopping cart has been prepared.  Now we just have to present the selections and a link to check out with the shopping cart.\r\n\r\nFirst, locate the following line toward the end of the stylesheet as we left it in the last section:\r\n\r\n        <xsl:copy-of select=\"$shopping_cart\" />\r\n\r\nDelete this, and let's replace it by building some HTML:\r\n\r\n        <xsl:variable name=\"shopping_cart_purchase_url\" \r\n                      select=\"exsl:node-set($shopping_cart)//PurchaseUrl\" />\r\n        \r\n        <html xmlns=\"http://www.w3.org/1999/xhtml\">\r\n          <head><title>Wishlist Shopping Cart</title>\\</head>\r\n          <body>\r\n            <p class=\"title\">\r\n              Here are your wishlist items\r\n              <a href=\"{$shopping_cart_purchase_url}\">\r\n                <img src=\"http://g-images.amazon.com/images/G/01/detail/shoppingcart-header-02.gif\" />\r\n              </a> \r\n              items:\r\n            </p>\r\n\r\nWe're using the `exsl:note-set` function again to access the contents of `$shopping_cart` with an XPath expression.  We pluck out the value of the `PurchaseUrl` in the shopping cart and place it in the variable `shopping_cart_purchase_url`.  Then, after a bit of HTML preamble, we borrow a shopping cart icon from Amazon itself to construct a link to which we can browse later to purchase the selected items.  This HTML is very simple so far; it's likely too simple, so eventually you may like to toss some CSS in here to improve the looks of things.  But, I'll leave that as an exercise for the reader.  \r\n\r\nNext, let's build a display of the items selected by iterating first through the wishlists:\r\n        \r\n            <xsl:for-each select=\"exsl:node-set($random_products)/wishes:wishitem\">\r\n              <div class=\"Detail\">\r\n\r\n                <p class=\"wishlistLabel\">\r\n                  <xsl:value-of select=\"wishes:wishlist/@label\" />\r\n                </p>\r\n\r\nThis begins a block for each wishlist, starting off with a paragraph containing the label we gave each wishlist.  Next, let's include a few details about the product chosen.  Again, all of the bits of data included for each product are described in the AWS documentation in the *Overview* under *Amazon Web Services Data Model*.  Checking that out, we can see that the data includes a URL to images of several sizes representing the product.  Let's include the medium-sized image as a link to the product's detail page:\r\n\r\n                <p class=\"Product\">\r\n                  <a href=\"{Details/@url}\">\r\n                    <img src=\"{Details/ImageUrlMedium}\" />\r\n                  </a>\r\n                  <br />\r\n\r\nWe can also include the product's name as a link:\r\n\r\n                  <span class=\"ProductName\">\r\n                    <a href=\"{Details/@url}\">\r\n                      <xsl:value-of select=\"Details/ProductName\" />\r\n                    </a>\r\n                  </span>\r\n                  <br />\r\n\r\nAnd, it would be nice to provide a listing of people involved in creating the product (ie. the artists and/or authors):\r\n\r\n              <xsl:for-each select=\"./Details/Artists/Artist | \r\n                                    ./Details/Authors/Author\">\r\n                <span class=\"Author\">by <xsl:value-of select=\".\" /></span><br />\r\n              </xsl:for-each>\r\n\r\nNote that here, the XPath selecting the data is just a bit more involved, since this information can be found in both `Artist` and `Author` elements.  In another case, we might care to make a distinction, but it really isn't all that important for this project.  The data model also provides an indication of from which catalog this product came, as well as its date of release.  Let's include that for good measure:\r\n              \r\n              (\r\n              <xsl:value-of select=\"Details/Catalog\" /> -\r\n              <span class=\"ReleaseDate\">\r\n                <xsl:value-of select=\"Details/ReleaseDate\" />\r\n              </span>\r\n              )\r\n              <br />\r\n            </p>\r\n\r\nAnother thing that would be nice to know is how much this thing costs--we've got this information provided in the XML data as well, so let's include it:\r\n            \r\n            <p>\r\n              <span class=\"PriceLabel\">List Price:</span> \r\n              <span class=\"ListPrice\">\r\n                <xsl:value-of select=\"Details/ListPrice\" />\r\n              </span>\r\n              <br />\r\n              \r\n              <span class=\"PriceLabel\">Our Price:</span>\r\n              <span class=\"OurPrice\">\r\n                <xsl:value-of select=\"Details/OurPrice\" />\r\n              </span>\r\n              <br />\r\n\r\n              <span class=\"PriceLabel\">Used Price:</span> \r\n              <span class=\"UsedPrice\">\r\n                <xsl:value-of select=\"Details/UsedPrice\" />\r\n              </span>\r\n              <br />\r\n            </p>\r\n\r\nSomething to note about these prices, too, is that although the used price is listed, the shopping cart will contain new items from Amazon's shelves.  You might want to compare these prices though, and make a change to the shopping cart when you get there, if a used item is acceptable.  (Another good reason for manual intervention in our Wish-of-the-Month club.)\r\n\r\nOh yeah, and we should include one other bit of information:\r\n            \r\n            <p>(<xsl:value-of select=\"Details/Availability\" />)</p>\r\n\r\nThis tells us whether or not this item can actually be bought, at present.  Although we used this data earlier to try to filter out unavailable items, we should still display this information just in case we missed something.\r\n\r\nFinally, let's clean up and finish the HTML:\r\n            \r\n          </div>\r\n        </xsl:for-each>\r\n        \r\n      </body>\r\n    </html>\r\n\r\nRunning this stylesheet ([wishes-ex5.xsl][wishes-ex5.xsl]) should give you a page that looks something like this in a browser:\r\n\r\n![Wishlist HTML screenshot][wishes_html_screenshot]\r\n\r\n### Scheduling Monthly Emails\r\n\r\nSome ready-made files are available for this section:\r\n* [`wishes-ex6.xsl`][wishes-ex6.xsl]: The sixth (and final) iteration of the stylesheet in development.\r\n\r\nThat HTML we're producing is fine, but what we really want to do is get it delivered to us.  We could set up a scheduled run that would periodically generate a page for us to visit, but the whole point of this is laziness.  How about firing off an email with this content?  There are two things to help us with this: [RFC 1521][rfc1521] shows us how to construct email messages with a variety of content types; and [`sendmail`][man_sendmail] will let us send these messages out.  And then, with the help of `cron`, we can fire up this process every month.\r\n\r\nAlong with producing XML, XSLT can also construct plain text output--which is just what we need to create MIME email messages.  [RFC 1521][rfc1521] doesn't make for the most thrilling reading, but there are a few articles to be found that summarize things (such as [this article][email_mime_and_html] and [this article][email_html_and_text]).   To make a long story short, a basic shell for an email message using MIME to include an HTML part and a plain text part looks something like this:\r\n\r\n    To: someone@example.org\r\n    Subject: Some useful email subject\r\n    MIME-Version: 1.0\r\n    Content-Type: multipart/alternative; boundary=\"theBoundaryString\"\r\n\r\n    --theBoundaryString\r\n    Content-Type: text/plain\r\n\r\n    Some plain text representation goes here...\r\n\r\n    --theBoundaryString\r\n    Content-Type: text/html\r\n    Content-Transfer-Encoding: 7bit\r\n    Content-Disposition: inline\r\n    Content-Base: \"http://www.decafbad.com/\"\r\n\r\n    <html xmlns=\"http://www.w3.org/1999/xhtml\">\r\n        <p>Some HTML representation goes here...</p>\r\n    </html>\r\n\r\n    --theBoundaryString--\r\n\r\nI've snuck in the idea of providing both an HTML version (which we've already done) and a new plain text version.  Depending on your email program and your preferences, one type might be more useful than the other.  In any case, it's not all that hard to offer both here.  To start sending these email messages, though, we'll need an email address.  So, add that as an element in [wishes.xml][wishes.xml]:\r\n\r\n    <wishes xmlns=\"http://www.decafbad.com/2004/05/wishes\">\r\n      <email>deus_x@pobox.com</email>\r\n      <maxprice>15.00</maxprice>\r\n      <associate>0xdecafbad-20</associate>\r\n      <devtoken>D8HVH869XA0NP</devtoken>\r\n      <wishlists>\r\n        <wishlist label=\"Me\">1QWYI6P2JF3Q5</wishlist>\r\n        <wishlist label=\"The Girl\">35OIOYWQ9XQAE</wishlist>\r\n      </wishlists>\r\n    </wishes>\r\n\r\nLet's extract this data into a global variable near the start of the stylesheet:\r\n\r\n      <xsl:variable name=\"email_to\"  select=\"/wishes:wishes/wishes:email\" />\r\n\r\nStart editing the final template of the stylesheet, inserting before the start of HTML content:\r\n\r\n        <!-- Eat all the line breaks generated so far -->\r\n        <xsl:text>To: </xsl:text><xsl:value-of select=\"$email_to\" />   \r\n    Subject: 0xDECAFBAD's Amazon Wish-of-the-Month Club\r\n    MIME-Version: 1.0\r\n    Content-Type: multipart/alternative; boundary=\"theBoundaryString\"\r\n\r\nThis is the header for the email.  Up until now, we've been generating XML with the stylesheet and haven't cared very much about any extra whitespace or line breaks which might sneak into the output.  However, in an email header, whitespace is important since a blank line is what's used to separate the headers from the body of the email message.  So, any stray blank lines will cause what we might have meant to be headers to be interpreted as part of the message instead.  Producing the first header in the email with `xsl:text` tags causes the XSL processor to throw away any leading whitespace which would have appeared before the first header.\r\n\r\nOther than this little twist, the email header looks pretty much like the shell.  We fill in the `To` address from the global variable `$email_to` and define a `Subject` line.  The `MIME-Version` and `Content-Type` headers are what enable us to include both text and HTML versions in one email.\r\n\r\nNow we can start into one of the parts:\r\n\r\n    --theBoundaryString\r\n    Content-Type: text/plain\r\n\r\nThis begins the plain text section of the email, using the *boundary string* as defined in the headers to delinieate the section's beginning.  The section can also have its own set of headers, of which we use only one: `Content-Type`.  Moving along, let's work on the text content itself.\r\n\r\n    Here are your wishlist items:\r\n\r\n    <xsl:value-of select=\"$shopping_cart_purchase_url\" /><xsl:text>\r\n    </xsl:text>\r\n\r\nNo shopping cart image here, but this includes the human-viewable URL which leads to a shopping cart on Amazon.com.  The usage of `xsl:text` here forces a line break where there otherwise wouldn't have been one with the usage of `xsl:value-of`.  Now, let's iterate through each of the wishlists and list out the product details:\r\n\r\n    <xsl:for-each select=\"exsl:node-set($random_products)/wishes:wishitem\">\r\n    ---------------------------------------------------------------------------\r\n    <xsl:value-of select=\"wishes:wishlist/@label\" \r\n           disable-output-escaping=\"yes\" />\r\n    ---------------------------------------------------------------------------\r\n\r\n    <xsl:value-of select=\"Details/ProductName\" \r\n           disable-output-escaping=\"yes\" />\r\n\r\n    <xsl:for-each select=\"./Details/Artists/Artist | \r\n                          ./Details/Authors/Author\">\r\n    by <xsl:value-of select=\".\"  \r\n       disable-output-escaping=\"yes\"/>\r\n    </xsl:for-each>\r\n\r\n    Catalog:      <xsl:value-of select=\"Details/Catalog\" \r\n       disable-output-escaping=\"yes\" />\r\n    Released:     <xsl:value-of select=\"Details/ReleaseDate\" \r\n       disable-output-escaping=\"yes\" />\r\n\r\n    List Price:   <xsl:value-of select=\"Details/ListPrice\"  \r\n         disable-output-escaping=\"yes\"/> \r\n    Our  Price:   <xsl:value-of select=\"Details/UsedPrice\"  \r\n         disable-output-escaping=\"yes\"/> \r\n    Used Price:   <xsl:value-of select=\"Details/OurPrice\"  \r\n         disable-output-escaping=\"yes\"/> \r\n            \r\n    Availability: <xsl:value-of select=\"Details/Availability\"  \r\n           disable-output-escaping=\"yes\"/>\r\n    <xsl:text>\r\n\r\n    </xsl:text>\r\n    <xsl:value-of select=\"Details/@url\"  \r\n           disable-output-escaping=\"yes\"/>\r\n    <xsl:text>\r\n    </xsl:text>\r\n\r\n    </xsl:for-each>\r\n\r\nMost everything in this stretch should look very similar to the HTML version we just finished.  The biggest difference is that every bit of information pulled in using `xsl:value-of` is done using the `disable-output-escaping` option.  When this is `yes`, things like ampersands are no longer escaped for valid XML output.  Since this bit of the email is plain text, we don't want to see `&amp;` in album titles, so this will cause ampersands to appear unmolested.\r\n\r\nThat's the plain text version finished.  Now let's create the HTML version:\r\n\r\n    --theBoundaryString\r\n    Content-Type: text/html\r\n    Content-Transfer-Encoding: 7bit\r\n    Content-Disposition: inline\r\n    Content-Base: \"http://www.decafbad.com/2004/05/wishes\"\r\n\r\nThe boundary string appears again, signifying the end of the plain text section and the start of the HTML section.  Headers appear here which specify that what follows is HTML; that it's encoded in 7-bit characters; that it should be included in the message display itself (rather than presented as an attachment to be saved); and that all relative URLs which might appear in the HTML should be treated as having a base URL as specified.  This last part allows HTML in email to refer to images and other pages on another site without making all the URLs absolute.\r\n\r\nWe don't need to make any modifications to the HTML as we built it in the last iteration of the stylesheet, so we can just include it unchanged:\r\n\r\n    <html xmlns=\"http://www.w3.org/1999/xhtml\">\r\n    ...\r\n    </html>\r\n\r\n    --theBoundaryString--\r\n    \r\nThis final appearance of the boundary string is bracketed on both sides by dashes, which indicates the end of the final section of the document.  We should be ready to try this in combination with `sendmail` in a shell:\r\n\r\n    $ xsltproc wishes-ex6.xsl wishes.xml | sendmail -it\r\n\r\nIf everything has worked correctly, there should be an email arriving in your mailbox sometime soon.  (Or in my inbox, if you followed the directions literally and didn't supply your own email address.)  The options supplied to `sendmail` are fairly basic: \r\n\r\n* `-i` causes lines consisting solely of `.` *not* to be treated as an end-of-input signal.\r\n* `-t` causes `sendmail` to look in the message headers (ie. `To:`) for a list of recipients.\r\n\r\nIf you don't happen to have have `sendmail` available, you might want to look into what local mail programs you have available which can accept the output from the stylesheet.\r\n\r\nOnce you have this working, the final task is to schedule its monthly execution with your local `cron` installation.  If you haven't played with `cron` before, there are many resources and tutorials available ([here's one][cron1] and [here's another][cron2]).  You should add something like the following to your user account's `crontab`:\r\n\r\n    0 0 * 1 *  (cd /your/working/path; xsltproc wishes.xsl wishes.xml | sendmail -it)\r\n\r\nThe \"`0 0 * 1 *`\" indicates to `cron` that this set of commands should be run at midnight on the first of every months.  Note also that `/your/working/path` should be replaced by the path to where you've been working during this project.  And finally, I've renamed the final iteration of the stylesheet file to simply `wishes.xsl`.\r\n\r\n### Conclusion\r\n\r\nSo that's it--we have an XSL stylesheet which queries Amazon Web Services for products contained in multiple wishlists; selects a random item from each; prepares a shopping cart containing those items; and finally generates an email message containing both plain text and HTML presentations of the shopping cart and selected items.\r\n\r\nThough this implementation serves the purpose I wrote about at the start of this article, there are definitely many areas where this can be improved upon or expanded:\r\n\r\n* Many people think Amazon is an evil company for their use of patents.  I can't say that I'm entirely happy with them for this myself, but their AWS offering is just too nice to resist tinkering with.  It might be interesting to investigate other retailers' wishlist offerings, where they exist, and to see how this idea might be made to work with other (or even multiple) retailers.  Even better, come up with your own wishlist system, and a cross-retailer shopping cart.\r\n\r\n* I chose XSLT as the implementation technology because I thought it would be more natural to deal with Amazon's XML this way.  There are, admittedly, a few awkward parts in the resulting stylesheet however.  Sometimes it's good to see a project like this through, just to get a sense for where things do go awkward with a technology or my understanding of it.  It could be interesting to transliterate this into a scripting language like Python or Perl, perhaps using the [libxml bindings][python_libxml] to do so.\r\n\r\n* The error and failure handling in this implementation are all but non-existent.  Should anything unexpected happen while dealing with Amazon Web Services, the results aren't likely to be very pretty.  You may want to consider improving in this area.  One instance I identified was to report when the sanity limit was hit in looping through wishlist pages, versus an actual end of pages.\r\n\r\n* If you play around with making more wishlist queries using the techniques here, you might want to consider caching the full set of data pulled in by the multiple-page calls to AWS, in order to prevent hammering Amazon's servers with repeated requests for the same data, likely unchanged.\r\n\r\n* I still don't know why `exsl:random` doesn't work for me.  Although I thought using a web service for random numbers was intereting, it would be very nice if I didn't have to use it.\r\n\r\n* The HTML presentation could certainly use some good CSS to make it more attractive.\r\n\r\nFeel free to send me any suggestions, criticisms, or complaints related to this article!\r\n\r\n[missadroit]: http://missadroit.livejournal.com \"Miss Adroit, my favorite girl in the world\"\r\n[mywishlist]: http://www.amazon.com/exec/obidos/registry/1QWYI6P2JF3Q5 \"Buy me something, will ya?\"\r\n[herwishlist]: http://www.amazon.com/exec/obidos/registry/35OIOYWQ9XQAE \"Buy her something, will ya?\"\r\n[amazonapi]: http://www.amazon.com/gp/aws/landing.html \"Amazon Web Services\"\r\n[libxml]: http://www.xmlsoft.org/\r\n[xalan]: http://xml.apache.org/xalan-j/\r\n[sablotron]: http://www.gingerall.com/charlie/ga/xml/p_sab.xml\r\n[saxon]: http://saxon.sourceforge.net/\r\n[exslt]: http://www.exslt.org/\r\n[libxslt]: http://www.xmlsoft.org/XSLT.html\r\n[spideringhacks]: http://www.amazon.com/exec/obidos/ASIN/0596005776/0xdecafbad-20 \"O'Reilly's Spidering Hacks\"\r\n[xslscraper]: http://www.decafbad.com/twiki/bin/view/Main/XslScraper \"Scrape RSS and Atom from HTML using Tidy and XSLT\"\r\n[awsdownload]: http://www.amazon.com/gp/browse.html/ref=sc_fe_c_2/002-7899886-3676027?%5Fencoding=UTF8&#38;node=3434641&#38;no=3435361&#38;me=A36L942TSJ2AJA\r\n[awstoken]: https://associates.amazon.com/exec/panama/associates/join/developer/application.html\r\n[amazonassociate]: http://associates.amazon.com\r\n[wlsearch]: http://www.amazon.com/gp/registry/search.html/002-7899886-3676027?%5Fencoding=UTF8&#38;type=wishlist\r\n[wlurl]: http://xml.amazon.com/onca/xml3?t=0xdecafbad-20&#38;dev-t=D8HVH869XA0NP&#38;type=lite&#38;WishlistSearch=35OIOYWQ9XQAE&#38;f=xml\r\n[detailsurl]: http://www.amazon.com/exec/obidos/ASIN/0262133601/0xdecafbad-20?dev-t=D8HVH869XA0NP%26camp=2025%26link_code=xm2\r\n[awslite]: http://xml.amazon.com/schemas3/dev-lite.xsd\r\n[fink]: http://fink.sourceforge.net\r\n[testxslt]: http://www.entropy.ch:16080/software/macosx/#testxslt\r\n[darwinports]: http://darwinports.opendarwin.org/\r\n[curl]: http://www.decafbad.com/#TODO\r\n[wget]: http://www.decafbad.com/#TODO\r\n[xpconcat]: http://www.w3.org/TR/2002/WD-xquery-operators-20020816/#func-concat\r\n[xpdocument]: http://www.w3.org/TR/2002/WD-xquery-operators-20020816/#func-document\r\n[wishescvs]: http://www.decafbad.com/cvs/hacks/wishes/\r\n[wishes.tar.gz]: http://www.decafbad.com/cvs/hacks/wishes/wishes.tar.gz?tarball=1 \"All Wish-of-the-Month Club files wrapped up in a tarball\"\r\n[wishes.xml]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.xml\r\n[wishes.html]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.html\r\n[wishes-ex1.xsl]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex1.xsl\r\n[wishes-ex2.xsl]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex2.xsl\r\n[wishes-ex3.xsl]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex3.xsl\r\n[wishes-ex4.xsl]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex4.xsl\r\n[wishes-ex5.xsl]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex5.xsl\r\n[wishes-ex6.xsl]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex6.xsl\r\n[random-xml]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/random-xml\r\n[wishes_html_screenshot]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.jpg\r\n[xslt_iteration]: http://www.dpawson.co.uk/xsl/sect2/N4806.html \"Iteration in XSLT\"\r\n[xslt_recursion]: http://www-106.ibm.com/developerworks/xml/library/x-xslrecur/ \"Use recursion effectively in XSL\"\r\n[exsl_random]: http://www.exslt.org/math/functions/random/index.html\r\n[exsl_node_set]: http://www.exslt.org/exsl/functions/node-set/index.html\r\n[rand_url]: http://www.decafbad.com/2004/05/random-xml?int=1&#38;min=10&#38;max=20 \"A random integer between 10 and 20, in XML\"\r\n[xslt_result_tree_fragment]: http://www.w3.org/TR/xslt#section-Result-Tree-Fragments\r\n\r\n[email_attach_anatomy]: http://www.dpo.uab.edu/Email/attach.html \"Anatomy of an Email Attachment\"\r\n[email_mime_and_html]: http://www.abiglime.com/webmaster/articles/cgi/010698.htm \"How to encapsulate HTML in an email message\"\r\n\r\n[email_html_and_text]: http://www.wilsonweb.com/wmt5/html-email-multi.htm \"Sending HTML and Plain Text E-Mail Simultaneously\"\r\n[man_sendmail]: http://www.hmug.org/man/8/sendmail.html \"man: sendmail\"\r\n[rfc1521]: http://www.faqs.org/rfcs/rfc1521.html \"RFC 1521\"\r\n[cron1]: http://www.lysator.liu.se/~forsberg/linux/cron.html \"Doing things periodically - Using CRON\"\r\n[cron2]: http://www.itworld.com/Comp/2378/swol-0825-unix101/ \"Using cron basics\"\r\n[python_libxml]: http://xmlsoft.org/python.html \r\n[part2]: http://www.decafbad.com/blog/2004/06/27/wishofthemonthclub2\r\n[part1]: http://www.decafbad.com/blog/2004/06/16/wishofthemonthclub1\r\n<!--more-->\r\nshortname=wishofthemonthclub3\r\n",
    "parentPath": "../blog.lmorchard.com/posts/archives/2004",
    "path": "2004/07/06/wishofthemonthclub3",
    "thumbnail": "http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.jpg",
    "summary": "<p><i>This is the exciting conclusion of the Wish-of-the-Month Club.  Before continuing on, you may want to catch up with parts <a href=\"http://www.decafbad.com/blog/2004/06/16/wishofthemonthclub1\">one</a> and <a href=\"http://www.decafbad.com/blog/2004/06/27/wishofthemonthclub2\">two</a>.</i></p>\n<h3 id=\"presenting-the-results\">Presenting the Results</h3>\n<p>Some ready-made files are available for this section:</p>\n<ul>\n<li><a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex5.xsl\"><code>wishes-ex5.xsl</code></a>: The fifth iteration of the stylesheet in development.</li>\n<li><a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.html\"><code>wishes.html</code></a>: Sample output in HTML</li>\n</ul>\n<p>We&apos;ve finally gotten together all the bits of information we need--wishlists have been queried; random items have been selected; and a shopping cart has been prepared.  Now we just have to present the selections and a link to check out with the shopping cart.</p>\n<p>First, locate the following line toward the end of the stylesheet as we left it in the last section:</p>\n<pre><code>    &lt;xsl:copy-of select=&quot;$shopping_cart&quot; /&gt;</code></pre>\n<p>Delete this, and let&apos;s replace it by building some HTML:</p>\n<pre><code>    &lt;xsl:variable name=&quot;shopping_cart_purchase_url&quot; \n                  select=&quot;exsl:node-set($shopping_cart)//PurchaseUrl&quot; /&gt;\n\n    &lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;\n      &lt;head&gt;&lt;title&gt;Wishlist Shopping Cart&lt;/title&gt;\\&lt;/head&gt;\n      &lt;body&gt;\n        &lt;p class=&quot;title&quot;&gt;\n          Here are your wishlist items\n          &lt;a href=&quot;{$shopping_cart_purchase_url}&quot;&gt;\n            &lt;img src=&quot;http://g-images.amazon.com/images/G/01/detail/shoppingcart-header-02.gif&quot; /&gt;\n          &lt;/a&gt; \n          items:\n        &lt;/p&gt;</code></pre>\n<p>We&apos;re using the <code>exsl:note-set</code> function again to access the contents of <code>$shopping_cart</code> with an XPath expression.  We pluck out the value of the <code>PurchaseUrl</code> in the shopping cart and place it in the variable <code>shopping_cart_purchase_url</code>.  Then, after a bit of HTML preamble, we borrow a shopping cart icon from Amazon itself to construct a link to which we can browse later to purchase the selected items.  This HTML is very simple so far; it&apos;s likely too simple, so eventually you may like to toss some CSS in here to improve the looks of things.  But, I&apos;ll leave that as an exercise for the reader.  </p>\n<p>Next, let&apos;s build a display of the items selected by iterating first through the wishlists:</p>\n<pre><code>        &lt;xsl:for-each select=&quot;exsl:node-set($random_products)/wishes:wishitem&quot;&gt;\n          &lt;div class=&quot;Detail&quot;&gt;\n\n            &lt;p class=&quot;wishlistLabel&quot;&gt;\n              &lt;xsl:value-of select=&quot;wishes:wishlist/@label&quot; /&gt;\n            &lt;/p&gt;</code></pre>\n<p>This begins a block for each wishlist, starting off with a paragraph containing the label we gave each wishlist.  Next, let&apos;s include a few details about the product chosen.  Again, all of the bits of data included for each product are described in the AWS documentation in the <em>Overview</em> under <em>Amazon Web Services Data Model</em>.  Checking that out, we can see that the data includes a URL to images of several sizes representing the product.  Let&apos;s include the medium-sized image as a link to the product&apos;s detail page:</p>\n<pre><code>            &lt;p class=&quot;Product&quot;&gt;\n              &lt;a href=&quot;{Details/@url}&quot;&gt;\n                &lt;img src=&quot;{Details/ImageUrlMedium}&quot; /&gt;\n              &lt;/a&gt;\n              &lt;br /&gt;</code></pre>\n<p>We can also include the product&apos;s name as a link:</p>\n<pre><code>              &lt;span class=&quot;ProductName&quot;&gt;\n                &lt;a href=&quot;{Details/@url}&quot;&gt;\n                  &lt;xsl:value-of select=&quot;Details/ProductName&quot; /&gt;\n                &lt;/a&gt;\n              &lt;/span&gt;\n              &lt;br /&gt;</code></pre>\n<p>And, it would be nice to provide a listing of people involved in creating the product (ie. the artists and/or authors):</p>\n<pre><code>          &lt;xsl:for-each select=&quot;./Details/Artists/Artist | \n                                ./Details/Authors/Author&quot;&gt;\n            &lt;span class=&quot;Author&quot;&gt;by &lt;xsl:value-of select=&quot;.&quot; /&gt;&lt;/span&gt;&lt;br /&gt;\n          &lt;/xsl:for-each&gt;</code></pre>\n<p>Note that here, the XPath selecting the data is just a bit more involved, since this information can be found in both <code>Artist</code> and <code>Author</code> elements.  In another case, we might care to make a distinction, but it really isn&apos;t all that important for this project.  The data model also provides an indication of from which catalog this product came, as well as its date of release.  Let&apos;s include that for good measure:</p>\n<pre><code>          (\n          &lt;xsl:value-of select=&quot;Details/Catalog&quot; /&gt; -\n          &lt;span class=&quot;ReleaseDate&quot;&gt;\n            &lt;xsl:value-of select=&quot;Details/ReleaseDate&quot; /&gt;\n          &lt;/span&gt;\n          )\n          &lt;br /&gt;\n        &lt;/p&gt;</code></pre>\n<p>Another thing that would be nice to know is how much this thing costs--we&apos;ve got this information provided in the XML data as well, so let&apos;s include it:</p>\n<pre><code>        &lt;p&gt;\n          &lt;span class=&quot;PriceLabel&quot;&gt;List Price:&lt;/span&gt; \n          &lt;span class=&quot;ListPrice&quot;&gt;\n            &lt;xsl:value-of select=&quot;Details/ListPrice&quot; /&gt;\n          &lt;/span&gt;\n          &lt;br /&gt;\n\n          &lt;span class=&quot;PriceLabel&quot;&gt;Our Price:&lt;/span&gt;\n          &lt;span class=&quot;OurPrice&quot;&gt;\n            &lt;xsl:value-of select=&quot;Details/OurPrice&quot; /&gt;\n          &lt;/span&gt;\n          &lt;br /&gt;\n\n          &lt;span class=&quot;PriceLabel&quot;&gt;Used Price:&lt;/span&gt; \n          &lt;span class=&quot;UsedPrice&quot;&gt;\n            &lt;xsl:value-of select=&quot;Details/UsedPrice&quot; /&gt;\n          &lt;/span&gt;\n          &lt;br /&gt;\n        &lt;/p&gt;</code></pre>\n<p>Something to note about these prices, too, is that although the used price is listed, the shopping cart will contain new items from Amazon&apos;s shelves.  You might want to compare these prices though, and make a change to the shopping cart when you get there, if a used item is acceptable.  (Another good reason for manual intervention in our Wish-of-the-Month club.)</p>\n<p>Oh yeah, and we should include one other bit of information:</p>\n<pre><code>        &lt;p&gt;(&lt;xsl:value-of select=&quot;Details/Availability&quot; /&gt;)&lt;/p&gt;</code></pre>\n<p>This tells us whether or not this item can actually be bought, at present.  Although we used this data earlier to try to filter out unavailable items, we should still display this information just in case we missed something.</p>\n<p>Finally, let&apos;s clean up and finish the HTML:</p>\n<pre><code>      &lt;/div&gt;\n    &lt;/xsl:for-each&gt;\n\n  &lt;/body&gt;\n&lt;/html&gt;</code></pre>\n<p>Running this stylesheet (<a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex5.xsl\">wishes-ex5.xsl</a>) should give you a page that looks something like this in a browser:</p>\n<p><img src=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.jpg\" alt=\"Wishlist HTML screenshot\"></p>\n<h3 id=\"scheduling-monthly-emails\">Scheduling Monthly Emails</h3>\n<p>Some ready-made files are available for this section:</p>\n<ul>\n<li><a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex6.xsl\"><code>wishes-ex6.xsl</code></a>: The sixth (and final) iteration of the stylesheet in development.</li>\n</ul>\n<p>That HTML we&apos;re producing is fine, but what we really want to do is get it delivered to us.  We could set up a scheduled run that would periodically generate a page for us to visit, but the whole point of this is laziness.  How about firing off an email with this content?  There are two things to help us with this: <a href=\"http://www.faqs.org/rfcs/rfc1521.html\" title=\"RFC 1521\">RFC 1521</a> shows us how to construct email messages with a variety of content types; and <a href=\"http://www.hmug.org/man/8/sendmail.html\" title=\"man: sendmail\"><code>sendmail</code></a> will let us send these messages out.  And then, with the help of <code>cron</code>, we can fire up this process every month.</p>\n<p>Along with producing XML, XSLT can also construct plain text output--which is just what we need to create MIME email messages.  <a href=\"http://www.faqs.org/rfcs/rfc1521.html\" title=\"RFC 1521\">RFC 1521</a> doesn&apos;t make for the most thrilling reading, but there are a few articles to be found that summarize things (such as <a href=\"http://www.abiglime.com/webmaster/articles/cgi/010698.htm\" title=\"How to encapsulate HTML in an email message\">this article</a> and <a href=\"http://www.wilsonweb.com/wmt5/html-email-multi.htm\" title=\"Sending HTML and Plain Text E-Mail Simultaneously\">this article</a>).   To make a long story short, a basic shell for an email message using MIME to include an HTML part and a plain text part looks something like this:</p>\n<pre><code>To: someone@example.org\nSubject: Some useful email subject\nMIME-Version: 1.0\nContent-Type: multipart/alternative; boundary=&quot;theBoundaryString&quot;\n\n--theBoundaryString\nContent-Type: text/plain\n\nSome plain text representation goes here...\n\n--theBoundaryString\nContent-Type: text/html\nContent-Transfer-Encoding: 7bit\nContent-Disposition: inline\nContent-Base: &quot;http://www.decafbad.com/&quot;\n\n&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;\n    &lt;p&gt;Some HTML representation goes here...&lt;/p&gt;\n&lt;/html&gt;\n\n--theBoundaryString--</code></pre>\n<p>I&apos;ve snuck in the idea of providing both an HTML version (which we&apos;ve already done) and a new plain text version.  Depending on your email program and your preferences, one type might be more useful than the other.  In any case, it&apos;s not all that hard to offer both here.  To start sending these email messages, though, we&apos;ll need an email address.  So, add that as an element in <a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.xml\">wishes.xml</a>:</p>\n<pre><code>&lt;wishes xmlns=&quot;http://www.decafbad.com/2004/05/wishes&quot;&gt;\n  &lt;email&gt;deus_x@pobox.com&lt;/email&gt;\n  &lt;maxprice&gt;15.00&lt;/maxprice&gt;\n  &lt;associate&gt;0xdecafbad-20&lt;/associate&gt;\n  &lt;devtoken&gt;D8HVH869XA0NP&lt;/devtoken&gt;\n  &lt;wishlists&gt;\n    &lt;wishlist label=&quot;Me&quot;&gt;1QWYI6P2JF3Q5&lt;/wishlist&gt;\n    &lt;wishlist label=&quot;The Girl&quot;&gt;35OIOYWQ9XQAE&lt;/wishlist&gt;\n  &lt;/wishlists&gt;\n&lt;/wishes&gt;</code></pre>\n<p>Let&apos;s extract this data into a global variable near the start of the stylesheet:</p>\n<pre><code>  &lt;xsl:variable name=&quot;email_to&quot;  select=&quot;/wishes:wishes/wishes:email&quot; /&gt;</code></pre>\n<p>Start editing the final template of the stylesheet, inserting before the start of HTML content:</p>\n<pre><code>    &lt;!-- Eat all the line breaks generated so far --&gt;\n    &lt;xsl:text&gt;To: &lt;/xsl:text&gt;&lt;xsl:value-of select=&quot;$email_to&quot; /&gt;   \nSubject: 0xDECAFBAD&apos;s Amazon Wish-of-the-Month Club\nMIME-Version: 1.0\nContent-Type: multipart/alternative; boundary=&quot;theBoundaryString&quot;</code></pre>\n<p>This is the header for the email.  Up until now, we&apos;ve been generating XML with the stylesheet and haven&apos;t cared very much about any extra whitespace or line breaks which might sneak into the output.  However, in an email header, whitespace is important since a blank line is what&apos;s used to separate the headers from the body of the email message.  So, any stray blank lines will cause what we might have meant to be headers to be interpreted as part of the message instead.  Producing the first header in the email with <code>xsl:text</code> tags causes the XSL processor to throw away any leading whitespace which would have appeared before the first header.</p>\n<p>Other than this little twist, the email header looks pretty much like the shell.  We fill in the <code>To</code> address from the global variable <code>$email_to</code> and define a <code>Subject</code> line.  The <code>MIME-Version</code> and <code>Content-Type</code> headers are what enable us to include both text and HTML versions in one email.</p>\n<p>Now we can start into one of the parts:</p>\n<pre><code>--theBoundaryString\nContent-Type: text/plain</code></pre>\n<p>This begins the plain text section of the email, using the <em>boundary string</em> as defined in the headers to delinieate the section&apos;s beginning.  The section can also have its own set of headers, of which we use only one: <code>Content-Type</code>.  Moving along, let&apos;s work on the text content itself.</p>\n<pre><code>Here are your wishlist items:\n\n&lt;xsl:value-of select=&quot;$shopping_cart_purchase_url&quot; /&gt;&lt;xsl:text&gt;\n&lt;/xsl:text&gt;</code></pre>\n<p>No shopping cart image here, but this includes the human-viewable URL which leads to a shopping cart on Amazon.com.  The usage of <code>xsl:text</code> here forces a line break where there otherwise wouldn&apos;t have been one with the usage of <code>xsl:value-of</code>.  Now, let&apos;s iterate through each of the wishlists and list out the product details:</p>\n<pre><code>&lt;xsl:for-each select=&quot;exsl:node-set($random_products)/wishes:wishitem&quot;&gt;\n---------------------------------------------------------------------------\n&lt;xsl:value-of select=&quot;wishes:wishlist/@label&quot; \n       disable-output-escaping=&quot;yes&quot; /&gt;\n---------------------------------------------------------------------------\n\n&lt;xsl:value-of select=&quot;Details/ProductName&quot; \n       disable-output-escaping=&quot;yes&quot; /&gt;\n\n&lt;xsl:for-each select=&quot;./Details/Artists/Artist | \n                      ./Details/Authors/Author&quot;&gt;\nby &lt;xsl:value-of select=&quot;.&quot;  \n   disable-output-escaping=&quot;yes&quot;/&gt;\n&lt;/xsl:for-each&gt;\n\nCatalog:      &lt;xsl:value-of select=&quot;Details/Catalog&quot; \n   disable-output-escaping=&quot;yes&quot; /&gt;\nReleased:     &lt;xsl:value-of select=&quot;Details/ReleaseDate&quot; \n   disable-output-escaping=&quot;yes&quot; /&gt;\n\nList Price:   &lt;xsl:value-of select=&quot;Details/ListPrice&quot;  \n     disable-output-escaping=&quot;yes&quot;/&gt; \nOur  Price:   &lt;xsl:value-of select=&quot;Details/UsedPrice&quot;  \n     disable-output-escaping=&quot;yes&quot;/&gt; \nUsed Price:   &lt;xsl:value-of select=&quot;Details/OurPrice&quot;  \n     disable-output-escaping=&quot;yes&quot;/&gt; \n\nAvailability: &lt;xsl:value-of select=&quot;Details/Availability&quot;  \n       disable-output-escaping=&quot;yes&quot;/&gt;\n&lt;xsl:text&gt;\n\n&lt;/xsl:text&gt;\n&lt;xsl:value-of select=&quot;Details/@url&quot;  \n       disable-output-escaping=&quot;yes&quot;/&gt;\n&lt;xsl:text&gt;\n&lt;/xsl:text&gt;\n\n&lt;/xsl:for-each&gt;</code></pre>\n<p>Most everything in this stretch should look very similar to the HTML version we just finished.  The biggest difference is that every bit of information pulled in using <code>xsl:value-of</code> is done using the <code>disable-output-escaping</code> option.  When this is <code>yes</code>, things like ampersands are no longer escaped for valid XML output.  Since this bit of the email is plain text, we don&apos;t want to see <code>&amp;amp;</code> in album titles, so this will cause ampersands to appear unmolested.</p>\n<p>That&apos;s the plain text version finished.  Now let&apos;s create the HTML version:</p>\n<pre><code>--theBoundaryString\nContent-Type: text/html\nContent-Transfer-Encoding: 7bit\nContent-Disposition: inline\nContent-Base: &quot;http://www.decafbad.com/2004/05/wishes&quot;</code></pre>\n<p>The boundary string appears again, signifying the end of the plain text section and the start of the HTML section.  Headers appear here which specify that what follows is HTML; that it&apos;s encoded in 7-bit characters; that it should be included in the message display itself (rather than presented as an attachment to be saved); and that all relative URLs which might appear in the HTML should be treated as having a base URL as specified.  This last part allows HTML in email to refer to images and other pages on another site without making all the URLs absolute.</p>\n<p>We don&apos;t need to make any modifications to the HTML as we built it in the last iteration of the stylesheet, so we can just include it unchanged:</p>\n<pre><code>&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;\n...\n&lt;/html&gt;\n\n--theBoundaryString--</code></pre>\n<p>This final appearance of the boundary string is bracketed on both sides by dashes, which indicates the end of the final section of the document.  We should be ready to try this in combination with <code>sendmail</code> in a shell:</p>\n<pre><code>$ xsltproc wishes-ex6.xsl wishes.xml | sendmail -it</code></pre>\n<p>If everything has worked correctly, there should be an email arriving in your mailbox sometime soon.  (Or in my inbox, if you followed the directions literally and didn&apos;t supply your own email address.)  The options supplied to <code>sendmail</code> are fairly basic: </p>\n<ul>\n<li><code>-i</code> causes lines consisting solely of <code>.</code> <em>not</em> to be treated as an end-of-input signal.</li>\n<li><code>-t</code> causes <code>sendmail</code> to look in the message headers (ie. <code>To:</code>) for a list of recipients.</li>\n</ul>\n<p>If you don&apos;t happen to have have <code>sendmail</code> available, you might want to look into what local mail programs you have available which can accept the output from the stylesheet.</p>\n<p>Once you have this working, the final task is to schedule its monthly execution with your local <code>cron</code> installation.  If you haven&apos;t played with <code>cron</code> before, there are many resources and tutorials available (<a href=\"http://www.lysator.liu.se/~forsberg/linux/cron.html\" title=\"Doing things periodically - Using CRON\">here&apos;s one</a> and <a href=\"http://www.itworld.com/Comp/2378/swol-0825-unix101/\" title=\"Using cron basics\">here&apos;s another</a>).  You should add something like the following to your user account&apos;s <code>crontab</code>:</p>\n<pre><code>0 0 * 1 *  (cd /your/working/path; xsltproc wishes.xsl wishes.xml | sendmail -it)</code></pre>\n<p>The &quot;<code>0 0 * 1 *</code>&quot; indicates to <code>cron</code> that this set of commands should be run at midnight on the first of every months.  Note also that <code>/your/working/path</code> should be replaced by the path to where you&apos;ve been working during this project.  And finally, I&apos;ve renamed the final iteration of the stylesheet file to simply <code>wishes.xsl</code>.</p>\n<h3 id=\"conclusion\">Conclusion</h3>\n<p>So that&apos;s it--we have an XSL stylesheet which queries Amazon Web Services for products contained in multiple wishlists; selects a random item from each; prepares a shopping cart containing those items; and finally generates an email message containing both plain text and HTML presentations of the shopping cart and selected items.</p>\n<p>Though this implementation serves the purpose I wrote about at the start of this article, there are definitely many areas where this can be improved upon or expanded:</p>\n<ul>\n<li><p>Many people think Amazon is an evil company for their use of patents.  I can&apos;t say that I&apos;m entirely happy with them for this myself, but their AWS offering is just too nice to resist tinkering with.  It might be interesting to investigate other retailers&apos; wishlist offerings, where they exist, and to see how this idea might be made to work with other (or even multiple) retailers.  Even better, come up with your own wishlist system, and a cross-retailer shopping cart.</p>\n</li>\n<li><p>I chose XSLT as the implementation technology because I thought it would be more natural to deal with Amazon&apos;s XML this way.  There are, admittedly, a few awkward parts in the resulting stylesheet however.  Sometimes it&apos;s good to see a project like this through, just to get a sense for where things do go awkward with a technology or my understanding of it.  It could be interesting to transliterate this into a scripting language like Python or Perl, perhaps using the <a href=\"http://xmlsoft.org/python.html\">libxml bindings</a> to do so.</p>\n</li>\n<li><p>The error and failure handling in this implementation are all but non-existent.  Should anything unexpected happen while dealing with Amazon Web Services, the results aren&apos;t likely to be very pretty.  You may want to consider improving in this area.  One instance I identified was to report when the sanity limit was hit in looping through wishlist pages, versus an actual end of pages.</p>\n</li>\n<li><p>If you play around with making more wishlist queries using the techniques here, you might want to consider caching the full set of data pulled in by the multiple-page calls to AWS, in order to prevent hammering Amazon&apos;s servers with repeated requests for the same data, likely unchanged.</p>\n</li>\n<li><p>I still don&apos;t know why <code>exsl:random</code> doesn&apos;t work for me.  Although I thought using a web service for random numbers was intereting, it would be very nice if I didn&apos;t have to use it.</p>\n</li>\n<li><p>The HTML presentation could certainly use some good CSS to make it more attractive.</p>\n</li>\n</ul>\n<p>Feel free to send me any suggestions, criticisms, or complaints related to this article!</p>\n"
  },
  {
    "comments_archived": true,
    "date": "2004-06-28T01:44:51.000Z",
    "excerpt": "Here's the next installment of the Wish-of-the-Month Club.  You can revisit the first part, too, if you've missed it.  I'd meant to post it within a week of the first part, so apologies all around to anyone who has been tapping a foot waiting for it.  Enjoy!",
    "layout": "post",
    "tags": [
      "hacks",
      "xml"
    ],
    "title": "Wish-of-the-Month Club, Part 2 of 3",
    "wordpress_id": 530,
    "wordpress_slug": "wishofthemonthclub2",
    "wordpress_url": "http://www.decafbad.com/blog/?p=530",
    "year": "2004",
    "month": "06",
    "day": "27",
    "isDir": false,
    "slug": "wishofthemonthclub2",
    "postName": "2004-06-27-wishofthemonthclub2",
    "html": "<p><i>Here&#39;s the next installment of the Wish-of-the-Month Club.  You can <a href=\"http://www.decafbad.com/blog/2004/06/16/wishofthemonthclub1\">revisit the first part</a>, too, if you&#39;ve missed it.  I&#39;d meant to post it within a week of the first part, so apologies all around to anyone who has been tapping a foot waiting for it.  Enjoy!</i></p>\n<h3 id=\"paging-through-wishes\">Paging Through Wishes</h3>\n<p>Some ready-made files are available for this section:</p>\n<ul>\n<li><a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex2.xsl\"><code>wishes-ex2.xsl</code></a>: The second iteration of the stylesheet in development.</li>\n</ul>\n<p>Now we&#39;ve got a way to make queries against Amazon Web Services, not entirely unlike what you might be used to if you tinker with MySQL databases on a regular basis.  At this point, though, we still have a bit of refining to make to this query.  If you take a look at the data produced by the query in its current state, and compare that to what you see on wishlists in your browser, you should notice some things missing.</p>\n<p>If you look at <a href=\"http://www.amazon.com/exec/obidos/registry/1QWYI6P2JF3Q5\" title=\"Buy me something, will ya?\">my wishlist</a>, you&#39;ll notice that items span several pages when visited by browser.  As it turns out, AWS queries work in a similar fashion--each query returns only a limited number of items (about 10), and an additional parameter supplied to further queries is required to step through further pages of results.  So, using what we&#39;ve built so far will only get us to the first page of wishlist items; to get all of the items, we&#39;ll need a way to step through all of the pages.</p>\n<p>In playing with this, I experienced a bit of hairpulling frustration:  The AWS documentation, under &quot;Generating Additional Product Results&quot;, claims that XML returned by the service will supply a count of the total pages available for a given query.  And although I see this element present in other types of searches, the <code>TotalPages</code> element is absent when querying on wishlists.  This may be a bug, or it may be an undocumented change in the service--either way, it was a surprise and leaves me with no official way to know how many pages I need to ask for in order to have a complete set of data.  </p>\n<p>With some further tinkering, though, I figured out a workaround: If a query is made for a page number beyond the final page, the XML returned will be a duplicate of the final page.  Once I see a duplicate item appear, I know it&#39;s time to stop paging through results.  This is completely undocumented behavior, and could break at any time (ie. if Amazon decided to start issuing an error for a page index out of bounds), but it&#39;ll work for now.</p>\n<p>This calls for reworking the <code>processWishlist</code> template.  For a given wishlist, it will need to iterate through a sequence of page numbers, requesting XML from AWS for each, stopping when the first duplicate page is found.  Since XSLT is heavily steeped in functional programming concepts, this sort of <a href=\"http://www.dpawson.co.uk/xsl/sect2/N4806.html\" title=\"Iteration in XSLT\">iteration in XSLT</a> is best done <a href=\"http://www-106.ibm.com/developerworks/xml/library/x-xslrecur/\" title=\"Use recursion effectively in XSL\">with recursion</a>:</p>\n<pre><code>  &lt;xsl:template name=&quot;processWishlist&quot;&gt;\n\n    &lt;xsl:param name=&quot;wishlist&quot; /&gt;              &lt;!-- Wishlist ID --&gt;\n    &lt;xsl:param name=&quot;max&quot;   select=&quot;50&quot; /&gt;     &lt;!-- Arbitrary upper loop limit --&gt;\n    &lt;xsl:param name=&quot;curr_page&quot; select=&quot;1&quot; /&gt;  &lt;!-- Curr page # --&gt;\n    &lt;xsl:param name=&quot;prev_first_asin&quot; /&gt;       &lt;!-- Keeping track of repeats --&gt;</code></pre>\n<p>The first modification to this template is the addition of three parameters:</p>\n<ul>\n<li><code>max</code> provides an arbitrary upper limit to the number of pages through which this template will iterate.</li>\n<li><code>curr_page</code> contains the number of the page to be requested in this iteration.</li>\n<li><code>prev_first_asin</code> will contain the ASIN number of the first item from the previous iteration&#39;s page of results.</li>\n</ul>\n<p>Next, we modify the URL used to query for wishlist data:</p>\n<pre><code>    &lt;!-- Fetch the wishlist products --&gt;\n    &lt;xsl:variable name=&quot;details&quot; select=&quot;document(concat(\n                  &#39;http://xml.amazon.com/onca/xml3?&#39;,\n                  &#39;t=&#39;,$associate,&#39;&amp;amp;&#39;,\n                  &#39;dev-t=&#39;,$devtoken,&#39;&amp;amp;&#39;,\n                  &#39;WishlistSearch=&#39;,$wishlist,&#39;&amp;amp;&#39;,\n                  &#39;type=lite&amp;amp;f=xml&amp;amp;&#39;,\n                  &#39;page=&#39;,$curr_page))//Details&quot; /&gt;</code></pre>\n<p>The only addition here beyond the previous version is the <code>page</code> parameter in the URL.  Not much mystery here--this parameter specifies which page of results we want.  Now, let&#39;s build the loop:</p>\n<pre><code>    &lt;!-- Snag the first item Asin --&gt;\n    &lt;xsl:variable name=&quot;curr_first_asin&quot; select=&quot;$details/Asin/text()&quot; /&gt;\n\n    &lt;!-- If we haven&#39;t exceeded the loop limit, and this first Asin isn&#39;t --&gt;\n    &lt;!-- a repeat of the previous loop (indicating we&#39;ve run out of new   --&gt;\n    &lt;!-- pages), then go ahead...                                         --&gt;\n    &lt;xsl:if test=&quot;(($curr_page+1) &amp;lt; $max) and\n                  (string-length($curr_first_asin) &amp;gt; 0) and\n                  not($curr_first_asin = $prev_first_asin)&quot;&gt;</code></pre>\n<p>We capture the ASIN of the first item in this page of results and check to see if we should continue.  This <code>if</code> conditional first ensures that we&#39;re not past the sanity guard for loop iterations, makes sure that we actually got a non-empty current first ASIN, then checks our current first product&#39;s ASIN against what was passed in as the previous iteration&#39;s first product&#39;s ASIN.  If this was the first time through the loop, this value should be empty and therefore wouldn&#39;t match the current ASIN.  But, if we&#39;ve gone past the end of results, the previous and current ASIN values should match, and the conditional will fail.</p>\n<p>Moving along into the body of the conditional, we copy in wishlist products filtered on a price maximum, just as before:</p>\n<pre><code>      &lt;!-- Copy products, filtering on a maximum price --&gt;\n      &lt;xsl:copy-of select=&quot;$details/OurPrice[number(substring(\n                   text(),2)) &amp;lt; $maxprice]/..&quot; /&gt;</code></pre>\n<p>Having done that, we move onto the recursive end of this template:</p>\n<pre><code>      &lt;!-- Loop by recursion to get the next page --&gt;\n      &lt;xsl:call-template name=&quot;processWishlist&quot;&gt;\n        &lt;xsl:with-param name=&quot;wishlist&quot;        select=&quot;$wishlist&quot; /&gt;\n        &lt;xsl:with-param name=&quot;max&quot;             select=&quot;$max&quot; /&gt;\n        &lt;xsl:with-param name=&quot;curr_page&quot;       select=&quot;$curr_page + 1&quot; /&gt;\n        &lt;xsl:with-param name=&quot;prev_first_asin&quot; select=&quot;$curr_first_asin&quot; /&gt;\n      &lt;/xsl:call-template&gt;\n\n    &lt;/xsl:if&gt;    \n  &lt;/xsl:template&gt;</code></pre>\n<p>Here, the template makes a recursive call back to itself, passing through the wishlist ID and the maximum iteration count.  Since variables in XSLT are immutable, meaning that their values can&#39;t be changed once they&#39;ve been set, we can&#39;t increment <code>$curr_page</code> in-place like a loop counter in other languages--so, the current page count <em>value</em> is incremented and passed to the recursive call as a parameter.  Finally, the current first item&#39;s ASIN is passed along, to become the previous ASIN for the next iteration.</p>\n<p>Note that when the conditional fails--that is, if the loop limit is passed or a duplicate page is detected--the loop ends.  In other words, nothing further happens and execution pops back up out of all the levels of recursion and the top-level template ends.  </p>\n<p>I wrote &quot;<em>when</em> the conditional fails&quot;.  This is a key point: for the loop to eventually end, this conditional <em>must</em> fail (or be made to fail) at some point, else this loop will happily progress through page requests forever.  This is the reason for the <code>$max</code> parameter limiting the number of iterations, in case something goes haywire--like, oh say, a failure of our duplicate-page detection hack as a loop ending condition.  A useful exercise for the reader might be to add some additional diagnostic code to report that the limit was hit versus a natural end to results.</p>\n<h3 id=\"random-numbers\">Random Numbers</h3>\n<p>Some ready-made files are available for this section:</p>\n<ul>\n<li><a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex3.xsl\"><code>wishes-ex3.xsl</code></a>: The third iteration of the stylesheet in development.</li>\n<li><a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/random-xml\"><code>random-xml</code></a>: A Perl CGI script used as a web service to generate random numbers.</li>\n</ul>\n<p>Armed with a template that will query against the full set of items in a wishlist, we&#39;re ready to look into making a random selection from a list of products.  </p>\n<p>But first, we need to pick a random number.  Unfortunately, there doesn&#39;t appear to be any <code>random()</code> function in the XPath or XSLT standards.  There <em>is</em> a <a href=\"http://www.exslt.org/math/functions/random/index.html\"><code>math:random()</code></a> from EXSLT implemented in <code>libxslt</code>, but I seem to be having a bit of a problem getting it to produce anything other than the same sequence of numbers.  I suspect there&#39;s a problem in seeding the random number generator, but I&#39;ve yet to work out how to fix it.  (Suggestions welcome.)</p>\n<p>So, I cheated and made another workaround with a CGI script on my web server that generates random numbers in a simple XML document.  Currently, it&#39;s hosted here:</p>\n<pre><code>http://www.decafbad.com/2004/05/random-xml</code></pre>\n<p>And this is what the script looks like:</p>\n<pre><code>#!/usr/bin/perl\n\nuse strict;\nuse CGI;\n\nmy $q = new CGI();\n\nmy $min = $q-&gt;param(&#39;min&#39;) or 0;\nmy $max = $q-&gt;param(&#39;max&#39;) or 1;\nmy $int = $q-&gt;param(&#39;int&#39;);\n\nmy $num = $min + ( rand() * ($max - $min));\nif ($int) { $num = int($num); }\n\nprint $q-&gt;header(&#39;text/xml&#39;);\nprint &quot;&lt;rand&gt;$num&lt;/rand&gt;\\n&quot;;</code></pre>\n<p>This is a very simple CGI.  It accepts the parameters <code>max</code>, <code>min</code>, and <code>int</code>.  The values of these parameters determine the maximum and minimum value for the random number returned, and whether or not it should be an integer.  For example, the <a href=\"http://www.decafbad.com/2004/05/random-xml?int=1&#38;min=10&#38;max=20\" title=\"A random integer between 10 and 20, in XML\">following URL</a> should return an integer between 10 and 20:</p>\n<pre><code>http://www.decafbad.com/2004/05/random-xml?\nint=1&amp;#38;min=10&amp;#38;max=20</code></pre>\n<p>Using this as a web service in the stylesheet with the <code>document()</code> function, we can get a random number.  If you&#39;ve got web space where you can host CGI scripts, I suggest you host a copy of this script yourself, since I can&#39;t guarantee how long mine will stick around.  But, for as long at works, feel free to use the service from my server.</p>\n<p>Moving along, let&#39;s add a new named template to the stylesheet, called <code>randomWishlistProduct</code>:</p>\n<pre><code>  &lt;xsl:template name=&quot;randomWishlistProduct&quot;&gt;\n\n    &lt;xsl:param name=&quot;wishlist&quot; /&gt; &lt;!-- Wishlist ID --&gt;\n\n    &lt;!-- Gather all the products for the current wishlist --&gt;\n    &lt;xsl:variable name=&quot;products&quot;&gt;\n      &lt;xsl:call-template name=&quot;processWishlist&quot;&gt;\n        &lt;xsl:with-param name=&quot;wishlist&quot; select=&quot;$wishlist&quot; /&gt;\n      &lt;/xsl:call-template&gt;\n    &lt;/xsl:variable&gt;</code></pre>\n<p>Just like the <code>processWishlist</code> template, we start by defining the parameter <code>wishlist</code> to accept a wishlist ID.  Using this ID, we call the <code>processWishlist</code> template itself and store the complete list of products queried from the wishlist into the variable <code>$products</code>.</p>\n<pre><code>    &lt;!-- Count the products in the wishlist --&gt;\n    &lt;xsl:variable name=&quot;max_products&quot;\n                  select=&quot;count(exsl:node-set($products)/Details)&quot; /&gt;</code></pre>\n<p>This next step counts the number of products found in the wishlist.  The one tricky bit here is the use of the EXSLT function <a href=\"http://www.exslt.org/exsl/functions/node-set/index.html\"><code>exsl:node-set()</code></a>: The <code>$products</code> variable contains what&#39;s called a <a href=\"http://www.w3.org/TR/xslt#section-Result-Tree-Fragments\"><em>result tree fragment</em></a>, which is a kind of cross between XML data nodes and a plain old string.  This type of data does not normally allow the full set of XPath operators to be used on it, so first we need to use <code>exsl:node-set()</code> to turn it into a full-fledged node set.  Then we can look up the <code>Details</code> element nodes and count them.  </p>\n<pre><code>    &lt;!-- Conjure up a random index within the list of products --&gt;\n    &lt;xsl:variable name=&quot;rand_product_num&quot;\n                  select=&quot;document(concat(\n                  &#39;http://www.decafbad.com/2004/05/random-xml?&#39;,\n                  &#39;int=1&amp;amp;&#39;,\n                  &#39;min=1&amp;amp;&#39;,\n                  &#39;max=&#39;,$max_products))/rand&quot; /&gt;</code></pre>\n<p>Here is where the random number service comes in handy.  The <code>concat()</code> function is used to build the URL to the service, with parameters specifying that the number should be an integer, and should fall between 1 and the number of products in the wishlist.  The <code>document()</code> function grabs the XML document from the service, and the value is extracted from the single element the document contains.</p>\n<p>There is an alternative to this last bit, should you happen to have a properly working <code>math:random()</code> function in your XSLT processor:</p>\n<pre><code>    &lt;xsl:variable name=&quot;rand_product_num&quot; select=&quot;round( math:random() *\n                  $max_products ) + 1&quot; /&gt;</code></pre>\n<p>If you can use this instead, you&#39;ll have no need for the random number web service.  This version is obviously more concise, and doesn&#39;t require another trip out to a web service.  You might want to try it--but if you find that you keep getting the same wishlist items selected, then you&#39;ve run into the problem I found with the random number generator.</p>\n<p>Now, let&#39;s wrap this template up by selecting an item:</p>\n<pre><code>    &lt;!-- Copy the product as indexed by the random number --&gt;\n    &lt;xsl:copy-of select=&quot;exsl:node-set($products)/Details[\n                 position()=$rand_product_num]&quot; /&gt;\n\n  &lt;/xsl:template&gt;</code></pre>\n<p>Again, we need to use the <code>exsl:node-set()</code> function to turn the result tree fragment in the <code>$products</code> variable into a node set, from which we select and copy the <code>Details</code> element whose position in the data is indexed by the random number we just selected.  Just one last tweak needed to wrap up this iteration of our stylesheet.  We need to swap out the call to the <code>processWishlist</code> function at the end and replace it with a call to <code>randomWishlistProduct</code>:</p>\n<pre><code>  &lt;xsl:template match=&quot;/wishes:wishes&quot;&gt;\n\n    &lt;xsl:for-each select=&quot;//wishes:wishlist&quot;&gt;\n      &lt;wishes:wishitem&gt;\n        &lt;xsl:copy-of select=&quot;.&quot; /&gt;\n        &lt;xsl:call-template name=&quot;randomWishlistProduct&quot;&gt;\n          &lt;xsl:with-param name=&quot;wishlist&quot; select=&quot;.&quot; /&gt;\n        &lt;/xsl:call-template&gt;\n      &lt;/wishes:wishitem&gt;\n    &lt;/xsl:for-each&gt;\n\n  &lt;/xsl:template&gt;</code></pre>\n<p>After these changes, you should be able to run the stylesheet ([wishes-ex3.xsl][wishes_ex3]) and get something like the following:</p>\n<pre><code>&lt;wishes:wishitem xmlns:wishes=&quot;http://www.decafbad.com/2004/05/wishes&quot;&gt;\n    &lt;wishes:wishlist label=&quot;The Girl&quot;&gt;35OIOYWQ9XQAE&lt;/wishes:wishlist&gt;\n    &lt;Details ...&gt;...&lt;/Details&gt;\n&lt;/wishes:wishitem&gt;\n&lt;wishes:wishitem xmlns:wishes=&quot;http://www.decafbad.com/2004/05/wishes&quot;&gt;\n    &lt;wishes:wishlist label=&quot;Me&quot;&gt;1QWYI6P2JF3Q5&lt;/wishes:wishlist&gt;\n    &lt;Details ...&gt;...&lt;/Details&gt;\n&lt;/wishes:wishitem&gt;</code></pre>\n<p>This is similar to the output of the previous iteration of the stylesheet, but this time there&#39;s only one product selected at random for each wishlist.  </p>\n<h3 id=\"shopping-carts\">Shopping Carts</h3>\n<p>Some ready-made files are available for this section:</p>\n<ul>\n<li><a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex4.xsl\"><code>wishes-ex4.xsl</code></a>: The fourth iteration of the stylesheet in development.</li>\n</ul>\n<p>By this point, we&#39;ve been able to query and filter products in Amazon wishlists, and we&#39;ve selected an item at random from each wishlist we&#39;ve queried.  Now, let&#39;s enable some purchases.</p>\n<p>The AWS provides for Remote Shopping Cart functionality, whereby items can be added to an Amazon.com shopping cart programmatically.  This is about as close as we can get to automating the purchase of items selected from the wishlists--there is no API functionality for actually completing the ordering of items.  If you really think about it, this really is a good thing and <em>should</em> demand human intervention; we certainly wouldn&#39;t want this script going crazy and accidentally buying up everything on a wishlist.</p>\n<p>Documentation for the AWS Remote Shopping Cart explains that a shopping cart can be created and items added with a URL like the following:</p>\n<pre><code>http://xml.amazon.com/onca/xml3?\nShoppingCart=add&amp;#38;\nf=xml&amp;#38;\ndev-t=[Developer Token goes here]&amp;#38;\nt=[Associates ID goes here]&amp;#38;\nAsin.[ASIN goes here]=[quantity goes here]&amp;#38;\nsims=true</code></pre>\n<p>Part of this should look familiar, so we already know what to do with the developer token and the associates ID.  The last part, specifying product ASIN and quantity, can be filled out with information contained in the product records selected at random from the wishlists.  </p>\n<p>So, let&#39;s start by revising the template at the end of the stylesheet:</p>\n<pre><code>&lt;xsl:template match=&quot;/wishes:wishes&quot;&gt;\n\n    &lt;xsl:variable name=&quot;random_products&quot;&gt;      \n      &lt;xsl:for-each select=&quot;//wishes:wishlist&quot;&gt;\n        &lt;wishes:wishitem&gt;\n          &lt;xsl:copy-of select=&quot;.&quot; /&gt;\n          &lt;xsl:call-template name=&quot;randomWishlistProduct&quot;&gt;\n            &lt;xsl:with-param name=&quot;wishlist&quot; select=&quot;.&quot; /&gt;\n          &lt;/xsl:call-template&gt;\n        &lt;/wishes:wishitem&gt;\n      &lt;/xsl:for-each&gt;\n    &lt;/xsl:variable&gt;</code></pre>\n<p>Here, we&#39;ve taken what was the output of the previous iteration of the stylesheet and stuffed it into the variable <code>$random_products</code>.  Next, let&#39;s fill in the blanks and build a Remote Shopping Cart URL:</p>\n<pre><code>    &lt;xsl:variable name=&quot;shopping_cart_create_url&quot;&gt;\n      &lt;!-- Standard AWS URL --&gt;\n      &lt;xsl:text&gt;http://xml.amazon.com/onca/xml3?&lt;/xsl:text&gt;\n\n      &lt;!-- Add in the selected items --&gt;\n      &lt;xsl:for-each select=&quot;exsl:node-set($random_products)\n                            /wishes:wishitem/Details&quot;&gt;\n        &lt;xsl:text&gt;Asin.&lt;/xsl:text&gt;&lt;xsl:value-of select=&quot;Asin&quot; /&gt;\n        &lt;xsl:text&gt;=1&amp;amp;&lt;/xsl:text&gt;\n      &lt;/xsl:for-each&gt;\n\n      &lt;!-- Wrap up with the shopping cart function and required tokens --&gt;\n      &lt;xsl:text&gt;ShoppingCart=add&amp;amp;&lt;/xsl:text&gt;\n      &lt;xsl:text&gt;f=xml&amp;amp;&lt;/xsl:text&gt;\n      &lt;xsl:text&gt;dev-t=&lt;/xsl:text&gt;&lt;xsl:value-of select=&quot;$devtoken&quot; /&gt;\n      &lt;xsl:text&gt;&amp;amp;&lt;/xsl:text&gt;\n      &lt;xsl:text&gt;t=&lt;/xsl:text&gt;&lt;xsl:value-of select=&quot;$associate&quot; /&gt;\n    &lt;/xsl:variable&gt;</code></pre>\n<p>Since simple XPath doesn&#39;t allow for the looping needed for multiple items, we can&#39;t just concatenate this URL together in a <code>select</code> expression like we did with the wishlist item query.  So, we use <code>xslt:foreach</code> to build this with blocks of text using the <code>xsl:text</code> element.  We iterate though the random products chosen from wishlists and add an ASIN for each to the URL with a quantity of 1. Then, we use the <code>$devtoken</code> and <code>$associate</code> variables to fill in their respective spots.</p>\n<p>Note that this could have been written without using the <code>xsl:text</code> elements like so:</p>\n<pre><code>    &lt;xsl:variable name=&quot;shopping_cart_create_url&quot;&gt;http://xml.amazon.\n    com/onca/xml3?ShoppingCart=add&amp;amp;f=xml&amp;amp;dev-t=&lt;xsl:value-of \n    select=&quot;$devtoken&quot; /&gt;&amp;amp;t=&lt;xsl:value-of select=&quot;$associate&quot; /&gt;\n    &amp;amp;&lt;xsl:for-each select=&quot;exsl:node-set($random_products)/\n    wishes:wishitem/Details&quot;&gt;Asin.&lt;xsl:value-of select=&quot;Asin&quot; /&gt;=1\n    &amp;amp;&lt;/xsl:for-each&gt;&lt;/xsl:variable&gt;</code></pre>\n<p>This removes the clutter of all the <code>xsl:text</code> elements, but it would need to be piled all on one line in order to keep undesired whitespace from getting into the URL.  I made a small attempt at wrapping this line here, but line breaks and spaces would leave us with a non-functioning shopping cart URL.  It&#39;s up to you to decide which to use--personally, I prefer the <code>xsl:text</code> clutter for the ability to add in comments and clarify things a bit.</p>\n<p>Finally, having built the shopping cart URL, let&#39;s use it to get a shopping cart and wrap things up:</p>\n<pre><code>    &lt;xsl:variable name=&quot;shopping_cart&quot;\n                  select=&quot;document($shopping_cart_create_url)&quot; /&gt;\n\n    &lt;xsl:copy-of select=&quot;$shopping_cart&quot; /&gt;\n\n&lt;/xsl:template&gt;  </code></pre>\n<p>As an aside, this part is pushing the concept of a REST web service a bit: In the REST philosophy, requests using the GET method (which is what <code>document()</code> uses) should only return existing resources and not create new resources or cause modifications to happen.  Instead, these sorts of actions should use a POST request.  But, since we&#39;ve already accepted a few rough edges and workarounds in this project so far, we won&#39;t let a point of esoterica like that stop us.  (That and, well, this is the way Amazon designed their web service, so we&#39;ll take what we can get.)</p>\n<p>Once you run this iteration of the stylesheet ([wishes-ex4.xsl][wishes_ex4]), you should get something like this XML as output:</p>\n<pre><code>&lt;ShoppingCartResponse ...&gt;\n  ...\n  &lt;ShoppingCart&gt;\n   &lt;CartId&gt;...&lt;/CartId&gt;\n   &lt;HMAC&gt;...&lt;/HMAC&gt;\n   &lt;PurchaseUrl&gt;...&lt;/PurchaseUrl&gt;\n   &lt;Items&gt;\n    &lt;Item&gt;...&lt;/item&gt;\n    &lt;Item&gt;...&lt;/item&gt;\n   &lt;/Items&gt;\n  &lt;/ShoppingCart&gt;\n  ...\n&lt;/ShoppingCartResponse&gt;</code></pre>\n<p>The AWS documentation describes the vital elements here like so:</p>\n<ul>\n<li><code>CartId</code> - The Cart ID is the unique identifier for a given shopping cart.</li>\n<li><code>HMAC</code> - The HMAC is a security token that must be passed back to Amazon Web Services for using an existing cart.</li>\n<li><code>PurchaseUrl</code> - Use the purchase URL to transfer the remote shopping cart from your application to Amazon so that your application&#39;s users may complete their purchases.&#160; The purchase URL merges the remote shopping cart with the Amazon.com shopping cart. </li>\n</ul>\n<p>So, in short, whenever we want to do any sort of manipulation on this Remote Shopping Cart via AWS, we&#39;ll need to remember and later supply both the <code>CartId</code> and <code>HMAC</code> found in the XML returned at its creation.  And, once we&#39;re all ready to check out, the <code>PurchaseUrl</code> points to where we&#39;ll need to browse in person.</p>\n<h3 id=\"stay-tuned\">Stay Tuned!</h3>\n<p>This concludes Part 2 of the Wish-of-the-Month Club.  Following this will be the final part, where we tie everything together and start firing off monthly emails!</p>\n<!-- links -->\n\n<!--more-->\n<p>shortname=wishofthemonthclub2</p>\n",
    "body": "<i>Here's the next installment of the Wish-of-the-Month Club.  You can [revisit the first part][part1], too, if you've missed it.  I'd meant to post it within a week of the first part, so apologies all around to anyone who has been tapping a foot waiting for it.  Enjoy!</i>\r\n\r\n### Paging Through Wishes\r\n\r\nSome ready-made files are available for this section:\r\n* [`wishes-ex2.xsl`][wishes-ex2.xsl]: The second iteration of the stylesheet in development.\r\n\r\nNow we've got a way to make queries against Amazon Web Services, not entirely unlike what you might be used to if you tinker with MySQL databases on a regular basis.  At this point, though, we still have a bit of refining to make to this query.  If you take a look at the data produced by the query in its current state, and compare that to what you see on wishlists in your browser, you should notice some things missing.\r\n\r\nIf you look at [my wishlist][mywishlist], you'll notice that items span several pages when visited by browser.  As it turns out, AWS queries work in a similar fashion--each query returns only a limited number of items (about 10), and an additional parameter supplied to further queries is required to step through further pages of results.  So, using what we've built so far will only get us to the first page of wishlist items; to get all of the items, we'll need a way to step through all of the pages.\r\n\r\nIn playing with this, I experienced a bit of hairpulling frustration:  The AWS documentation, under \"Generating Additional Product Results\", claims that XML returned by the service will supply a count of the total pages available for a given query.  And although I see this element present in other types of searches, the `TotalPages` element is absent when querying on wishlists.  This may be a bug, or it may be an undocumented change in the service--either way, it was a surprise and leaves me with no official way to know how many pages I need to ask for in order to have a complete set of data.  \r\n\r\nWith some further tinkering, though, I figured out a workaround: If a query is made for a page number beyond the final page, the XML returned will be a duplicate of the final page.  Once I see a duplicate item appear, I know it's time to stop paging through results.  This is completely undocumented behavior, and could break at any time (ie. if Amazon decided to start issuing an error for a page index out of bounds), but it'll work for now.\r\n\r\nThis calls for reworking the `processWishlist` template.  For a given wishlist, it will need to iterate through a sequence of page numbers, requesting XML from AWS for each, stopping when the first duplicate page is found.  Since XSLT is heavily steeped in functional programming concepts, this sort of [iteration in XSLT][xslt_iteration] is best done [with recursion][xslt_recursion]:\r\n\r\n      <xsl:template name=\"processWishlist\">\r\n\r\n        <xsl:param name=\"wishlist\" />              <!-- Wishlist ID -->\r\n        <xsl:param name=\"max\"   select=\"50\" />     <!-- Arbitrary upper loop limit -->\r\n        <xsl:param name=\"curr_page\" select=\"1\" />  <!-- Curr page # -->\r\n        <xsl:param name=\"prev_first_asin\" />       <!-- Keeping track of repeats -->\r\n\r\nThe first modification to this template is the addition of three parameters:\r\n\r\n* `max` provides an arbitrary upper limit to the number of pages through which this template will iterate.\r\n* `curr_page` contains the number of the page to be requested in this iteration.\r\n* `prev_first_asin` will contain the ASIN number of the first item from the previous iteration's page of results.\r\n\r\nNext, we modify the URL used to query for wishlist data:\r\n\r\n        <!-- Fetch the wishlist products -->\r\n        <xsl:variable name=\"details\" select=\"document(concat(\r\n                      'http://xml.amazon.com/onca/xml3?',\r\n                      't=',$associate,'&amp;',\r\n                      'dev-t=',$devtoken,'&amp;',\r\n                      'WishlistSearch=',$wishlist,'&amp;',\r\n                      'type=lite&amp;f=xml&amp;',\r\n                      'page=',$curr_page))//Details\" />\r\n\r\nThe only addition here beyond the previous version is the `page` parameter in the URL.  Not much mystery here--this parameter specifies which page of results we want.  Now, let's build the loop:\r\n    \r\n        <!-- Snag the first item Asin -->\r\n        <xsl:variable name=\"curr_first_asin\" select=\"$details/Asin/text()\" />\r\n    \r\n        <!-- If we haven't exceeded the loop limit, and this first Asin isn't -->\r\n        <!-- a repeat of the previous loop (indicating we've run out of new   -->\r\n        <!-- pages), then go ahead...                                         -->\r\n        <xsl:if test=\"(($curr_page+1) &lt; $max) and\r\n                      (string-length($curr_first_asin) &gt; 0) and\r\n                      not($curr_first_asin = $prev_first_asin)\">\r\n      \r\nWe capture the ASIN of the first item in this page of results and check to see if we should continue.  This `if` conditional first ensures that we're not past the sanity guard for loop iterations, makes sure that we actually got a non-empty current first ASIN, then checks our current first product's ASIN against what was passed in as the previous iteration's first product's ASIN.  If this was the first time through the loop, this value should be empty and therefore wouldn't match the current ASIN.  But, if we've gone past the end of results, the previous and current ASIN values should match, and the conditional will fail.\r\n\r\nMoving along into the body of the conditional, we copy in wishlist products filtered on a price maximum, just as before:\r\n      \r\n          <!-- Copy products, filtering on a maximum price -->\r\n          <xsl:copy-of select=\"$details/OurPrice[number(substring(\r\n                       text(),2)) &lt; $maxprice]/..\" />\r\n\r\nHaving done that, we move onto the recursive end of this template:\r\n      \r\n          <!-- Loop by recursion to get the next page -->\r\n          <xsl:call-template name=\"processWishlist\">\r\n            <xsl:with-param name=\"wishlist\"        select=\"$wishlist\" />\r\n            <xsl:with-param name=\"max\"             select=\"$max\" />\r\n            <xsl:with-param name=\"curr_page\"       select=\"$curr_page + 1\" />\r\n            <xsl:with-param name=\"prev_first_asin\" select=\"$curr_first_asin\" />\r\n          </xsl:call-template>\r\n\r\n        </xsl:if>    \r\n      </xsl:template>\r\n\r\nHere, the template makes a recursive call back to itself, passing through the wishlist ID and the maximum iteration count.  Since variables in XSLT are immutable, meaning that their values can't be changed once they've been set, we can't increment `$curr_page` in-place like a loop counter in other languages--so, the current page count *value* is incremented and passed to the recursive call as a parameter.  Finally, the current first item's ASIN is passed along, to become the previous ASIN for the next iteration.\r\n\r\nNote that when the conditional fails--that is, if the loop limit is passed or a duplicate page is detected--the loop ends.  In other words, nothing further happens and execution pops back up out of all the levels of recursion and the top-level template ends.  \r\n\r\nI wrote \"*when* the conditional fails\".  This is a key point: for the loop to eventually end, this conditional *must* fail (or be made to fail) at some point, else this loop will happily progress through page requests forever.  This is the reason for the `$max` parameter limiting the number of iterations, in case something goes haywire--like, oh say, a failure of our duplicate-page detection hack as a loop ending condition.  A useful exercise for the reader might be to add some additional diagnostic code to report that the limit was hit versus a natural end to results.\r\n\r\n\r\n### Random Numbers\r\n\r\nSome ready-made files are available for this section:\r\n* [`wishes-ex3.xsl`][wishes-ex3.xsl]: The third iteration of the stylesheet in development.\r\n* [`random-xml`][random-xml]: A Perl CGI script used as a web service to generate random numbers.\r\n\r\nArmed with a template that will query against the full set of items in a wishlist, we're ready to look into making a random selection from a list of products.  \r\n\r\nBut first, we need to pick a random number.  Unfortunately, there doesn't appear to be any `random()` function in the XPath or XSLT standards.  There *is* a [`math:random()`][exsl_random] from EXSLT implemented in `libxslt`, but I seem to be having a bit of a problem getting it to produce anything other than the same sequence of numbers.  I suspect there's a problem in seeding the random number generator, but I've yet to work out how to fix it.  (Suggestions welcome.)\r\n\r\nSo, I cheated and made another workaround with a CGI script on my web server that generates random numbers in a simple XML document.  Currently, it's hosted here:\r\n\r\n    http://www.decafbad.com/2004/05/random-xml\r\n\r\nAnd this is what the script looks like:\r\n\r\n    #!/usr/bin/perl\r\n\r\n    use strict;\r\n    use CGI;\r\n\r\n    my $q = new CGI();\r\n\r\n    my $min = $q->param('min') or 0;\r\n    my $max = $q->param('max') or 1;\r\n    my $int = $q->param('int');\r\n\r\n    my $num = $min + ( rand() * ($max - $min));\r\n    if ($int) { $num = int($num); }\r\n\r\n    print $q->header('text/xml');\r\n    print \"<rand>$num</rand>\\n\";\r\n\r\nThis is a very simple CGI.  It accepts the parameters `max`, `min`, and `int`.  The values of these parameters determine the maximum and minimum value for the random number returned, and whether or not it should be an integer.  For example, the [following URL][rand_url] should return an integer between 10 and 20:\r\n\r\n    http://www.decafbad.com/2004/05/random-xml?\r\n    int=1&#38;min=10&#38;max=20\r\n\r\nUsing this as a web service in the stylesheet with the `document()` function, we can get a random number.  If you've got web space where you can host CGI scripts, I suggest you host a copy of this script yourself, since I can't guarantee how long mine will stick around.  But, for as long at works, feel free to use the service from my server.\r\n\r\nMoving along, let's add a new named template to the stylesheet, called `randomWishlistProduct`:\r\n\r\n      <xsl:template name=\"randomWishlistProduct\">\r\n    \r\n        <xsl:param name=\"wishlist\" /> <!-- Wishlist ID -->\r\n        \r\n        <!-- Gather all the products for the current wishlist -->\r\n        <xsl:variable name=\"products\">\r\n          <xsl:call-template name=\"processWishlist\">\r\n            <xsl:with-param name=\"wishlist\" select=\"$wishlist\" />\r\n          </xsl:call-template>\r\n        </xsl:variable>\r\n\r\nJust like the `processWishlist` template, we start by defining the parameter `wishlist` to accept a wishlist ID.  Using this ID, we call the `processWishlist` template itself and store the complete list of products queried from the wishlist into the variable `$products`.\r\n\r\n        <!-- Count the products in the wishlist -->\r\n        <xsl:variable name=\"max_products\"\r\n                      select=\"count(exsl:node-set($products)/Details)\" />\r\n\r\nThis next step counts the number of products found in the wishlist.  The one tricky bit here is the use of the EXSLT function [`exsl:node-set()`][exsl_node_set]: The `$products` variable contains what's called a [*result tree fragment*][xslt_result_tree_fragment], which is a kind of cross between XML data nodes and a plain old string.  This type of data does not normally allow the full set of XPath operators to be used on it, so first we need to use `exsl:node-set()` to turn it into a full-fledged node set.  Then we can look up the `Details` element nodes and count them.  \r\n\r\n        <!-- Conjure up a random index within the list of products -->\r\n        <xsl:variable name=\"rand_product_num\"\r\n                      select=\"document(concat(\r\n                      'http://www.decafbad.com/2004/05/random-xml?',\r\n                      'int=1&amp;',\r\n                      'min=1&amp;',\r\n                      'max=',$max_products))/rand\" />\r\n\r\nHere is where the random number service comes in handy.  The `concat()` function is used to build the URL to the service, with parameters specifying that the number should be an integer, and should fall between 1 and the number of products in the wishlist.  The `document()` function grabs the XML document from the service, and the value is extracted from the single element the document contains.\r\n\r\nThere is an alternative to this last bit, should you happen to have a properly working `math:random()` function in your XSLT processor:\r\n\r\n        <xsl:variable name=\"rand_product_num\" select=\"round( math:random() *\r\n                      $max_products ) + 1\" />\r\n\r\nIf you can use this instead, you'll have no need for the random number web service.  This version is obviously more concise, and doesn't require another trip out to a web service.  You might want to try it--but if you find that you keep getting the same wishlist items selected, then you've run into the problem I found with the random number generator.\r\n\r\nNow, let's wrap this template up by selecting an item:\r\n        \r\n        <!-- Copy the product as indexed by the random number -->\r\n        <xsl:copy-of select=\"exsl:node-set($products)/Details[\r\n                     position()=$rand_product_num]\" />\r\n           \r\n      </xsl:template>\r\n\r\nAgain, we need to use the `exsl:node-set()` function to turn the result tree fragment in the `$products` variable into a node set, from which we select and copy the `Details` element whose position in the data is indexed by the random number we just selected.  Just one last tweak needed to wrap up this iteration of our stylesheet.  We need to swap out the call to the `processWishlist` function at the end and replace it with a call to `randomWishlistProduct`:\r\n\r\n      <xsl:template match=\"/wishes:wishes\">\r\n\r\n        <xsl:for-each select=\"//wishes:wishlist\">\r\n          <wishes:wishitem>\r\n            <xsl:copy-of select=\".\" />\r\n            <xsl:call-template name=\"randomWishlistProduct\">\r\n              <xsl:with-param name=\"wishlist\" select=\".\" />\r\n            </xsl:call-template>\r\n          </wishes:wishitem>\r\n        </xsl:for-each>\r\n    \r\n      </xsl:template>\r\n\r\nAfter these changes, you should be able to run the stylesheet ([wishes-ex3.xsl][wishes_ex3]) and get something like the following:\r\n\r\n    <wishes:wishitem xmlns:wishes=\"http://www.decafbad.com/2004/05/wishes\">\r\n        <wishes:wishlist label=\"The Girl\">35OIOYWQ9XQAE</wishes:wishlist>\r\n        <Details ...>...</Details>\r\n    </wishes:wishitem>\r\n    <wishes:wishitem xmlns:wishes=\"http://www.decafbad.com/2004/05/wishes\">\r\n        <wishes:wishlist label=\"Me\">1QWYI6P2JF3Q5</wishes:wishlist>\r\n        <Details ...>...</Details>\r\n    </wishes:wishitem>\r\n\r\nThis is similar to the output of the previous iteration of the stylesheet, but this time there's only one product selected at random for each wishlist.  \r\n\r\n### Shopping Carts\r\n\r\nSome ready-made files are available for this section:\r\n* [`wishes-ex4.xsl`][wishes-ex4.xsl]: The fourth iteration of the stylesheet in development.\r\n\r\nBy this point, we've been able to query and filter products in Amazon wishlists, and we've selected an item at random from each wishlist we've queried.  Now, let's enable some purchases.\r\n\r\nThe AWS provides for Remote Shopping Cart functionality, whereby items can be added to an Amazon.com shopping cart programmatically.  This is about as close as we can get to automating the purchase of items selected from the wishlists--there is no API functionality for actually completing the ordering of items.  If you really think about it, this really is a good thing and *should* demand human intervention; we certainly wouldn't want this script going crazy and accidentally buying up everything on a wishlist.\r\n\r\nDocumentation for the AWS Remote Shopping Cart explains that a shopping cart can be created and items added with a URL like the following:\r\n\r\n    http://xml.amazon.com/onca/xml3?\r\n    ShoppingCart=add&#38;\r\n    f=xml&#38;\r\n    dev-t=[Developer Token goes here]&#38;\r\n    t=[Associates ID goes here]&#38;\r\n    Asin.[ASIN goes here]=[quantity goes here]&#38;\r\n    sims=true\r\n\r\nPart of this should look familiar, so we already know what to do with the developer token and the associates ID.  The last part, specifying product ASIN and quantity, can be filled out with information contained in the product records selected at random from the wishlists.  \r\n\r\nSo, let's start by revising the template at the end of the stylesheet:\r\n\r\n    <xsl:template match=\"/wishes:wishes\">\r\n\r\n        <xsl:variable name=\"random_products\">      \r\n          <xsl:for-each select=\"//wishes:wishlist\">\r\n            <wishes:wishitem>\r\n              <xsl:copy-of select=\".\" />\r\n              <xsl:call-template name=\"randomWishlistProduct\">\r\n                <xsl:with-param name=\"wishlist\" select=\".\" />\r\n              </xsl:call-template>\r\n            </wishes:wishitem>\r\n          </xsl:for-each>\r\n        </xsl:variable>\r\n\r\nHere, we've taken what was the output of the previous iteration of the stylesheet and stuffed it into the variable `$random_products`.  Next, let's fill in the blanks and build a Remote Shopping Cart URL:\r\n\r\n        <xsl:variable name=\"shopping_cart_create_url\">\r\n          <!-- Standard AWS URL -->\r\n          <xsl:text>http://xml.amazon.com/onca/xml3?</xsl:text>\r\n\r\n          <!-- Add in the selected items -->\r\n          <xsl:for-each select=\"exsl:node-set($random_products)\r\n                                /wishes:wishitem/Details\">\r\n            <xsl:text>Asin.</xsl:text><xsl:value-of select=\"Asin\" />\r\n            <xsl:text>=1&amp;</xsl:text>\r\n          </xsl:for-each>\r\n\r\n          <!-- Wrap up with the shopping cart function and required tokens -->\r\n          <xsl:text>ShoppingCart=add&amp;</xsl:text>\r\n          <xsl:text>f=xml&amp;</xsl:text>\r\n          <xsl:text>dev-t=</xsl:text><xsl:value-of select=\"$devtoken\" />\r\n          <xsl:text>&amp;</xsl:text>\r\n          <xsl:text>t=</xsl:text><xsl:value-of select=\"$associate\" />\r\n        </xsl:variable>\r\n    \r\nSince simple XPath doesn't allow for the looping needed for multiple items, we can't just concatenate this URL together in a `select` expression like we did with the wishlist item query.  So, we use `xslt:foreach` to build this with blocks of text using the `xsl:text` element.  We iterate though the random products chosen from wishlists and add an ASIN for each to the URL with a quantity of 1. Then, we use the `$devtoken` and `$associate` variables to fill in their respective spots.\r\n\r\nNote that this could have been written without using the `xsl:text` elements like so:\r\n\r\n        <xsl:variable name=\"shopping_cart_create_url\">http://xml.amazon.\r\n        com/onca/xml3?ShoppingCart=add&amp;f=xml&amp;dev-t=<xsl:value-of \r\n        select=\"$devtoken\" />&amp;t=<xsl:value-of select=\"$associate\" />\r\n        &amp;<xsl:for-each select=\"exsl:node-set($random_products)/\r\n        wishes:wishitem/Details\">Asin.<xsl:value-of select=\"Asin\" />=1\r\n        &amp;</xsl:for-each></xsl:variable>\r\n\r\nThis removes the clutter of all the `xsl:text` elements, but it would need to be piled all on one line in order to keep undesired whitespace from getting into the URL.  I made a small attempt at wrapping this line here, but line breaks and spaces would leave us with a non-functioning shopping cart URL.  It's up to you to decide which to use--personally, I prefer the `xsl:text` clutter for the ability to add in comments and clarify things a bit.\r\n\r\nFinally, having built the shopping cart URL, let's use it to get a shopping cart and wrap things up:\r\n\r\n        <xsl:variable name=\"shopping_cart\"\r\n                      select=\"document($shopping_cart_create_url)\" />\r\n    \r\n        <xsl:copy-of select=\"$shopping_cart\" />\r\n    \r\n    </xsl:template>  \r\n\r\nAs an aside, this part is pushing the concept of a REST web service a bit: In the REST philosophy, requests using the GET method (which is what `document()` uses) should only return existing resources and not create new resources or cause modifications to happen.  Instead, these sorts of actions should use a POST request.  But, since we've already accepted a few rough edges and workarounds in this project so far, we won't let a point of esoterica like that stop us.  (That and, well, this is the way Amazon designed their web service, so we'll take what we can get.)\r\n\r\nOnce you run this iteration of the stylesheet ([wishes-ex4.xsl][wishes_ex4]), you should get something like this XML as output:\r\n\r\n    <ShoppingCartResponse ...>\r\n      ...\r\n      <ShoppingCart>\r\n       <CartId>...</CartId>\r\n       <HMAC>...</HMAC>\r\n       <PurchaseUrl>...</PurchaseUrl>\r\n       <Items>\r\n        <Item>...</item>\r\n        <Item>...</item>\r\n       </Items>\r\n      </ShoppingCart>\r\n      ...\r\n    </ShoppingCartResponse>\r\n\r\nThe AWS documentation describes the vital elements here like so:\r\n\r\n* `CartId` - The Cart ID is the unique identifier for a given shopping cart.\r\n* `HMAC` - The HMAC is a security token that must be passed back to Amazon Web Services for using an existing cart.\r\n* `PurchaseUrl` - Use the purchase URL to transfer the remote shopping cart from your application to Amazon so that your application's users may complete their purchases.&#160; The purchase URL merges the remote shopping cart with the Amazon.com shopping cart. \r\n\r\nSo, in short, whenever we want to do any sort of manipulation on this Remote Shopping Cart via AWS, we'll need to remember and later supply both the `CartId` and `HMAC` found in the XML returned at its creation.  And, once we're all ready to check out, the `PurchaseUrl` points to where we'll need to browse in person.\r\n\r\n### Stay Tuned!\r\n\r\nThis concludes Part 2 of the Wish-of-the-Month Club.  Following this will be the final part, where we tie everything together and start firing off monthly emails!\r\n\r\n<!-- links -->\r\n\r\n[missadroit]: http://missadroit.livejournal.com \"Miss Adroit, my favorite girl in the world\"\r\n[mywishlist]: http://www.amazon.com/exec/obidos/registry/1QWYI6P2JF3Q5 \"Buy me something, will ya?\"\r\n[herwishlist]: http://www.amazon.com/exec/obidos/registry/35OIOYWQ9XQAE \"Buy her something, will ya?\"\r\n[amazonapi]: http://www.amazon.com/gp/aws/landing.html \"Amazon Web Services\"\r\n[libxml]: http://www.xmlsoft.org/\r\n[xalan]: http://xml.apache.org/xalan-j/\r\n[sablotron]: http://www.gingerall.com/charlie/ga/xml/p_sab.xml\r\n[saxon]: http://saxon.sourceforge.net/\r\n[exslt]: http://www.exslt.org/\r\n[libxslt]: http://www.xmlsoft.org/XSLT.html\r\n[spideringhacks]: http://www.amazon.com/exec/obidos/ASIN/0596005776/0xdecafbad-20 \"O'Reilly's Spidering Hacks\"\r\n[xslscraper]: http://www.decafbad.com/twiki/bin/view/Main/XslScraper \"Scrape RSS and Atom from HTML using Tidy and XSLT\"\r\n[awsdownload]: http://www.amazon.com/gp/browse.html/ref=sc_fe_c_2/002-7899886-3676027?%5Fencoding=UTF8&#38;node=3434641&#38;no=3435361&#38;me=A36L942TSJ2AJA\r\n[awstoken]: https://associates.amazon.com/exec/panama/associates/join/developer/application.html\r\n[amazonassociate]: http://associates.amazon.com\r\n[wlsearch]: http://www.amazon.com/gp/registry/search.html/002-7899886-3676027?%5Fencoding=UTF8&#38;type=wishlist\r\n[wlurl]: http://xml.amazon.com/onca/xml3?t=0xdecafbad-20&#38;dev-t=D8HVH869XA0NP&#38;type=lite&#38;WishlistSearch=35OIOYWQ9XQAE&#38;f=xml\r\n[detailsurl]: http://www.amazon.com/exec/obidos/ASIN/0262133601/0xdecafbad-20?dev-t=D8HVH869XA0NP%26camp=2025%26link_code=xm2\r\n[awslite]: http://xml.amazon.com/schemas3/dev-lite.xsd\r\n[fink]: http://fink.sourceforge.net\r\n[testxslt]: http://www.entropy.ch:16080/software/macosx/#testxslt\r\n[darwinports]: http://darwinports.opendarwin.org/\r\n[curl]: http://www.decafbad.com/#TODO\r\n[wget]: http://www.decafbad.com/#TODO\r\n[xpconcat]: http://www.w3.org/TR/2002/WD-xquery-operators-20020816/#func-concat\r\n[xpdocument]: http://www.w3.org/TR/2002/WD-xquery-operators-20020816/#func-document\r\n[wishescvs]: http://www.decafbad.com/cvs/hacks/wishes/\r\n[wishes.tar.gz]: http://www.decafbad.com/cvs/hacks/wishes/wishes.tar.gz?tarball=1 \"All Wish-of-the-Month Club files wrapped up in a tarball\"\r\n[wishes.xml]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.xml\r\n[wishes-ex1.xsl]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex1.xsl\r\n[wishes-ex2.xsl]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex2.xsl\r\n[wishes-ex3.xsl]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex3.xsl\r\n[wishes-ex4.xsl]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex4.xsl\r\n[wishes-ex5.xsl]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex5.xsl\r\n[wishes-ex6.xsl]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex6.xsl\r\n[random-xml]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/random-xml\r\n[wishes_html_screenshot]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.jpg\r\n[xslt_iteration]: http://www.dpawson.co.uk/xsl/sect2/N4806.html \"Iteration in XSLT\"\r\n[xslt_recursion]: http://www-106.ibm.com/developerworks/xml/library/x-xslrecur/ \"Use recursion effectively in XSL\"\r\n[exsl_random]: http://www.exslt.org/math/functions/random/index.html\r\n[exsl_node_set]: http://www.exslt.org/exsl/functions/node-set/index.html\r\n[rand_url]: http://www.decafbad.com/2004/05/random-xml?int=1&#38;min=10&#38;max=20 \"A random integer between 10 and 20, in XML\"\r\n[xslt_result_tree_fragment]: http://www.w3.org/TR/xslt#section-Result-Tree-Fragments\r\n\r\n[email_attach_anatomy]: http://www.dpo.uab.edu/Email/attach.html \"Anatomy of an Email Attachment\"\r\n[email_mime_and_html]: http://www.abiglime.com/webmaster/articles/cgi/010698.htm \"How to encapsulate HTML in an email message\"\r\n\r\n[email_html_and_text]: http://www.wilsonweb.com/wmt5/html-email-multi.htm \"Sending HTML and Plain Text E-Mail Simultaneously\"\r\n[man_sendmail]: http://www.hmug.org/man/8/sendmail.html \"man: sendmail\"\r\n[rfc1521]: http://www.faqs.org/rfcs/rfc1521.html \"RFC 1521\"\r\n[cron1]: http://www.lysator.liu.se/~forsberg/linux/cron.html \"Doing things periodically - Using CRON\"\r\n[cron2]: http://www.itworld.com/Comp/2378/swol-0825-unix101/ \"Using cron basics\"\r\n[python_libxml]: http://xmlsoft.org/python.html \r\n[part1]: http://www.decafbad.com/blog/2004/06/16/wishofthemonthclub1\r\n<!--more-->\r\nshortname=wishofthemonthclub2\r\n",
    "parentPath": "../blog.lmorchard.com/posts/archives/2004",
    "path": "2004/06/28/wishofthemonthclub2",
    "summary": "<p><i>Here&apos;s the next installment of the Wish-of-the-Month Club.  You can <a href=\"http://www.decafbad.com/blog/2004/06/16/wishofthemonthclub1\">revisit the first part</a>, too, if you&apos;ve missed it.  I&apos;d meant to post it within a week of the first part, so apologies all around to anyone who has been tapping a foot waiting for it.  Enjoy!</i></p>\n<h3 id=\"paging-through-wishes\">Paging Through Wishes</h3>\n<p>Some ready-made files are available for this section:</p>\n<ul>\n<li><a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex2.xsl\"><code>wishes-ex2.xsl</code></a>: The second iteration of the stylesheet in development.</li>\n</ul>\n<p>Now we&apos;ve got a way to make queries against Amazon Web Services, not entirely unlike what you might be used to if you tinker with MySQL databases on a regular basis.  At this point, though, we still have a bit of refining to make to this query.  If you take a look at the data produced by the query in its current state, and compare that to what you see on wishlists in your browser, you should notice some things missing.</p>\n<p>If you look at <a href=\"http://www.amazon.com/exec/obidos/registry/1QWYI6P2JF3Q5\" title=\"Buy me something, will ya?\">my wishlist</a>, you&apos;ll notice that items span several pages when visited by browser.  As it turns out, AWS queries work in a similar fashion--each query returns only a limited number of items (about 10), and an additional parameter supplied to further queries is required to step through further pages of results.  So, using what we&apos;ve built so far will only get us to the first page of wishlist items; to get all of the items, we&apos;ll need a way to step through all of the pages.</p>\n<p>In playing with this, I experienced a bit of hairpulling frustration:  The AWS documentation, under &quot;Generating Additional Product Results&quot;, claims that XML returned by the service will supply a count of the total pages available for a given query.  And although I see this element present in other types of searches, the <code>TotalPages</code> element is absent when querying on wishlists.  This may be a bug, or it may be an undocumented change in the service--either way, it was a surprise and leaves me with no official way to know how many pages I need to ask for in order to have a complete set of data.  </p>\n<p>With some further tinkering, though, I figured out a workaround: If a query is made for a page number beyond the final page, the XML returned will be a duplicate of the final page.  Once I see a duplicate item appear, I know it&apos;s time to stop paging through results.  This is completely undocumented behavior, and could break at any time (ie. if Amazon decided to start issuing an error for a page index out of bounds), but it&apos;ll work for now.</p>\n<p>This calls for reworking the <code>processWishlist</code> template.  For a given wishlist, it will need to iterate through a sequence of page numbers, requesting XML from AWS for each, stopping when the first duplicate page is found.  Since XSLT is heavily steeped in functional programming concepts, this sort of <a href=\"http://www.dpawson.co.uk/xsl/sect2/N4806.html\" title=\"Iteration in XSLT\">iteration in XSLT</a> is best done <a href=\"http://www-106.ibm.com/developerworks/xml/library/x-xslrecur/\" title=\"Use recursion effectively in XSL\">with recursion</a>:</p>\n<pre><code>  &lt;xsl:template name=&quot;processWishlist&quot;&gt;\n\n    &lt;xsl:param name=&quot;wishlist&quot; /&gt;              &lt;!-- Wishlist ID --&gt;\n    &lt;xsl:param name=&quot;max&quot;   select=&quot;50&quot; /&gt;     &lt;!-- Arbitrary upper loop limit --&gt;\n    &lt;xsl:param name=&quot;curr_page&quot; select=&quot;1&quot; /&gt;  &lt;!-- Curr page # --&gt;\n    &lt;xsl:param name=&quot;prev_first_asin&quot; /&gt;       &lt;!-- Keeping track of repeats --&gt;</code></pre>\n<p>The first modification to this template is the addition of three parameters:</p>\n<ul>\n<li><code>max</code> provides an arbitrary upper limit to the number of pages through which this template will iterate.</li>\n<li><code>curr_page</code> contains the number of the page to be requested in this iteration.</li>\n<li><code>prev_first_asin</code> will contain the ASIN number of the first item from the previous iteration&apos;s page of results.</li>\n</ul>\n<p>Next, we modify the URL used to query for wishlist data:</p>\n<pre><code>    &lt;!-- Fetch the wishlist products --&gt;\n    &lt;xsl:variable name=&quot;details&quot; select=&quot;document(concat(\n                  &apos;http://xml.amazon.com/onca/xml3?&apos;,\n                  &apos;t=&apos;,$associate,&apos;&amp;amp;&apos;,\n                  &apos;dev-t=&apos;,$devtoken,&apos;&amp;amp;&apos;,\n                  &apos;WishlistSearch=&apos;,$wishlist,&apos;&amp;amp;&apos;,\n                  &apos;type=lite&amp;amp;f=xml&amp;amp;&apos;,\n                  &apos;page=&apos;,$curr_page))//Details&quot; /&gt;</code></pre>\n<p>The only addition here beyond the previous version is the <code>page</code> parameter in the URL.  Not much mystery here--this parameter specifies which page of results we want.  Now, let&apos;s build the loop:</p>\n<pre><code>    &lt;!-- Snag the first item Asin --&gt;\n    &lt;xsl:variable name=&quot;curr_first_asin&quot; select=&quot;$details/Asin/text()&quot; /&gt;\n\n    &lt;!-- If we haven&apos;t exceeded the loop limit, and this first Asin isn&apos;t --&gt;\n    &lt;!-- a repeat of the previous loop (indicating we&apos;ve run out of new   --&gt;\n    &lt;!-- pages), then go ahead...                                         --&gt;\n    &lt;xsl:if test=&quot;(($curr_page+1) &amp;lt; $max) and\n                  (string-length($curr_first_asin) &amp;gt; 0) and\n                  not($curr_first_asin = $prev_first_asin)&quot;&gt;</code></pre>\n<p>We capture the ASIN of the first item in this page of results and check to see if we should continue.  This <code>if</code> conditional first ensures that we&apos;re not past the sanity guard for loop iterations, makes sure that we actually got a non-empty current first ASIN, then checks our current first product&apos;s ASIN against what was passed in as the previous iteration&apos;s first product&apos;s ASIN.  If this was the first time through the loop, this value should be empty and therefore wouldn&apos;t match the current ASIN.  But, if we&apos;ve gone past the end of results, the previous and current ASIN values should match, and the conditional will fail.</p>\n<p>Moving along into the body of the conditional, we copy in wishlist products filtered on a price maximum, just as before:</p>\n<pre><code>      &lt;!-- Copy products, filtering on a maximum price --&gt;\n      &lt;xsl:copy-of select=&quot;$details/OurPrice[number(substring(\n                   text(),2)) &amp;lt; $maxprice]/..&quot; /&gt;</code></pre>\n<p>Having done that, we move onto the recursive end of this template:</p>\n<pre><code>      &lt;!-- Loop by recursion to get the next page --&gt;\n      &lt;xsl:call-template name=&quot;processWishlist&quot;&gt;\n        &lt;xsl:with-param name=&quot;wishlist&quot;        select=&quot;$wishlist&quot; /&gt;\n        &lt;xsl:with-param name=&quot;max&quot;             select=&quot;$max&quot; /&gt;\n        &lt;xsl:with-param name=&quot;curr_page&quot;       select=&quot;$curr_page + 1&quot; /&gt;\n        &lt;xsl:with-param name=&quot;prev_first_asin&quot; select=&quot;$curr_first_asin&quot; /&gt;\n      &lt;/xsl:call-template&gt;\n\n    &lt;/xsl:if&gt;    \n  &lt;/xsl:template&gt;</code></pre>\n<p>Here, the template makes a recursive call back to itself, passing through the wishlist ID and the maximum iteration count.  Since variables in XSLT are immutable, meaning that their values can&apos;t be changed once they&apos;ve been set, we can&apos;t increment <code>$curr_page</code> in-place like a loop counter in other languages--so, the current page count <em>value</em> is incremented and passed to the recursive call as a parameter.  Finally, the current first item&apos;s ASIN is passed along, to become the previous ASIN for the next iteration.</p>\n<p>Note that when the conditional fails--that is, if the loop limit is passed or a duplicate page is detected--the loop ends.  In other words, nothing further happens and execution pops back up out of all the levels of recursion and the top-level template ends.  </p>\n<p>I wrote &quot;<em>when</em> the conditional fails&quot;.  This is a key point: for the loop to eventually end, this conditional <em>must</em> fail (or be made to fail) at some point, else this loop will happily progress through page requests forever.  This is the reason for the <code>$max</code> parameter limiting the number of iterations, in case something goes haywire--like, oh say, a failure of our duplicate-page detection hack as a loop ending condition.  A useful exercise for the reader might be to add some additional diagnostic code to report that the limit was hit versus a natural end to results.</p>\n<h3 id=\"random-numbers\">Random Numbers</h3>\n<p>Some ready-made files are available for this section:</p>\n<ul>\n<li><a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex3.xsl\"><code>wishes-ex3.xsl</code></a>: The third iteration of the stylesheet in development.</li>\n<li><a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/random-xml\"><code>random-xml</code></a>: A Perl CGI script used as a web service to generate random numbers.</li>\n</ul>\n<p>Armed with a template that will query against the full set of items in a wishlist, we&apos;re ready to look into making a random selection from a list of products.  </p>\n<p>But first, we need to pick a random number.  Unfortunately, there doesn&apos;t appear to be any <code>random()</code> function in the XPath or XSLT standards.  There <em>is</em> a <a href=\"http://www.exslt.org/math/functions/random/index.html\"><code>math:random()</code></a> from EXSLT implemented in <code>libxslt</code>, but I seem to be having a bit of a problem getting it to produce anything other than the same sequence of numbers.  I suspect there&apos;s a problem in seeding the random number generator, but I&apos;ve yet to work out how to fix it.  (Suggestions welcome.)</p>\n<p>So, I cheated and made another workaround with a CGI script on my web server that generates random numbers in a simple XML document.  Currently, it&apos;s hosted here:</p>\n<pre><code>http://www.decafbad.com/2004/05/random-xml</code></pre>\n<p>And this is what the script looks like:</p>\n<pre><code>#!/usr/bin/perl\n\nuse strict;\nuse CGI;\n\nmy $q = new CGI();\n\nmy $min = $q-&gt;param(&apos;min&apos;) or 0;\nmy $max = $q-&gt;param(&apos;max&apos;) or 1;\nmy $int = $q-&gt;param(&apos;int&apos;);\n\nmy $num = $min + ( rand() * ($max - $min));\nif ($int) { $num = int($num); }\n\nprint $q-&gt;header(&apos;text/xml&apos;);\nprint &quot;&lt;rand&gt;$num&lt;/rand&gt;\\n&quot;;</code></pre>\n<p>This is a very simple CGI.  It accepts the parameters <code>max</code>, <code>min</code>, and <code>int</code>.  The values of these parameters determine the maximum and minimum value for the random number returned, and whether or not it should be an integer.  For example, the <a href=\"http://www.decafbad.com/2004/05/random-xml?int=1&amp;min=10&amp;max=20\" title=\"A random integer between 10 and 20, in XML\">following URL</a> should return an integer between 10 and 20:</p>\n<pre><code>http://www.decafbad.com/2004/05/random-xml?\nint=1&amp;#38;min=10&amp;#38;max=20</code></pre>\n<p>Using this as a web service in the stylesheet with the <code>document()</code> function, we can get a random number.  If you&apos;ve got web space where you can host CGI scripts, I suggest you host a copy of this script yourself, since I can&apos;t guarantee how long mine will stick around.  But, for as long at works, feel free to use the service from my server.</p>\n<p>Moving along, let&apos;s add a new named template to the stylesheet, called <code>randomWishlistProduct</code>:</p>\n<pre><code>  &lt;xsl:template name=&quot;randomWishlistProduct&quot;&gt;\n\n    &lt;xsl:param name=&quot;wishlist&quot; /&gt; &lt;!-- Wishlist ID --&gt;\n\n    &lt;!-- Gather all the products for the current wishlist --&gt;\n    &lt;xsl:variable name=&quot;products&quot;&gt;\n      &lt;xsl:call-template name=&quot;processWishlist&quot;&gt;\n        &lt;xsl:with-param name=&quot;wishlist&quot; select=&quot;$wishlist&quot; /&gt;\n      &lt;/xsl:call-template&gt;\n    &lt;/xsl:variable&gt;</code></pre>\n<p>Just like the <code>processWishlist</code> template, we start by defining the parameter <code>wishlist</code> to accept a wishlist ID.  Using this ID, we call the <code>processWishlist</code> template itself and store the complete list of products queried from the wishlist into the variable <code>$products</code>.</p>\n<pre><code>    &lt;!-- Count the products in the wishlist --&gt;\n    &lt;xsl:variable name=&quot;max_products&quot;\n                  select=&quot;count(exsl:node-set($products)/Details)&quot; /&gt;</code></pre>\n<p>This next step counts the number of products found in the wishlist.  The one tricky bit here is the use of the EXSLT function <a href=\"http://www.exslt.org/exsl/functions/node-set/index.html\"><code>exsl:node-set()</code></a>: The <code>$products</code> variable contains what&apos;s called a <a href=\"http://www.w3.org/TR/xslt#section-Result-Tree-Fragments\"><em>result tree fragment</em></a>, which is a kind of cross between XML data nodes and a plain old string.  This type of data does not normally allow the full set of XPath operators to be used on it, so first we need to use <code>exsl:node-set()</code> to turn it into a full-fledged node set.  Then we can look up the <code>Details</code> element nodes and count them.  </p>\n<pre><code>    &lt;!-- Conjure up a random index within the list of products --&gt;\n    &lt;xsl:variable name=&quot;rand_product_num&quot;\n                  select=&quot;document(concat(\n                  &apos;http://www.decafbad.com/2004/05/random-xml?&apos;,\n                  &apos;int=1&amp;amp;&apos;,\n                  &apos;min=1&amp;amp;&apos;,\n                  &apos;max=&apos;,$max_products))/rand&quot; /&gt;</code></pre>\n<p>Here is where the random number service comes in handy.  The <code>concat()</code> function is used to build the URL to the service, with parameters specifying that the number should be an integer, and should fall between 1 and the number of products in the wishlist.  The <code>document()</code> function grabs the XML document from the service, and the value is extracted from the single element the document contains.</p>\n<p>There is an alternative to this last bit, should you happen to have a properly working <code>math:random()</code> function in your XSLT processor:</p>\n<pre><code>    &lt;xsl:variable name=&quot;rand_product_num&quot; select=&quot;round( math:random() *\n                  $max_products ) + 1&quot; /&gt;</code></pre>\n<p>If you can use this instead, you&apos;ll have no need for the random number web service.  This version is obviously more concise, and doesn&apos;t require another trip out to a web service.  You might want to try it--but if you find that you keep getting the same wishlist items selected, then you&apos;ve run into the problem I found with the random number generator.</p>\n<p>Now, let&apos;s wrap this template up by selecting an item:</p>\n<pre><code>    &lt;!-- Copy the product as indexed by the random number --&gt;\n    &lt;xsl:copy-of select=&quot;exsl:node-set($products)/Details[\n                 position()=$rand_product_num]&quot; /&gt;\n\n  &lt;/xsl:template&gt;</code></pre>\n<p>Again, we need to use the <code>exsl:node-set()</code> function to turn the result tree fragment in the <code>$products</code> variable into a node set, from which we select and copy the <code>Details</code> element whose position in the data is indexed by the random number we just selected.  Just one last tweak needed to wrap up this iteration of our stylesheet.  We need to swap out the call to the <code>processWishlist</code> function at the end and replace it with a call to <code>randomWishlistProduct</code>:</p>\n<pre><code>  &lt;xsl:template match=&quot;/wishes:wishes&quot;&gt;\n\n    &lt;xsl:for-each select=&quot;//wishes:wishlist&quot;&gt;\n      &lt;wishes:wishitem&gt;\n        &lt;xsl:copy-of select=&quot;.&quot; /&gt;\n        &lt;xsl:call-template name=&quot;randomWishlistProduct&quot;&gt;\n          &lt;xsl:with-param name=&quot;wishlist&quot; select=&quot;.&quot; /&gt;\n        &lt;/xsl:call-template&gt;\n      &lt;/wishes:wishitem&gt;\n    &lt;/xsl:for-each&gt;\n\n  &lt;/xsl:template&gt;</code></pre>\n<p>After these changes, you should be able to run the stylesheet ([wishes-ex3.xsl][wishes_ex3]) and get something like the following:</p>\n<pre><code>&lt;wishes:wishitem xmlns:wishes=&quot;http://www.decafbad.com/2004/05/wishes&quot;&gt;\n    &lt;wishes:wishlist label=&quot;The Girl&quot;&gt;35OIOYWQ9XQAE&lt;/wishes:wishlist&gt;\n    &lt;Details ...&gt;...&lt;/Details&gt;\n&lt;/wishes:wishitem&gt;\n&lt;wishes:wishitem xmlns:wishes=&quot;http://www.decafbad.com/2004/05/wishes&quot;&gt;\n    &lt;wishes:wishlist label=&quot;Me&quot;&gt;1QWYI6P2JF3Q5&lt;/wishes:wishlist&gt;\n    &lt;Details ...&gt;...&lt;/Details&gt;\n&lt;/wishes:wishitem&gt;</code></pre>\n<p>This is similar to the output of the previous iteration of the stylesheet, but this time there&apos;s only one product selected at random for each wishlist.  </p>\n<h3 id=\"shopping-carts\">Shopping Carts</h3>\n<p>Some ready-made files are available for this section:</p>\n<ul>\n<li><a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex4.xsl\"><code>wishes-ex4.xsl</code></a>: The fourth iteration of the stylesheet in development.</li>\n</ul>\n<p>By this point, we&apos;ve been able to query and filter products in Amazon wishlists, and we&apos;ve selected an item at random from each wishlist we&apos;ve queried.  Now, let&apos;s enable some purchases.</p>\n<p>The AWS provides for Remote Shopping Cart functionality, whereby items can be added to an Amazon.com shopping cart programmatically.  This is about as close as we can get to automating the purchase of items selected from the wishlists--there is no API functionality for actually completing the ordering of items.  If you really think about it, this really is a good thing and <em>should</em> demand human intervention; we certainly wouldn&apos;t want this script going crazy and accidentally buying up everything on a wishlist.</p>\n<p>Documentation for the AWS Remote Shopping Cart explains that a shopping cart can be created and items added with a URL like the following:</p>\n<pre><code>http://xml.amazon.com/onca/xml3?\nShoppingCart=add&amp;#38;\nf=xml&amp;#38;\ndev-t=[Developer Token goes here]&amp;#38;\nt=[Associates ID goes here]&amp;#38;\nAsin.[ASIN goes here]=[quantity goes here]&amp;#38;\nsims=true</code></pre>\n<p>Part of this should look familiar, so we already know what to do with the developer token and the associates ID.  The last part, specifying product ASIN and quantity, can be filled out with information contained in the product records selected at random from the wishlists.  </p>\n<p>So, let&apos;s start by revising the template at the end of the stylesheet:</p>\n<pre><code>&lt;xsl:template match=&quot;/wishes:wishes&quot;&gt;\n\n    &lt;xsl:variable name=&quot;random_products&quot;&gt;      \n      &lt;xsl:for-each select=&quot;//wishes:wishlist&quot;&gt;\n        &lt;wishes:wishitem&gt;\n          &lt;xsl:copy-of select=&quot;.&quot; /&gt;\n          &lt;xsl:call-template name=&quot;randomWishlistProduct&quot;&gt;\n            &lt;xsl:with-param name=&quot;wishlist&quot; select=&quot;.&quot; /&gt;\n          &lt;/xsl:call-template&gt;\n        &lt;/wishes:wishitem&gt;\n      &lt;/xsl:for-each&gt;\n    &lt;/xsl:variable&gt;</code></pre>\n<p>Here, we&apos;ve taken what was the output of the previous iteration of the stylesheet and stuffed it into the variable <code>$random_products</code>.  Next, let&apos;s fill in the blanks and build a Remote Shopping Cart URL:</p>\n<pre><code>    &lt;xsl:variable name=&quot;shopping_cart_create_url&quot;&gt;\n      &lt;!-- Standard AWS URL --&gt;\n      &lt;xsl:text&gt;http://xml.amazon.com/onca/xml3?&lt;/xsl:text&gt;\n\n      &lt;!-- Add in the selected items --&gt;\n      &lt;xsl:for-each select=&quot;exsl:node-set($random_products)\n                            /wishes:wishitem/Details&quot;&gt;\n        &lt;xsl:text&gt;Asin.&lt;/xsl:text&gt;&lt;xsl:value-of select=&quot;Asin&quot; /&gt;\n        &lt;xsl:text&gt;=1&amp;amp;&lt;/xsl:text&gt;\n      &lt;/xsl:for-each&gt;\n\n      &lt;!-- Wrap up with the shopping cart function and required tokens --&gt;\n      &lt;xsl:text&gt;ShoppingCart=add&amp;amp;&lt;/xsl:text&gt;\n      &lt;xsl:text&gt;f=xml&amp;amp;&lt;/xsl:text&gt;\n      &lt;xsl:text&gt;dev-t=&lt;/xsl:text&gt;&lt;xsl:value-of select=&quot;$devtoken&quot; /&gt;\n      &lt;xsl:text&gt;&amp;amp;&lt;/xsl:text&gt;\n      &lt;xsl:text&gt;t=&lt;/xsl:text&gt;&lt;xsl:value-of select=&quot;$associate&quot; /&gt;\n    &lt;/xsl:variable&gt;</code></pre>\n<p>Since simple XPath doesn&apos;t allow for the looping needed for multiple items, we can&apos;t just concatenate this URL together in a <code>select</code> expression like we did with the wishlist item query.  So, we use <code>xslt:foreach</code> to build this with blocks of text using the <code>xsl:text</code> element.  We iterate though the random products chosen from wishlists and add an ASIN for each to the URL with a quantity of 1. Then, we use the <code>$devtoken</code> and <code>$associate</code> variables to fill in their respective spots.</p>\n<p>Note that this could have been written without using the <code>xsl:text</code> elements like so:</p>\n<pre><code>    &lt;xsl:variable name=&quot;shopping_cart_create_url&quot;&gt;http://xml.amazon.\n    com/onca/xml3?ShoppingCart=add&amp;amp;f=xml&amp;amp;dev-t=&lt;xsl:value-of \n    select=&quot;$devtoken&quot; /&gt;&amp;amp;t=&lt;xsl:value-of select=&quot;$associate&quot; /&gt;\n    &amp;amp;&lt;xsl:for-each select=&quot;exsl:node-set($random_products)/\n    wishes:wishitem/Details&quot;&gt;Asin.&lt;xsl:value-of select=&quot;Asin&quot; /&gt;=1\n    &amp;amp;&lt;/xsl:for-each&gt;&lt;/xsl:variable&gt;</code></pre>\n<p>This removes the clutter of all the <code>xsl:text</code> elements, but it would need to be piled all on one line in order to keep undesired whitespace from getting into the URL.  I made a small attempt at wrapping this line here, but line breaks and spaces would leave us with a non-functioning shopping cart URL.  It&apos;s up to you to decide which to use--personally, I prefer the <code>xsl:text</code> clutter for the ability to add in comments and clarify things a bit.</p>\n<p>Finally, having built the shopping cart URL, let&apos;s use it to get a shopping cart and wrap things up:</p>\n<pre><code>    &lt;xsl:variable name=&quot;shopping_cart&quot;\n                  select=&quot;document($shopping_cart_create_url)&quot; /&gt;\n\n    &lt;xsl:copy-of select=&quot;$shopping_cart&quot; /&gt;\n\n&lt;/xsl:template&gt;  </code></pre>\n<p>As an aside, this part is pushing the concept of a REST web service a bit: In the REST philosophy, requests using the GET method (which is what <code>document()</code> uses) should only return existing resources and not create new resources or cause modifications to happen.  Instead, these sorts of actions should use a POST request.  But, since we&apos;ve already accepted a few rough edges and workarounds in this project so far, we won&apos;t let a point of esoterica like that stop us.  (That and, well, this is the way Amazon designed their web service, so we&apos;ll take what we can get.)</p>\n<p>Once you run this iteration of the stylesheet ([wishes-ex4.xsl][wishes_ex4]), you should get something like this XML as output:</p>\n<pre><code>&lt;ShoppingCartResponse ...&gt;\n  ...\n  &lt;ShoppingCart&gt;\n   &lt;CartId&gt;...&lt;/CartId&gt;\n   &lt;HMAC&gt;...&lt;/HMAC&gt;\n   &lt;PurchaseUrl&gt;...&lt;/PurchaseUrl&gt;\n   &lt;Items&gt;\n    &lt;Item&gt;...&lt;/item&gt;\n    &lt;Item&gt;...&lt;/item&gt;\n   &lt;/Items&gt;\n  &lt;/ShoppingCart&gt;\n  ...\n&lt;/ShoppingCartResponse&gt;</code></pre>\n<p>The AWS documentation describes the vital elements here like so:</p>\n<ul>\n<li><code>CartId</code> - The Cart ID is the unique identifier for a given shopping cart.</li>\n<li><code>HMAC</code> - The HMAC is a security token that must be passed back to Amazon Web Services for using an existing cart.</li>\n<li><code>PurchaseUrl</code> - Use the purchase URL to transfer the remote shopping cart from your application to Amazon so that your application&apos;s users may complete their purchases.&#xA0; The purchase URL merges the remote shopping cart with the Amazon.com shopping cart. </li>\n</ul>\n<p>So, in short, whenever we want to do any sort of manipulation on this Remote Shopping Cart via AWS, we&apos;ll need to remember and later supply both the <code>CartId</code> and <code>HMAC</code> found in the XML returned at its creation.  And, once we&apos;re all ready to check out, the <code>PurchaseUrl</code> points to where we&apos;ll need to browse in person.</p>\n<h3 id=\"stay-tuned\">Stay Tuned!</h3>\n<p>This concludes Part 2 of the Wish-of-the-Month Club.  Following this will be the final part, where we tie everything together and start firing off monthly emails!</p>\n<!-- links -->\n\n"
  },
  {
    "comments_archived": true,
    "date": "2004-06-16T11:42:48.000Z",
    "excerpt": "For some time now, my girlfriend and I have been accumulating things we want in wishlists on Amazon.com.  Though they have come in handy with relatives at Christmas and on birthdays, neither of us really expects to see a regular flow of gifts from them.  For the most part, they've just become holding tanks for things we intend to buy for each other or ourselves.  On one particular visit, though, the notion of a Wish-of-the-Month club popped into my head.",
    "layout": "post",
    "tags": [
      "hacks",
      "xml"
    ],
    "title": "Wish-of-the-Month Club, Part 1 of 3",
    "wordpress_id": 529,
    "wordpress_slug": "wishofthemonthclub1",
    "wordpress_url": "http://www.decafbad.com/blog/?p=529",
    "year": "2004",
    "month": "06",
    "day": "16",
    "isDir": false,
    "slug": "wishofthemonthclub1",
    "postName": "2004-06-16-wishofthemonthclub1",
    "html": "<p><i>Remember that <a href=\"http://www.decafbad.com/blog/2004/05/25/i_was_a_preteen_transactor_author_wannabe_and_still_am\">I wrote a little while ago</a> about wanting to publish some articles here that I&#39;d want to read?  Well, I&#39;ve been hard at work since then to turn out the first set and I think I&#39;ve finally got something for you.  I <a href=\"http://www.decafbad.com/blog/2004/06/13/i_will_do_the_fandango\">mentioned</a> earlier this week that I was taking this seriously, so I hope it shows.  So, with many thanks to <a href=\"http://missadroit.livejournal.com\" title=\"Miss Adroit, my favorite girl in the world\">my girlfriend&#39;s</a> kind editorial help, and with some measure of anxiety, here goes...</i></p>\n<h3 id=\"introduction\">Introduction</h3>\n<p>For some time now, my girlfriend and I have been accumulating things we want in wishlists on Amazon.com.  <a href=\"http://www.amazon.com/exec/obidos/registry/1QWYI6P2JF3Q5\">Here&#39;s mine</a> and <a href=\"http://www.amazon.com/exec/obidos/registry/35OIOYWQ9XQAE\">here&#39;s hers</a> - if you visit them, you can see we&#39;ve both got quite a few things listed.  Though they have come in handy with relatives at Christmas and on birthdays, neither of us really expects to see a regular flow of gifts from them.  For the most part, they&#39;ve just become holding tanks for things we intend to buy for each other or ourselves.  </p>\n<p>However, I tend to forget we have these lists except for occasional visit to Amazon when I think, &quot;Oh yeah, wishlists.  I should pick up a thing or two, there&#39;s some good stuff piled up in them.&quot;  On one particular visit, though, the notion of a Wish-of-the-Month club popped into my head: We could afford to grab at least one item for each of us from our wishlists on a monthly basis, provided that we remembered to place an order.  It&#39;d be better than signing up for a book or music club, driven by someone else&#39;s idea of what we wanted.  Unfortunately, there&#39;s that problem for busy, absentminded, and people like us: remembering to place an order.</p>\n<p>But wait, isn&#39;t this the sort of thing computers are for?  I should be able to cobble something together that would peruse our wishlists and--given some criteria like a price maximum--select an item at random for each of us and send them on their way.  With this, I could schedule a monthly run and start whittling down those lists.</p>\n<h3 id=\"gathering-tools\">Gathering Tools</h3>\n<p>Before I start working through the project itself, let&#39;s establish some assumptions and then gather some tools and materials:</p>\n<p>I&#39;m going to assume that you&#39;re using a UN*X operating system (ie. Linux, Mac OS X, etc.) and that you&#39;re reasonably familiar with getting around in a shell and editing files.  Things presented here could be adapted for Windows fairly easily, but I&#39;ll leave that as an exercise to the reader.  Also, you may need to build and install a package or two, so know-how in that regard will serve as well.  And finally: some familiarity with XML and XSLT would be useful, but you won&#39;t need to be a guru with either.</p>\n<p>Oh, and all the files I&#39;ll be introducing in this project can be downloaded from my website as a tarball:  <a href=\"http://www.decafbad.com/cvs/hacks/wishes/wishes.tar.gz?tarball=1\" title=\"All Wish-of-the-Month Club files wrapped up in a tarball\"><code>wishes.tar.gz</code></a>.  If you feel like browsing, you can see these files in my <a href=\"http://www.decafbad.com/cvs/hacks/wishes/\">CVS repository</a>.  And if you feel like checking out a copy via anonymous CVS, the username is <code>anoncvs</code> and the password is blank--email me for help, if you need it.</p>\n<p>So, how do we get a look at these wishlists?  Lately, I&#39;ve been tinkering a bit with <a href=\"http://www.decafbad.com/twiki/bin/view/Main/XslScraper\" title=\"Scrape RSS and Atom from HTML using Tidy and XSLT\">scraping information from</a> and <a href=\"http://www.amazon.com/exec/obidos/ASIN/0596005776/0xdecafbad-20\" title=\"O&#39;Reilly&#39;s Spidering Hacks\">automating access to</a> websites.  It&#39;s a bit like a puzzle game, with all the accompanying frustrations and happy breakthroughs.  However, where most puzzle games are designed with a solution in mind, this game isn&#39;t even necessarily meant to be played depending on the intentions of website owners.</p>\n<p>Fortunately, the folks at Amazon.com have made things very friendly to tinkerers by providing an API, called <a href=\"http://www.amazon.com/gp/aws/landing.html\" title=\"Amazon Web Services\">Amazon Web Services</a> (or AWS).  You&#39;ll want to <a href=\"http://www.amazon.com/gp/browse.html/ref=sc_fe_c_2/002-7899886-3676027?%5Fencoding=UTF8&#38;node=3434641&#38;no=3435361&#38;me=A36L942TSJ2AJA\">download</a> the AWS developer&#39;s kit, which contains a wealth of documentation and examples.  After downloading these materials, you should <a href=\"https://associates.amazon.com/exec/panama/associates/join/developer/application.html\">apply for a developer&#39;s token</a> for use with the service.  AWS provides both SOAP and REST interfaces to functionality and data at their site; personally, I prefer the HTTP-and-XML approach taken by the REST interface, so that&#39;s what we&#39;ll be using here. </p>\n<p>To handle the XML produced by AWS, we&#39;ll be using the <code>xsltproc</code> command from <a href=\"http://www.xmlsoft.org/XSLT.html\">the XML C parser and toolkit of Gnome</a>.  There are other XSLT processors--such as <a href=\"http://xml.apache.org/xalan-j/\">Xalan</a>, <a href=\"http://www.gingerall.com/charlie/ga/xml/p_sab.xml\">Sablotron</a>, and <a href=\"http://saxon.sourceforge.net/\">Saxon</a>--but I&#39;ve found <a href=\"http://www.xmlsoft.org/XSLT.html\">libxslt</a> easiest to feed and care for on the various platforms with which I tinker.  It also seems to support a very large swath of <a href=\"http://www.exslt.org/\">EXSLT extensions</a>, all of which come in very handy, yet seem to receive uneven support in other XSLT processors.  We&#39;ll be pulling a trick or two out of that bag, so its support is key.</p>\n<p>You may or may not already have <a href=\"http://www.xmlsoft.org/XSLT.html\">libsxlt</a> installed.  Depending on your variant of Linux, it might be as simple as a single package-management command or it might be a bit more complex if you need to compile from source.  For Mac OS X, I recommend using <a href=\"http://fink.sourceforge.net\">Fink</a> for your packaging needs.  Although, <a href=\"http://darwinports.opendarwin.org/\">DarwinPorts</a> is nice as well, if you&#39;re used to The BSD Way.</p>\n<p>A bonus for OS X users: Marc Liyanage has provided a great Open Source tool named <a href=\"http://www.entropy.ch:16080/software/macosx/#testxslt\">TestXSLT</a> that embeds <a href=\"http://www.xmlsoft.org/XSLT.html\">libxslt</a>, among other XSLT processors, in a slick GUI for easier use.  This might come in handy for you as things develop.</p>\n<h3 id=\"wishlists-in-xml\">Wishlists in XML</h3>\n<p>Okay, we&#39;ve got a working environment, a head start on accessing Amazon wishlists as XML, and a way to manipulate that XML using <code>xsltproc</code>.  Let&#39;s start playing.  First things first, we need to gain access to Amazon wishlists in XML form.  Reading through the <a href=\"http://www.amazon.com/gp/browse.html/ref=sc_fe_c_2/002-7899886-3676027?%5Fencoding=UTF8&#38;node=3434641&#38;no=3435361&#38;me=A36L942TSJ2AJA\">AWS documentation</a> reveals that wish list searches are available via a URL constructed like so:</p>\n<pre><code>http://xml.amazon.com/onca/xml3?\nt=[Associates ID goes here]&amp;#38;\ndev-t=[Developer Token goes here]&amp;#38;\nWishlistSearch=[wishlist ID goes here]&amp;#38;\ntype=[lite or heavy]&amp;#38;\nf=xml</code></pre>\n<p>I received an ID of <code>0xdecafbad-20</code> when I <a href=\"http://associates.amazon.com\">signed up to be an associate</a> a few years ago.  This will ensure that I get credited for sales made via the API--which isn&#39;t as important for the present project, since I&#39;ll be buying items myself, but it&#39;ll come in handy in later projects.  Also, when I <a href=\"https://associates.amazon.com/exec/panama/associates/join/developer/application.html\">signed up for a developer&#39;s token</a>, this is what I was given: <code>D8HVH869XA0NP</code>  I&#39;m disclosing my own here for the sake of example, but you should <a href=\"https://associates.amazon.com/exec/panama/associates/join/developer/application.html\">sign up</a> and get your own.</p>\n<p>So, that fills in the first two parts of the URL.  For the purposes of this project, let&#39;s just go with the <code>lite</code> option for type.  As for the wishlist ID, let&#39;s take a look the wishlist URLs to which I linked earlier:</p>\n<pre><code>http://www.amazon.com/exec/obidos/registry/35OIOYWQ9XQAE\nhttp://www.amazon.com/exec/obidos/registry/1QWYI6P2JF3Q5</code></pre>\n<p>You can discover these wishlist URLs using <a href=\"http://www.amazon.com/gp/registry/search.html/002-7899886-3676027?%5Fencoding=UTF8&#38;type=wishlist\">Amazon&#39;s Wish List Search</a> feature, in which case a wishlist URL might appear like so:</p>\n<pre><code>http://www.amazon.com/gp/registry/registry.html/\n002-7899886-3676027?%5Fencoding=UTF8&amp;#38;\nid=35OIOYWQ9XQAE</code></pre>\n<p>In either case, there is a 13-character ID in each variety of wish list URL: this string is the wish list ID.  So, the ID for my girlfriend&#39;s wishlist is <code> 35OIOYWQ9XQAE</code> and mine is <code>1QWYI6P2JF3Q5</code>.  Given this piece of the puzzle, we can fill in the blanks to come up with the following URL for my girlfriend&#39;s wish list:</p>\n<pre><code>http://xml.amazon.com/onca/xml3?\nt=0xdecafbad-20&amp;#38;\ndev-t=D8HVH869XA0NP&amp;#38;\ntype=lite&amp;#38;\nWishlistSearch=35OIOYWQ9XQAE&amp;#38;\nf=xml</code></pre>\n<p><a href=\"http://xml.amazon.com/onca/xml3?t=0xdecafbad-20&#38;dev-t=D8HVH869XA0NP&#38;type=lite&#38;WishlistSearch=35OIOYWQ9XQAE&#38;f=xml\">Check out the XML resulting from this URL</a>--you may want to use a tool such as <code>curl</code> or <code>wget</code> instead of viewing this directly in your browser.  You&#39;ll see some XML that looks something like this:</p>\n<pre><code>&lt;ProductInfo&gt;\n...\n&lt;Details url=&quot;(some long URL)&quot;&gt;\n  &lt;Asin&gt;0262133601&lt;/Asin&gt;\n  &lt;ProductName&gt;Foundations of Statistical Natural Language Processing&lt;/ProductName&gt;\n  &lt;Catalog&gt;Book&lt;/Catalog&gt;\n  &lt;Authors&gt;\n     &lt;Author&gt;Christopher D. Manning&lt;/Author&gt;\n     &lt;Author&gt;Hinrich Sch&amp;#252;tze&lt;/Author&gt;\n  &lt;/Authors&gt;\n  &lt;ReleaseDate&gt;18 June, 1999&lt;/ReleaseDate&gt;\n  &lt;Manufacturer&gt;MIT Press&lt;/Manufacturer&gt;\n  &lt;ImageUrlSmall&gt;(another long url)&lt;/ImageUrlSmall&gt;\n  &lt;ImageUrlMedium&gt;(yet another long url)&lt;/ImageUrlMedium&gt;\n  &lt;ImageUrlLarge&gt;(one last long url)&lt;/ImageUrlLarge&gt;\n  &lt;Availability&gt;Usually ships within 24 hours&lt;/Availability&gt;\n  &lt;ListPrice&gt;$75.00&lt;/ListPrice&gt;\n  &lt;OurPrice&gt;$63.75&lt;/OurPrice&gt;\n  &lt;UsedPrice&gt;$49.99&lt;/UsedPrice&gt;\n&lt;/Details&gt;\n...\n&lt;/ProductInfo&gt;</code></pre>\n<p>Note that the <a href=\"http://www.amazon.com/exec/obidos/ASIN/0262133601/0xdecafbad-20?dev-t=D8HVH869XA0NP%26camp=2025%26link_code=xm2\">long URL</a> in the <code>Detail</code> element&#39;s <code>url</code> attribute links to the human-viewable product detail page at Amazon.  I&#39;ve also left a few other things out, such as the URLs to product images; I just thought I&#39;d edit it a bit to be friendlier to your browser at home.  There&#39;s a <a href=\"http://xml.amazon.com/schemas3/dev-lite.xsd\">schema</a> for this XML data, and the ins-and-outs are explained in the AWS documentation under &quot;Amazon Web Services Data Model&quot;.</p>\n<h3 id=\"querying-the-wishes\">Querying The Wishes</h3>\n<p>Some ready-made files are available for this section:</p>\n<ul>\n<li><a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex1.xsl\"><code>wishes-ex1.xsl</code></a>: The first iteration of the stylesheet in development.</li>\n<li><a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.xml\"><code>wishes.xml</code></a>: An XML document used as input with the stylesheet.</li>\n</ul>\n<p>Now that we&#39;ve got some XML from Amazon to play with, let&#39;s start tinkering with an XSLT stylesheet to process it.  In the interests of flexibility and reusability, we can parameterize a few things in XML before starting in on the stylesheet:</p>\n<pre><code>&lt;wishes xmlns=&quot;http://www.decafbad.com/2004/05/wishes&quot;&gt;\n  &lt;maxprice&gt;15.00&lt;/maxprice&gt;\n  &lt;associate&gt;0xdecafbad-20&lt;/associate&gt;\n  &lt;devtoken&gt;D8HVH869XA0NP&lt;/devtoken&gt;\n  &lt;email&gt;deus_x@pobox.com&lt;/email&gt;\n  &lt;wishlists&gt;\n    &lt;wishlist label=&quot;The Girl&quot;&gt;35OIOYWQ9XQAE&lt;/wishlist&gt;\n    &lt;wishlist label=&quot;Me&quot;&gt;1QWYI6P2JF3Q5&lt;/wishlist&gt;\n  &lt;/wishlists&gt;\n&lt;/wishes&gt;</code></pre>\n<p>Hopefully, the data here is fairly self-explanatory:  I&#39;ve established a maximum price for item selection; provided my associate ID and developer token; there&#39;s an email address to which I eventually want to send the results of all this work; and I&#39;ve made a list of wishlist IDs, each with a readable label. Given this, let&#39;s start out simple and  use this to get some data from Amazon:</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;xsl:stylesheet version=&quot;1.0&quot;\n            xmlns:wishes=&quot;http://www.decafbad.com/2004/05/wishes&quot;\n            xmlns:xsl=&quot;http://www.w3.org/1999/XSL/Transform&quot;&gt;\n  &lt;xsl:output indent=&quot;yes&quot; /&gt;\n\n  &lt;!-- Grab our global settings --&gt;\n  &lt;xsl:variable name=&quot;maxprice&quot;  select=&quot;/wishes:wishes/wishes:maxprice&quot; /&gt;  \n  &lt;xsl:variable name=&quot;associate&quot; select=&quot;/wishes:wishes/wishes:associate&quot; /&gt;\n  &lt;xsl:variable name=&quot;devtoken&quot;  select=&quot;/wishes:wishes/wishes:devtoken&quot; /&gt;</code></pre>\n<p>So far so good--things start off by pulling in some of the parameters into variables.  Next, let&#39;s dig into actually querying wishlist data with a reusable template:</p>\n<pre><code>  &lt;xsl:template name=&quot;processWishlist&quot;&gt;\n    &lt;xsl:param name=&quot;wishlist&quot; /&gt;\n\n    &lt;xsl:variable name=&quot;details&quot; select=&quot;document(concat(\n        &#39;http://xml.amazon.com/onca/xml3?&#39;,\n        &#39;t=&#39;,$associate,&#39;&amp;amp;&#39;,\n        &#39;dev-t=&#39;,$devtoken,&#39;&amp;amp;&#39;,\n        &#39;WishlistSearch=&#39;,$wishlist,&#39;&amp;amp;&#39;,\n        &#39;type=lite&amp;amp;f=xml&#39;))//Details&quot; /&gt;</code></pre>\n<p>First thing into this template, we accept a parameter named <code>wishlist</code> which is expected to contain a wishlist ID string.  Next, we build an AWS URL by concatenating together the pieces we have in variables (associate ID, developer&#39;s token, and wishlist ID) using the XPath function <a href=\"http://www.w3.org/TR/2002/WD-xquery-operators-20020816/#func-concat\"><code>concat()</code></a>.  Once we have this URL, we use the function <a href=\"http://www.w3.org/TR/2002/WD-xquery-operators-20020816/#func-document\"><code>document()</code></a> to make a request and fetch the XML data for that URL.  From this, we select all the <code>Details</code> elements.  </p>\n<p>Then with that data, we can do some filtering on the price and availability.  We want to make sure that not only will we select items that are within our budget, but that they are available to buy in the first place:</p>\n<pre><code>    &lt;xsl:copy-of select=&quot;$details[\n      number(substring(OurPrice/text(),2)) &amp;lt; $maxprice\n      and\n      contains(Availability, &#39;Usually ships within&#39;)\n      ]&quot; /&gt;\n\n  &lt;/xsl:template&gt;</code></pre>\n<p>This code is just a little bit funky, since the price data given by Amazon contains a dollar sign, and we want to make a numerical comparison.  So, we chop the dollar sign off and convert to a number before making the comparison.  Also, there&#39;s an assumption here about what will show up in the <code>Availability</code> element: &quot;Usually ships within&quot;  Other things that might show up will declare that the item is out of stock, discontinued, or otherwise not shipping.  This might need some tweaking someday, but it seems to work for now.</p>\n<p>Taken all together, this template has the effect of a SQL SELECT statement somewhat like this:</p>\n<pre><code>SELECT * \nFROM Amazon.WishlistItems \nWHERE WishlistID = $wishlist AND \n      OurPrice &lt; $maxprice AND\n      Availability like &#39;%Usually ships within%&#39;;</code></pre>\n<p><code>document()</code> is a very useful XPath function.  It allows us to pull in XML from external files and, in our case, from external URLs via HTTP requests.  This gives us the ability to make queries against REST web services like AWS--which, among many other reasons, is why I prefer REST web services over SOAP.  (I don&#39;t even want to think about trying to access a SOAP service from XSLT.)</p>\n<p>Now, let&#39;s wrap up this first iteration of the stylesheet by trying out the query template on each of the wishlist IDs:</p>\n<pre><code>  &lt;xsl:template match=&quot;/wishes:wishes&quot;&gt;\n    &lt;xsl:for-each select=&quot;//wishes:wishlist&quot;&gt;\n      &lt;wishes:wishitem&gt;\n        &lt;xsl:copy-of select=&quot;.&quot; /&gt;\n        &lt;xsl:call-template name=&quot;processWishlist&quot;&gt;\n              &lt;xsl:with-param name=&quot;wishlist&quot; \n                              select=&quot;.&quot; /&gt;\n        &lt;/xsl:call-template&gt;\n      &lt;/wishes:wishitem&gt;\n    &lt;/xsl:for-each&gt;\n  &lt;/xsl:template&gt;\n\n&lt;/xsl:stylesheet&gt;</code></pre>\n<p>You can get a <a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex1.xsl\">completed version of this stylesheet</a>, along with <a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.xml\">the input XML</a>, in case you haven&#39;t been cutting and pasting together a copy of your own along the way.  Try it out in a shell with:</p>\n<pre><code>$ xsltproc wishes_ex1.xsl wishes.xml</code></pre>\n<p>Alternately, you could check it out using <a href=\"http://www.entropy.ch:16080/software/macosx/#testxslt\">TestXSLT</a> under OS X.  You should get something like the following:</p>\n<pre><code>&lt;wishes:wishitem xmlns:wishes=&quot;http://www.decafbad.com/2004/05/wishes&quot;&gt;\n    &lt;wishes:wishlist label=&quot;The Girl&quot;&gt;35OIOYWQ9XQAE&lt;/wishes:wishlist&gt;\n    &lt;Details ...&gt;...&lt;/Details&gt;\n    &lt;Details ...&gt;...&lt;/Details&gt;\n    ...\n&lt;/wishes:wishitem&gt;\n&lt;wishes:wishitem xmlns:wishes=&quot;http://www.decafbad.com/2004/05/wishes&quot;&gt;\n    &lt;wishes:wishlist label=&quot;Me&quot;&gt;1QWYI6P2JF3Q5&lt;/wishes:wishlist&gt;\n    &lt;Details ...&gt;...&lt;/Details&gt;\n    &lt;Details ...&gt;...&lt;/Details&gt;\n    ...\n&lt;/wishes:wishitem&gt;</code></pre>\n<p>Obviously, this example XML is much abridged, but hopefully you can get the gist:  For each wishlist ID, there is a containing <code>wishitem</code> element.  It contains a copy of the <code>wishlist</code> element from the input XML, followed by all the <code>Details</code> elements filtered and copied from the Amazon XML with the help of the <code>processWishlist</code> template.</p>\n<h3 id=\"thats-all-for-now\">That&#39;s All for Now!</h3>\n<p>And that&#39;s the end of Part 1.  Next up, we&#39;ll be delving into a few more wrinkles in the wishlist querying process, selecting random items in XSLT, and the Remote Shopping Cart interface in Amazon Web Services.  Stay tuned!</p>\n<!-- links -->\n\n<!--more-->\n<p>shortname=wishofthemonthclub1</p>\n<div id=\"comments\" class=\"comments archived-comments\"><h3>Archived Comments</h3>\n<ul class=\"comments\">\n<li class=\"comment\" id=\"comment-221082740\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://inflatus.net\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2c0ee9a9038c85c0510a7a5fd3f030ab&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://inflatus.net\">poepping</a>\n</div>\n<a href=\"#comment-221082740\" class=\"permalink\"><time datetime=\"2004-06-16T17:24:01\">2004-06-16T17:24:01</time></a>\n</div>\n<div class=\"content\">I was using the amazon wish list api a few months ago, and back then the wish list was out of date, and was missing the newest week or two of stuff.  You might want to check this if this is important to you.\nIn the future, you could add the feature of ordering the stuff that has a higher priority on it. :)\nCool project though. I think i'm going to go back through my old code and try it again to see if they fixed the delay.\nbtw, I miss your links of the day.</div>\n</li>\n<li class=\"comment\" id=\"comment-221082741\">\n<div class=\"meta\">\n<div class=\"author\">\n<a class=\"avatar image\" rel=\"nofollow\" \nhref=\"http://www.mpwilson.com/uccu/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=99b77c34a0e26fd04a058f8c2dbab290&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\n<a class=\"avatar name\" rel=\"nofollow\" \nhref=\"http://www.mpwilson.com/uccu/\">Mad William Flint</a>\n</div>\n<a href=\"#comment-221082741\" class=\"permalink\"><time datetime=\"2004-06-16T19:40:55\">2004-06-16T19:40:55</time></a>\n</div>\n<div class=\"content\">very nice.  whipping out my emacs now...</div>\n</li>\n</ul>\n</div>\n",
    "body": "<i>Remember that [I wrote a little while ago][lasttime] about wanting to publish some articles here that I'd want to read?  Well, I've been hard at work since then to turn out the first set and I think I've finally got something for you.  I [mentioned][lasttime2] earlier this week that I was taking this seriously, so I hope it shows.  So, with many thanks to [my girlfriend's][missadroit] kind editorial help, and with some measure of anxiety, here goes...</i>\r\n\r\n### Introduction\r\n\r\nFor some time now, my girlfriend and I have been accumulating things we want in wishlists on Amazon.com.  [Here's mine][mywishlist] and [here's hers][herwishlist] - if you visit them, you can see we've both got quite a few things listed.  Though they have come in handy with relatives at Christmas and on birthdays, neither of us really expects to see a regular flow of gifts from them.  For the most part, they've just become holding tanks for things we intend to buy for each other or ourselves.  \r\n\r\nHowever, I tend to forget we have these lists except for occasional visit to Amazon when I think, \"Oh yeah, wishlists.  I should pick up a thing or two, there's some good stuff piled up in them.\"  On one particular visit, though, the notion of a Wish-of-the-Month club popped into my head: We could afford to grab at least one item for each of us from our wishlists on a monthly basis, provided that we remembered to place an order.  It'd be better than signing up for a book or music club, driven by someone else's idea of what we wanted.  Unfortunately, there's that problem for busy, absentminded, and people like us: remembering to place an order.\r\n\r\nBut wait, isn't this the sort of thing computers are for?  I should be able to cobble something together that would peruse our wishlists and--given some criteria like a price maximum--select an item at random for each of us and send them on their way.  With this, I could schedule a monthly run and start whittling down those lists.\r\n\r\n### Gathering Tools\r\n\r\nBefore I start working through the project itself, let's establish some assumptions and then gather some tools and materials:\r\n\r\nI'm going to assume that you're using a UN*X operating system (ie. Linux, Mac OS X, etc.) and that you're reasonably familiar with getting around in a shell and editing files.  Things presented here could be adapted for Windows fairly easily, but I'll leave that as an exercise to the reader.  Also, you may need to build and install a package or two, so know-how in that regard will serve as well.  And finally: some familiarity with XML and XSLT would be useful, but you won't need to be a guru with either.\r\n\r\nOh, and all the files I'll be introducing in this project can be downloaded from my website as a tarball:  [`wishes.tar.gz`][wishes.tar.gz].  If you feel like browsing, you can see these files in my [CVS repository][wishescvs].  And if you feel like checking out a copy via anonymous CVS, the username is `anoncvs` and the password is blank--email me for help, if you need it.\r\n\r\nSo, how do we get a look at these wishlists?  Lately, I've been tinkering a bit with [scraping information from][xslscraper] and [automating access to][spideringhacks] websites.  It's a bit like a puzzle game, with all the accompanying frustrations and happy breakthroughs.  However, where most puzzle games are designed with a solution in mind, this game isn't even necessarily meant to be played depending on the intentions of website owners.\r\n\r\nFortunately, the folks at Amazon.com have made things very friendly to tinkerers by providing an API, called [Amazon Web Services][amazonapi] (or AWS).  You'll want to [download][awsdownload] the AWS developer's kit, which contains a wealth of documentation and examples.  After downloading these materials, you should [apply for a developer's token][awstoken] for use with the service.  AWS provides both SOAP and REST interfaces to functionality and data at their site; personally, I prefer the HTTP-and-XML approach taken by the REST interface, so that's what we'll be using here. \r\n\r\nTo handle the XML produced by AWS, we'll be using the `xsltproc` command from [the XML C parser and toolkit of Gnome][libxslt].  There are other XSLT processors--such as [Xalan][xalan], [Sablotron][sablotron], and [Saxon][saxon]--but I've found [libxslt][libxslt] easiest to feed and care for on the various platforms with which I tinker.  It also seems to support a very large swath of [EXSLT extensions][exslt], all of which come in very handy, yet seem to receive uneven support in other XSLT processors.  We'll be pulling a trick or two out of that bag, so its support is key.\r\n\r\nYou may or may not already have [libsxlt][libxslt] installed.  Depending on your variant of Linux, it might be as simple as a single package-management command or it might be a bit more complex if you need to compile from source.  For Mac OS X, I recommend using [Fink][fink] for your packaging needs.  Although, [DarwinPorts][darwinports] is nice as well, if you're used to The BSD Way.\r\n\r\nA bonus for OS X users: Marc Liyanage has provided a great Open Source tool named [TestXSLT][testxslt] that embeds [libxslt][libxslt], among other XSLT processors, in a slick GUI for easier use.  This might come in handy for you as things develop.\r\n\r\n### Wishlists in XML\r\n\r\nOkay, we've got a working environment, a head start on accessing Amazon wishlists as XML, and a way to manipulate that XML using `xsltproc`.  Let's start playing.  First things first, we need to gain access to Amazon wishlists in XML form.  Reading through the [AWS documentation][awsdownload] reveals that wish list searches are available via a URL constructed like so:\r\n\r\n    http://xml.amazon.com/onca/xml3?\r\n    t=[Associates ID goes here]&#38;\r\n    dev-t=[Developer Token goes here]&#38;\r\n    WishlistSearch=[wishlist ID goes here]&#38;\r\n    type=[lite or heavy]&#38;\r\n    f=xml\r\n\r\nI received an ID of `0xdecafbad-20` when I [signed up to be an associate][amazonassociate] a few years ago.  This will ensure that I get credited for sales made via the API--which isn't as important for the present project, since I'll be buying items myself, but it'll come in handy in later projects.  Also, when I [signed up for a developer's token][awstoken], this is what I was given: `D8HVH869XA0NP`  I'm disclosing my own here for the sake of example, but you should [sign up][awstoken] and get your own.\r\n\r\nSo, that fills in the first two parts of the URL.  For the purposes of this project, let's just go with the `lite` option for type.  As for the wishlist ID, let's take a look the wishlist URLs to which I linked earlier:\r\n\r\n    http://www.amazon.com/exec/obidos/registry/35OIOYWQ9XQAE\r\n    http://www.amazon.com/exec/obidos/registry/1QWYI6P2JF3Q5\r\n\r\nYou can discover these wishlist URLs using [Amazon's Wish List Search][wlsearch] feature, in which case a wishlist URL might appear like so:\r\n\r\n    http://www.amazon.com/gp/registry/registry.html/\r\n    002-7899886-3676027?%5Fencoding=UTF8&#38;\r\n    id=35OIOYWQ9XQAE\r\n\r\nIn either case, there is a 13-character ID in each variety of wish list URL: this string is the wish list ID.  So, the ID for my girlfriend's wishlist is ` 35OIOYWQ9XQAE` and mine is `1QWYI6P2JF3Q5`.  Given this piece of the puzzle, we can fill in the blanks to come up with the following URL for my girlfriend's wish list:\r\n\r\n    http://xml.amazon.com/onca/xml3?\r\n    t=0xdecafbad-20&#38;\r\n    dev-t=D8HVH869XA0NP&#38;\r\n    type=lite&#38;\r\n    WishlistSearch=35OIOYWQ9XQAE&#38;\r\n    f=xml\r\n\r\n[Check out the XML resulting from this URL][wlurl]--you may want to use a tool such as `curl` or `wget` instead of viewing this directly in your browser.  You'll see some XML that looks something like this:\r\n\r\n    <ProductInfo>\r\n    ...\r\n    <Details url=\"(some long URL)\">\r\n      <Asin>0262133601</Asin>\r\n      <ProductName>Foundations of Statistical Natural Language Processing</ProductName>\r\n      <Catalog>Book</Catalog>\r\n      <Authors>\r\n         <Author>Christopher D. Manning</Author>\r\n         <Author>Hinrich Sch&#252;tze</Author>\r\n      </Authors>\r\n      <ReleaseDate>18 June, 1999</ReleaseDate>\r\n      <Manufacturer>MIT Press</Manufacturer>\r\n      <ImageUrlSmall>(another long url)</ImageUrlSmall>\r\n      <ImageUrlMedium>(yet another long url)</ImageUrlMedium>\r\n      <ImageUrlLarge>(one last long url)</ImageUrlLarge>\r\n      <Availability>Usually ships within 24 hours</Availability>\r\n      <ListPrice>$75.00</ListPrice>\r\n      <OurPrice>$63.75</OurPrice>\r\n      <UsedPrice>$49.99</UsedPrice>\r\n    </Details>\r\n    ...\r\n    </ProductInfo>\r\n\r\nNote that the [long URL][detailsurl] in the `Detail` element's `url` attribute links to the human-viewable product detail page at Amazon.  I've also left a few other things out, such as the URLs to product images; I just thought I'd edit it a bit to be friendlier to your browser at home.  There's a [schema][awslite] for this XML data, and the ins-and-outs are explained in the AWS documentation under \"Amazon Web Services Data Model\".\r\n\r\n### Querying The Wishes\r\n\r\nSome ready-made files are available for this section:\r\n* [`wishes-ex1.xsl`][wishes-ex1.xsl]: The first iteration of the stylesheet in development.\r\n* [`wishes.xml`][wishes.xml]: An XML document used as input with the stylesheet.\r\n\r\nNow that we've got some XML from Amazon to play with, let's start tinkering with an XSLT stylesheet to process it.  In the interests of flexibility and reusability, we can parameterize a few things in XML before starting in on the stylesheet:\r\n\r\n    <wishes xmlns=\"http://www.decafbad.com/2004/05/wishes\">\r\n      <maxprice>15.00</maxprice>\r\n      <associate>0xdecafbad-20</associate>\r\n      <devtoken>D8HVH869XA0NP</devtoken>\r\n      <email>deus_x@pobox.com</email>\r\n      <wishlists>\r\n        <wishlist label=\"The Girl\">35OIOYWQ9XQAE</wishlist>\r\n        <wishlist label=\"Me\">1QWYI6P2JF3Q5</wishlist>\r\n      </wishlists>\r\n    </wishes>\r\n\r\nHopefully, the data here is fairly self-explanatory:  I've established a maximum price for item selection; provided my associate ID and developer token; there's an email address to which I eventually want to send the results of all this work; and I've made a list of wishlist IDs, each with a readable label. Given this, let's start out simple and  use this to get some data from Amazon:\r\n\r\n    <?xml version=\"1.0\"?>\r\n    <xsl:stylesheet version=\"1.0\"\r\n                xmlns:wishes=\"http://www.decafbad.com/2004/05/wishes\"\r\n                xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\">\r\n      <xsl:output indent=\"yes\" />\r\n\r\n      <!-- Grab our global settings -->\r\n      <xsl:variable name=\"maxprice\"  select=\"/wishes:wishes/wishes:maxprice\" />  \r\n      <xsl:variable name=\"associate\" select=\"/wishes:wishes/wishes:associate\" />\r\n      <xsl:variable name=\"devtoken\"  select=\"/wishes:wishes/wishes:devtoken\" />\r\n\r\nSo far so good--things start off by pulling in some of the parameters into variables.  Next, let's dig into actually querying wishlist data with a reusable template:\r\n\r\n      <xsl:template name=\"processWishlist\">\r\n        <xsl:param name=\"wishlist\" />\r\n\r\n        <xsl:variable name=\"details\" select=\"document(concat(\r\n            'http://xml.amazon.com/onca/xml3?',\r\n            't=',$associate,'&amp;',\r\n            'dev-t=',$devtoken,'&amp;',\r\n            'WishlistSearch=',$wishlist,'&amp;',\r\n            'type=lite&amp;f=xml'))//Details\" />\r\n\r\nFirst thing into this template, we accept a parameter named `wishlist` which is expected to contain a wishlist ID string.  Next, we build an AWS URL by concatenating together the pieces we have in variables (associate ID, developer's token, and wishlist ID) using the XPath function [`concat()`][xpconcat].  Once we have this URL, we use the function [`document()`][xpdocument] to make a request and fetch the XML data for that URL.  From this, we select all the `Details` elements.  \r\n\r\nThen with that data, we can do some filtering on the price and availability.  We want to make sure that not only will we select items that are within our budget, but that they are available to buy in the first place:\r\n\r\n        <xsl:copy-of select=\"$details[\r\n          number(substring(OurPrice/text(),2)) &lt; $maxprice\r\n          and\r\n          contains(Availability, 'Usually ships within')\r\n          ]\" />\r\n\r\n      </xsl:template>\r\n\r\nThis code is just a little bit funky, since the price data given by Amazon contains a dollar sign, and we want to make a numerical comparison.  So, we chop the dollar sign off and convert to a number before making the comparison.  Also, there's an assumption here about what will show up in the `Availability` element: \"Usually ships within\"  Other things that might show up will declare that the item is out of stock, discontinued, or otherwise not shipping.  This might need some tweaking someday, but it seems to work for now.\r\n\r\nTaken all together, this template has the effect of a SQL SELECT statement somewhat like this:\r\n\r\n    SELECT * \r\n    FROM Amazon.WishlistItems \r\n    WHERE WishlistID = $wishlist AND \r\n          OurPrice < $maxprice AND\r\n          Availability like '%Usually ships within%';\r\n\r\n`document()` is a very useful XPath function.  It allows us to pull in XML from external files and, in our case, from external URLs via HTTP requests.  This gives us the ability to make queries against REST web services like AWS--which, among many other reasons, is why I prefer REST web services over SOAP.  (I don't even want to think about trying to access a SOAP service from XSLT.)\r\n\r\nNow, let's wrap up this first iteration of the stylesheet by trying out the query template on each of the wishlist IDs:\r\n\r\n      <xsl:template match=\"/wishes:wishes\">\r\n        <xsl:for-each select=\"//wishes:wishlist\">\r\n          <wishes:wishitem>\r\n            <xsl:copy-of select=\".\" />\r\n            <xsl:call-template name=\"processWishlist\">\r\n                  <xsl:with-param name=\"wishlist\" \r\n                                  select=\".\" />\r\n            </xsl:call-template>\r\n          </wishes:wishitem>\r\n        </xsl:for-each>\r\n      </xsl:template>\r\n  \r\n    </xsl:stylesheet>\r\n\r\nYou can get a [completed version of this stylesheet][wishes-ex1.xsl], along with [the input XML][wishes.xml], in case you haven't been cutting and pasting together a copy of your own along the way.  Try it out in a shell with:\r\n\r\n    $ xsltproc wishes_ex1.xsl wishes.xml\r\n\r\nAlternately, you could check it out using [TestXSLT][testxslt] under OS X.  You should get something like the following:\r\n\r\n    <wishes:wishitem xmlns:wishes=\"http://www.decafbad.com/2004/05/wishes\">\r\n        <wishes:wishlist label=\"The Girl\">35OIOYWQ9XQAE</wishes:wishlist>\r\n        <Details ...>...</Details>\r\n        <Details ...>...</Details>\r\n        ...\r\n    </wishes:wishitem>\r\n    <wishes:wishitem xmlns:wishes=\"http://www.decafbad.com/2004/05/wishes\">\r\n        <wishes:wishlist label=\"Me\">1QWYI6P2JF3Q5</wishes:wishlist>\r\n        <Details ...>...</Details>\r\n        <Details ...>...</Details>\r\n        ...\r\n    </wishes:wishitem>\r\n\r\nObviously, this example XML is much abridged, but hopefully you can get the gist:  For each wishlist ID, there is a containing `wishitem` element.  It contains a copy of the `wishlist` element from the input XML, followed by all the `Details` elements filtered and copied from the Amazon XML with the help of the `processWishlist` template.\r\n\r\n### That's All for Now!\r\n\r\nAnd that's the end of Part 1.  Next up, we'll be delving into a few more wrinkles in the wishlist querying process, selecting random items in XSLT, and the Remote Shopping Cart interface in Amazon Web Services.  Stay tuned!\r\n\r\n<!-- links -->\r\n\r\n[missadroit]: http://missadroit.livejournal.com \"Miss Adroit, my favorite girl in the world\"\r\n[mywishlist]: http://www.amazon.com/exec/obidos/registry/1QWYI6P2JF3Q5 \r\n[herwishlist]: http://www.amazon.com/exec/obidos/registry/35OIOYWQ9XQAE \r\n[amazonapi]: http://www.amazon.com/gp/aws/landing.html \"Amazon Web Services\"\r\n[libxml]: http://www.xmlsoft.org/\r\n[xalan]: http://xml.apache.org/xalan-j/\r\n[sablotron]: http://www.gingerall.com/charlie/ga/xml/p_sab.xml\r\n[saxon]: http://saxon.sourceforge.net/\r\n[exslt]: http://www.exslt.org/\r\n[libxslt]: http://www.xmlsoft.org/XSLT.html\r\n[spideringhacks]: http://www.amazon.com/exec/obidos/ASIN/0596005776/0xdecafbad-20 \"O'Reilly's Spidering Hacks\"\r\n[xslscraper]: http://www.decafbad.com/twiki/bin/view/Main/XslScraper \"Scrape RSS and Atom from HTML using Tidy and XSLT\"\r\n[awsdownload]: http://www.amazon.com/gp/browse.html/ref=sc_fe_c_2/002-7899886-3676027?%5Fencoding=UTF8&#38;node=3434641&#38;no=3435361&#38;me=A36L942TSJ2AJA\r\n[awstoken]: https://associates.amazon.com/exec/panama/associates/join/developer/application.html\r\n[amazonassociate]: http://associates.amazon.com\r\n[wlsearch]: http://www.amazon.com/gp/registry/search.html/002-7899886-3676027?%5Fencoding=UTF8&#38;type=wishlist\r\n[wlurl]: http://xml.amazon.com/onca/xml3?t=0xdecafbad-20&#38;dev-t=D8HVH869XA0NP&#38;type=lite&#38;WishlistSearch=35OIOYWQ9XQAE&#38;f=xml\r\n[detailsurl]: http://www.amazon.com/exec/obidos/ASIN/0262133601/0xdecafbad-20?dev-t=D8HVH869XA0NP%26camp=2025%26link_code=xm2\r\n[awslite]: http://xml.amazon.com/schemas3/dev-lite.xsd\r\n[fink]: http://fink.sourceforge.net\r\n[testxslt]: http://www.entropy.ch:16080/software/macosx/#testxslt\r\n[darwinports]: http://darwinports.opendarwin.org/\r\n[curl]: http://www.decafbad.com/#TODO\r\n[wget]: http://www.decafbad.com/#TODO\r\n[xpconcat]: http://www.w3.org/TR/2002/WD-xquery-operators-20020816/#func-concat\r\n[xpdocument]: http://www.w3.org/TR/2002/WD-xquery-operators-20020816/#func-document\r\n[wishescvs]: http://www.decafbad.com/cvs/hacks/wishes/\r\n[wishes.tar.gz]: http://www.decafbad.com/cvs/hacks/wishes/wishes.tar.gz?tarball=1 \"All Wish-of-the-Month Club files wrapped up in a tarball\"\r\n[wishes.xml]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.xml\r\n[wishes-ex1.xsl]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex1.xsl\r\n[wishes-ex2.xsl]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex2.xsl\r\n[wishes-ex3.xsl]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex3.xsl\r\n[wishes-ex4.xsl]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex4.xsl\r\n[wishes-ex5.xsl]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex5.xsl\r\n[wishes-ex6.xsl]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex6.xsl\r\n[random-xml]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/random-xml\r\n[wishes_html_screenshot]: http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.jpg\r\n[xslt_iteration]: http://www.dpawson.co.uk/xsl/sect2/N4806.html \"Iteration in XSLT\"\r\n[xslt_recursion]: http://www-106.ibm.com/developerworks/xml/library/x-xslrecur/ \"Use recursion effectively in XSL\"\r\n[exsl_random]: http://www.exslt.org/math/functions/random/index.html\r\n[exsl_node_set]: http://www.exslt.org/exsl/functions/node-set/index.html\r\n[rand_url]: http://www.decafbad.com/2004/05/random-xml?int=1&#38;min=10&#38;max=20 \"A random integer between 10 and 20, in XML\"\r\n[xslt_result_tree_fragment]: http://www.w3.org/TR/xslt#section-Result-Tree-Fragments\r\n\r\n[email_attach_anatomy]: http://www.dpo.uab.edu/Email/attach.html \"Anatomy of an Email Attachment\"\r\n[email_mime_and_html]: http://www.abiglime.com/webmaster/articles/cgi/010698.htm \"How to encapsulate HTML in an email message\"\r\n\r\n[email_html_and_text]: http://www.wilsonweb.com/wmt5/html-email-multi.htm \"Sending HTML and Plain Text E-Mail Simultaneously\"\r\n[man_sendmail]: http://www.hmug.org/man/8/sendmail.html \"man: sendmail\"\r\n[rfc1521]: http://www.faqs.org/rfcs/rfc1521.html \"RFC 1521\"\r\n[cron1]: http://www.lysator.liu.se/~forsberg/linux/cron.html \"Doing things periodically - Using CRON\"\r\n[cron2]: http://www.itworld.com/Comp/2378/swol-0825-unix101/ \"Using cron basics\"\r\n[python_libxml]: http://xmlsoft.org/python.html \r\n[lasttime]: http://www.decafbad.com/blog/2004/05/25/i_was_a_preteen_transactor_author_wannabe_and_still_am\r\n[lasttime2]: http://www.decafbad.com/blog/2004/06/13/i_will_do_the_fandango\r\n<!--more-->\r\nshortname=wishofthemonthclub1\r\n\r\n<div id=\"comments\" class=\"comments archived-comments\">\r\n            <h3>Archived Comments</h3>\r\n            \r\n        <ul class=\"comments\">\r\n            \r\n        <li class=\"comment\" id=\"comment-221082740\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://inflatus.net\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=2c0ee9a9038c85c0510a7a5fd3f030ab&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://inflatus.net\">poepping</a>\r\n                </div>\r\n                <a href=\"#comment-221082740\" class=\"permalink\"><time datetime=\"2004-06-16T17:24:01\">2004-06-16T17:24:01</time></a>\r\n            </div>\r\n            <div class=\"content\">I was using the amazon wish list api a few months ago, and back then the wish list was out of date, and was missing the newest week or two of stuff.  You might want to check this if this is important to you.\r\n\r\nIn the future, you could add the feature of ordering the stuff that has a higher priority on it. :)\r\n\r\nCool project though. I think i'm going to go back through my old code and try it again to see if they fixed the delay.\r\n\r\nbtw, I miss your links of the day.</div>\r\n            \r\n        </li>\r\n    \r\n        <li class=\"comment\" id=\"comment-221082741\">\r\n            <div class=\"meta\">\r\n                <div class=\"author\">\r\n                    <a class=\"avatar image\" rel=\"nofollow\" \r\n                       href=\"http://www.mpwilson.com/uccu/\"><img src=\"http://www.gravatar.com/avatar.php?gravatar_id=99b77c34a0e26fd04a058f8c2dbab290&amp;size=32&amp;default=http://mediacdn.disqus.com/1320279820/images/noavatar32.png\"/></a>\r\n                    <a class=\"avatar name\" rel=\"nofollow\" \r\n                       href=\"http://www.mpwilson.com/uccu/\">Mad William Flint</a>\r\n                </div>\r\n                <a href=\"#comment-221082741\" class=\"permalink\"><time datetime=\"2004-06-16T19:40:55\">2004-06-16T19:40:55</time></a>\r\n            </div>\r\n            <div class=\"content\">very nice.  whipping out my emacs now...</div>\r\n            \r\n        </li>\r\n    \r\n        </ul>\r\n    \r\n        </div>\r\n    ",
    "parentPath": "../blog.lmorchard.com/posts/archives/2004",
    "path": "2004/06/16/wishofthemonthclub1",
    "summary": "<p><i>Remember that <a href=\"http://www.decafbad.com/blog/2004/05/25/i_was_a_preteen_transactor_author_wannabe_and_still_am\">I wrote a little while ago</a> about wanting to publish some articles here that I&apos;d want to read?  Well, I&apos;ve been hard at work since then to turn out the first set and I think I&apos;ve finally got something for you.  I <a href=\"http://www.decafbad.com/blog/2004/06/13/i_will_do_the_fandango\">mentioned</a> earlier this week that I was taking this seriously, so I hope it shows.  So, with many thanks to <a href=\"http://missadroit.livejournal.com\" title=\"Miss Adroit, my favorite girl in the world\">my girlfriend&apos;s</a> kind editorial help, and with some measure of anxiety, here goes...</i></p>\n<h3 id=\"introduction\">Introduction</h3>\n<p>For some time now, my girlfriend and I have been accumulating things we want in wishlists on Amazon.com.  <a href=\"http://www.amazon.com/exec/obidos/registry/1QWYI6P2JF3Q5\">Here&apos;s mine</a> and <a href=\"http://www.amazon.com/exec/obidos/registry/35OIOYWQ9XQAE\">here&apos;s hers</a> - if you visit them, you can see we&apos;ve both got quite a few things listed.  Though they have come in handy with relatives at Christmas and on birthdays, neither of us really expects to see a regular flow of gifts from them.  For the most part, they&apos;ve just become holding tanks for things we intend to buy for each other or ourselves.  </p>\n<p>However, I tend to forget we have these lists except for occasional visit to Amazon when I think, &quot;Oh yeah, wishlists.  I should pick up a thing or two, there&apos;s some good stuff piled up in them.&quot;  On one particular visit, though, the notion of a Wish-of-the-Month club popped into my head: We could afford to grab at least one item for each of us from our wishlists on a monthly basis, provided that we remembered to place an order.  It&apos;d be better than signing up for a book or music club, driven by someone else&apos;s idea of what we wanted.  Unfortunately, there&apos;s that problem for busy, absentminded, and people like us: remembering to place an order.</p>\n<p>But wait, isn&apos;t this the sort of thing computers are for?  I should be able to cobble something together that would peruse our wishlists and--given some criteria like a price maximum--select an item at random for each of us and send them on their way.  With this, I could schedule a monthly run and start whittling down those lists.</p>\n<h3 id=\"gathering-tools\">Gathering Tools</h3>\n<p>Before I start working through the project itself, let&apos;s establish some assumptions and then gather some tools and materials:</p>\n<p>I&apos;m going to assume that you&apos;re using a UN*X operating system (ie. Linux, Mac OS X, etc.) and that you&apos;re reasonably familiar with getting around in a shell and editing files.  Things presented here could be adapted for Windows fairly easily, but I&apos;ll leave that as an exercise to the reader.  Also, you may need to build and install a package or two, so know-how in that regard will serve as well.  And finally: some familiarity with XML and XSLT would be useful, but you won&apos;t need to be a guru with either.</p>\n<p>Oh, and all the files I&apos;ll be introducing in this project can be downloaded from my website as a tarball:  <a href=\"http://www.decafbad.com/cvs/hacks/wishes/wishes.tar.gz?tarball=1\" title=\"All Wish-of-the-Month Club files wrapped up in a tarball\"><code>wishes.tar.gz</code></a>.  If you feel like browsing, you can see these files in my <a href=\"http://www.decafbad.com/cvs/hacks/wishes/\">CVS repository</a>.  And if you feel like checking out a copy via anonymous CVS, the username is <code>anoncvs</code> and the password is blank--email me for help, if you need it.</p>\n<p>So, how do we get a look at these wishlists?  Lately, I&apos;ve been tinkering a bit with <a href=\"http://www.decafbad.com/twiki/bin/view/Main/XslScraper\" title=\"Scrape RSS and Atom from HTML using Tidy and XSLT\">scraping information from</a> and <a href=\"http://www.amazon.com/exec/obidos/ASIN/0596005776/0xdecafbad-20\" title=\"O&apos;Reilly&apos;s Spidering Hacks\">automating access to</a> websites.  It&apos;s a bit like a puzzle game, with all the accompanying frustrations and happy breakthroughs.  However, where most puzzle games are designed with a solution in mind, this game isn&apos;t even necessarily meant to be played depending on the intentions of website owners.</p>\n<p>Fortunately, the folks at Amazon.com have made things very friendly to tinkerers by providing an API, called <a href=\"http://www.amazon.com/gp/aws/landing.html\" title=\"Amazon Web Services\">Amazon Web Services</a> (or AWS).  You&apos;ll want to <a href=\"http://www.amazon.com/gp/browse.html/ref=sc_fe_c_2/002-7899886-3676027?%5Fencoding=UTF8&amp;node=3434641&amp;no=3435361&amp;me=A36L942TSJ2AJA\">download</a> the AWS developer&apos;s kit, which contains a wealth of documentation and examples.  After downloading these materials, you should <a href=\"https://associates.amazon.com/exec/panama/associates/join/developer/application.html\">apply for a developer&apos;s token</a> for use with the service.  AWS provides both SOAP and REST interfaces to functionality and data at their site; personally, I prefer the HTTP-and-XML approach taken by the REST interface, so that&apos;s what we&apos;ll be using here. </p>\n<p>To handle the XML produced by AWS, we&apos;ll be using the <code>xsltproc</code> command from <a href=\"http://www.xmlsoft.org/XSLT.html\">the XML C parser and toolkit of Gnome</a>.  There are other XSLT processors--such as <a href=\"http://xml.apache.org/xalan-j/\">Xalan</a>, <a href=\"http://www.gingerall.com/charlie/ga/xml/p_sab.xml\">Sablotron</a>, and <a href=\"http://saxon.sourceforge.net/\">Saxon</a>--but I&apos;ve found <a href=\"http://www.xmlsoft.org/XSLT.html\">libxslt</a> easiest to feed and care for on the various platforms with which I tinker.  It also seems to support a very large swath of <a href=\"http://www.exslt.org/\">EXSLT extensions</a>, all of which come in very handy, yet seem to receive uneven support in other XSLT processors.  We&apos;ll be pulling a trick or two out of that bag, so its support is key.</p>\n<p>You may or may not already have <a href=\"http://www.xmlsoft.org/XSLT.html\">libsxlt</a> installed.  Depending on your variant of Linux, it might be as simple as a single package-management command or it might be a bit more complex if you need to compile from source.  For Mac OS X, I recommend using <a href=\"http://fink.sourceforge.net\">Fink</a> for your packaging needs.  Although, <a href=\"http://darwinports.opendarwin.org/\">DarwinPorts</a> is nice as well, if you&apos;re used to The BSD Way.</p>\n<p>A bonus for OS X users: Marc Liyanage has provided a great Open Source tool named <a href=\"http://www.entropy.ch:16080/software/macosx/#testxslt\">TestXSLT</a> that embeds <a href=\"http://www.xmlsoft.org/XSLT.html\">libxslt</a>, among other XSLT processors, in a slick GUI for easier use.  This might come in handy for you as things develop.</p>\n<h3 id=\"wishlists-in-xml\">Wishlists in XML</h3>\n<p>Okay, we&apos;ve got a working environment, a head start on accessing Amazon wishlists as XML, and a way to manipulate that XML using <code>xsltproc</code>.  Let&apos;s start playing.  First things first, we need to gain access to Amazon wishlists in XML form.  Reading through the <a href=\"http://www.amazon.com/gp/browse.html/ref=sc_fe_c_2/002-7899886-3676027?%5Fencoding=UTF8&amp;node=3434641&amp;no=3435361&amp;me=A36L942TSJ2AJA\">AWS documentation</a> reveals that wish list searches are available via a URL constructed like so:</p>\n<pre><code>http://xml.amazon.com/onca/xml3?\nt=[Associates ID goes here]&amp;#38;\ndev-t=[Developer Token goes here]&amp;#38;\nWishlistSearch=[wishlist ID goes here]&amp;#38;\ntype=[lite or heavy]&amp;#38;\nf=xml</code></pre>\n<p>I received an ID of <code>0xdecafbad-20</code> when I <a href=\"http://associates.amazon.com\">signed up to be an associate</a> a few years ago.  This will ensure that I get credited for sales made via the API--which isn&apos;t as important for the present project, since I&apos;ll be buying items myself, but it&apos;ll come in handy in later projects.  Also, when I <a href=\"https://associates.amazon.com/exec/panama/associates/join/developer/application.html\">signed up for a developer&apos;s token</a>, this is what I was given: <code>D8HVH869XA0NP</code>  I&apos;m disclosing my own here for the sake of example, but you should <a href=\"https://associates.amazon.com/exec/panama/associates/join/developer/application.html\">sign up</a> and get your own.</p>\n<p>So, that fills in the first two parts of the URL.  For the purposes of this project, let&apos;s just go with the <code>lite</code> option for type.  As for the wishlist ID, let&apos;s take a look the wishlist URLs to which I linked earlier:</p>\n<pre><code>http://www.amazon.com/exec/obidos/registry/35OIOYWQ9XQAE\nhttp://www.amazon.com/exec/obidos/registry/1QWYI6P2JF3Q5</code></pre>\n<p>You can discover these wishlist URLs using <a href=\"http://www.amazon.com/gp/registry/search.html/002-7899886-3676027?%5Fencoding=UTF8&amp;type=wishlist\">Amazon&apos;s Wish List Search</a> feature, in which case a wishlist URL might appear like so:</p>\n<pre><code>http://www.amazon.com/gp/registry/registry.html/\n002-7899886-3676027?%5Fencoding=UTF8&amp;#38;\nid=35OIOYWQ9XQAE</code></pre>\n<p>In either case, there is a 13-character ID in each variety of wish list URL: this string is the wish list ID.  So, the ID for my girlfriend&apos;s wishlist is <code> 35OIOYWQ9XQAE</code> and mine is <code>1QWYI6P2JF3Q5</code>.  Given this piece of the puzzle, we can fill in the blanks to come up with the following URL for my girlfriend&apos;s wish list:</p>\n<pre><code>http://xml.amazon.com/onca/xml3?\nt=0xdecafbad-20&amp;#38;\ndev-t=D8HVH869XA0NP&amp;#38;\ntype=lite&amp;#38;\nWishlistSearch=35OIOYWQ9XQAE&amp;#38;\nf=xml</code></pre>\n<p><a href=\"http://xml.amazon.com/onca/xml3?t=0xdecafbad-20&amp;dev-t=D8HVH869XA0NP&amp;type=lite&amp;WishlistSearch=35OIOYWQ9XQAE&amp;f=xml\">Check out the XML resulting from this URL</a>--you may want to use a tool such as <code>curl</code> or <code>wget</code> instead of viewing this directly in your browser.  You&apos;ll see some XML that looks something like this:</p>\n<pre><code>&lt;ProductInfo&gt;\n...\n&lt;Details url=&quot;(some long URL)&quot;&gt;\n  &lt;Asin&gt;0262133601&lt;/Asin&gt;\n  &lt;ProductName&gt;Foundations of Statistical Natural Language Processing&lt;/ProductName&gt;\n  &lt;Catalog&gt;Book&lt;/Catalog&gt;\n  &lt;Authors&gt;\n     &lt;Author&gt;Christopher D. Manning&lt;/Author&gt;\n     &lt;Author&gt;Hinrich Sch&amp;#252;tze&lt;/Author&gt;\n  &lt;/Authors&gt;\n  &lt;ReleaseDate&gt;18 June, 1999&lt;/ReleaseDate&gt;\n  &lt;Manufacturer&gt;MIT Press&lt;/Manufacturer&gt;\n  &lt;ImageUrlSmall&gt;(another long url)&lt;/ImageUrlSmall&gt;\n  &lt;ImageUrlMedium&gt;(yet another long url)&lt;/ImageUrlMedium&gt;\n  &lt;ImageUrlLarge&gt;(one last long url)&lt;/ImageUrlLarge&gt;\n  &lt;Availability&gt;Usually ships within 24 hours&lt;/Availability&gt;\n  &lt;ListPrice&gt;$75.00&lt;/ListPrice&gt;\n  &lt;OurPrice&gt;$63.75&lt;/OurPrice&gt;\n  &lt;UsedPrice&gt;$49.99&lt;/UsedPrice&gt;\n&lt;/Details&gt;\n...\n&lt;/ProductInfo&gt;</code></pre>\n<p>Note that the <a href=\"http://www.amazon.com/exec/obidos/ASIN/0262133601/0xdecafbad-20?dev-t=D8HVH869XA0NP%26camp=2025%26link_code=xm2\">long URL</a> in the <code>Detail</code> element&apos;s <code>url</code> attribute links to the human-viewable product detail page at Amazon.  I&apos;ve also left a few other things out, such as the URLs to product images; I just thought I&apos;d edit it a bit to be friendlier to your browser at home.  There&apos;s a <a href=\"http://xml.amazon.com/schemas3/dev-lite.xsd\">schema</a> for this XML data, and the ins-and-outs are explained in the AWS documentation under &quot;Amazon Web Services Data Model&quot;.</p>\n<h3 id=\"querying-the-wishes\">Querying The Wishes</h3>\n<p>Some ready-made files are available for this section:</p>\n<ul>\n<li><a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex1.xsl\"><code>wishes-ex1.xsl</code></a>: The first iteration of the stylesheet in development.</li>\n<li><a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.xml\"><code>wishes.xml</code></a>: An XML document used as input with the stylesheet.</li>\n</ul>\n<p>Now that we&apos;ve got some XML from Amazon to play with, let&apos;s start tinkering with an XSLT stylesheet to process it.  In the interests of flexibility and reusability, we can parameterize a few things in XML before starting in on the stylesheet:</p>\n<pre><code>&lt;wishes xmlns=&quot;http://www.decafbad.com/2004/05/wishes&quot;&gt;\n  &lt;maxprice&gt;15.00&lt;/maxprice&gt;\n  &lt;associate&gt;0xdecafbad-20&lt;/associate&gt;\n  &lt;devtoken&gt;D8HVH869XA0NP&lt;/devtoken&gt;\n  &lt;email&gt;deus_x@pobox.com&lt;/email&gt;\n  &lt;wishlists&gt;\n    &lt;wishlist label=&quot;The Girl&quot;&gt;35OIOYWQ9XQAE&lt;/wishlist&gt;\n    &lt;wishlist label=&quot;Me&quot;&gt;1QWYI6P2JF3Q5&lt;/wishlist&gt;\n  &lt;/wishlists&gt;\n&lt;/wishes&gt;</code></pre>\n<p>Hopefully, the data here is fairly self-explanatory:  I&apos;ve established a maximum price for item selection; provided my associate ID and developer token; there&apos;s an email address to which I eventually want to send the results of all this work; and I&apos;ve made a list of wishlist IDs, each with a readable label. Given this, let&apos;s start out simple and  use this to get some data from Amazon:</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;xsl:stylesheet version=&quot;1.0&quot;\n            xmlns:wishes=&quot;http://www.decafbad.com/2004/05/wishes&quot;\n            xmlns:xsl=&quot;http://www.w3.org/1999/XSL/Transform&quot;&gt;\n  &lt;xsl:output indent=&quot;yes&quot; /&gt;\n\n  &lt;!-- Grab our global settings --&gt;\n  &lt;xsl:variable name=&quot;maxprice&quot;  select=&quot;/wishes:wishes/wishes:maxprice&quot; /&gt;  \n  &lt;xsl:variable name=&quot;associate&quot; select=&quot;/wishes:wishes/wishes:associate&quot; /&gt;\n  &lt;xsl:variable name=&quot;devtoken&quot;  select=&quot;/wishes:wishes/wishes:devtoken&quot; /&gt;</code></pre>\n<p>So far so good--things start off by pulling in some of the parameters into variables.  Next, let&apos;s dig into actually querying wishlist data with a reusable template:</p>\n<pre><code>  &lt;xsl:template name=&quot;processWishlist&quot;&gt;\n    &lt;xsl:param name=&quot;wishlist&quot; /&gt;\n\n    &lt;xsl:variable name=&quot;details&quot; select=&quot;document(concat(\n        &apos;http://xml.amazon.com/onca/xml3?&apos;,\n        &apos;t=&apos;,$associate,&apos;&amp;amp;&apos;,\n        &apos;dev-t=&apos;,$devtoken,&apos;&amp;amp;&apos;,\n        &apos;WishlistSearch=&apos;,$wishlist,&apos;&amp;amp;&apos;,\n        &apos;type=lite&amp;amp;f=xml&apos;))//Details&quot; /&gt;</code></pre>\n<p>First thing into this template, we accept a parameter named <code>wishlist</code> which is expected to contain a wishlist ID string.  Next, we build an AWS URL by concatenating together the pieces we have in variables (associate ID, developer&apos;s token, and wishlist ID) using the XPath function <a href=\"http://www.w3.org/TR/2002/WD-xquery-operators-20020816/#func-concat\"><code>concat()</code></a>.  Once we have this URL, we use the function <a href=\"http://www.w3.org/TR/2002/WD-xquery-operators-20020816/#func-document\"><code>document()</code></a> to make a request and fetch the XML data for that URL.  From this, we select all the <code>Details</code> elements.  </p>\n<p>Then with that data, we can do some filtering on the price and availability.  We want to make sure that not only will we select items that are within our budget, but that they are available to buy in the first place:</p>\n<pre><code>    &lt;xsl:copy-of select=&quot;$details[\n      number(substring(OurPrice/text(),2)) &amp;lt; $maxprice\n      and\n      contains(Availability, &apos;Usually ships within&apos;)\n      ]&quot; /&gt;\n\n  &lt;/xsl:template&gt;</code></pre>\n<p>This code is just a little bit funky, since the price data given by Amazon contains a dollar sign, and we want to make a numerical comparison.  So, we chop the dollar sign off and convert to a number before making the comparison.  Also, there&apos;s an assumption here about what will show up in the <code>Availability</code> element: &quot;Usually ships within&quot;  Other things that might show up will declare that the item is out of stock, discontinued, or otherwise not shipping.  This might need some tweaking someday, but it seems to work for now.</p>\n<p>Taken all together, this template has the effect of a SQL SELECT statement somewhat like this:</p>\n<pre><code>SELECT * \nFROM Amazon.WishlistItems \nWHERE WishlistID = $wishlist AND \n      OurPrice &lt; $maxprice AND\n      Availability like &apos;%Usually ships within%&apos;;</code></pre>\n<p><code>document()</code> is a very useful XPath function.  It allows us to pull in XML from external files and, in our case, from external URLs via HTTP requests.  This gives us the ability to make queries against REST web services like AWS--which, among many other reasons, is why I prefer REST web services over SOAP.  (I don&apos;t even want to think about trying to access a SOAP service from XSLT.)</p>\n<p>Now, let&apos;s wrap up this first iteration of the stylesheet by trying out the query template on each of the wishlist IDs:</p>\n<pre><code>  &lt;xsl:template match=&quot;/wishes:wishes&quot;&gt;\n    &lt;xsl:for-each select=&quot;//wishes:wishlist&quot;&gt;\n      &lt;wishes:wishitem&gt;\n        &lt;xsl:copy-of select=&quot;.&quot; /&gt;\n        &lt;xsl:call-template name=&quot;processWishlist&quot;&gt;\n              &lt;xsl:with-param name=&quot;wishlist&quot; \n                              select=&quot;.&quot; /&gt;\n        &lt;/xsl:call-template&gt;\n      &lt;/wishes:wishitem&gt;\n    &lt;/xsl:for-each&gt;\n  &lt;/xsl:template&gt;\n\n&lt;/xsl:stylesheet&gt;</code></pre>\n<p>You can get a <a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes-ex1.xsl\">completed version of this stylesheet</a>, along with <a href=\"http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.xml\">the input XML</a>, in case you haven&apos;t been cutting and pasting together a copy of your own along the way.  Try it out in a shell with:</p>\n<pre><code>$ xsltproc wishes_ex1.xsl wishes.xml</code></pre>\n<p>Alternately, you could check it out using <a href=\"http://www.entropy.ch:16080/software/macosx/#testxslt\">TestXSLT</a> under OS X.  You should get something like the following:</p>\n<pre><code>&lt;wishes:wishitem xmlns:wishes=&quot;http://www.decafbad.com/2004/05/wishes&quot;&gt;\n    &lt;wishes:wishlist label=&quot;The Girl&quot;&gt;35OIOYWQ9XQAE&lt;/wishes:wishlist&gt;\n    &lt;Details ...&gt;...&lt;/Details&gt;\n    &lt;Details ...&gt;...&lt;/Details&gt;\n    ...\n&lt;/wishes:wishitem&gt;\n&lt;wishes:wishitem xmlns:wishes=&quot;http://www.decafbad.com/2004/05/wishes&quot;&gt;\n    &lt;wishes:wishlist label=&quot;Me&quot;&gt;1QWYI6P2JF3Q5&lt;/wishes:wishlist&gt;\n    &lt;Details ...&gt;...&lt;/Details&gt;\n    &lt;Details ...&gt;...&lt;/Details&gt;\n    ...\n&lt;/wishes:wishitem&gt;</code></pre>\n<p>Obviously, this example XML is much abridged, but hopefully you can get the gist:  For each wishlist ID, there is a containing <code>wishitem</code> element.  It contains a copy of the <code>wishlist</code> element from the input XML, followed by all the <code>Details</code> elements filtered and copied from the Amazon XML with the help of the <code>processWishlist</code> template.</p>\n<h3 id=\"thats-all-for-now\">That&apos;s All for Now!</h3>\n<p>And that&apos;s the end of Part 1.  Next up, we&apos;ll be delving into a few more wrinkles in the wishlist querying process, selecting random items in XSLT, and the Remote Shopping Cart interface in Amazon Web Services.  Stay tuned!</p>\n<!-- links -->\n\n"
  }
]