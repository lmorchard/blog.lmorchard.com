[
  {
    "comments_archived": true,
    "date": "2007-10-17T07:22:47.000Z",
    "layout": "post",
    "tags": [
      "webdev",
      "rss",
      "php",
      "atom",
      "xml",
      "opml",
      "feedmagick",
      "feedmagick2",
      "feeds"
    ],
    "title": "OPML reading lists in FeedMagick2",
    "wordpress_id": 1066,
    "wordpress_slug": "opml-reading-lists-in-feedmagick2",
    "wordpress_url": "http://decafbad.com/blog/2007/10/17/opml-reading-lists-in-feedmagick2",
    "year": "2007",
    "month": "10",
    "day": "17",
    "isDir": false,
    "slug": "opml-reading-lists-in-feedmagick2",
    "postName": "2007-10-17-opml-reading-lists-in-feedmagick2",
    "parentPath": "./content/posts/archives/2007",
    "path": "2007/10/17/opml-reading-lists-in-feedmagick2",
    "prevPostPath": "2007/10/18/wine-is-nicely-enabled",
    "nextPostPath": "2007/10/10/beautiful-code"
  },
  {
    "comments_archived": true,
    "date": "2007-04-30T03:06:32.000Z",
    "layout": "post",
    "tags": [
      "webdev",
      "rss",
      "php",
      "atom",
      "xml",
      "feedmagick",
      "feedmagick2",
      "feeds"
    ],
    "title": "Say hello to FeedMagick2",
    "wordpress_id": 1048,
    "wordpress_slug": "say-hello-to-feedmagick2",
    "wordpress_url": "http://decafbad.com/blog/2007/04/29/say-hello-to-feedmagick2",
    "year": "2007",
    "month": "04",
    "day": "29",
    "isDir": false,
    "slug": "say-hello-to-feedmagick2",
    "postName": "2007-04-29-say-hello-to-feedmagick2",
    "parentPath": "./content/posts/archives/2007",
    "path": "2007/04/30/say-hello-to-feedmagick2",
    "prevPostPath": "2007/05/09/scribbling-in-ink",
    "nextPostPath": "2007/04/05/i-heart-ficlets-microformats-and-feed-scrapers"
  },
  {
    "comments_archived": true,
    "date": "2006-11-24T06:28:11.000Z",
    "layout": "post",
    "tags": [
      "asides",
      "aggregators",
      "rss",
      "firefox",
      "atom",
      "xsl",
      "xml"
    ],
    "title": "content sniffing sucks",
    "wordpress_id": 1021,
    "wordpress_slug": "content-sniffing-sucks",
    "wordpress_url": "http://decafbad.com/blog/2006/11/24/content-sniffing-sucks",
    "year": "2006",
    "month": "11",
    "day": "24",
    "isDir": false,
    "slug": "content-sniffing-sucks",
    "postName": "2006-11-24-content-sniffing-sucks",
    "parentPath": "./content/posts/archives/2006",
    "path": "2006/11/24/content-sniffing-sucks",
    "prevPostPath": "2006/11/28/stickis-and-subethaedit-icon",
    "nextPostPath": "2006/11/17/macbook-pro-volume-settings-are-aware-of-headphone-presence"
  },
  {
    "comments_archived": true,
    "date": "2006-11-15T08:07:12.000Z",
    "layout": "post",
    "tags": [
      "asides",
      "webdev",
      "php",
      "outliners",
      "outlining",
      "xoxooutliner",
      "xsl",
      "xoxo",
      "xml",
      "opml"
    ],
    "title": "XoxoOutliner and further outline addressing adventures",
    "wordpress_id": 1019,
    "wordpress_slug": "xoxooutliner-and-further-outline-addressing-adventures",
    "wordpress_url": "http://decafbad.com/blog/2006/11/15/xoxooutliner-and-further-outline-addressing-adventures",
    "year": "2006",
    "month": "11",
    "day": "15",
    "isDir": false,
    "slug": "xoxooutliner-and-further-outline-addressing-adventures",
    "postName": "2006-11-15-xoxooutliner-and-further-outline-addressing-adventures",
    "parentPath": "./content/posts/archives/2006",
    "path": "2006/11/15/xoxooutliner-and-further-outline-addressing-adventures",
    "prevPostPath": "2006/11/17/macbook-pro-volume-settings-are-aware-of-headphone-presence",
    "nextPostPath": "2006/11/13/xoxooutliner-and-suboutline-addressing"
  },
  {
    "comments_archived": true,
    "date": "2006-11-13T09:34:02.000Z",
    "layout": "post",
    "tags": [
      "asides",
      "webdev",
      "php",
      "outlining",
      "xoxooutliner",
      "xsl",
      "xoxo",
      "xml"
    ],
    "title": "XoxoOutliner and suboutline addressing",
    "wordpress_id": 1018,
    "wordpress_slug": "xoxooutliner-and-suboutline-addressing",
    "wordpress_url": "http://decafbad.com/blog/2006/11/13/xoxooutliner-and-suboutline-addressing",
    "year": "2006",
    "month": "11",
    "day": "13",
    "isDir": false,
    "slug": "xoxooutliner-and-suboutline-addressing",
    "postName": "2006-11-13-xoxooutliner-and-suboutline-addressing",
    "parentPath": "./content/posts/archives/2006",
    "path": "2006/11/13/xoxooutliner-and-suboutline-addressing",
    "prevPostPath": "2006/11/15/xoxooutliner-and-further-outline-addressing-adventures",
    "nextPostPath": "2006/11/12/xoxooutliner-shows-some-signs-of-life"
  },
  {
    "comments_archived": true,
    "date": "2005-12-19T23:15:03.000Z",
    "layout": "post",
    "tags": [
      "asides",
      "xml",
      "feedmagick",
      "lazyweb",
      "syndcation",
      "facepalm"
    ],
    "title": "Sometimes the lazyweb delivers with a deluge",
    "wordpress_id": 806,
    "wordpress_slug": "sometimes-the-lazyweb-delivers-with-a-deluge",
    "wordpress_url": "http://decafbad.com/blog/?p=806",
    "year": "2005",
    "month": "12",
    "day": "19",
    "isDir": false,
    "slug": "sometimes-the-lazyweb-delivers-with-a-deluge",
    "postName": "2005-12-19-sometimes-the-lazyweb-delivers-with-a-deluge",
    "parentPath": "./content/posts/archives/2005",
    "path": "2005/12/19/sometimes-the-lazyweb-delivers-with-a-deluge",
    "prevPostPath": "2005/12/22/modding-is-not-the-same-as-piracy",
    "nextPostPath": "2005/12/19/feedburner-feeds-give-heartburn-to-php-xml-parsers"
  },
  {
    "comments_archived": true,
    "date": "2005-12-19T04:17:55.000Z",
    "layout": "post",
    "tags": [
      "asides",
      "ajax",
      "json",
      "webdev",
      "xml"
    ],
    "title": "Okay, okay, JSON is pretty hot",
    "wordpress_id": 802,
    "wordpress_slug": "okay-okay-json-is-pretty-hot",
    "wordpress_url": "http://decafbad.com/blog/?p=802",
    "year": "2005",
    "month": "12",
    "day": "18",
    "isDir": false,
    "slug": "okay-okay-json-is-pretty-hot",
    "postName": "2005-12-18-okay-okay-json-is-pretty-hot",
    "parentPath": "./content/posts/archives/2005",
    "path": "2005/12/19/okay-okay-json-is-pretty-hot",
    "prevPostPath": "2005/12/19/feedburner-feeds-give-heartburn-to-php-xml-parsers",
    "nextPostPath": "2005/12/19/js-versus-php"
  },
  {
    "comments_archived": true,
    "date": "2005-09-26T01:12:46.000Z",
    "layout": "post",
    "tags": [
      "webdev",
      "rss",
      "syndication",
      "webservices",
      "atom",
      "xml"
    ],
    "title": "Templates:  Good or Evil?",
    "wordpress_id": 689,
    "wordpress_slug": "templates-good-or-evil",
    "wordpress_url": "http://decafbad.com/blog/?p=689",
    "year": "2005",
    "month": "09",
    "day": "25",
    "isDir": false,
    "slug": "templates-good-or-evil",
    "postName": "2005-09-25-templates-good-or-evil",
    "parentPath": "./content/posts/archives/2005",
    "path": "2005/09/26/templates-good-or-evil",
    "prevPostPath": "2005/09/26/let-there-be-no-serenity-1701b",
    "nextPostPath": "2005/09/25/battlestar-galacticas-opening-teaser"
  },
  {
    "comments_archived": true,
    "date": "2005-09-13T23:45:47.000Z",
    "layout": "post",
    "tags": [
      "rss",
      "syndication",
      "writing",
      "atom",
      "xml",
      "books",
      "hackingrssandatom"
    ],
    "title": "Hacking RSS and Atom is out!",
    "wordpress_id": 680,
    "wordpress_slug": "hacking-rss-and-atom-is-out",
    "wordpress_url": "http://www.decafbad.com/blog/?p=680",
    "year": "2005",
    "month": "09",
    "day": "13",
    "isDir": false,
    "slug": "hacking-rss-and-atom-is-out",
    "postName": "2005-09-13-hacking-rss-and-atom-is-out",
    "parentPath": "./content/posts/archives/2005",
    "path": "2005/09/13/hacking-rss-and-atom-is-out",
    "thumbnail": "http://www.decafbad.com/blog_attachments/IMG_3554-1-tm.jpg",
    "prevPostPath": "2005/09/22/yaks-books-feeds",
    "nextPostPath": "2005/09/13/redesigninprogress"
  },
  {
    "comments_archived": true,
    "date": "2004-12-23T05:58:41.000Z",
    "excerpt": "So, in the spirit of pico-projects, I've started building that address book application I mentioned awhile ago and I want to start writing about it as I go.",
    "layout": "post",
    "tags": [
      "hacks",
      "xml"
    ],
    "title": "Building an Address Book as a Modern Web App",
    "wordpress_id": 580,
    "wordpress_slug": "abook1",
    "wordpress_url": "http://www.decafbad.com/blog/?p=580",
    "year": "2004",
    "month": "12",
    "day": "23",
    "isDir": false,
    "slug": "abook1",
    "postName": "2004-12-23-abook1",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/12/23/abook1",
    "thumbnail": "http://www.decafbad.com/2004/12/abook-architecture.jpg",
    "summary": "So, in the spirit of pico-projects, I've started building that address book application I mentioned awhile ago and I want to start writing about it as I go.\nFirst off, hopefully you'll notice the quick diagram I threw together in OmniGraffle.  This is a sort of rough sketch of the loosely-joined architecture I want to explore with this thing.  \n\nData: This is where address book entries live.\nModel: A set of objects encapsulating the data, this is how address book entries will be accessed.\nREST API: Model objects exposed as resources identified by URI, serialized and deserialized as XML, and manipulated by GET / PUT / POST / DELETE methods.\nXSLT Filter: XML data produced by REST API calls can be first passed through XSL at a given URL before being served up as a response.  \nHTML, CSS, JavaScript: Thanks to the XSLT filter layer, the XML vocabulary used to describe address book entries can be transformed into user interface presentation.\nHTTP: Everything happens via HTTP...\nWeb Browser Client: ...and everything is viewed in a web browser.\n\nNow, I call this a loosely-joined architecture because I want to stress that you should be able to swap out just about any part of this whenever you want.  \nWant the Data to be in MySQL?  Fine.  Want it to be in flat files?  Fine.  Just make sure the Model can cope while maintaining a consistent interface for the REST API.  Want to change the user interface in the browser?  Great-- ideally, all you have to do is change some XSLT files.  I'm writing everything from the XSLT Filter down to the Model in Python.  Don't like that?  Fine.  Rewrite it all in Perl, and hopefully everything from the XSLT up to the browser will still be useful to you.\nAt some point, you might even want to ditch the browser for a native desktop client.  Fabulous! Just ignore everything past the REST API and HTTP, don't use any XSLT in the Filter, and use the API and XML directly.\nI don't think any of this is particularly revolutionary-- although I thought it was when I first saw Amazon Web Services doing some of this, and I hope to throw a little GMail in as well.  I hope that this will all be useful as I muddle through explaining what I'm doing.  In the meantime, you can see me getting the stage set as I start checking things into my Subversion repository over here:\n\nhttp://www.decafbad.com/svn/trunk/hacks/abook/",
    "prevPostPath": "2005/01/07/belated-happy-new-year",
    "nextPostPath": "2004/12/16/synchronet"
  },
  {
    "comments_archived": true,
    "date": "2004-12-03T01:15:52.000Z",
    "excerpt": "Both ZPT and XSLT very different technologies, but they are often used in similar contexts.  More than once, I've wished that XSLT was as simple as ZPT (i.e. less verbose and intrusive, more document centered), and I've wished that ZPT had some of the features of XSLT (i.e. ability to be used as a transforming filter).",
    "layout": "post",
    "tags": [
      "xml",
      "python"
    ],
    "title": "Cross-breeding XSLT and ZPT",
    "wordpress_id": 570,
    "wordpress_slug": "crossbreedingxsltzpt",
    "wordpress_url": "http://www.decafbad.com/blog/?p=570",
    "year": "2004",
    "month": "12",
    "day": "02",
    "isDir": false,
    "slug": "crossbreedingxsltzpt",
    "postName": "2004-12-02-crossbreedingxsltzpt",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/12/03/crossbreedingxsltzpt",
    "summary": "I've recently been doing some side work involving Zope and, along with the rest of the suite of technologies it offers, I've been happy to be working with Zope Page Templates again.  I dabbled with them a bit when they first came out, and a Zope-free implementation named SimpleTAL was one of the core components of the iteration of my news aggregator which came before FeedReactor.\nOut of all the templating and content generation approaches I've used, Zope Page Templates are my favorite yet.  Pretty expressive, yet unobtrusive; nicely powerful, yet not quite something with which you'd want to write an entire application (and that's a feature, not a bug).  \nI've yet to be in a work-a-day team that uses ZPT-- but I can see where a lot of production, delegation, and integration issues would have gone much smoother had I used ZPT instead of Template Toolkit for the web app framework I created at a previous company.  (Though I do have to say TT2 is very nicely done!)  And where I am now, I spend most of my days trying to pummel ASP 3.0 pages into some semblance of logic/presentation separation-- I would certainly dive at the chance to dump VBScript and <% cruft %> for a bit of Python and ZPT.  (But, you know, it's a living.)\nA close second favorite is XSLT.  I've really been hot on it lately, having worked it into the core of FeedReactor in place of SimpleTAL.  And in other hacks, I've really come to appreciate it's role as a filter segment in pipelines between REST web services and URL-as-command-line invocations.\nGranted, both ZPT and XSLT very different technologies, but they are often used in similar contexts.  More than once, I've wished that XSLT was as simple as ZPT (i.e. less verbose and intrusive, more document centered), and I've wished that ZPT had some of the features of XSLT (i.e. ability to be used as a transforming filter).\nReading Ryan Tomayko's description of Kid got me thinking, and googling.  One thing I turned up from a mailing list archive asked about an “XSL implementation of TAL?”  It struck me as a tad nutty at first, but then I started having inklings that just maybe it could be done.  (Whether it should be done, well...)  But the kernel of the idea grabbed me: Instead of using TALES path expressions to look up values in Pythonic space, why not use XPath expressions to look up values from a supplied XML document?\nThis strikes me as such an obvious idea that someone has to already have done it and possibly rejected it for good reason.  On the other hand, maybe this is the sort of thing Ryan's thinking about-- I wonder how hard it would be to hack this into Kid?  It would give only a subset of XSLT's capabilities in trade for simplicity, and would only offer the “pull” approach, but it would give XML-pipelining to a ZPT-ish technology.\nI think this is something I want to look into a bit further at some point.",
    "prevPostPath": "2004/12/03/if-you-snore-get-tested-for-sleep-apnea-now",
    "nextPostPath": "2004/12/02/nofroogleapi"
  },
  {
    "comments_archived": true,
    "date": "2004-11-30T21:53:35.000Z",
    "excerpt": "This has been where most of my private hacking sessions have been taking me over the past year or so:  combining HTML, CSS, DOM, JavaScript, XML, XSLT, and REST to build what I consider to be a next-generation web app.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "Next generation web apps using REST, XML, XSLT, and XmlHTTPRequest",
    "wordpress_id": 568,
    "wordpress_slug": "nextgenwebapps",
    "wordpress_url": "http://www.decafbad.com/blog/?p=568",
    "year": "2004",
    "month": "11",
    "day": "30",
    "isDir": false,
    "slug": "nextgenwebapps",
    "postName": "2004-11-30-nextgenwebapps",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/11/30/nextgenwebapps",
    "summary": "So, like I was saying:  I've been working on FeedReactor and have been doing some things with it that I find rather interesting, independent of news aggregation.  \nOne of the core goals I have for FeedReactor is to explore what it takes to build a web app that exploits principles of REST architecture.  Having already sung the praises of XML-RPC, I wanted to get immersed in REST and see what all the hubbub was about.  I've got some ways to go, but I think I understand the major concepts now, and it's a pretty nifty frame within which to work.\nBut, two other things I've added to my mix have really made things interesting for me:  \n\nXSLT filtering\nThe XmlHTTPRequest object\n\nXSLT and REST make a really good pair, as Amazon Web Services already demonstrate.  Inspired by that API (and earlier experiments), I use XML for all the input and output formats in my API and accept a query string parameter that contains the path to an XSLT file.  When this parameter is supplied, the XML output by the API is first processed using the given XSLT.  (Think of it like piping API output through xsltproc.)\nSo, with a properly constructed collection of XSLT, I can present a browser-viewable HTML user interface served up directly from REST API calls.  Links, frame sets, and iframes present in the HTML lead the user from that call to the next XSLT-wrapped REST API call. \nBut, once the initial HTML-and-JavaScript payload reaches the browser, it gets better (ala Gmail):  \nOn older browsers (if I happen to care about them), I can make new HTTP requests back to the server from JavaScript using iframes.  In this case, XSLT filtering lets me retrofit the API's responses to the HTML-and-JavaScript crud I need to serve up to make things happen back in the browser client.  Unfortunately, passing data to the API (which expects XML, not form submissions) is still a bit wonky and requires some hacks and exceptions involving hidden forms and such.\nHowever, on the newer browsers, it's all about the XmlHTTPRequest object.  With this facility, I can make clean asynchronous requests back to the REST API, including XML data in the request body if I feel like it.  Responses are handled by JavaScript callbacks, which twiddle the browser DOM to update the user interface in response.  \nSo, after the major initial contact with the API to supply the browser with HTML by way of XSLT, most future interactions take place in the form of direct calls to the REST API using XML.  Although for some things, it's easier to just reload a page of HTML, it's nicer for most interactions to be handled via DOM manipulations in-place.  I've been amazed at the Gmail-like responsiveness I get from FeedReactor when I'm skimming through news items, marking some as seen or flagged, and popping open the descriptions on others.  \nI suppose I shouldn't be amazed at the responsiveness, since I'm using some of the same techniques as Gmail.  However, my daily-use installation of FeedReactor is presently running on an old 300Mhz Debian Linux PC at home, and it's taking me through the daily produce of 600 subscribed feeds faster than any desktop aggregator has yet.  Of course, this is partly a product of my familiarity with the UI I've cobbled together, but... the server's running on a 300Mhz PC with 256MB of RAM!  And the client is my 867Mhz G4 PowerBook, running Firefox or Safari, depending on my mood.\nAlthough I can't see when I'll have time for it, I really want to explore this approach further using desktop apps on OS X and accessing the API from Flash movies (maybe using Laszlo).  I'd also like to see how far I can go toward adapting the interface toward mobile devices like my Treo 600.\nSo anyway, this has been where most of my private hacking sessions have been taking me over the past year or so:  combining HTML, CSS, DOM, JavaScript, XML, XSLT, and REST to build what I consider to be a next-generation web app.  \nNow, although I use FeedReactor on a daily basis to keep up with all my feeds, it's nowhere near any state suitable for public consumption.  I add new subscriptions from a command-line script and still fiddle with the database directly for some operations.  I'd like to have a personal-server version of it ready for use by some alpha geeks before or not long into the new year, but I'd like to share some of the things I've been doing with it before then.\nWith that in mind, I think I'll wrap up this entry and think about putting together a quick tutorial pico-project to demonstrate some of the concepts.  Maybe an address book, or something equally simple-yet-useful.  \nStay tuned.",
    "prevPostPath": "2004/12/02/nofroogleapi",
    "nextPostPath": "2004/11/30/pico-projects-and-trepanation"
  },
  {
    "comments_archived": true,
    "date": "2004-10-08T17:07:49.000Z",
    "excerpt": "So I had an idea for a quick podcasting listening hack on the way into work this morning.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "Using iTunes as a podcast aggregator, with a little help from XSLT",
    "wordpress_id": 561,
    "wordpress_slug": "itunesxslt",
    "wordpress_url": "http://www.decafbad.com/blog/?p=561",
    "year": "2004",
    "month": "10",
    "day": "08",
    "isDir": false,
    "slug": "itunesxslt",
    "postName": "2004-10-08-itunesxslt",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/10/08/itunesxslt",
    "summary": "So I had an idea for a quick podcasting listening hack on the way into work this morning. Check it out:\n\nTake one list of RSS feeds in OPML.\nThrow in a bit of XSLT.\nCombine using xsltproc to make a playlist that works in iTunes.\n\nAnd, oh yeah, I just happen to have an xsltproc web service laying around, so:\n\nSupply a URL to your OPML in this form.\nGet a freshly-built playlist.\n\nNow, this has been barely tested and is the product of a ten-minute hacking session.  There are likely an enormous number of things wrong with this.  That said, iTunes does seem to open the playlist happily, and it looks like only new streams are added with repeated openings of the playlist.\nYou will want to be careful to ensure that your OPML is valid XML (mine wasn't, on initial export from iPodderX - escape those freaking ampersands in URLs already!), and I have no idea what would happen if any of the RSS feeds in your subscriptions turn up invalid.  \nHave I mentioned that, despite their unforgiving and sometimes fragile nature, I love XML technologies?\nIf this looks useful, maybe I'll work it over a bit more and pair it up with some python to handle actually downloading the MP3s and torrents.\nUpdate: Oh yeah, and I'm expecting this will be useful with an iTunes smart playlist crafted along these lines:\n\nDate Added in the last 1 days\nPlay Count is less than 1\n\nUpdate #2: Another use I just found for this playlist, is on my Xbox Media Center.  I generate this playlist via cronjob every few hours, and store it on an SMB share accessible to the XBMC.  Voila!  Listening to podcasts on my stereo system via the Xbox.  Yeah, nothing big, just kind of nifty.",
    "prevPostPath": "2004/10/11/allgrowedup",
    "nextPostPath": "2004/10/07/podcastinghype"
  },
  {
    "comments_archived": true,
    "date": "2004-09-17T13:32:30.000Z",
    "excerpt": "Wow.  So it looks like there are some people starting to follow to what I'm doing with dbagg3, and they're showing me how woefully prepared I am for the attention from tinkerers who are actually trying to, you know, run my code.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "dbagg3: Please excuse the mess",
    "wordpress_id": 549,
    "wordpress_slug": "dbagg3mess",
    "wordpress_url": "http://www.decafbad.com/blog/?p=549",
    "year": "2004",
    "month": "09",
    "day": "17",
    "isDir": false,
    "slug": "dbagg3mess",
    "postName": "2004-09-17-dbagg3mess",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/17/dbagg3mess",
    "summary": "Wow.  So it looks like there are some people starting to follow to what I'm doing with dbagg3, and they're showing me how woefully prepared I am for the attention from tinkerers who are actually trying to, you know, run my code.  Things have been crazy busy for me at work, so I haven't been getting done what I've planned.  But, I do need to pull a few things together and clean a few things up.  I'll soon be answering the smattering of email I've gotten so far, but until then, a few quick thoughts:\n\nMy source control is a bit of a mess at the moment.  Not only have I switched from CVS to SVN-- but even if you followed me in that migration, I've not kept committed code in working order.  I already know that this is a horrible habit, but since no one's really been looking, I haven't been called on it until now.  (Heh, heh--d'oh.)  Planning this weekend (but hopefully today) to resolve this, so that moving forward, svn trunk will be (as far as possible) in a working state at any given moment.\n\nI've hacked one of my dependencies, SQLObject, by applying a patch to support SELECT DISTINCT queries.  This has understandably caused problems for some people who have no idea what I did.  This patch has turned out to be essential, though I don't know if/when it will or would be included in a release of SQLObject.  So...  I wonder if I should dump my working copy of SQLObject into source control?  Otherwise, applying the DISTINCT patch to your SQLObject install should work.\n\nAt some point very soon, I want to change the name of this thing to feedReactor.  Yes, I know there's already a feedparser, and a feeddemon, and a feedburner, and someone's probably got a feedkitchensink in the works, but I like this name and want to run with it.\n\n\nSo, in the meantime while I straighten some things out, please excuse the mess and thanks for bearing with me!",
    "prevPostPath": "2004/09/18/are-powerbook-hard-drives-supposed-to-sound-like-amiga-floppy-drives",
    "nextPostPath": "2004/09/16/moving-time-from-cvs-to-subversion"
  },
  {
    "comments_archived": true,
    "date": "2004-09-16T15:29:04.000Z",
    "excerpt": "So, I'm waiting for the other shoe to drop.  After making sure things seemed reasonably stable post-server-move, I migrated my CVS repository here to Subversion.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "Moving time: From CVS to Subversion",
    "wordpress_id": 548,
    "wordpress_slug": "moving-time-from-cvs-to-subversion",
    "wordpress_url": "http://www.decafbad.com/blog/?p=548",
    "year": "2004",
    "month": "09",
    "day": "16",
    "isDir": false,
    "slug": "moving-time-from-cvs-to-subversion",
    "postName": "2004-09-16-moving-time-from-cvs-to-subversion",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/16/moving-time-from-cvs-to-subversion",
    "prevPostPath": "2004/09/17/dbagg3mess",
    "nextPostPath": "2004/09/15/manipulating-aggregate-resources-in-a-rest-api"
  },
  {
    "comments_archived": true,
    "date": "2004-09-15T18:48:53.000Z",
    "excerpt": "So... am I missing a more elegant RESTful way of doing this which doesn't result in a quadrillion HTTP requests?",
    "layout": "post",
    "tags": [
      "xml"
    ],
    "title": "Manipulating aggregate resources in a REST API?",
    "wordpress_id": 547,
    "wordpress_slug": "manipulating-aggregate-resources-in-a-rest-api",
    "wordpress_url": "http://www.decafbad.com/blog/?p=547",
    "year": "2004",
    "month": "09",
    "day": "15",
    "isDir": false,
    "slug": "manipulating-aggregate-resources-in-a-rest-api",
    "postName": "2004-09-15-manipulating-aggregate-resources-in-a-rest-api",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/15/manipulating-aggregate-resources-in-a-rest-api",
    "prevPostPath": "2004/09/16/moving-time-from-cvs-to-subversion",
    "nextPostPath": "2004/09/13/dbagg3alive"
  },
  {
    "comments_archived": true,
    "date": "2004-09-13T22:11:41.000Z",
    "excerpt": "So at this point, it's all URLs and barely working HTML, but it's exciting to me at least.  And it's dogfood for me, since I'm using this crud to get my daily (hourly?) fix.  Pretty soon, I'll be diving into wrapping more of a proper usable web app around this, with user management and stuff that works in MSIE.  Until then, maybe someone else will see this and catch a buzz from it.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "Early dbagg3 demo is alive and kicking",
    "wordpress_id": 546,
    "wordpress_slug": "dbagg3alive",
    "wordpress_url": "http://www.decafbad.com/blog/?p=546",
    "year": "2004",
    "month": "09",
    "day": "13",
    "isDir": false,
    "slug": "dbagg3alive",
    "postName": "2004-09-13-dbagg3alive",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/13/dbagg3alive",
    "summary": "Got some very good work in this weekend on switching servers and getting dbagg3 in some semblance of working order somewhere other than on my overworked and decidedly non-publicly-demonstrable laptop.\nThis stuff is so this side of premature, that I'm probably about to cause JohnCompanies to send hit-men out to cancel me, along with my hosting account (have I said that I really appreciate the help so far?).  But I just have to get this out: I'm easily excited by shiny code and gadgets, but it's so much easier to get excited when I can see something in working condition before taking a screwdriver to it.  So... remember when I mentioned all those URLs?  They're working out nicely.\nFirst, check out a simple two-pane view of news items, ala Bloglines:\n\nhttp://feeds.decafbad.com/api/users/demo.xml?xsl=xsl/two-pane/index.xsl&content-type=text/html\n\nTaking this apart, you can see:\n\nA user account: http://feeds.decafbad.com/api/users/demo.xml\nSome XSL: http://feeds.decafbad.com/xsl/two-pane/index.xsl\n... and a specified content type (text/html)\n\nIf your curiosity is piqued by this, view source and pay attention to link URLs.  It's more of the same:  XML produced by a REST API, passed through XSL, delivered as HTML.\nHere, take a look at another view on this demo user's aggregated items:\n\nhttp://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/outliner/index.xsl&content-type=text/html\n\nUnfortunately, this only seems to be working decently with Firefox and Safari.  MSIE seems to be balking at the dynamic stuff, though I've had it working there in a previous incarnation of this code.  So hopefully this will be fixed soon.\nAt any rate, what you should see is a single-pane outliner-style display of feed entries.  This is the style of aggregator UI I've been using for almost 3 years now.  Disclosure triangles open entries up to show summaries and further content.  “[seen]” links hide the entries, while “[queue]” hides an entry while tossing it into a queue for viewing later.\nSpeaking of that, you can see what's in the queue right now:\n\nhttp://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&content-type=text/html&show_queued=1\n\nHere is a display of queued entries, with another stylesheet applied that shows everything in a flat and open blog-like template.  It's not reverse-chronological, but that's not hard to accomplish with a flag or a tweak to an <xsl:sort> tag.  \nSo that's just the start of things.  Remember when I was rambling on about XML storage and query?  A URL like this is one product of that:\n\nhttp://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&content-type=text/html&entry_xpath=//entry/title[contains(text(),'OS%20X')]\n\nThis should show you a flat listing of all entries whose titles contain “OS X”.  This is far from perfect, but it's very exciting to me-- it's got a lot of promise, stuff that first caught my eye when I saw Jon Udell playing awhile back.\nNow, something that you might not notice until doing a bit more digging, is that all these attributes like “seen” and “query” are annotations made by the user on entries.  If you take a peek at some of the Javascript under the hood, you might notice some XmlHTTPRequest code going on.  To mark something as “seen” or “queued”, I POST XML to a URL like this:\n\nhttp://feeds.decafbad.com/api/users/demo/subscriptions/638/entries/60567/notes/\n\nThe upshot of this is that these attributes are not limited to “seen” or “queued” flags-- in fact, these annotations can (well, in theory) be any pairing of arbitrary XML and a name.  This annotation then gets injected into the entry, when viewed by the user who owns the annotation, like so:\n\nhttp://feeds.decafbad.com/api/users/demo/subscriptions/638/entries/60567.xml\n\nIn fact, you could invent a new annotation called 'tags' and filter for entries with this annotation with a URL like this:\n\nhttp://feeds.decafbad.com/api/users/demo/subscriptions/now-12.xml?xsl=xsl/full.xsl&content-type=text/html&entry\\_notes\\_xpath=//dbagg3:note[@name='tags' and contains(text(),'#food#') and contains(text(),'#odd#')]\n\nEventually, what I'd really like to see this start doing is something akin to del.icio.us-style tagging while you're reading.  Then, you can have public queries that pull feeds based on your (and others') tags and spit things back out as feeds again with the proper XSL stylings.\nSo at this point, it's all URLs and barely working HTML, but it's exciting to me at least.  And it's dogfood for me, since I'm using this crud to get my daily (hourly?) fix.  Pretty soon, I'll be diving into wrapping more of a proper usable web app around this, with user management and stuff that works in MSIE.  Until then, maybe someone else will see this and catch a buzz from it.\nStay tuned.",
    "prevPostPath": "2004/09/15/manipulating-aggregate-resources-in-a-rest-api",
    "nextPostPath": "2004/09/12/moving-time-again"
  },
  {
    "comments_archived": true,
    "date": "2004-09-01T10:47:41.000Z",
    "excerpt": "But, while I'm in the process of wheel reinvention, how about I borrow Kimbro's idea?  I just threw together a quick class called XPathDict, based on libxml2.",
    "layout": "post",
    "tags": [
      "hacks",
      "xml"
    ],
    "title": "XPath based Python dictionaries, on loan",
    "wordpress_id": 544,
    "wordpress_slug": "xpath-based-python-dictionaries-on-loan",
    "wordpress_url": "http://www.decafbad.com/blog/?p=544",
    "year": "2004",
    "month": "09",
    "day": "01",
    "isDir": false,
    "slug": "xpath-based-python-dictionaries-on-loan",
    "postName": "2004-09-01-xpath-based-python-dictionaries-on-loan",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/09/01/xpath-based-python-dictionaries-on-loan",
    "prevPostPath": "2004/09/12/moving-time-again",
    "nextPostPath": "2004/08/31/dbagg3-makingprogress"
  },
  {
    "comments_archived": true,
    "date": "2004-08-31T01:37:42.000Z",
    "excerpt": "Work has been insanely busy lately, but I have made some more progress with [`dbagg3`][dbagg3].  The code is all in CVS, so feel free to take a gander-- I don't have a ton of time for a proper write up, but I do want to spew a little bit.",
    "layout": "post",
    "tags": [
      "hacks",
      "syndication",
      "xml"
    ],
    "title": "Making progress on dbagg3",
    "wordpress_id": 543,
    "wordpress_slug": "dbagg3-makingprogress",
    "wordpress_url": "http://www.decafbad.com/blog/?p=543",
    "year": "2004",
    "month": "08",
    "day": "30",
    "isDir": false,
    "slug": "dbagg3-makingprogress",
    "postName": "2004-08-30-dbagg3-makingprogress",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/08/31/dbagg3-makingprogress",
    "summary": "Work has been insanely busy lately, but I have made some more progress with dbagg3.  The code is all in CVS, so feel free to take a gander-- I don't have a ton of time for a proper write up, but I do want to spew a little bit. \nAs per my previous musings on XML in a SQL database, I revamped the database.  Now things are sliced up by feed and entry tables, rows in each containing a few metadata columns and then one big column for an XML dump.  This lets me index on  date and parent feed and such, meanwhile punting on the issue of dicing things like authors or content up further.  And, as extension elements start to show up, this handling is dumb enough to simply store things it doesn't know about without mangling them.  This is a very good thing and one of my big goals for this beast.\nThe other thing that I'm getting excited about is the REST API built atop the Atom store.  Rather than spend time on proper documentation, here's a quick dump from the appropriate module:\nURL: GET /feeds/\nURL: GET /feeds/{id}.xml\nURL: GET /feeds/{id}/{yyyy}/{mm}/{dd}/{hstart}-{hend}.xml\nURL: GET /feeds/{id}/{yyyy}/{mm}/{dd}/{hh}.xml\nURL: GET /feeds/{id}/{yyyy}/{mm}/{dd}.xml\nURL: GET /feeds/{id}/{yyyy}/{mm}.xml\nURL: GET /feeds/{id}/now-{nowoff}.xml\nURL: GET /feeds/{fid}/entries/{eid}.xml\nURL: GET /users/\nURL: GET /users/{uname}.xml\nURL: POST /users/\nURL: DELETE /users/{uname}.xml\nURL: PUT /users/{uname}.xml\nURL: GET /users/{uname}/prefs.xml\nURL: GET /users/{uname}/prefs/\nURL: POST /users/{uname}/prefs/{pname}.{type}\nURL: PUT /users/{uname}/prefs/{pname}.{type}\nURL: GET /users/{uname}/prefs/{pname}.{type}\nURL: DELETE /users/{uname}/prefs/{pname}.{type}\nURL: GET /users/{uname}/subscriptions.{type}\nURL: GET /users/{uname}/subscriptions/\nURL: POST /users/{uname}/subscriptions/\nURL: DELETE /users/{uname}/subscriptions/{id}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}/{dd}/{hstart}-{hend}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}/{dd}/{hh}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}/{dd}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/{yyyy}/{mm}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/now-{hours}.xml\nURL: GET /users/{uname}/subscriptions/{sid}/now.xml\nURL: GET /users/{uname}/subscriptions/{yyyy}/{mm}/{dd}/{hstart}-{hend}.xml\nURL: GET /users/{uname}/subscriptions/{yyyy}/{mm}/{dd}/{hh}.xml\nURL: GET /users/{uname}/subscriptions/{yyyy}/{mm}/{dd}.xml\nURL: GET /users/{uname}/subscriptions/{yyyy}/{mm}.xml\nURL: GET /users/{uname}/subscriptions/now-{hours}.xml\nURL: GET /users/{uname}/subscriptions/now.xml\nURL: GET /users/{uname}/subscriptions/{sid}/entries/{eid}.xml\n\nHopefully, the structure of these URL patterns make a little bit of sense.  The too-clever thing about these is that they're both documentation in the module's docstrings, and parsed out to register methods with automagically-generated regexes applied to incoming URL requests.  (I may eventually realize just how stupid an idea this is, but not yet.)  \nThis list is nowhere near complete or final or even all that well thought out yet.  But, it seems to be working out pretty well so far, and it's so easy to tinker with the API to sketch out ideas in working code.  Eating my own dogfood, my first browser window of the day tends to open on this URL:\nhttp://localhost/~deusx/dbagg3.5/api/users/default/subscriptions/\nnow-12.xml?xsl=xsl/full.xsl&#38;content-type=text/html\n\nThis grabs the last 12 hours' worth of items from default's subscriptions, passing them through the XSL at xsl/full.xsl on the way to my browser with a content type of text/html.  This tends to produce about 1000-1500 entries in about 15 seconds on my PowerBook, which is better than I'd expected.  \nPretty soon, I'll be implementing the ability to post metadata onto feed entries under subscriptions.  Then, I can mark items as seen, attach categories, tags, and notes.  From there, I can exclude seen items from queries, produce new aggregate feeds based on my tagging or notes, among a few other ideas I've got stewing.\nA little more work, and I think I'll be able to throw together the beginnings of a Bloglines-style three-pane browser interface, as well as improving the functionality of my own outliner-style display with XmlHTTPRequest-based calls to the API to enable refresh-free interaction.  From there, I have some ideas for desktop apps and maybe even some tinkering in Flash.  (Wow... has it really been over a year since I was writing about Flash & REST?)\nAnd then, I want to implement the Atom API and allow users to create feeds to which they can post their own items and share read-only with others (or share writing with a group).  From there, this thing can turn into a read/write Atom storage tank, serving both as an aggregator and a blog publishing engine, given the appropriate XSL work.\nLots of ideas stewing.  Now I just have to get the time and possibly a new web server, since I'd like to eventually open up an installation of this to fellow tinkerers, but this poor little box can barely take what it's tasked with at present...\nOh yeah, and one other thing:  I've been thinking about names better than dbagg3.  The one that's sticking around in my head so far is feedReactor.  What do you think?",
    "prevPostPath": "2004/09/01/xpath-based-python-dictionaries-on-loan",
    "nextPostPath": "2004/08/30/crappyvideogames"
  },
  {
    "comments_archived": true,
    "date": "2004-08-24T03:14:40.000Z",
    "excerpt": "I tell ya, this is an idea that's catching.  Feeds go into a searchable stew, come back out as new synthetic feeds.  What comes out looks like what goes in, and there's a well-defined spec behind it.  Sprinkle in the elegance of loosely coupled UNIX pipelines and filters, REST interfaces, and XML tech like XSLT for munging, and you've got the makings of the next generation of syndication and XML feeds.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "More Cooks in the Feed Stew Kitchen",
    "wordpress_id": 540,
    "wordpress_slug": "more-cooks-in-the-feed-stew-kitchen",
    "wordpress_url": "http://www.decafbad.com/blog/?p=540",
    "year": "2004",
    "month": "08",
    "day": "23",
    "isDir": false,
    "slug": "more-cooks-in-the-feed-stew-kitchen",
    "postName": "2004-08-23-more-cooks-in-the-feed-stew-kitchen",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/08/24/more-cooks-in-the-feed-stew-kitchen",
    "prevPostPath": "2004/08/29/blogging-without-thought",
    "nextPostPath": "2004/08/23/slicing-and-dicing-to-make-atom-soup-in-dbagg3"
  },
  {
    "comments_archived": true,
    "date": "2004-08-23T22:52:06.000Z",
    "excerpt": "I've been putting more work into dbagg3, but I'm getting hung up on the database.  Well, actually I'm getting hung up on the subject of XML storage, query, and retrieval in general-- but at present, I'm trying to cram all this data into MySQL and SQLite databases.  But, my tendencies as an abstraction astronaut and my lack of database savvy are tying me (and my data) in knots.  I kept meaning to write a bit Atom (and XML in general) with regard to database storage and query, so maybe now's the time.",
    "layout": "post",
    "tags": [
      "syndication",
      "xml"
    ],
    "title": "Slicing and Dicing to Make Atom Soup in dbagg3",
    "wordpress_id": 539,
    "wordpress_slug": "slicing-and-dicing-to-make-atom-soup-in-dbagg3",
    "wordpress_url": "http://www.decafbad.com/blog/?p=539",
    "year": "2004",
    "month": "08",
    "day": "23",
    "isDir": false,
    "slug": "slicing-and-dicing-to-make-atom-soup-in-dbagg3",
    "postName": "2004-08-23-slicing-and-dicing-to-make-atom-soup-in-dbagg3",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/08/23/slicing-and-dicing-to-make-atom-soup-in-dbagg3",
    "prevPostPath": "2004/08/24/more-cooks-in-the-feed-stew-kitchen",
    "nextPostPath": "2004/08/23/mysql-and-xml-output"
  },
  {
    "comments_archived": true,
    "date": "2004-08-23T05:09:51.000Z",
    "excerpt": "So...  How many of you have ever used mysql -X?",
    "layout": "post",
    "tags": [
      "hacks",
      "xml"
    ],
    "title": "mysql and XML output",
    "wordpress_id": 538,
    "wordpress_slug": "mysql-and-xml-output",
    "wordpress_url": "http://www.decafbad.com/blog/?p=538",
    "year": "2004",
    "month": "08",
    "day": "23",
    "isDir": false,
    "slug": "mysql-and-xml-output",
    "postName": "2004-08-23-mysql-and-xml-output",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/08/23/mysql-and-xml-output",
    "prevPostPath": "2004/08/23/slicing-and-dicing-to-make-atom-soup-in-dbagg3",
    "nextPostPath": "2004/08/05/dbagg3cvs"
  },
  {
    "comments_archived": true,
    "date": "2004-07-06T21:05:45.000Z",
    "excerpt": "This is the exciting conclusion of the Wish-of-the-Month Club.  Before continuing on, you may want to catch up with parts one and two.",
    "layout": "post",
    "tags": [
      "hacks",
      "xml"
    ],
    "title": "Wish-of-the-Month Club, Part 3 of 3",
    "wordpress_id": 532,
    "wordpress_slug": "wishofthemonthclub3",
    "wordpress_url": "http://www.decafbad.com/blog/?p=532",
    "year": "2004",
    "month": "07",
    "day": "06",
    "isDir": false,
    "slug": "wishofthemonthclub3",
    "postName": "2004-07-06-wishofthemonthclub3",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/07/06/wishofthemonthclub3",
    "thumbnail": "http://www.decafbad.com/cvs/*checkout*/hacks/wishes/wishes.jpg",
    "summary": "This is the exciting conclusion of the Wish-of-the-Month Club.  Before continuing on, you may want to catch up with parts one and two.\nPresenting the Results\nSome ready-made files are available for this section:\n\nwishes-ex5.xsl: The fifth iteration of the stylesheet in development.\nwishes.html: Sample output in HTML\n\nWe've finally gotten together all the bits of information we need--wishlists have been queried; random items have been selected; and a shopping cart has been prepared.  Now we just have to present the selections and a link to check out with the shopping cart.\nFirst, locate the following line toward the end of the stylesheet as we left it in the last section:\n    <xsl:copy-of select=\"$shopping_cart\" />\n\nDelete this, and let's replace it by building some HTML:\n    <xsl:variable name=\"shopping_cart_purchase_url\" \n                  select=\"exsl:node-set($shopping_cart)//PurchaseUrl\" />\n    \n    <html xmlns=\"http://www.w3.org/1999/xhtml\">\n      <head><title>Wishlist Shopping Cart</title>\\</head>\n      <body>\n        <p class=\"title\">\n          Here are your wishlist items\n          <a href=\"{$shopping_cart_purchase_url}\">\n            <img src=\"http://g-images.amazon.com/images/G/01/detail/shoppingcart-header-02.gif\" />\n          </a> \n          items:\n        </p>\n\nWe're using the exsl:note-set function again to access the contents of $shopping_cart with an XPath expression.  We pluck out the value of the PurchaseUrl in the shopping cart and place it in the variable shopping_cart_purchase_url.  Then, after a bit of HTML preamble, we borrow a shopping cart icon from Amazon itself to construct a link to which we can browse later to purchase the selected items.  This HTML is very simple so far; it's likely too simple, so eventually you may like to toss some CSS in here to improve the looks of things.  But, I'll leave that as an exercise for the reader.  \nNext, let's build a display of the items selected by iterating first through the wishlists:\n        <xsl:for-each select=\"exsl:node-set($random_products)/wishes:wishitem\">\n          <div class=\"Detail\">\n\n            <p class=\"wishlistLabel\">\n              <xsl:value-of select=\"wishes:wishlist/@label\" />\n            </p>\n\nThis begins a block for each wishlist, starting off with a paragraph containing the label we gave each wishlist.  Next, let's include a few details about the product chosen.  Again, all of the bits of data included for each product are described in the AWS documentation in the Overview under Amazon Web Services Data Model.  Checking that out, we can see that the data includes a URL to images of several sizes representing the product.  Let's include the medium-sized image as a link to the product's detail page:\n            <p class=\"Product\">\n              <a href=\"{Details/@url}\">\n                <img src=\"{Details/ImageUrlMedium}\" />\n              </a>\n              <br />\n\nWe can also include the product's name as a link:\n              <span class=\"ProductName\">\n                <a href=\"{Details/@url}\">\n                  <xsl:value-of select=\"Details/ProductName\" />\n                </a>\n              </span>\n              <br />\n\nAnd, it would be nice to provide a listing of people involved in creating the product (ie. the artists and/or authors):\n          <xsl:for-each select=\"./Details/Artists/Artist | \n                                ./Details/Authors/Author\">\n            <span class=\"Author\">by <xsl:value-of select=\".\" /></span><br />\n          </xsl:for-each>\n\nNote that here, the XPath selecting the data is just a bit more involved, since this information can be found in both Artist and Author elements.  In another case, we might care to make a distinction, but it really isn't all that important for this project.  The data model also provides an indication of from which catalog this product came, as well as its date of release.  Let's include that for good measure:\n          (\n          <xsl:value-of select=\"Details/Catalog\" /> -\n          <span class=\"ReleaseDate\">\n            <xsl:value-of select=\"Details/ReleaseDate\" />\n          </span>\n          )\n          <br />\n        </p>\n\nAnother thing that would be nice to know is how much this thing costs--we've got this information provided in the XML data as well, so let's include it:\n        <p>\n          <span class=\"PriceLabel\">List Price:</span> \n          <span class=\"ListPrice\">\n            <xsl:value-of select=\"Details/ListPrice\" />\n          </span>\n          <br />\n          \n          <span class=\"PriceLabel\">Our Price:</span>\n          <span class=\"OurPrice\">\n            <xsl:value-of select=\"Details/OurPrice\" />\n          </span>\n          <br />\n\n          <span class=\"PriceLabel\">Used Price:</span> \n          <span class=\"UsedPrice\">\n            <xsl:value-of select=\"Details/UsedPrice\" />\n          </span>\n          <br />\n        </p>\n\nSomething to note about these prices, too, is that although the used price is listed, the shopping cart will contain new items from Amazon's shelves.  You might want to compare these prices though, and make a change to the shopping cart when you get there, if a used item is acceptable.  (Another good reason for manual intervention in our Wish-of-the-Month club.)\nOh yeah, and we should include one other bit of information:\n        <p>(<xsl:value-of select=\"Details/Availability\" />)</p>\n\nThis tells us whether or not this item can actually be bought, at present.  Although we used this data earlier to try to filter out unavailable items, we should still display this information just in case we missed something.\nFinally, let's clean up and finish the HTML:\n      </div>\n    </xsl:for-each>\n    \n  </body>\n</html>\n\nRunning this stylesheet (wishes-ex5.xsl) should give you a page that looks something like this in a browser:\n\nScheduling Monthly Emails\nSome ready-made files are available for this section:\n\nwishes-ex6.xsl: The sixth (and final) iteration of the stylesheet in development.\n\nThat HTML we're producing is fine, but what we really want to do is get it delivered to us.  We could set up a scheduled run that would periodically generate a page for us to visit, but the whole point of this is laziness.  How about firing off an email with this content?  There are two things to help us with this: RFC 1521 shows us how to construct email messages with a variety of content types; and sendmail will let us send these messages out.  And then, with the help of cron, we can fire up this process every month.\nAlong with producing XML, XSLT can also construct plain text output--which is just what we need to create MIME email messages.  RFC 1521 doesn't make for the most thrilling reading, but there are a few articles to be found that summarize things (such as this article and this article).   To make a long story short, a basic shell for an email message using MIME to include an HTML part and a plain text part looks something like this:\nTo: someone@example.org\nSubject: Some useful email subject\nMIME-Version: 1.0\nContent-Type: multipart/alternative; boundary=\"theBoundaryString\"\n\n--theBoundaryString\nContent-Type: text/plain\n\nSome plain text representation goes here...\n\n--theBoundaryString\nContent-Type: text/html\nContent-Transfer-Encoding: 7bit\nContent-Disposition: inline\nContent-Base: \"http://www.decafbad.com/\"\n\n<html xmlns=\"http://www.w3.org/1999/xhtml\">\n    <p>Some HTML representation goes here...</p>\n</html>\n\n--theBoundaryString--\n\nI've snuck in the idea of providing both an HTML version (which we've already done) and a new plain text version.  Depending on your email program and your preferences, one type might be more useful than the other.  In any case, it's not all that hard to offer both here.  To start sending these email messages, though, we'll need an email address.  So, add that as an element in wishes.xml:\n<wishes xmlns=\"http://www.decafbad.com/2004/05/wishes\">\n  <email>deus_x@pobox.com</email>\n  <maxprice>15.00</maxprice>\n  <associate>0xdecafbad-20</associate>\n  <devtoken>D8HVH869XA0NP</devtoken>\n  <wishlists>\n    <wishlist label=\"Me\">1QWYI6P2JF3Q5</wishlist>\n    <wishlist label=\"The Girl\">35OIOYWQ9XQAE</wishlist>\n  </wishlists>\n</wishes>\n\nLet's extract this data into a global variable near the start of the stylesheet:\n  <xsl:variable name=\"email_to\"  select=\"/wishes:wishes/wishes:email\" />\n\nStart editing the final template of the stylesheet, inserting before the start of HTML content:\n    <!-- Eat all the line breaks generated so far -->\n    <xsl:text>To: </xsl:text><xsl:value-of select=\"$email_to\" />   \nSubject: 0xDECAFBAD's Amazon Wish-of-the-Month Club\nMIME-Version: 1.0\nContent-Type: multipart/alternative; boundary=\"theBoundaryString\"\n\nThis is the header for the email.  Up until now, we've been generating XML with the stylesheet and haven't cared very much about any extra whitespace or line breaks which might sneak into the output.  However, in an email header, whitespace is important since a blank line is what's used to separate the headers from the body of the email message.  So, any stray blank lines will cause what we might have meant to be headers to be interpreted as part of the message instead.  Producing the first header in the email with xsl:text tags causes the XSL processor to throw away any leading whitespace which would have appeared before the first header.\nOther than this little twist, the email header looks pretty much like the shell.  We fill in the To address from the global variable $email_to and define a Subject line.  The MIME-Version and Content-Type headers are what enable us to include both text and HTML versions in one email.\nNow we can start into one of the parts:\n--theBoundaryString\nContent-Type: text/plain\n\nThis begins the plain text section of the email, using the boundary string as defined in the headers to delinieate the section's beginning.  The section can also have its own set of headers, of which we use only one: Content-Type.  Moving along, let's work on the text content itself.\nHere are your wishlist items:\n\n<xsl:value-of select=\"$shopping_cart_purchase_url\" /><xsl:text>\n</xsl:text>\n\nNo shopping cart image here, but this includes the human-viewable URL which leads to a shopping cart on Amazon.com.  The usage of xsl:text here forces a line break where there otherwise wouldn't have been one with the usage of xsl:value-of.  Now, let's iterate through each of the wishlists and list out the product details:\n<xsl:for-each select=\"exsl:node-set($random_products)/wishes:wishitem\">\n---------------------------------------------------------------------------\n<xsl:value-of select=\"wishes:wishlist/@label\" \n       disable-output-escaping=\"yes\" />\n---------------------------------------------------------------------------\n\n<xsl:value-of select=\"Details/ProductName\" \n       disable-output-escaping=\"yes\" />\n\n<xsl:for-each select=\"./Details/Artists/Artist | \n                      ./Details/Authors/Author\">\nby <xsl:value-of select=\".\"  \n   disable-output-escaping=\"yes\"/>\n</xsl:for-each>\n\nCatalog:      <xsl:value-of select=\"Details/Catalog\" \n   disable-output-escaping=\"yes\" />\nReleased:     <xsl:value-of select=\"Details/ReleaseDate\" \n   disable-output-escaping=\"yes\" />\n\nList Price:   <xsl:value-of select=\"Details/ListPrice\"  \n     disable-output-escaping=\"yes\"/> \nOur  Price:   <xsl:value-of select=\"Details/UsedPrice\"  \n     disable-output-escaping=\"yes\"/> \nUsed Price:   <xsl:value-of select=\"Details/OurPrice\"  \n     disable-output-escaping=\"yes\"/> \n        \nAvailability: <xsl:value-of select=\"Details/Availability\"  \n       disable-output-escaping=\"yes\"/>\n<xsl:text>\n\n</xsl:text>\n<xsl:value-of select=\"Details/@url\"  \n       disable-output-escaping=\"yes\"/>\n<xsl:text>\n</xsl:text>\n\n</xsl:for-each>\n\nMost everything in this stretch should look very similar to the HTML version we just finished.  The biggest difference is that every bit of information pulled in using xsl:value-of is done using the disable-output-escaping option.  When this is yes, things like ampersands are no longer escaped for valid XML output.  Since this bit of the email is plain text, we don't want to see &amp; in album titles, so this will cause ampersands to appear unmolested.\nThat's the plain text version finished.  Now let's create the HTML version:\n--theBoundaryString\nContent-Type: text/html\nContent-Transfer-Encoding: 7bit\nContent-Disposition: inline\nContent-Base: \"http://www.decafbad.com/2004/05/wishes\"\n\nThe boundary string appears again, signifying the end of the plain text section and the start of the HTML section.  Headers appear here which specify that what follows is HTML; that it's encoded in 7-bit characters; that it should be included in the message display itself (rather than presented as an attachment to be saved); and that all relative URLs which might appear in the HTML should be treated as having a base URL as specified.  This last part allows HTML in email to refer to images and other pages on another site without making all the URLs absolute.\nWe don't need to make any modifications to the HTML as we built it in the last iteration of the stylesheet, so we can just include it unchanged:\n<html xmlns=\"http://www.w3.org/1999/xhtml\">\n...\n</html>\n\n--theBoundaryString--\n\nThis final appearance of the boundary string is bracketed on both sides by dashes, which indicates the end of the final section of the document.  We should be ready to try this in combination with sendmail in a shell:\n$ xsltproc wishes-ex6.xsl wishes.xml | sendmail -it\n\nIf everything has worked correctly, there should be an email arriving in your mailbox sometime soon.  (Or in my inbox, if you followed the directions literally and didn't supply your own email address.)  The options supplied to sendmail are fairly basic: \n\n-i causes lines consisting solely of . not to be treated as an end-of-input signal.\n-t causes sendmail to look in the message headers (ie. To:) for a list of recipients.\n\nIf you don't happen to have have sendmail available, you might want to look into what local mail programs you have available which can accept the output from the stylesheet.\nOnce you have this working, the final task is to schedule its monthly execution with your local cron installation.  If you haven't played with cron before, there are many resources and tutorials available (here's one and here's another).  You should add something like the following to your user account's crontab:\n0 0 * 1 *  (cd /your/working/path; xsltproc wishes.xsl wishes.xml | sendmail -it)\n\nThe \"0 0 * 1 *\" indicates to cron that this set of commands should be run at midnight on the first of every months.  Note also that /your/working/path should be replaced by the path to where you've been working during this project.  And finally, I've renamed the final iteration of the stylesheet file to simply wishes.xsl.\nConclusion\nSo that's it--we have an XSL stylesheet which queries Amazon Web Services for products contained in multiple wishlists; selects a random item from each; prepares a shopping cart containing those items; and finally generates an email message containing both plain text and HTML presentations of the shopping cart and selected items.\nThough this implementation serves the purpose I wrote about at the start of this article, there are definitely many areas where this can be improved upon or expanded:\n\nMany people think Amazon is an evil company for their use of patents.  I can't say that I'm entirely happy with them for this myself, but their AWS offering is just too nice to resist tinkering with.  It might be interesting to investigate other retailers' wishlist offerings, where they exist, and to see how this idea might be made to work with other (or even multiple) retailers.  Even better, come up with your own wishlist system, and a cross-retailer shopping cart.\n\nI chose XSLT as the implementation technology because I thought it would be more natural to deal with Amazon's XML this way.  There are, admittedly, a few awkward parts in the resulting stylesheet however.  Sometimes it's good to see a project like this through, just to get a sense for where things do go awkward with a technology or my understanding of it.  It could be interesting to transliterate this into a scripting language like Python or Perl, perhaps using the libxml bindings to do so.\n\nThe error and failure handling in this implementation are all but non-existent.  Should anything unexpected happen while dealing with Amazon Web Services, the results aren't likely to be very pretty.  You may want to consider improving in this area.  One instance I identified was to report when the sanity limit was hit in looping through wishlist pages, versus an actual end of pages.\n\nIf you play around with making more wishlist queries using the techniques here, you might want to consider caching the full set of data pulled in by the multiple-page calls to AWS, in order to prevent hammering Amazon's servers with repeated requests for the same data, likely unchanged.\n\nI still don't know why exsl:random doesn't work for me.  Although I thought using a web service for random numbers was intereting, it would be very nice if I didn't have to use it.\n\nThe HTML presentation could certainly use some good CSS to make it more attractive.\n\n\nFeel free to send me any suggestions, criticisms, or complaints related to this article!",
    "prevPostPath": "2004/07/15/dork-funk",
    "nextPostPath": "2004/06/28/radioiorock-scraper"
  },
  {
    "comments_archived": true,
    "date": "2004-06-28T01:44:51.000Z",
    "excerpt": "Here's the next installment of the Wish-of-the-Month Club.  You can revisit the first part, too, if you've missed it.  I'd meant to post it within a week of the first part, so apologies all around to anyone who has been tapping a foot waiting for it.  Enjoy!",
    "layout": "post",
    "tags": [
      "hacks",
      "xml"
    ],
    "title": "Wish-of-the-Month Club, Part 2 of 3",
    "wordpress_id": 530,
    "wordpress_slug": "wishofthemonthclub2",
    "wordpress_url": "http://www.decafbad.com/blog/?p=530",
    "year": "2004",
    "month": "06",
    "day": "27",
    "isDir": false,
    "slug": "wishofthemonthclub2",
    "postName": "2004-06-27-wishofthemonthclub2",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/06/28/wishofthemonthclub2",
    "summary": "Here's the next installment of the Wish-of-the-Month Club.  You can revisit the first part, too, if you've missed it.  I'd meant to post it within a week of the first part, so apologies all around to anyone who has been tapping a foot waiting for it.  Enjoy!\nPaging Through Wishes\nSome ready-made files are available for this section:\n\nwishes-ex2.xsl: The second iteration of the stylesheet in development.\n\nNow we've got a way to make queries against Amazon Web Services, not entirely unlike what you might be used to if you tinker with MySQL databases on a regular basis.  At this point, though, we still have a bit of refining to make to this query.  If you take a look at the data produced by the query in its current state, and compare that to what you see on wishlists in your browser, you should notice some things missing.\nIf you look at my wishlist, you'll notice that items span several pages when visited by browser.  As it turns out, AWS queries work in a similar fashion--each query returns only a limited number of items (about 10), and an additional parameter supplied to further queries is required to step through further pages of results.  So, using what we've built so far will only get us to the first page of wishlist items; to get all of the items, we'll need a way to step through all of the pages.\nIn playing with this, I experienced a bit of hairpulling frustration:  The AWS documentation, under \"Generating Additional Product Results\", claims that XML returned by the service will supply a count of the total pages available for a given query.  And although I see this element present in other types of searches, the TotalPages element is absent when querying on wishlists.  This may be a bug, or it may be an undocumented change in the service--either way, it was a surprise and leaves me with no official way to know how many pages I need to ask for in order to have a complete set of data.  \nWith some further tinkering, though, I figured out a workaround: If a query is made for a page number beyond the final page, the XML returned will be a duplicate of the final page.  Once I see a duplicate item appear, I know it's time to stop paging through results.  This is completely undocumented behavior, and could break at any time (ie. if Amazon decided to start issuing an error for a page index out of bounds), but it'll work for now.\nThis calls for reworking the processWishlist template.  For a given wishlist, it will need to iterate through a sequence of page numbers, requesting XML from AWS for each, stopping when the first duplicate page is found.  Since XSLT is heavily steeped in functional programming concepts, this sort of iteration in XSLT is best done with recursion:\n  <xsl:template name=\"processWishlist\">\n\n    <xsl:param name=\"wishlist\" />              <!-- Wishlist ID -->\n    <xsl:param name=\"max\"   select=\"50\" />     <!-- Arbitrary upper loop limit -->\n    <xsl:param name=\"curr_page\" select=\"1\" />  <!-- Curr page # -->\n    <xsl:param name=\"prev_first_asin\" />       <!-- Keeping track of repeats -->\n\nThe first modification to this template is the addition of three parameters:\n\nmax provides an arbitrary upper limit to the number of pages through which this template will iterate.\ncurr_page contains the number of the page to be requested in this iteration.\nprev_first_asin will contain the ASIN number of the first item from the previous iteration's page of results.\n\nNext, we modify the URL used to query for wishlist data:\n    <!-- Fetch the wishlist products -->\n    <xsl:variable name=\"details\" select=\"document(concat(\n                  'http://xml.amazon.com/onca/xml3?',\n                  't=',$associate,'&amp;',\n                  'dev-t=',$devtoken,'&amp;',\n                  'WishlistSearch=',$wishlist,'&amp;',\n                  'type=lite&amp;f=xml&amp;',\n                  'page=',$curr_page))//Details\" />\n\nThe only addition here beyond the previous version is the page parameter in the URL.  Not much mystery here--this parameter specifies which page of results we want.  Now, let's build the loop:\n    <!-- Snag the first item Asin -->\n    <xsl:variable name=\"curr_first_asin\" select=\"$details/Asin/text()\" />\n\n    <!-- If we haven't exceeded the loop limit, and this first Asin isn't -->\n    <!-- a repeat of the previous loop (indicating we've run out of new   -->\n    <!-- pages), then go ahead...                                         -->\n    <xsl:if test=\"(($curr_page+1) &lt; $max) and\n                  (string-length($curr_first_asin) &gt; 0) and\n                  not($curr_first_asin = $prev_first_asin)\">\n  \n\nWe capture the ASIN of the first item in this page of results and check to see if we should continue.  This if conditional first ensures that we're not past the sanity guard for loop iterations, makes sure that we actually got a non-empty current first ASIN, then checks our current first product's ASIN against what was passed in as the previous iteration's first product's ASIN.  If this was the first time through the loop, this value should be empty and therefore wouldn't match the current ASIN.  But, if we've gone past the end of results, the previous and current ASIN values should match, and the conditional will fail.\nMoving along into the body of the conditional, we copy in wishlist products filtered on a price maximum, just as before:\n      <!-- Copy products, filtering on a maximum price -->\n      <xsl:copy-of select=\"$details/OurPrice[number(substring(\n                   text(),2)) &lt; $maxprice]/..\" />\n\nHaving done that, we move onto the recursive end of this template:\n      <!-- Loop by recursion to get the next page -->\n      <xsl:call-template name=\"processWishlist\">\n        <xsl:with-param name=\"wishlist\"        select=\"$wishlist\" />\n        <xsl:with-param name=\"max\"             select=\"$max\" />\n        <xsl:with-param name=\"curr_page\"       select=\"$curr_page + 1\" />\n        <xsl:with-param name=\"prev_first_asin\" select=\"$curr_first_asin\" />\n      </xsl:call-template>\n\n    </xsl:if>    \n  </xsl:template>\n\nHere, the template makes a recursive call back to itself, passing through the wishlist ID and the maximum iteration count.  Since variables in XSLT are immutable, meaning that their values can't be changed once they've been set, we can't increment $curr_page in-place like a loop counter in other languages--so, the current page count value is incremented and passed to the recursive call as a parameter.  Finally, the current first item's ASIN is passed along, to become the previous ASIN for the next iteration.\nNote that when the conditional fails--that is, if the loop limit is passed or a duplicate page is detected--the loop ends.  In other words, nothing further happens and execution pops back up out of all the levels of recursion and the top-level template ends.  \nI wrote \"when the conditional fails\".  This is a key point: for the loop to eventually end, this conditional must fail (or be made to fail) at some point, else this loop will happily progress through page requests forever.  This is the reason for the $max parameter limiting the number of iterations, in case something goes haywire--like, oh say, a failure of our duplicate-page detection hack as a loop ending condition.  A useful exercise for the reader might be to add some additional diagnostic code to report that the limit was hit versus a natural end to results.\nRandom Numbers\nSome ready-made files are available for this section:\n\nwishes-ex3.xsl: The third iteration of the stylesheet in development.\nrandom-xml: A Perl CGI script used as a web service to generate random numbers.\n\nArmed with a template that will query against the full set of items in a wishlist, we're ready to look into making a random selection from a list of products.  \nBut first, we need to pick a random number.  Unfortunately, there doesn't appear to be any random() function in the XPath or XSLT standards.  There is a math:random() from EXSLT implemented in libxslt, but I seem to be having a bit of a problem getting it to produce anything other than the same sequence of numbers.  I suspect there's a problem in seeding the random number generator, but I've yet to work out how to fix it.  (Suggestions welcome.)\nSo, I cheated and made another workaround with a CGI script on my web server that generates random numbers in a simple XML document.  Currently, it's hosted here:\nhttp://www.decafbad.com/2004/05/random-xml\n\nAnd this is what the script looks like:\n#!/usr/bin/perl\n\nuse strict;\nuse CGI;\n\nmy $q = new CGI();\n\nmy $min = $q->param('min') or 0;\nmy $max = $q->param('max') or 1;\nmy $int = $q->param('int');\n\nmy $num = $min + ( rand() * ($max - $min));\nif ($int) { $num = int($num); }\n\nprint $q->header('text/xml');\nprint \"<rand>$num</rand>\\n\";\n\nThis is a very simple CGI.  It accepts the parameters max, min, and int.  The values of these parameters determine the maximum and minimum value for the random number returned, and whether or not it should be an integer.  For example, the following URL should return an integer between 10 and 20:\nhttp://www.decafbad.com/2004/05/random-xml?\nint=1&#38;min=10&#38;max=20\n\nUsing this as a web service in the stylesheet with the document() function, we can get a random number.  If you've got web space where you can host CGI scripts, I suggest you host a copy of this script yourself, since I can't guarantee how long mine will stick around.  But, for as long at works, feel free to use the service from my server.\nMoving along, let's add a new named template to the stylesheet, called randomWishlistProduct:\n  <xsl:template name=\"randomWishlistProduct\">\n\n    <xsl:param name=\"wishlist\" /> <!-- Wishlist ID -->\n    \n    <!-- Gather all the products for the current wishlist -->\n    <xsl:variable name=\"products\">\n      <xsl:call-template name=\"processWishlist\">\n        <xsl:with-param name=\"wishlist\" select=\"$wishlist\" />\n      </xsl:call-template>\n    </xsl:variable>\n\nJust like the processWishlist template, we start by defining the parameter wishlist to accept a wishlist ID.  Using this ID, we call the processWishlist template itself and store the complete list of products queried from the wishlist into the variable $products.\n    <!-- Count the products in the wishlist -->\n    <xsl:variable name=\"max_products\"\n                  select=\"count(exsl:node-set($products)/Details)\" />\n\nThis next step counts the number of products found in the wishlist.  The one tricky bit here is the use of the EXSLT function exsl:node-set(): The $products variable contains what's called a result tree fragment, which is a kind of cross between XML data nodes and a plain old string.  This type of data does not normally allow the full set of XPath operators to be used on it, so first we need to use exsl:node-set() to turn it into a full-fledged node set.  Then we can look up the Details element nodes and count them.  \n    <!-- Conjure up a random index within the list of products -->\n    <xsl:variable name=\"rand_product_num\"\n                  select=\"document(concat(\n                  'http://www.decafbad.com/2004/05/random-xml?',\n                  'int=1&amp;',\n                  'min=1&amp;',\n                  'max=',$max_products))/rand\" />\n\nHere is where the random number service comes in handy.  The concat() function is used to build the URL to the service, with parameters specifying that the number should be an integer, and should fall between 1 and the number of products in the wishlist.  The document() function grabs the XML document from the service, and the value is extracted from the single element the document contains.\nThere is an alternative to this last bit, should you happen to have a properly working math:random() function in your XSLT processor:\n    <xsl:variable name=\"rand_product_num\" select=\"round( math:random() *\n                  $max_products ) + 1\" />\n\nIf you can use this instead, you'll have no need for the random number web service.  This version is obviously more concise, and doesn't require another trip out to a web service.  You might want to try it--but if you find that you keep getting the same wishlist items selected, then you've run into the problem I found with the random number generator.\nNow, let's wrap this template up by selecting an item:\n    <!-- Copy the product as indexed by the random number -->\n    <xsl:copy-of select=\"exsl:node-set($products)/Details[\n                 position()=$rand_product_num]\" />\n       \n  </xsl:template>\n\nAgain, we need to use the exsl:node-set() function to turn the result tree fragment in the $products variable into a node set, from which we select and copy the Details element whose position in the data is indexed by the random number we just selected.  Just one last tweak needed to wrap up this iteration of our stylesheet.  We need to swap out the call to the processWishlist function at the end and replace it with a call to randomWishlistProduct:\n  <xsl:template match=\"/wishes:wishes\">\n\n    <xsl:for-each select=\"//wishes:wishlist\">\n      <wishes:wishitem>\n        <xsl:copy-of select=\".\" />\n        <xsl:call-template name=\"randomWishlistProduct\">\n          <xsl:with-param name=\"wishlist\" select=\".\" />\n        </xsl:call-template>\n      </wishes:wishitem>\n    </xsl:for-each>\n\n  </xsl:template>\n\nAfter these changes, you should be able to run the stylesheet ([wishes-ex3.xsl][wishes_ex3]) and get something like the following:\n<wishes:wishitem xmlns:wishes=\"http://www.decafbad.com/2004/05/wishes\">\n    <wishes:wishlist label=\"The Girl\">35OIOYWQ9XQAE</wishes:wishlist>\n    <Details ...>...</Details>\n</wishes:wishitem>\n<wishes:wishitem xmlns:wishes=\"http://www.decafbad.com/2004/05/wishes\">\n    <wishes:wishlist label=\"Me\">1QWYI6P2JF3Q5</wishes:wishlist>\n    <Details ...>...</Details>\n</wishes:wishitem>\n\nThis is similar to the output of the previous iteration of the stylesheet, but this time there's only one product selected at random for each wishlist.  \nShopping Carts\nSome ready-made files are available for this section:\n\nwishes-ex4.xsl: The fourth iteration of the stylesheet in development.\n\nBy this point, we've been able to query and filter products in Amazon wishlists, and we've selected an item at random from each wishlist we've queried.  Now, let's enable some purchases.\nThe AWS provides for Remote Shopping Cart functionality, whereby items can be added to an Amazon.com shopping cart programmatically.  This is about as close as we can get to automating the purchase of items selected from the wishlists--there is no API functionality for actually completing the ordering of items.  If you really think about it, this really is a good thing and should demand human intervention; we certainly wouldn't want this script going crazy and accidentally buying up everything on a wishlist.\nDocumentation for the AWS Remote Shopping Cart explains that a shopping cart can be created and items added with a URL like the following:\nhttp://xml.amazon.com/onca/xml3?\nShoppingCart=add&#38;\nf=xml&#38;\ndev-t=[Developer Token goes here]&#38;\nt=[Associates ID goes here]&#38;\nAsin.[ASIN goes here]=[quantity goes here]&#38;\nsims=true\n\nPart of this should look familiar, so we already know what to do with the developer token and the associates ID.  The last part, specifying product ASIN and quantity, can be filled out with information contained in the product records selected at random from the wishlists.  \nSo, let's start by revising the template at the end of the stylesheet:\n<xsl:template match=\"/wishes:wishes\">\n\n    <xsl:variable name=\"random_products\">      \n      <xsl:for-each select=\"//wishes:wishlist\">\n        <wishes:wishitem>\n          <xsl:copy-of select=\".\" />\n          <xsl:call-template name=\"randomWishlistProduct\">\n            <xsl:with-param name=\"wishlist\" select=\".\" />\n          </xsl:call-template>\n        </wishes:wishitem>\n      </xsl:for-each>\n    </xsl:variable>\n\nHere, we've taken what was the output of the previous iteration of the stylesheet and stuffed it into the variable $random_products.  Next, let's fill in the blanks and build a Remote Shopping Cart URL:\n    <xsl:variable name=\"shopping_cart_create_url\">\n      <!-- Standard AWS URL -->\n      <xsl:text>http://xml.amazon.com/onca/xml3?</xsl:text>\n\n      <!-- Add in the selected items -->\n      <xsl:for-each select=\"exsl:node-set($random_products)\n                            /wishes:wishitem/Details\">\n        <xsl:text>Asin.</xsl:text><xsl:value-of select=\"Asin\" />\n        <xsl:text>=1&amp;</xsl:text>\n      </xsl:for-each>\n\n      <!-- Wrap up with the shopping cart function and required tokens -->\n      <xsl:text>ShoppingCart=add&amp;</xsl:text>\n      <xsl:text>f=xml&amp;</xsl:text>\n      <xsl:text>dev-t=</xsl:text><xsl:value-of select=\"$devtoken\" />\n      <xsl:text>&amp;</xsl:text>\n      <xsl:text>t=</xsl:text><xsl:value-of select=\"$associate\" />\n    </xsl:variable>\n\nSince simple XPath doesn't allow for the looping needed for multiple items, we can't just concatenate this URL together in a select expression like we did with the wishlist item query.  So, we use xslt:foreach to build this with blocks of text using the xsl:text element.  We iterate though the random products chosen from wishlists and add an ASIN for each to the URL with a quantity of 1. Then, we use the $devtoken and $associate variables to fill in their respective spots.\nNote that this could have been written without using the xsl:text elements like so:\n    <xsl:variable name=\"shopping_cart_create_url\">http://xml.amazon.\n    com/onca/xml3?ShoppingCart=add&amp;f=xml&amp;dev-t=<xsl:value-of \n    select=\"$devtoken\" />&amp;t=<xsl:value-of select=\"$associate\" />\n    &amp;<xsl:for-each select=\"exsl:node-set($random_products)/\n    wishes:wishitem/Details\">Asin.<xsl:value-of select=\"Asin\" />=1\n    &amp;</xsl:for-each></xsl:variable>\n\nThis removes the clutter of all the xsl:text elements, but it would need to be piled all on one line in order to keep undesired whitespace from getting into the URL.  I made a small attempt at wrapping this line here, but line breaks and spaces would leave us with a non-functioning shopping cart URL.  It's up to you to decide which to use--personally, I prefer the xsl:text clutter for the ability to add in comments and clarify things a bit.\nFinally, having built the shopping cart URL, let's use it to get a shopping cart and wrap things up:\n    <xsl:variable name=\"shopping_cart\"\n                  select=\"document($shopping_cart_create_url)\" />\n\n    <xsl:copy-of select=\"$shopping_cart\" />\n\n</xsl:template>  \n\nAs an aside, this part is pushing the concept of a REST web service a bit: In the REST philosophy, requests using the GET method (which is what document() uses) should only return existing resources and not create new resources or cause modifications to happen.  Instead, these sorts of actions should use a POST request.  But, since we've already accepted a few rough edges and workarounds in this project so far, we won't let a point of esoterica like that stop us.  (That and, well, this is the way Amazon designed their web service, so we'll take what we can get.)\nOnce you run this iteration of the stylesheet ([wishes-ex4.xsl][wishes_ex4]), you should get something like this XML as output:\n<ShoppingCartResponse ...>\n  ...\n  <ShoppingCart>\n   <CartId>...</CartId>\n   <HMAC>...</HMAC>\n   <PurchaseUrl>...</PurchaseUrl>\n   <Items>\n    <Item>...</item>\n    <Item>...</item>\n   </Items>\n  </ShoppingCart>\n  ...\n</ShoppingCartResponse>\n\nThe AWS documentation describes the vital elements here like so:\n\nCartId - The Cart ID is the unique identifier for a given shopping cart.\nHMAC - The HMAC is a security token that must be passed back to Amazon Web Services for using an existing cart.\nPurchaseUrl - Use the purchase URL to transfer the remote shopping cart from your application to Amazon so that your application's users may complete their purchases.  The purchase URL merges the remote shopping cart with the Amazon.com shopping cart.\n\nSo, in short, whenever we want to do any sort of manipulation on this Remote Shopping Cart via AWS, we'll need to remember and later supply both the CartId and HMAC found in the XML returned at its creation.  And, once we're all ready to check out, the PurchaseUrl points to where we'll need to browse in person.\nStay Tuned!\nThis concludes Part 2 of the Wish-of-the-Month Club.  Following this will be the final part, where we tie everything together and start firing off monthly emails!",
    "prevPostPath": "2004/06/28/radioiorock-scraper",
    "nextPostPath": "2004/06/16/wishofthemonthclub1"
  },
  {
    "comments_archived": true,
    "date": "2004-06-16T11:42:48.000Z",
    "excerpt": "For some time now, my girlfriend and I have been accumulating things we want in wishlists on Amazon.com.  Though they have come in handy with relatives at Christmas and on birthdays, neither of us really expects to see a regular flow of gifts from them.  For the most part, they've just become holding tanks for things we intend to buy for each other or ourselves.  On one particular visit, though, the notion of a Wish-of-the-Month club popped into my head.",
    "layout": "post",
    "tags": [
      "hacks",
      "xml"
    ],
    "title": "Wish-of-the-Month Club, Part 1 of 3",
    "wordpress_id": 529,
    "wordpress_slug": "wishofthemonthclub1",
    "wordpress_url": "http://www.decafbad.com/blog/?p=529",
    "year": "2004",
    "month": "06",
    "day": "16",
    "isDir": false,
    "slug": "wishofthemonthclub1",
    "postName": "2004-06-16-wishofthemonthclub1",
    "parentPath": "./content/posts/archives/2004",
    "path": "2004/06/16/wishofthemonthclub1",
    "summary": "Remember that I wrote a little while ago about wanting to publish some articles here that I'd want to read?  Well, I've been hard at work since then to turn out the first set and I think I've finally got something for you.  I mentioned earlier this week that I was taking this seriously, so I hope it shows.  So, with many thanks to my girlfriend's kind editorial help, and with some measure of anxiety, here goes...\nIntroduction\nFor some time now, my girlfriend and I have been accumulating things we want in wishlists on Amazon.com.  Here's mine and here's hers - if you visit them, you can see we've both got quite a few things listed.  Though they have come in handy with relatives at Christmas and on birthdays, neither of us really expects to see a regular flow of gifts from them.  For the most part, they've just become holding tanks for things we intend to buy for each other or ourselves.  \nHowever, I tend to forget we have these lists except for occasional visit to Amazon when I think, \"Oh yeah, wishlists.  I should pick up a thing or two, there's some good stuff piled up in them.\"  On one particular visit, though, the notion of a Wish-of-the-Month club popped into my head: We could afford to grab at least one item for each of us from our wishlists on a monthly basis, provided that we remembered to place an order.  It'd be better than signing up for a book or music club, driven by someone else's idea of what we wanted.  Unfortunately, there's that problem for busy, absentminded, and people like us: remembering to place an order.\nBut wait, isn't this the sort of thing computers are for?  I should be able to cobble something together that would peruse our wishlists and--given some criteria like a price maximum--select an item at random for each of us and send them on their way.  With this, I could schedule a monthly run and start whittling down those lists.\nGathering Tools\nBefore I start working through the project itself, let's establish some assumptions and then gather some tools and materials:\nI'm going to assume that you're using a UN*X operating system (ie. Linux, Mac OS X, etc.) and that you're reasonably familiar with getting around in a shell and editing files.  Things presented here could be adapted for Windows fairly easily, but I'll leave that as an exercise to the reader.  Also, you may need to build and install a package or two, so know-how in that regard will serve as well.  And finally: some familiarity with XML and XSLT would be useful, but you won't need to be a guru with either.\nOh, and all the files I'll be introducing in this project can be downloaded from my website as a tarball:  wishes.tar.gz.  If you feel like browsing, you can see these files in my CVS repository.  And if you feel like checking out a copy via anonymous CVS, the username is anoncvs and the password is blank--email me for help, if you need it.\nSo, how do we get a look at these wishlists?  Lately, I've been tinkering a bit with scraping information from and automating access to websites.  It's a bit like a puzzle game, with all the accompanying frustrations and happy breakthroughs.  However, where most puzzle games are designed with a solution in mind, this game isn't even necessarily meant to be played depending on the intentions of website owners.\nFortunately, the folks at Amazon.com have made things very friendly to tinkerers by providing an API, called Amazon Web Services (or AWS).  You'll want to download the AWS developer's kit, which contains a wealth of documentation and examples.  After downloading these materials, you should apply for a developer's token for use with the service.  AWS provides both SOAP and REST interfaces to functionality and data at their site; personally, I prefer the HTTP-and-XML approach taken by the REST interface, so that's what we'll be using here. \nTo handle the XML produced by AWS, we'll be using the xsltproc command from the XML C parser and toolkit of Gnome.  There are other XSLT processors--such as Xalan, Sablotron, and Saxon--but I've found libxslt easiest to feed and care for on the various platforms with which I tinker.  It also seems to support a very large swath of EXSLT extensions, all of which come in very handy, yet seem to receive uneven support in other XSLT processors.  We'll be pulling a trick or two out of that bag, so its support is key.\nYou may or may not already have libsxlt installed.  Depending on your variant of Linux, it might be as simple as a single package-management command or it might be a bit more complex if you need to compile from source.  For Mac OS X, I recommend using Fink for your packaging needs.  Although, DarwinPorts is nice as well, if you're used to The BSD Way.\nA bonus for OS X users: Marc Liyanage has provided a great Open Source tool named TestXSLT that embeds libxslt, among other XSLT processors, in a slick GUI for easier use.  This might come in handy for you as things develop.\nWishlists in XML\nOkay, we've got a working environment, a head start on accessing Amazon wishlists as XML, and a way to manipulate that XML using xsltproc.  Let's start playing.  First things first, we need to gain access to Amazon wishlists in XML form.  Reading through the AWS documentation reveals that wish list searches are available via a URL constructed like so:\nhttp://xml.amazon.com/onca/xml3?\nt=[Associates ID goes here]&#38;\ndev-t=[Developer Token goes here]&#38;\nWishlistSearch=[wishlist ID goes here]&#38;\ntype=[lite or heavy]&#38;\nf=xml\n\nI received an ID of 0xdecafbad-20 when I signed up to be an associate a few years ago.  This will ensure that I get credited for sales made via the API--which isn't as important for the present project, since I'll be buying items myself, but it'll come in handy in later projects.  Also, when I signed up for a developer's token, this is what I was given: D8HVH869XA0NP  I'm disclosing my own here for the sake of example, but you should sign up and get your own.\nSo, that fills in the first two parts of the URL.  For the purposes of this project, let's just go with the lite option for type.  As for the wishlist ID, let's take a look the wishlist URLs to which I linked earlier:\nhttp://www.amazon.com/exec/obidos/registry/35OIOYWQ9XQAE\nhttp://www.amazon.com/exec/obidos/registry/1QWYI6P2JF3Q5\n\nYou can discover these wishlist URLs using Amazon's Wish List Search feature, in which case a wishlist URL might appear like so:\nhttp://www.amazon.com/gp/registry/registry.html/\n002-7899886-3676027?%5Fencoding=UTF8&#38;\nid=35OIOYWQ9XQAE\n\nIn either case, there is a 13-character ID in each variety of wish list URL: this string is the wish list ID.  So, the ID for my girlfriend's wishlist is  35OIOYWQ9XQAE and mine is 1QWYI6P2JF3Q5.  Given this piece of the puzzle, we can fill in the blanks to come up with the following URL for my girlfriend's wish list:\nhttp://xml.amazon.com/onca/xml3?\nt=0xdecafbad-20&#38;\ndev-t=D8HVH869XA0NP&#38;\ntype=lite&#38;\nWishlistSearch=35OIOYWQ9XQAE&#38;\nf=xml\n\nCheck out the XML resulting from this URL--you may want to use a tool such as curl or wget instead of viewing this directly in your browser.  You'll see some XML that looks something like this:\n<ProductInfo>\n...\n<Details url=\"(some long URL)\">\n  <Asin>0262133601</Asin>\n  <ProductName>Foundations of Statistical Natural Language Processing</ProductName>\n  <Catalog>Book</Catalog>\n  <Authors>\n     <Author>Christopher D. Manning</Author>\n     <Author>Hinrich Sch&#252;tze</Author>\n  </Authors>\n  <ReleaseDate>18 June, 1999</ReleaseDate>\n  <Manufacturer>MIT Press</Manufacturer>\n  <ImageUrlSmall>(another long url)</ImageUrlSmall>\n  <ImageUrlMedium>(yet another long url)</ImageUrlMedium>\n  <ImageUrlLarge>(one last long url)</ImageUrlLarge>\n  <Availability>Usually ships within 24 hours</Availability>\n  <ListPrice>$75.00</ListPrice>\n  <OurPrice>$63.75</OurPrice>\n  <UsedPrice>$49.99</UsedPrice>\n</Details>\n...\n</ProductInfo>\n\nNote that the long URL in the Detail element's url attribute links to the human-viewable product detail page at Amazon.  I've also left a few other things out, such as the URLs to product images; I just thought I'd edit it a bit to be friendlier to your browser at home.  There's a schema for this XML data, and the ins-and-outs are explained in the AWS documentation under \"Amazon Web Services Data Model\".\nQuerying The Wishes\nSome ready-made files are available for this section:\n\nwishes-ex1.xsl: The first iteration of the stylesheet in development.\nwishes.xml: An XML document used as input with the stylesheet.\n\nNow that we've got some XML from Amazon to play with, let's start tinkering with an XSLT stylesheet to process it.  In the interests of flexibility and reusability, we can parameterize a few things in XML before starting in on the stylesheet:\n<wishes xmlns=\"http://www.decafbad.com/2004/05/wishes\">\n  <maxprice>15.00</maxprice>\n  <associate>0xdecafbad-20</associate>\n  <devtoken>D8HVH869XA0NP</devtoken>\n  <email>deus_x@pobox.com</email>\n  <wishlists>\n    <wishlist label=\"The Girl\">35OIOYWQ9XQAE</wishlist>\n    <wishlist label=\"Me\">1QWYI6P2JF3Q5</wishlist>\n  </wishlists>\n</wishes>\n\nHopefully, the data here is fairly self-explanatory:  I've established a maximum price for item selection; provided my associate ID and developer token; there's an email address to which I eventually want to send the results of all this work; and I've made a list of wishlist IDs, each with a readable label. Given this, let's start out simple and  use this to get some data from Amazon:\n<?xml version=\"1.0\"?>\n<xsl:stylesheet version=\"1.0\"\n            xmlns:wishes=\"http://www.decafbad.com/2004/05/wishes\"\n            xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\">\n  <xsl:output indent=\"yes\" />\n\n  <!-- Grab our global settings -->\n  <xsl:variable name=\"maxprice\"  select=\"/wishes:wishes/wishes:maxprice\" />  \n  <xsl:variable name=\"associate\" select=\"/wishes:wishes/wishes:associate\" />\n  <xsl:variable name=\"devtoken\"  select=\"/wishes:wishes/wishes:devtoken\" />\n\nSo far so good--things start off by pulling in some of the parameters into variables.  Next, let's dig into actually querying wishlist data with a reusable template:\n  <xsl:template name=\"processWishlist\">\n    <xsl:param name=\"wishlist\" />\n\n    <xsl:variable name=\"details\" select=\"document(concat(\n        'http://xml.amazon.com/onca/xml3?',\n        't=',$associate,'&amp;',\n        'dev-t=',$devtoken,'&amp;',\n        'WishlistSearch=',$wishlist,'&amp;',\n        'type=lite&amp;f=xml'))//Details\" />\n\nFirst thing into this template, we accept a parameter named wishlist which is expected to contain a wishlist ID string.  Next, we build an AWS URL by concatenating together the pieces we have in variables (associate ID, developer's token, and wishlist ID) using the XPath function concat().  Once we have this URL, we use the function document() to make a request and fetch the XML data for that URL.  From this, we select all the Details elements.  \nThen with that data, we can do some filtering on the price and availability.  We want to make sure that not only will we select items that are within our budget, but that they are available to buy in the first place:\n    <xsl:copy-of select=\"$details[\n      number(substring(OurPrice/text(),2)) &lt; $maxprice\n      and\n      contains(Availability, 'Usually ships within')\n      ]\" />\n\n  </xsl:template>\n\nThis code is just a little bit funky, since the price data given by Amazon contains a dollar sign, and we want to make a numerical comparison.  So, we chop the dollar sign off and convert to a number before making the comparison.  Also, there's an assumption here about what will show up in the Availability element: \"Usually ships within\"  Other things that might show up will declare that the item is out of stock, discontinued, or otherwise not shipping.  This might need some tweaking someday, but it seems to work for now.\nTaken all together, this template has the effect of a SQL SELECT statement somewhat like this:\nSELECT * \nFROM Amazon.WishlistItems \nWHERE WishlistID = $wishlist AND \n      OurPrice < $maxprice AND\n      Availability like '%Usually ships within%';\n\ndocument() is a very useful XPath function.  It allows us to pull in XML from external files and, in our case, from external URLs via HTTP requests.  This gives us the ability to make queries against REST web services like AWS--which, among many other reasons, is why I prefer REST web services over SOAP.  (I don't even want to think about trying to access a SOAP service from XSLT.)\nNow, let's wrap up this first iteration of the stylesheet by trying out the query template on each of the wishlist IDs:\n  <xsl:template match=\"/wishes:wishes\">\n    <xsl:for-each select=\"//wishes:wishlist\">\n      <wishes:wishitem>\n        <xsl:copy-of select=\".\" />\n        <xsl:call-template name=\"processWishlist\">\n              <xsl:with-param name=\"wishlist\" \n                              select=\".\" />\n        </xsl:call-template>\n      </wishes:wishitem>\n    </xsl:for-each>\n  </xsl:template>\n\n</xsl:stylesheet>\n\nYou can get a completed version of this stylesheet, along with the input XML, in case you haven't been cutting and pasting together a copy of your own along the way.  Try it out in a shell with:\n$ xsltproc wishes_ex1.xsl wishes.xml\n\nAlternately, you could check it out using TestXSLT under OS X.  You should get something like the following:\n<wishes:wishitem xmlns:wishes=\"http://www.decafbad.com/2004/05/wishes\">\n    <wishes:wishlist label=\"The Girl\">35OIOYWQ9XQAE</wishes:wishlist>\n    <Details ...>...</Details>\n    <Details ...>...</Details>\n    ...\n</wishes:wishitem>\n<wishes:wishitem xmlns:wishes=\"http://www.decafbad.com/2004/05/wishes\">\n    <wishes:wishlist label=\"Me\">1QWYI6P2JF3Q5</wishes:wishlist>\n    <Details ...>...</Details>\n    <Details ...>...</Details>\n    ...\n</wishes:wishitem>\n\nObviously, this example XML is much abridged, but hopefully you can get the gist:  For each wishlist ID, there is a containing wishitem element.  It contains a copy of the wishlist element from the input XML, followed by all the Details elements filtered and copied from the Amazon XML with the help of the processWishlist template.\nThat's All for Now!\nAnd that's the end of Part 1.  Next up, we'll be delving into a few more wrinkles in the wishlist querying process, selecting random items in XSLT, and the Remote Shopping Cart interface in Amazon Web Services.  Stay tuned!",
    "prevPostPath": "2004/06/28/wishofthemonthclub2",
    "nextPostPath": "2004/06/14/info-freako-or-whos-already-past-arguing-about-syndication-formats"
  }
]