<?xml version="1.0" encoding="UTF-8"?>
  <rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
      <title>Tag: ml - blog.lmorchard.com</title>
      <description>It&#39;s all spinning wheels &amp; self-doubt until the first pot of coffee.</description>
      <link>https://lmorchard.github.io/blog.lmorchard.com/tag/ml/</link>
      <atom:link href="https://lmorchard.github.io/blog.lmorchard.com/index.rss" rel="self" type="application/rss+xml" />
      <item>
          <title>A bad workman blames his tools</title>
          
          <description
                >&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;The Verge, &quot;&lt;a href=&quot;https://www.theverge.com/news/668315/anthropic-claude-legal-filing-citation-error&quot;&gt;Anthropic blames Claude AI for ‚Äòembarrassing and unintentional mistake‚Äô in legal filing&lt;/a&gt;&quot;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Anthropic has responded to allegations that it used an AI-fabricated source in its legal battle against music publishers, saying its Claude chatbot made an ‚Äúhonest citation mistake.‚Äù&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is dumb. Don&#39;t do that. That&#39;s like blaming your cordless drill for hitting a pipe or wiring in the wall while working to mount a shelf. It&#39;s not the tool&#39;s fault. A bad workman blames his tools. It&#39;s your hand holding the tool‚Äîown the mistake.&lt;/p&gt;
&lt;/body&gt;&lt;/html&gt;</description
              >
          <pubDate>Fri, 16 May 2025 16:42:00 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2025/05/16/dont-blame-the-tool-blame-the-hand/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2025/05/16/dont-blame-the-tool-blame-the-hand/</guid>
        </item><item>
          <title>Quoting Max Woolf</title>
          
          <description
                >&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;Max Woolf, &quot;&lt;a href=&quot;https://minimaxir.com/2025/05/llm-use/&quot;&gt;As an Experienced LLM User, I Actually Don&#39;t Use Generative LLMs Often&lt;/a&gt;&quot;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Two things can be true simultaneously: (a) LLM provider cost economics are too negative to return positive ROI to investors, and (b) LLMs are useful for solving problems that are meaningful and high impact, albeit not to the AGI hype that would justify point (a). This particular combination creates a frustrating gray area that requires a nuance that an ideologically split social media can no longer support gracefully.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I think this jibes well with what I &lt;a href=&quot;https://blog.lmorchard.com/2025/05/13/thinking-about-llms/&quot;&gt;tried exporting from my head&lt;/a&gt;, yesterday.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;There is one silly technique I discovered to allow a LLM to improve my writing without having it do my writing: feed it the text of my mostly-complete blog post, and ask the LLM to pretend to be a cynical Hacker News commenter and write five distinct comments based on the blog post. This not only identifies weaker arguments for potential criticism, but it also doesn‚Äôt tell me what I should write in the post to preemptively address that negative feedback so I have to solve it organically.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Oh, I might have to try that. ü§î I have used Claude to occasionally critique and brutally edit down some of the rambling texts that I&#39;ve spewed into an editor. But this sounds like a whole &#39;nother level.&lt;/p&gt;
&lt;/body&gt;&lt;/html&gt;</description
              >
          <pubDate>Wed, 14 May 2025 21:59:00 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2025/05/14/quoting-max-woolf/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2025/05/14/quoting-max-woolf/</guid>
        </item><item>
          <title>Quoting Katie Parrott</title>
          
          <description
                >&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;Katie Parrott, &quot;&lt;a href=&quot;https://every.to/working-overtime/it-s-me-hi-i-m-the-vibe-coder&quot;&gt;It‚Äôs Me, Hi. I‚Äôm the Vibe Coder.&lt;/a&gt;&quot;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;And then there are people like me, who aren‚Äôt chasing entry into the engineer club or a seven-figure seed round. We&#39;re writers, designers, business owners, and domain experts motivated by specific problems we deeply understand, &lt;a href=&quot;https://every.to/chain-of-thought/you-re-a-developer-now&quot;&gt;empowered by AI tools&lt;/a&gt; that finally &lt;a href=&quot;https://every.to/podcast/how-to-win-with-prompt-engineering&quot;&gt;speak our language&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Vibe coding hints at a future where software emerges from the inside out‚Äîfrom the people closest to the problems. As AI lowers the technical barrier, we may see more tools built by marketers, editors, researchers‚Äîanyone with deep context and a persistent itch to fix things.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This kind of thing is very exciting to me. While &lt;a href=&quot;https://blog.lmorchard.com/2025/05/13/thinking-about-llms/&quot;&gt;I think&lt;/a&gt; vibe coding is currently flawed &amp;amp; fraught for folks who don&#39;t entirely understand the code, I agree with Simon Willison that &quot;&lt;a href=&quot;https://simonwillison.net/2025/Mar/19/vibe-coding/#let-s-not-lose-track-of-what-makes-vibe-coding-special&quot;&gt;everyone deserves the ability to automate tedious tasks in ther lives with computers&lt;/a&gt;&quot;.&lt;/p&gt;
&lt;p&gt;There&#39;s a lot of hype and cynicism in tension out there. But, I&#39;ve personally cycled through a bunch of AI tools in the past few years. I&#39;ve seen their actual utility and glimmers of where they can go next.&lt;/p&gt;
&lt;p&gt;Trying to stay sober here, but I&#39;d love to see more tools meet users where they are and lower the technical bar overall. I think it&#39;s both possible and worth it to work toward improving the capability &amp;amp; reliability of these tools for folks outside of the programming &quot;priesthood&quot;.&lt;/p&gt;
&lt;/body&gt;&lt;/html&gt;</description
              >
          <pubDate>Wed, 14 May 2025 20:18:00 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2025/05/14/quoting-katie-parrott/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2025/05/14/quoting-katie-parrott/</guid>
        </item><item>
          <title>What I&#39;m thinking about AI and LLMs</title>
          <description
                >&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;I&#39;m in a weird place with this current AI wave in the tech industry. I feel like a good chunk of folks would tar &amp;amp; feather me if I wrote anything but a complete denunciation, while another chunk I already blocked during the crypto &amp;amp; NFT craze. I still feel like writing something, though, if only to bounce it off the screen for myself.&lt;/body&gt;&lt;/html&gt;</description
              >
          
          <pubDate>Tue, 13 May 2025 22:15:00 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2025/05/13/thinking-about-llms/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2025/05/13/thinking-about-llms/</guid>
        </item><item>
          <title>Been doing a lot of (hand)writing outside my blog</title>
          
          <description
                >&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;Just realized today that I&#39;ve written my 359th three-page week-daily handwritten journal entry on my &lt;a href=&quot;https://shop.boox.com/collections/all/products/tabultrac&quot;&gt;BOOX Tab Ultra C e-ink tablet&lt;/a&gt;. I&#39;ve also got paper volumes going back to 2017 with similar cadence. That&#39;s a lot of writing that no one but me will probably ever read. But, I do read it, occasionally, to sort myself out.&lt;/p&gt;
&lt;p&gt;I&#39;ve got a back-burnered side project to train a handwriting recognition model to actually convert my journal entries to text. I should get back to that. No off-the-shelf model has yet been able to successfully decipher my script.&lt;/p&gt;
&lt;p&gt;I&#39;ve also got a notion, once I&#39;ve converted my journals, to try feeding them to an LLM - either as a fine-tuned model or searching via RAG. Then, I could maybe pull themes and trends out of my past writing and ask annoying questions of my insufferable past self.&lt;/p&gt;
&lt;/body&gt;&lt;/html&gt;</description
              >
          <pubDate>Fri, 09 May 2025 19:00:00 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2025/05/09/been-doing-a-lot-of-handwriting-outside/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2025/05/09/been-doing-a-lot-of-handwriting-outside/</guid>
        </item><item>
          <title>Clustering ideas with Llamafile and Web Components</title>
          <description
                >&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;TL;DR: In my previous posts, I tinkered with a few variations on clustering ideas by named topics using embeddings and text generation. In this post, I&#39;m going to show off a web UI that I built to make this stuff easier to play with interactively.&lt;/body&gt;&lt;/html&gt;</description
              >
          
          <pubDate>Wed, 19 Jun 2024 19:00:00 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2024/06/19/topic-clustering-llamafile-web-components/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2024/06/19/topic-clustering-llamafile-web-components/</guid>
        </item><item>
          <title>Clustering ideas with Llamafile</title>
          <description
                >&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;TL;DR: In my previous post, I used local models with PyTorch and Sentence Transformers to roughly cluster ideas by named topic. In this post, I&#39;ll try that again, but this time with Llamafile.&lt;/body&gt;&lt;/html&gt;</description
              >
          
          <pubDate>Fri, 10 May 2024 19:00:00 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2024/05/10/topic-clustering-llamafile/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2024/05/10/topic-clustering-llamafile/</guid>
        </item><item>
          <title>Clustering ideas with local ML/AI models</title>
          <description
                >&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;TL;DR: In my previous post, I used APIs from OpenAI to roughly cluster ideas by named topic. In this post, I&#39;ll try that again, but this time with local models on my own hardware.&lt;/body&gt;&lt;/html&gt;</description
              >
          
          <pubDate>Wed, 01 May 2024 19:00:00 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2024/05/01/topic-clustering-local-models/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2024/05/01/topic-clustering-local-models/</guid>
        </item><item>
          <title>Clustering ideas by topic with machine learning and generative AI</title>
          <description
                >&lt;html&gt;&lt;head&gt;&lt;/head&gt;&lt;body&gt;TL;DR: FigJam has a feature where you can automatically cluster sticky notes by topic. I wanted to see if I could glue some things together to implement this myself.&lt;/body&gt;&lt;/html&gt;</description
              >
          
          <pubDate>Sat, 27 Apr 2024 19:00:00 GMT</pubDate>
          <link>https://lmorchard.github.io/blog.lmorchard.com/2024/04/27/topic-clustering-gen-ai/</link>
          <guid isPermaLink="true">https://lmorchard.github.io/blog.lmorchard.com/2024/04/27/topic-clustering-gen-ai/</guid>
        </item>
    </channel>
  </rss>