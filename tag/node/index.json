[
  {
    "title": "How to build your own Easy-Blog Oven",
    "tags": [
      "metablogging",
      "blogging",
      "node",
      "webdev"
    ],
    "year": "2020",
    "month": "05",
    "day": "25",
    "isDir": true,
    "slug": "diy-easy-blog-oven-draft",
    "date": "2020-05-25T12:00:00.000Z",
    "postName": "2020-05-25-diy-easy-blog-oven-draft",
    "html": "<p><strong>TL;DR</strong>: I wanted to write more about building my <a href=\"/2020/05/24/easy-blog-oven/\">Easy-Blog Oven</a>. I mainly glued together things I already knew, but I think I learned some things and had some surprises anyway.</p>\n<!--more-->\n\n<nav role=\"navigation\" class=\"table-of-contents\"></nav>\n\n<p>While I was throwing together this new static site generator over the past couple of days, I kept thinking, &quot;I should build this as a reusable engine so other folks can use it.&quot;</p>\n<p>But, you know, I think I&#39;d rather write about how to make your own. That seems more interesting (to me, at least) than trying to generalize this thing outside of scratching my own itch. </p>\n<p>Also, I&#39;ve been meaning to write more anyway. So, here goes:</p>\n<h2 id=\"generating-a-static-site\">Generating a static site</h2>\n<p>Let&#39;s say you have <a href=\"https://github.com/lmorchard/blog.lmorchard.com/tree/master/posts\">a pile of Markdown files</a> lying around like I do. Consider <a href=\"./listing-01.js\">this script as a start</a>:</p>\n<pre><code class=\"language-javascript\">#!/usr/bin/env node\nconst path = require(&quot;path&quot;);\nconst globby = require(&quot;globby&quot;);\nconst mkdirp = require(&quot;mkdirp&quot;);\nconst util = require(&quot;util&quot;);\nconst fsOrig = require(&quot;fs&quot;);\nconst fs = {\n  readFile: util.promisify(fsOrig.readFile),\n  writeFile: util.promisify(fsOrig.writeFile),\n};\n\nconst config = {\n  postsDir: &quot;../../posts&quot;,\n  buildDir: &quot;/tmp/blog-build&quot;,\n};\n\nasync function main() {\n  const posts = [];\n\n  // Load all posts into memory\n  const files = globby.stream(`${config.postsDir}/**/*.{md,markdown}`);\n  for await (const file of files) {\n    posts.push({\n      path: file,\n      body: await fs.readFile(file, &quot;utf8&quot;),\n    });\n  }\n\n  // Write all posts to disk\n  for (const post of posts) {\n    const postPath = `${config.buildDir}/${path.basename(post.path)}`;\n    await mkdirp(postPath);\n    await fs.writeFile(`${postPath}/index.md`, post.body);\n  }\n}\n\nmain().catch((err) =&gt; console.error(err));\n</code></pre>\n<p>This code only does a few things:</p>\n<ol>\n<li>Use the <a href=\"https://www.npmjs.com/package/globby\">globby</a> module to find all the blog posts</li>\n<li>Read all of those files into an array in memory</li>\n<li>Write files to disk for each blog post</li>\n</ol>\n<p>So, we&#39;re done! A static site of Markdown files has been generated!</p>\n<h2 id=\"rendering-blog-posts-in-markdown\">Rendering blog posts in Markdown</h2>\n<p>Oh, wait: Usually a website is made up of HTML pages. <a href=\"./listing-02.js\">We&#39;ll want to render these Markdown files as HTML</a>:</p>\n<pre><code class=\"language-diff\">10a11\n&gt; const marked = require(&quot;marked&quot;);\n22a24,25\n&gt;     const body = await fs.readFile(file, &quot;utf8&quot;);\n&gt;     const html = marked(body);\n25c28,29\n&lt;       body: await fs.readFile(file, &quot;utf8&quot;),\n---\n&gt;       body,\n&gt;       html,\n33a38\n&gt;     await fs.writeFile(`${postPath}/index.html`, post.html);\n</code></pre>\n<pre><code class=\"language-javascript\">#!/usr/bin/env node\nconst path = require(&quot;path&quot;);\nconst globby = require(&quot;globby&quot;);\nconst mkdirp = require(&quot;mkdirp&quot;);\nconst util = require(&quot;util&quot;);\nconst fsOrig = require(&quot;fs&quot;);\nconst fs = {\n  readFile: util.promisify(fsOrig.readFile),\n  writeFile: util.promisify(fsOrig.writeFile),\n};\nconst marked = require(&quot;marked&quot;);\n\nconst config = {\n  postsDir: &quot;../../posts&quot;,\n  buildDir: &quot;/tmp/blog-build&quot;,\n};\n\nasync function main() {\n  const posts = [];\n\n  // Load all posts into memory\n  const files = globby.stream(`${config.postsDir}/**/*.{md,markdown}`);\n  for await (const file of files) {\n    const body = await fs.readFile(file, &quot;utf8&quot;);\n    const html = marked(body);\n    posts.push({\n      path: file,\n      body,\n      html,\n    });\n  }\n\n  // Write all posts to disk\n  for (const post of posts) {\n    const postPath = `${config.buildDir}/${path.basename(post.path)}`;\n    await mkdirp(postPath);\n    await fs.writeFile(`${postPath}/index.md`, post.body);\n    await fs.writeFile(`${postPath}/index.html`, post.html);\n  }\n}\n\nmain().catch((err) =&gt; console.error(err));\n</code></pre>\n<p>Here we add the <a href=\"https://www.npmjs.com/package/marked\">marked</a> module to the mix - <a href=\"https://www.npmjs.com/package/marked\">marked</a> is a fast Markdown-to-HTML renderer. Next, we create per-post directories and store <code>index.html</code> renderings of the Markdown files.</p>\n<p>Why create directories for the blog posts? This can help in producing clean URL paths - e.g. <code>/2020/05/25/diy-easy-blog-oven/</code> without a pesky <code>.html</code> at the end. <a href=\"https://www.w3.org/Provider/Style/URI.html\">It&#39;s an old web tradition.</a></p>\n<h2 id=\"wrapping-rendered-blog-posts-in-page-templates\">Wrapping rendered blog posts in page templates</h2>\n<p>We still don&#39;t quite have a <em>site</em> at this point. Those <code>index.html</code> files are just HTML fragments, not complete pages. We&#39;ll want to wrap the content of a blog post in a common page template - i.e. to frame the content, provide site navigation, etc.</p>\n<p>Okay, so let&#39;s render the blog post content within a page template:</p>\n<pre><code class=\"language-diff\">35a36\n&gt;     const postHtml = templateBlogPost({ post });\n38c39\n&lt;     await fs.writeFile(`${postPath}/index.html`, post.html);\n---\n&gt;     await fs.writeFile(`${postPath}/index.html`, postHtml);\n40a42,53\n&gt; \n&gt; const templateBlogPost = ({ post }) =&gt; `&lt;!DOCTYPE html&gt;\n&gt; &lt;html&gt;\n&gt;   &lt;head&gt;\n&gt;     &lt;title&gt;Blog post&lt;title&gt;\n&gt;   &lt;/head&gt;\n&gt;   &lt;body&gt;\n&gt;     &lt;h1&gt;Blog post&lt;h1&gt;\n&gt;     ${post.html}\n&gt;   &lt;/body&gt;\n&gt; &lt;html&gt;\n&gt; `;\n</code></pre>\n<pre><code class=\"language-javascript\">#!/usr/bin/env node\nconst path = require(&quot;path&quot;);\nconst globby = require(&quot;globby&quot;);\nconst mkdirp = require(&quot;mkdirp&quot;);\nconst util = require(&quot;util&quot;);\nconst fsOrig = require(&quot;fs&quot;);\nconst fs = {\n  readFile: util.promisify(fsOrig.readFile),\n  writeFile: util.promisify(fsOrig.writeFile),\n};\nconst marked = require(&quot;marked&quot;);\n\nconst config = {\n  postsDir: &quot;../../posts&quot;,\n  buildDir: &quot;/tmp/blog-build&quot;,\n};\n\nasync function main() {\n  const posts = [];\n\n  // Load all posts into memory\n  const files = globby.stream(`${config.postsDir}/**/*.{md,markdown}`);\n  for await (const file of files) {\n    const body = await fs.readFile(file, &quot;utf8&quot;);\n    const html = marked(body);\n    posts.push({\n      path: file,\n      body,\n      html,\n    });\n  }\n\n  // Write all posts to disk\n  for (const post of posts) {\n    const postPath = `${config.buildDir}/${path.basename(post.path)}`;\n    const postHtml = templateBlogPost({ post });\n    await mkdirp(postPath);\n    await fs.writeFile(`${postPath}/index.md`, post.body);\n    await fs.writeFile(`${postPath}/index.html`, postHtml);\n  }\n}\n\nconst templateBlogPost = ({ post }) =&gt; `&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;Blog post&lt;title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1&gt;Blog post&lt;h1&gt;\n    ${post.html}\n  &lt;/body&gt;\n&lt;html&gt;\n`;\n\nmain().catch((err) =&gt; console.error(err));\n</code></pre>\n<p>This is a dead simple page template using a function and a <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals\">template literal</a>. There&#39;s no site navigation, not even a proper title for each post. But, it&#39;s a start. Now we&#39;re building a collection of actual web pages!</p>\n<h2 id=\"adding-metadata-to-blog-posts\">Adding metadata to blog posts</h2>\n<p>Speaking of blog post titles, there&#39;s usually more to a blog post than the body content. We usually want some metadata: a title, at least. Maybe also a date, some tags, a thumbnail image. </p>\n<p> The venerable <a href=\"https://jekyllrb.com/\">Jekyll</a> static site generator support <a href=\"https://jekyllrb.com/docs/posts/\">YAML &quot;front matter&quot;</a> added to the top of a Markdown document as a header of structured data. A blog post following this convention looks something like this:</p>\n<pre><code class=\"language-markdown\">---\ntitle:  &quot;Welcome to My Blog &amp; Stuff!&quot;\ntags: [ &quot;foo&lt;something&gt;&quot;, &quot;bar&quot;, &quot;baz&quot; ]\n---\n\n# Welcome\n\n**Hello world**, this is my first blog post.\n</code></pre>\n<p>It really helps that this format is flexible and not particularly tied to <a href=\"https://jekyllrb.com/\">Jekyll</a>. So, I&#39;ve found it handy to regard it as a defacto standard and keep all my blog posts in this format.</p>\n<p>It&#39;s also convenient that there&#39;s a <a href=\"https://www.npmjs.com/package/front-matter\">front-matter</a> module on NPM to process this format. So, we can easily roll support for front matter into the site generator:</p>\n<pre><code class=\"language-diff\">11a12\n&gt; const frontmatter = require(&quot;front-matter&quot;);\n24c25,26\n&lt;     const body = await fs.readFile(file, &quot;utf8&quot;);\n---\n&gt;     const data = await fs.readFile(file, &quot;utf8&quot;);\n&gt;     const { attributes, body } = frontmatter(data);\n26a29,30\n&gt;       // Copy all the front matter attributes into the post.\n&gt;       ...attributes,\n46c50\n&lt;     &lt;title&gt;Blog post&lt;title&gt;\n---\n&gt;     &lt;title&gt;${post.title}&lt;title&gt;\n49c53,61\n&lt;     &lt;h1&gt;Blog post&lt;h1&gt;\n---\n&gt;     &lt;h1&gt;${post.title}&lt;h1&gt;\n&gt;     ${\n&gt;       post.tags &amp;&amp;\n&gt;       `\n&gt;       &lt;ul&gt;\n&gt;         ${post.tags.map((tag) =&gt; `&lt;li&gt;${tag}&lt;/li&gt;`).join(&quot;\\n&quot;)}\n&gt;       &lt;/ul&gt;\n&gt;     `\n&gt;     }\n</code></pre>\n<pre><code class=\"language-javascript\">#!/usr/bin/env node\nconst path = require(&quot;path&quot;);\nconst globby = require(&quot;globby&quot;);\nconst mkdirp = require(&quot;mkdirp&quot;);\nconst util = require(&quot;util&quot;);\nconst fsOrig = require(&quot;fs&quot;);\nconst fs = {\n  readFile: util.promisify(fsOrig.readFile),\n  writeFile: util.promisify(fsOrig.writeFile),\n};\nconst marked = require(&quot;marked&quot;);\nconst frontmatter = require(&quot;front-matter&quot;);\n\nconst config = {\n  postsDir: &quot;../../posts&quot;,\n  buildDir: &quot;/tmp/blog-build&quot;,\n};\n\nasync function main() {\n  const posts = [];\n\n  // Load all posts into memory\n  const files = globby.stream(`${config.postsDir}/**/*.{md,markdown}`);\n  for await (const file of files) {\n    const data = await fs.readFile(file, &quot;utf8&quot;);\n    const { attributes, body } = frontmatter(data);\n    const html = marked(body);\n    posts.push({\n      // Copy all the front matter attributes into the post.\n      ...attributes,\n      path: file,\n      body,\n      html,\n    });\n  }\n\n  // Write all posts to disk\n  for (const post of posts) {\n    const postPath = `${config.buildDir}/${path.basename(post.path)}`;\n    const postHtml = templateBlogPost({ post });\n    await mkdirp(postPath);\n    await fs.writeFile(`${postPath}/index.md`, post.body);\n    await fs.writeFile(`${postPath}/index.html`, postHtml);\n  }\n}\n\nconst templateBlogPost = ({ post }) =&gt; `&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;${post.title}&lt;title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1&gt;${post.title}&lt;h1&gt;\n    ${\n      post.tags &amp;&amp;\n      `\n      &lt;ul&gt;\n        ${post.tags.map((tag) =&gt; `&lt;li&gt;${tag}&lt;/li&gt;`).join(&quot;\\n&quot;)}\n      &lt;/ul&gt;\n    `\n    }\n    ${post.html}\n  &lt;/body&gt;\n&lt;html&gt;\n`;\n\nmain().catch((err) =&gt; console.error(err));\n</code></pre>\n<p>The <a href=\"https://www.npmjs.com/package/front-matter\">front-matter</a> module neatly parses the blog post YAML header into an object and separates the Markdown content body that follows. This lets us easily include metadata from the post in the page template.</p>\n<h2 id=\"using-tagged-template-literals-to-make-html-easier\">Using tagged template literals to make HTML easier</h2>\n<p>You may have noticed that I introduced a problem in that last section. Take another look at that example post:</p>\n<pre><code class=\"language-markdown\">---\ntitle:  &quot;Welcome to My Blog &amp; Stuff!&quot;\ntags: [ &quot;foo&lt;something&gt;&quot;, &quot;bar&quot;, &quot;baz&quot; ]\n---\n\n# Welcome\n\n**Hello world**, this is my first blog post.\n</code></pre>\n<p>The title has an ampersand - i.e. <code>&amp;</code> - which <em>should</em> be encoded in HTML output as an <code>&amp;amp;</code> entity. But, worse than that, look at those tags. I included a weird one - i.e. <code>foo&lt;something&gt;</code> - which will produce invalid markup if included as-is.</p>\n<p>This wasn&#39;t a problem with the content body in Markdown. That&#39;s <em>supposed</em> to be treated as raw HTML. The metadata, though, needs to be encoded by escaping any characters or sequences that make trouble for HTML.</p>\n<h3 id=\"tagged-template-literals-in-a-nutshell\">Tagged template literals in a nutshell</h3>\n<p>This is where I started having fun with <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals#Tagged_templates\">tagged template literals</a> in JavaScript. These are multi-line string literals that support variable substitutions and can be processed through a function of your choice.</p>\n<p>Here&#39;s an example of a tagged template literal function:</p>\n<pre><code class=\"language-javascript\">const passthrough = (strings, ...values) =&gt;\n  strings.reduce(\n    (result, string, idx) =&gt;\n      result\n        + string\n        // There might not be a value at this idx, \n        // if the template ends in a literal string\n        + (values[idx] ? values[idx] : &quot;&quot;),\n    &quot;&quot;\n  );\nconst msg = &quot;test&quot;;\nconst str = passthrough`\n  Hello world, this is a ${msg} of a tagged template.\n`;\nconsole.log(str);\n// Hello world, this is a test of a tagged template.\n</code></pre>\n<p>For what it&#39;s worth, I first found this example <a href=\"https://writingjavascript.org/posts/creating-functions-for-tagged-template-literals#minimal-example-of-a-tag-function\">from a site called Writing JavaScript</a>. Your mileage may vary, so this might be a too-terse use of <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/Reduce\">Array.reduce()</a>. But, for some reason this was the first time it really clicked for me. So, kudos to <a href=\"https://sethvincent.com/\">Seth Vincent</a> for putting that out there!</p>\n<p>Anyway, as the name <code>passthrough</code> suggests, this function just passes through the result of parsing the template literal. JavaScript splits the literal up into an array of strings, along with the result of resolving the variable substitutions as subsequent function parameters. The implementation of this <code>passthrough</code> function just glues all the strings together unchanged.</p>\n<h3 id=\"using-tagged-template-literals-for-html-encoding\">Using tagged template literals for HTML encoding</h3>\n<p>But, rather than a simple passthrough, we <em>could</em> filter &amp; transform both the strings and variable substitutions. In fact, this is what I came up with to ease\n producing HTML from template literals:</p>\n<pre><code class=\"language-diff\">12a13\n&gt; const escapeHtml = require(&quot;escape-html&quot;);\n40c41\n&lt;     const postHtml = templateBlogPost({ post });\n---\n&gt;     const postHtml = templateBlogPost({ post })();\n47c48,69\n&lt; const templateBlogPost = ({ post }) =&gt; `&lt;!DOCTYPE html&gt;\n---\n&gt; const unescaped = (raw) =&gt; () =&gt; raw;\n&gt; \n&gt; const html = (strings, ...values) =&gt;\n&gt;   unescaped(\n&gt;     strings\n&gt;       .reduce((result, string, i) =&gt; result + string + htmlValue(values[i]), &quot;&quot;)\n&gt;       .trim()\n&gt;   );\n&gt; \n&gt; const htmlValue = (value) =&gt; {\n&gt;   if (typeof value == &quot;undefined&quot;) {\n&gt;     return &quot;&quot;;\n&gt;   } else if (typeof value === &quot;function&quot;) {\n&gt;     return value();\n&gt;   } else if (Array.isArray(value)) {\n&gt;     return value.map(htmlValue).join(&quot;&quot;);\n&gt;   }\n&gt;   return escapeHtml(value);\n&gt; };\n&gt; \n&gt; const templateBlogPost = ({ post }) =&gt; html`\n&gt; &lt;!DOCTYPE html&gt;\n55a78,81\n&gt;       html`\n&gt;         &lt;ul&gt;\n&gt;           ${post.tags.map((tag) =&gt; html`&lt;li&gt;${tag}&lt;/li&gt;`)}\n&gt;         &lt;/ul&gt;\n57,60d82\n&lt;       &lt;ul&gt;\n&lt;         ${post.tags.map((tag) =&gt; `&lt;li&gt;${tag}&lt;/li&gt;`).join(&quot;\\n&quot;)}\n&lt;       &lt;/ul&gt;\n&lt;     `\n62c84\n&lt;     ${post.html}\n---\n&gt;     ${unescaped(post.html)}\n</code></pre>\n<pre><code class=\"language-javascript\">#!/usr/bin/env node\nconst path = require(&quot;path&quot;);\nconst globby = require(&quot;globby&quot;);\nconst mkdirp = require(&quot;mkdirp&quot;);\nconst util = require(&quot;util&quot;);\nconst fsOrig = require(&quot;fs&quot;);\nconst fs = {\n  readFile: util.promisify(fsOrig.readFile),\n  writeFile: util.promisify(fsOrig.writeFile),\n};\nconst marked = require(&quot;marked&quot;);\nconst frontmatter = require(&quot;front-matter&quot;);\nconst escapeHtml = require(&quot;escape-html&quot;);\n\nconst config = {\n  postsDir: &quot;../../posts&quot;,\n  buildDir: &quot;/tmp/blog-build&quot;,\n};\n\nasync function main() {\n  const posts = [];\n\n  // Load all posts into memory\n  const files = globby.stream(`${config.postsDir}/**/*.{md,markdown}`);\n  for await (const file of files) {\n    const data = await fs.readFile(file, &quot;utf8&quot;);\n    const { attributes, body } = frontmatter(data);\n    const html = marked(body);\n    posts.push({\n      // Copy all the front matter attributes into the post.\n      ...attributes,\n      path: file,\n      body,\n      html,\n    });\n  }\n\n  // Write all posts to disk\n  for (const post of posts) {\n    const postPath = `${config.buildDir}/${path.basename(post.path)}`;\n    const postHtml = templateBlogPost({ post })();\n    await mkdirp(postPath);\n    await fs.writeFile(`${postPath}/index.md`, post.body);\n    await fs.writeFile(`${postPath}/index.html`, postHtml);\n  }\n}\n\nconst unescaped = (raw) =&gt; () =&gt; raw;\n\nconst html = (strings, ...values) =&gt;\n  unescaped(\n    strings\n      .reduce((result, string, i) =&gt; result + string + htmlValue(values[i]), &quot;&quot;)\n      .trim()\n  );\n\nconst htmlValue = (value) =&gt; {\n  if (typeof value == &quot;undefined&quot;) {\n    return &quot;&quot;;\n  } else if (typeof value === &quot;function&quot;) {\n    return value();\n  } else if (Array.isArray(value)) {\n    return value.map(htmlValue).join(&quot;&quot;);\n  }\n  return escapeHtml(value);\n};\n\nconst templateBlogPost = ({ post }) =&gt; html`\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;${post.title}&lt;title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1&gt;${post.title}&lt;h1&gt;\n    ${\n      post.tags &amp;&amp;\n      html`\n        &lt;ul&gt;\n          ${post.tags.map((tag) =&gt; html`&lt;li&gt;${tag}&lt;/li&gt;`)}\n        &lt;/ul&gt;\n      `\n    }\n    ${unescaped(post.html)}\n  &lt;/body&gt;\n&lt;html&gt;\n`;\n\nmain().catch((err) =&gt; console.error(err));\n</code></pre>\n<h3 id=\"weird-quirks-of-my-html-templates\">Weird quirks of my HTML templates</h3>\n<p>There are a few strange things going on here. (Or, at least, I thought they were strange.)</p>\n<p>First off, my <code>html</code> template function returns a function. <em>That</em> function returns the desired string content. </p>\n<p>This was weird to me when I first learned about tagged template literals: <em>The function that processes a tagged template literal doesn&#39;t have to return a string!</em> It really confused in using modules like <a href=\"https://www.npmjs.com/package/htm\">HTM (Hyperscript Tagged Markup)</a> to create JSX-free components for <a href=\"https://preactjs.com/\">Preact</a>. But, as it turns out, a tagged template string can result in essentially <em>anything</em> - not just a string.</p>\n<p>And here&#39;s why I built it that way: I&#39;m using a function as the mechanism to indicate which values <em>should not be encoded for HTML</em>. The <code>htmlValue</code> function checks for <code>(typeof value === &quot;function&quot;)</code>. Any variable substitutions of type function are called &amp; included without escaping. All others are escaped for HTML.</p>\n<p>This might be a terrible idea, but it means my <code>html</code> template tag has two important features:</p>\n<ol>\n<li><p>It supports leaving selective variable substitutions raw &amp; unencoded:</p>\n<pre><code class=\"language-javascript\">html`\n  This variable ${() =&gt; &#39;&lt;b&gt;right here&lt;/b&gt;`} should be unescaped markup.\n`</code></pre>\n</li>\n<li><p>It supports templates-within-templates, since the <code>html</code> function itself returns a function:</p>\n<pre><code class=\"language-javascript\">html`\n&lt;ul&gt;\n  ${post.tags.map((tag) =&gt; html`&lt;li&gt;${tag}&lt;/li&gt;`)}\n&lt;/ul&gt;\n`</code></pre>\n</li>\n</ol>\n<p>For another way to think about it, consider that <a href=\"https://reactjs.org/docs/dom-elements.html#dangerouslysetinnerhtml\">React has a mechanism where unescaped markup is indicated</a> like so:</p>\n<pre><code class=\"language-html\">&lt;span dangerouslySetInnerHTML={{ __html: &quot;&lt;b&gt;right here&lt;/b&gt;&quot; }} /&gt;</code></pre>\n<p>The approach here is to just use <code>typeof value === &#39;function&#39;</code> in a similar spirit.</p>\n<p>I&#39;ve been happy so far with how this template scheme has turned out. It just leaves an awkward aspect where the final consumer of the template has to call the return value to get the result:</p>\n<pre><code class=\"language-javascript\">const postHtml = templateBlogPost({ post })();</code></pre>\n<p>But, this scheme has replaced a whole template engine dependency for me in <a href=\"https://github.com/lmorchard/blog.lmorchard.com/tree/master/templates\">my blog&#39;s collection of templates</a>. So, that&#39;s pretty neat.</p>\n<h3 id=\"a-note-for-vscode-users\">A note for VSCode users</h3>\n<p>Oh and there&#39;s one more benefit I found while using HTML in tagged templates: If you use VSCode as your editor, there&#39;s <a href=\"https://marketplace.visualstudio.com/items?itemName=bierner.lit-html\">the lit-html extension</a> to help manage &amp; format markup within tagged templates.</p>\n<p>Sure, the extension is <em>intended</em> mainly to help working with <a href=\"https://github.com/Polymer/lit-html\">lit-html</a> templates - but it works just as well for my tagged templates too!</p>\n<h2 id=\"improving-the-site-directory-layout\">Improving the site directory layout</h2>\n<p>Okay, now we have blog posts with YAML metadata and Markdown content paired with an HTML template scheme for publishing web pages. I&#39;ll leave improving those web pages as an exercise to the reader. You can <a href=\"https://github.com/lmorchard/blog.lmorchard.com/tree/master/templates\">peek at my templates</a> as an example, but you&#39;ll want your own look &amp; feel. Also my templates are terrible.</p>\n<p>Templates aside, the next improvement is around directory layout of the static web site. Earlier, I mentioned the &quot;<a href=\"https://www.w3.org/Provider/Style/URI.html\">old web tradition</a>&quot; of producing clean URL paths - e.g. <code>/2020/05/25/diy-easy-blog-oven/</code>. Well, our URL paths are a mess at this point. </p>\n<p>So, let&#39;s improve that by using dates to build directory paths:</p>\n<pre><code class=\"language-diff\">13a14\n&gt; const moment = require(&quot;moment&quot;);\n19a21,22\n&gt; const RE_POST_NAME = new RegExp(/(\\d{4})-(\\d{2})-(\\d{2})-(.*)/);\n&gt; \n28a32,42\n&gt; \n&gt;     // Get the filename without .md or .markdown extension\n&gt;     const postName = path.basename(file).split(&quot;.&quot;)[0];\n&gt;     // Just skip any files that don&#39;t match the naming convention\n&gt;     const dateMatch = RE_POST_NAME.exec(postName);\n&gt;     if (!dateMatch) continue;\n&gt; \n&gt;     const [, year, month, day, slug] = dateMatch;\n&gt;     const date = moment(attributes.date || `${year}-${month}-${day}T12:00:00Z`);\n&gt;     const postPath = `${date.format(&quot;YYYY/MM/DD&quot;)}/${slug}`;\n&gt; \n32c46,51\n&lt;       path: file,\n---\n&gt;       path: postPath,\n&gt;       year,\n&gt;       month,\n&gt;       day,\n&gt;       date,\n&gt;       slug,\n40c59\n&lt;     const postPath = `${config.buildDir}/${path.basename(post.path)}`;\n---\n&gt;     const postPath = `${config.buildDir}/${post.path}`;\n75a95\n&gt;     &lt;h2&gt;${post.date.format(&quot;dddd, MMMM Do YYYY, h:mm:ss a&quot;)}&lt;/h2&gt;\n</code></pre>\n<pre><code class=\"language-javascript\">#!/usr/bin/env node\nconst path = require(&quot;path&quot;);\nconst globby = require(&quot;globby&quot;);\nconst mkdirp = require(&quot;mkdirp&quot;);\nconst util = require(&quot;util&quot;);\nconst fsOrig = require(&quot;fs&quot;);\nconst fs = {\n  readFile: util.promisify(fsOrig.readFile),\n  writeFile: util.promisify(fsOrig.writeFile),\n};\nconst marked = require(&quot;marked&quot;);\nconst frontmatter = require(&quot;front-matter&quot;);\nconst escapeHtml = require(&quot;escape-html&quot;);\nconst moment = require(&quot;moment&quot;);\n\nconst config = {\n  postsDir: &quot;../../posts&quot;,\n  buildDir: &quot;/tmp/blog-build&quot;,\n};\n\nconst RE_POST_NAME = new RegExp(/(\\d{4})-(\\d{2})-(\\d{2})-(.*)/);\n\nasync function main() {\n  const posts = [];\n\n  // Load all posts into memory\n  const files = globby.stream(`${config.postsDir}/**/*.{md,markdown}`);\n  for await (const file of files) {\n    const data = await fs.readFile(file, &quot;utf8&quot;);\n    const { attributes, body } = frontmatter(data);\n    const html = marked(body);\n\n    // Get the filename without .md or .markdown extension\n    const postName = path.basename(file).split(&quot;.&quot;)[0];\n    // Just skip any files that don&#39;t match the naming convention\n    const dateMatch = RE_POST_NAME.exec(postName);\n    if (!dateMatch) continue;\n\n    const [, year, month, day, slug] = dateMatch;\n    const date = moment(attributes.date || `${year}-${month}-${day}T12:00:00Z`);\n    const postPath = `${date.format(&quot;YYYY/MM/DD&quot;)}/${slug}`;\n\n    posts.push({\n      // Copy all the front matter attributes into the post.\n      ...attributes,\n      path: postPath,\n      year,\n      month,\n      day,\n      date,\n      slug,\n      body,\n      html,\n    });\n  }\n\n  // Write all posts to disk\n  for (const post of posts) {\n    const postPath = `${config.buildDir}/${post.path}`;\n    const postHtml = templateBlogPost({ post })();\n    await mkdirp(postPath);\n    await fs.writeFile(`${postPath}/index.md`, post.body);\n    await fs.writeFile(`${postPath}/index.html`, postHtml);\n  }\n}\n\nconst unescaped = (raw) =&gt; () =&gt; raw;\n\nconst html = (strings, ...values) =&gt;\n  unescaped(\n    strings\n      .reduce((result, string, i) =&gt; result + string + htmlValue(values[i]), &quot;&quot;)\n      .trim()\n  );\n\nconst htmlValue = (value) =&gt; {\n  if (typeof value == &quot;undefined&quot;) {\n    return &quot;&quot;;\n  } else if (typeof value === &quot;function&quot;) {\n    return value();\n  } else if (Array.isArray(value)) {\n    return value.map(htmlValue).join(&quot;&quot;);\n  }\n  return escapeHtml(value);\n};\n\nconst templateBlogPost = ({ post }) =&gt; html`\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;${post.title}&lt;title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1&gt;${post.title}&lt;h1&gt;\n    &lt;h2&gt;${post.date.format(&quot;dddd, MMMM Do YYYY, h:mm:ss a&quot;)}&lt;/h2&gt;\n    ${\n      post.tags &amp;&amp;\n      html`\n        &lt;ul&gt;\n          ${post.tags.map((tag) =&gt; html`&lt;li&gt;${tag}&lt;/li&gt;`)}\n        &lt;/ul&gt;\n      `\n    }\n    ${unescaped(post.html)}\n  &lt;/body&gt;\n&lt;html&gt;\n`;\n\nmain().catch((err) =&gt; console.error(err));\n</code></pre>\n<p>For my blog, I use a filename convention like this: <code>2020-05-25-diy-easy-blog-oven.md</code></p>\n<p>This code takes advantage of that naming convention with a regular expression to extract the date and slug for use in constructing the directory structure during the build. However, as an override, I can explicitly set a date via the <code>date</code> attribute in the post&#39;s front matter.</p>\n<h3 id=\"dates--names--files-oh-my\">Dates &amp; names &amp; files, oh my!</h3>\n<p>Here&#39;s some context &amp; history behind that arrangement: Some file-based blogs I&#39;ve used read the file modification time as the source of the date. This could be nice, insofar as the date automatically updated as I edited the post. But, things fell apart if I backed up and restored the files while forgetting to preserve the timestamps. All the posts suddenly looked like they were published <em>today</em> - oops!</p>\n<p>I can also stash the date in a post&#39;s front matter as a <code>date</code> property. I&#39;ve done that in some places, occasionally as the result of an earlier database export from Movable Type or WordPress many years ago. I like to have it as an option.</p>\n<p>What I&#39;ve found works best, though, is to follow a naming convention for blog post filenames - i.e. <code>YYYY-MM-DD-slug.md</code>. This survives lots of mistakes in backup &amp; restore - and it gives me a natural sort order for listing files on disk.</p>\n<h3 id=\"an-aside-on-slugs\">An aside on slugs</h3>\n<p>Oh yeah, and <a href=\"https://en.wikipedia.org/wiki/Slug_(publishing)\">&quot;slug&quot; is a general term</a> for the ID or name of a blog post - independent from the title or headline of the post. A slug is what shows up in the URL to uniquely identify the post from others on the same day.</p>\n<p>Although slugs can be random IDs or automatically derived from titles, many web publishing systems treat the slug and title as separate properties managed by the author. A fun thing to watch for on news sites is when a draft of an article is submitted with an initial slug and title. Later, the title is changed but the slug is left untouched. This can result in some fun situations where the headline of an article has been made more subtle - but the slug retains some fairly blunt language.</p>\n<p>Anyway, I&#39;m getting punchy and I digress. In this system, the slug is derived from the filename of the blog post Markdown source file.</p>\n<h2 id=\"rendering-post-indexes-by-recent-date-and-tag\">Rendering post indexes by recent, date, and tag</h2>\n<p>Now that we have a decent directory structure, it would be nice to have index pages to navigate around the blog.</p>\n<p>Up to this point, I&#39;ve been trying to keep the changes to the script small and relatively easy to explain. From here, though, I&#39;m just going to go for broke and spew some code:</p>\n<pre><code class=\"language-diff\">64a65,118\n&gt; \n&gt;   writeIndexPage({\n&gt;     title: &quot;Recent posts&quot;,\n&gt;     path: &quot;&quot;,\n&gt;     posts: posts.slice(0, 15),\n&gt;   });\n&gt; \n&gt;   const postsByYear = indexBy(posts, ({ year }) =&gt; year);\n&gt;   for (const [year, posts] of Object.entries(postsByYear)) {\n&gt;     writeIndexPage({\n&gt;       title: `Year: ${year}`,\n&gt;       path: year,\n&gt;       posts,\n&gt;     });\n&gt;   }\n&gt; \n&gt;   const postsByMonth = indexBy(posts, ({ year, month }) =&gt; `${year}/${month}`);\n&gt;   for (const [month, posts] of Object.entries(postsByMonth)) {\n&gt;     writeIndexPage({\n&gt;       title: `Month: ${month}`,\n&gt;       path: month,\n&gt;       posts,\n&gt;     });\n&gt;   }\n&gt; \n&gt;   const postsByTag = indexBy(posts, ({ tags = [] }) =&gt; tags);\n&gt;   for (const [tag, posts] of Object.entries(postsByTag)) {\n&gt;     writeIndexPage({\n&gt;       title: `Tag: ${tag}`,\n&gt;       path: `tag/${tag}`,\n&gt;       posts,\n&gt;     });\n&gt;   }\n&gt; }\n&gt; \n&gt; function indexBy(items, keyFn) {\n&gt;   const index = {};\n&gt;   for (const item of items) {\n&gt;     const key = keyFn(item);\n&gt;     const keys = Array.isArray(key) ? key : [key];\n&gt;     for (const k of keys) {\n&gt;       if (k) index[k] = [...(index[k] || []), item];\n&gt;     }\n&gt;   }\n&gt;   return index;\n&gt; }\n&gt; \n&gt; async function writeIndexPage(indexProps) {\n&gt;   const indexPath = `${config.buildDir}/${indexProps.path}`;\n&gt;   await mkdirp(indexPath);\n&gt;   await fs.writeFile(\n&gt;     `${indexPath}/index.html`,\n&gt;     templateIndexPage(indexProps)()\n&gt;   );\n85a140,162\n&gt; \n&gt; const templateIndexPage = ({ title, posts }) =&gt; html`\n&gt; &lt;!DOCTYPE html&gt;\n&gt; &lt;html&gt;\n&gt;   &lt;head&gt;\n&gt;     &lt;title&gt;${title}&lt;title&gt;\n&gt;   &lt;/head&gt;\n&gt;   &lt;body&gt;\n&gt;     &lt;h1&gt;${title}&lt;h1&gt;\n&gt;     &lt;ul&gt;\n&gt;       ${posts.map(\n&gt;         (post) =&gt; html`\n&gt;           &lt;li&gt;\n&gt;             &lt;a href=&quot;/${post.path}/&quot;&gt;\n&gt;               ${post.date.format(&quot;dddd, MMMM Do YYYY&quot;)}: ${post.title}\n&gt;             &lt;/a&gt;\n&gt;           &lt;/li&gt;\n&gt;         `\n&gt;       )}\n&gt;     &lt;/ul&gt;\n&gt;   &lt;/body&gt;\n&gt; &lt;html&gt;\n&gt; `;\n</code></pre>\n<pre><code class=\"language-javascript\">#!/usr/bin/env node\nconst path = require(&quot;path&quot;);\nconst globby = require(&quot;globby&quot;);\nconst mkdirp = require(&quot;mkdirp&quot;);\nconst util = require(&quot;util&quot;);\nconst fsOrig = require(&quot;fs&quot;);\nconst fs = {\n  readFile: util.promisify(fsOrig.readFile),\n  writeFile: util.promisify(fsOrig.writeFile),\n};\nconst marked = require(&quot;marked&quot;);\nconst frontmatter = require(&quot;front-matter&quot;);\nconst escapeHtml = require(&quot;escape-html&quot;);\nconst moment = require(&quot;moment&quot;);\n\nconst config = {\n  postsDir: &quot;../../posts&quot;,\n  buildDir: &quot;/tmp/blog-build&quot;,\n};\n\nconst RE_POST_NAME = new RegExp(/(\\d{4})-(\\d{2})-(\\d{2})-(.*)/);\n\nasync function main() {\n  const posts = [];\n\n  // Load all posts into memory\n  const files = globby.stream(`${config.postsDir}/**/*.{md,markdown}`);\n  for await (const file of files) {\n    const data = await fs.readFile(file, &quot;utf8&quot;);\n    const { attributes, body } = frontmatter(data);\n    const html = marked(body);\n\n    // Get the filename without .md or .markdown extension\n    const postName = path.basename(file).split(&quot;.&quot;)[0];\n    // Just skip any files that don&#39;t match the naming convention\n    const dateMatch = RE_POST_NAME.exec(postName);\n    if (!dateMatch) continue;\n\n    const [, year, month, day, slug] = dateMatch;\n    const date = moment(attributes.date || `${year}-${month}-${day}T12:00:00Z`);\n    const postPath = `${date.format(&quot;YYYY/MM/DD&quot;)}/${slug}`;\n\n    posts.push({\n      // Copy all the front matter attributes into the post.\n      ...attributes,\n      path: postPath,\n      year,\n      month,\n      day,\n      date,\n      slug,\n      body,\n      html,\n    });\n  }\n\n  // Write all posts to disk\n  for (const post of posts) {\n    const postPath = `${config.buildDir}/${post.path}`;\n    const postHtml = templateBlogPost({ post })();\n    await mkdirp(postPath);\n    await fs.writeFile(`${postPath}/index.md`, post.body);\n    await fs.writeFile(`${postPath}/index.html`, postHtml);\n  }\n\n  writeIndexPage({\n    title: &quot;Recent posts&quot;,\n    path: &quot;&quot;,\n    posts: posts.slice(0, 15),\n  });\n\n  const postsByYear = indexBy(posts, ({ year }) =&gt; year);\n  for (const [year, posts] of Object.entries(postsByYear)) {\n    writeIndexPage({\n      title: `Year: ${year}`,\n      path: year,\n      posts,\n    });\n  }\n\n  const postsByMonth = indexBy(posts, ({ year, month }) =&gt; `${year}/${month}`);\n  for (const [month, posts] of Object.entries(postsByMonth)) {\n    writeIndexPage({\n      title: `Month: ${month}`,\n      path: month,\n      posts,\n    });\n  }\n\n  const postsByTag = indexBy(posts, ({ tags = [] }) =&gt; tags);\n  for (const [tag, posts] of Object.entries(postsByTag)) {\n    writeIndexPage({\n      title: `Tag: ${tag}`,\n      path: `tag/${tag}`,\n      posts,\n    });\n  }\n}\n\nfunction indexBy(items, keyFn) {\n  const index = {};\n  for (const item of items) {\n    const key = keyFn(item);\n    const keys = Array.isArray(key) ? key : [key];\n    for (const k of keys) {\n      if (k) index[k] = [...(index[k] || []), item];\n    }\n  }\n  return index;\n}\n\nasync function writeIndexPage(indexProps) {\n  const indexPath = `${config.buildDir}/${indexProps.path}`;\n  await mkdirp(indexPath);\n  await fs.writeFile(\n    `${indexPath}/index.html`,\n    templateIndexPage(indexProps)()\n  );\n}\n\nconst unescaped = (raw) =&gt; () =&gt; raw;\n\nconst html = (strings, ...values) =&gt;\n  unescaped(\n    strings\n      .reduce((result, string, i) =&gt; result + string + htmlValue(values[i]), &quot;&quot;)\n      .trim()\n  );\n\nconst htmlValue = (value) =&gt; {\n  if (typeof value == &quot;undefined&quot;) {\n    return &quot;&quot;;\n  } else if (typeof value === &quot;function&quot;) {\n    return value();\n  } else if (Array.isArray(value)) {\n    return value.map(htmlValue).join(&quot;&quot;);\n  }\n  return escapeHtml(value);\n};\n\nconst templateIndexPage = ({ title, posts }) =&gt; html`\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;${title}&lt;title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1&gt;${title}&lt;h1&gt;\n    &lt;ul&gt;\n      ${posts.map(\n        (post) =&gt; html`\n          &lt;li&gt;\n            &lt;a href=&quot;/${post.path}/&quot;&gt;\n              ${post.date.format(&quot;dddd, MMMM Do YYYY&quot;)}: ${post.title}\n            &lt;/a&gt;\n          &lt;/li&gt;\n        `\n      )}\n    &lt;/ul&gt;\n  &lt;/body&gt;\n&lt;html&gt;\n`;\n\nconst templateBlogPost = ({ post }) =&gt; html`\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;${post.title}&lt;title&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;h1&gt;${post.title}&lt;h1&gt;\n    &lt;h2&gt;${post.date.format(&quot;dddd, MMMM Do YYYY, h:mm:ss a&quot;)}&lt;/h2&gt;\n    ${\n      post.tags &amp;&amp;\n      html`\n        &lt;ul&gt;\n          ${post.tags.map((tag) =&gt; html`&lt;li&gt;${tag}&lt;/li&gt;`)}\n        &lt;/ul&gt;\n      `\n    }\n    ${unescaped(post.html)}\n  &lt;/body&gt;\n&lt;html&gt;\n`;\n\nmain().catch((err) =&gt; console.error(err));\n</code></pre>\n<p>There&#39;s a lot of repetition here, but I tried to keep it <a href=\"https://en.wikipedia.org/wiki/Don%27t_repeat_yourself\">DRY</a>. </p>\n<p>The gist is that, since we&#39;re loading all the blog posts into memory, we can easily collate posts into groupings based on attributes like year, month, and tags. The new <code>indexBy</code> utility function takes care of that.</p>\n<p>Once collated into convenient groupings, we can use the <code>writeIndexPage</code> utility function to build each index page via <code>templateIndexPage</code> and then write to disk at the approriate paths in the directory structure.</p>\n<p>This, by the way, is one of the things that surprised me: My blog has over 1000 posts, accumulated over the course of 18 years. I expected the execution time of this script to be impracticably slow.</p>\n<p>Well, the script at this point takes about 2 seconds on my computer:</p>\n<pre><code class=\"language-shell\">$ time node listing-07.js \nreal    0m1.646s\nuser    0m2.056s\nsys     0m0.305s</code></pre>\n<p>This was one of the big surprises I found when I started playing with this idea. I&#39;m used to thinking about databases and indexes and threads and clusters of servers when it comes to churning through lots of content. But, even if it looks like a lot of content to me as the author, it&#39;s not much at all to a modern computer.</p>\n<p>To be fair, I&#39;ve added complications to the code that <em>actually</em> publishes this blog versus the script I&#39;ve built up for this post. But, my &quot;production&quot; code still builds this whole site in under 7 seconds. And, if I feel like tinkering some more, I could probably optimize and bring that time back down again.</p>\n<h2 id=\"publishing-to-github-pages-via-actions\">Publishing to GitHub Pages via Actions</h2>\n<p>This is the final stretch. We&#39;ve got a script that generates a static site from blog posts - including indexes listing posts by year, month, and tag. The last thing is to get all of this content onto the web.</p>\n<p>When I last built a static site generator for my blog, <a href=\"https://blog.lmorchard.com/2015/10/22/blogging-via-travis/\">I hooked it up</a> to <a href=\"https://travis-ci.org/\">Travis CI</a> as a learning project. It was also convenient: When I pushed new content to GitHub, it eventually ended up on Amazon S3. Back in 2015, it was neat to see the Rube Goldberg machine kick into action without me having to run any code on my laptop.</p>\n<p>Since then, GitHub themselves have come up with their own offering in the workflow automation market with <a href=\"https://help.github.com/en/actions\">GitHub Actions</a>. It&#39;s worth reading the docs, but I don&#39;t want to sidetrack too far into a general tutorial. </p>\n<p>Long story short, building &amp; publishing a static site to <a href=\"https://pages.github.com/\">GitHub Pages</a> via Actions boils down to dropping a file like this as <a href=\"https://github.com/lmorchard/blog.lmorchard.com/blob/master/.github/workflows/stage.yml\"><code>.github/workflows/main.yml</code></a> in my GitHub repository:</p>\n<pre><code class=\"language-yaml\">name: Deploy to Github Pages\non:\n  push:\n    branches: [ master ]\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Use Node.js 14.2.0\n      uses: actions/setup-node@v1\n      with:\n        node-version: 14.2.0\n    - name: Set git identity\n      run: |\n        git config --global user.email &quot;you@example.com&quot;\n        git config --global user.name &quot;Your Name Here&quot;        \n    - name: Install\n      run: yarn install\n    - name: Build\n      run: node index.js\n    - name: Deploy\n      run: npx gh-pages -t -d build -r https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git\n</code></pre>\n<p>If you&#39;ve got experience with other workflow automation tools like <a href=\"https://travis-ci.org/\">Travis CI</a> or <a href=\"https://circleci.com/\">CircleCI</a>, this might look familiar. That is, this configuration file instructs <a href=\"https://help.github.com/en/actions\">GitHub Actions</a> to do stuff on every push to <code>master</code> branch:</p>\n<ul>\n<li>Fire up a virtual machine running Ubuntu Linux.</li>\n<li>Check out my repository.</li>\n<li>Set up Node.js v14.2.0.</li>\n<li>Configure git with my details - you&#39;ll want to customize this.</li>\n<li>Installs Node packages for the blog.</li>\n<li>Run the build script for the blog.</li>\n</ul>\n<p>Finally, in the most complicated line of the file, it runs a <code>gh-pages</code> command from NPM to push the built content into the <code>gh-pages</code> branch of the repo <a href=\"https://help.github.com/en/actions/configuring-and-managing-workflows/authenticating-with-the-github_token\">using secret credentials</a> injected into the environment. The nice thing about this last bit is that it adapts to whatever repository in which it&#39;s used, thanks to the variables.</p>\n<p>With a bit more research, this could probably be done even more simply. <a href=\"https://help.github.com/en/actions\">GitHub Actions</a> offers a marketplace of ready-made actions that you can drop into a workflow like this. What I&#39;ve got works for now, <a href=\"https://github.com/marketplace?type=actions&amp;query=github+pages\">but there&#39;s probably a tidier option available</a>.</p>\n<p>In any case, the end result of all of this should be an unexpectedly fast static site generator for a blog that self-publishes to <a href=\"https://pages.github.com/\">GitHub Pages</a> web hosting on pushes to a GitHub repository. As a bonus, since GitHub supports editing files directly from the web interface, you can even write blog posts in Markdown right from there and even preview your content!</p>\n<h2 id=\"next-steps\">Next steps</h2>\n<p>The script I built up in this post looks a lot like where I started with all of this at the start of the weekend. I&#39;ve since done a lot of complication, refactoring, and code golfing that probably wouldn&#39;t improve this post to explain. You can come take a peek at <a href=\"https://github.com/lmorchard/blog.lmorchard.com/\">my &quot;production&quot; code</a>, if you like. <a href=\"https://github.com/lmorchard/blog.lmorchard.com/\">It&#39;s all in GitHub</a>!</p>\n<p>Left as an exercise to the reader of this post are activities like the following:</p>\n<ul>\n<li>Refactor, clean, and <a href=\"https://en.wikipedia.org/wiki/Don%27t_repeat_yourself\">DRY</a> things up for yourself.</li>\n<li>Improve and customize the HTML templates, add your own CSS &amp; JS.</li>\n<li>Add comments - for example, <a href=\"https://disqus.com/admin/install/platforms/universalcode/\">Disqus is pretty convenient to add to a static site</a>.</li>\n<li>Better error handling - this script will just bail out if anything goes wrong.</li>\n<li>Publish to another web host - I use Amazon S3 &amp; CloudFront for my own domains.</li>\n<li>Try indexing some different collections of posts - e.g. it wouldn&#39;t be hard to add a <code>featured: true</code> flag to front matter and build a page of featured posts!</li>\n<li>Support directory-based posts - I do this to bundle the post Markdown along with associated images and other assets.</li>\n</ul>\n<p>In any case, I hope this walkthrough was worth the time to walk through. Feel free to do whatever you want with the code, whether you start a fabulous new blog or ignore it completely. Let me know what you thought, either in the comments or wherever else you might find me!</p>\n",
    "body": "**TL;DR**: I wanted to write more about building my [Easy-Blog Oven][]. I mainly glued together things I already knew, but I think I learned some things and had some surprises anyway.\n\n[easy-blog oven]: /2020/05/24/easy-blog-oven/\n\n<!--more-->\n\n<nav role=\"navigation\" class=\"table-of-contents\"></nav>\n\nWhile I was throwing together this new static site generator over the past couple of days, I kept thinking, \"I should build this as a reusable engine so other folks can use it.\"\n\nBut, you know, I think I'd rather write about how to make your own. That seems more interesting (to me, at least) than trying to generalize this thing outside of scratching my own itch. \n\nAlso, I've been meaning to write more anyway. So, here goes:\n\n## Generating a static site\n\nLet's say you have [a pile of Markdown files][posts-md] lying around like I do. Consider [this script as a start](./listing-01.js):\n\n[posts-md]: https://github.com/lmorchard/blog.lmorchard.com/tree/master/posts\n\n```javascript\n#!/usr/bin/env node\nconst path = require(\"path\");\nconst globby = require(\"globby\");\nconst mkdirp = require(\"mkdirp\");\nconst util = require(\"util\");\nconst fsOrig = require(\"fs\");\nconst fs = {\n  readFile: util.promisify(fsOrig.readFile),\n  writeFile: util.promisify(fsOrig.writeFile),\n};\n\nconst config = {\n  postsDir: \"../../posts\",\n  buildDir: \"/tmp/blog-build\",\n};\n\nasync function main() {\n  const posts = [];\n\n  // Load all posts into memory\n  const files = globby.stream(`${config.postsDir}/**/*.{md,markdown}`);\n  for await (const file of files) {\n    posts.push({\n      path: file,\n      body: await fs.readFile(file, \"utf8\"),\n    });\n  }\n\n  // Write all posts to disk\n  for (const post of posts) {\n    const postPath = `${config.buildDir}/${path.basename(post.path)}`;\n    await mkdirp(postPath);\n    await fs.writeFile(`${postPath}/index.md`, post.body);\n  }\n}\n\nmain().catch((err) => console.error(err));\n\n```\n\nThis code only does a few things:\n\n1. Use the [globby][] module to find all the blog posts\n1. Read all of those files into an array in memory\n1. Write files to disk for each blog post\n\n[globby]: https://www.npmjs.com/package/globby\n\nSo, we're done! A static site of Markdown files has been generated!\n\n## Rendering blog posts in Markdown\n\nOh, wait: Usually a website is made up of HTML pages. [We'll want to render these Markdown files as HTML](./listing-02.js):\n\n```diff\n10a11\n> const marked = require(\"marked\");\n22a24,25\n>     const body = await fs.readFile(file, \"utf8\");\n>     const html = marked(body);\n25c28,29\n<       body: await fs.readFile(file, \"utf8\"),\n---\n>       body,\n>       html,\n33a38\n>     await fs.writeFile(`${postPath}/index.html`, post.html);\n\n```\n```javascript\n#!/usr/bin/env node\nconst path = require(\"path\");\nconst globby = require(\"globby\");\nconst mkdirp = require(\"mkdirp\");\nconst util = require(\"util\");\nconst fsOrig = require(\"fs\");\nconst fs = {\n  readFile: util.promisify(fsOrig.readFile),\n  writeFile: util.promisify(fsOrig.writeFile),\n};\nconst marked = require(\"marked\");\n\nconst config = {\n  postsDir: \"../../posts\",\n  buildDir: \"/tmp/blog-build\",\n};\n\nasync function main() {\n  const posts = [];\n\n  // Load all posts into memory\n  const files = globby.stream(`${config.postsDir}/**/*.{md,markdown}`);\n  for await (const file of files) {\n    const body = await fs.readFile(file, \"utf8\");\n    const html = marked(body);\n    posts.push({\n      path: file,\n      body,\n      html,\n    });\n  }\n\n  // Write all posts to disk\n  for (const post of posts) {\n    const postPath = `${config.buildDir}/${path.basename(post.path)}`;\n    await mkdirp(postPath);\n    await fs.writeFile(`${postPath}/index.md`, post.body);\n    await fs.writeFile(`${postPath}/index.html`, post.html);\n  }\n}\n\nmain().catch((err) => console.error(err));\n\n```\n\nHere we add the [marked][] module to the mix - [marked][] is a fast Markdown-to-HTML renderer. Next, we create per-post directories and store `index.html` renderings of the Markdown files.\n\nWhy create directories for the blog posts? This can help in producing clean URL paths - e.g. `/2020/05/25/diy-easy-blog-oven/` without a pesky `.html` at the end. [It's an old web tradition.][cool-uris]\n\n[cool-uris]: https://www.w3.org/Provider/Style/URI.html\n[marked]: https://www.npmjs.com/package/marked\n\n## Wrapping rendered blog posts in page templates\n\nWe still don't quite have a *site* at this point. Those `index.html` files are just HTML fragments, not complete pages. We'll want to wrap the content of a blog post in a common page template - i.e. to frame the content, provide site navigation, etc.\n\nOkay, so let's render the blog post content within a page template:\n\n```diff\n35a36\n>     const postHtml = templateBlogPost({ post });\n38c39\n<     await fs.writeFile(`${postPath}/index.html`, post.html);\n---\n>     await fs.writeFile(`${postPath}/index.html`, postHtml);\n40a42,53\n> \n> const templateBlogPost = ({ post }) => `<!DOCTYPE html>\n> <html>\n>   <head>\n>     <title>Blog post<title>\n>   </head>\n>   <body>\n>     <h1>Blog post<h1>\n>     ${post.html}\n>   </body>\n> <html>\n> `;\n\n```\n```javascript\n#!/usr/bin/env node\nconst path = require(\"path\");\nconst globby = require(\"globby\");\nconst mkdirp = require(\"mkdirp\");\nconst util = require(\"util\");\nconst fsOrig = require(\"fs\");\nconst fs = {\n  readFile: util.promisify(fsOrig.readFile),\n  writeFile: util.promisify(fsOrig.writeFile),\n};\nconst marked = require(\"marked\");\n\nconst config = {\n  postsDir: \"../../posts\",\n  buildDir: \"/tmp/blog-build\",\n};\n\nasync function main() {\n  const posts = [];\n\n  // Load all posts into memory\n  const files = globby.stream(`${config.postsDir}/**/*.{md,markdown}`);\n  for await (const file of files) {\n    const body = await fs.readFile(file, \"utf8\");\n    const html = marked(body);\n    posts.push({\n      path: file,\n      body,\n      html,\n    });\n  }\n\n  // Write all posts to disk\n  for (const post of posts) {\n    const postPath = `${config.buildDir}/${path.basename(post.path)}`;\n    const postHtml = templateBlogPost({ post });\n    await mkdirp(postPath);\n    await fs.writeFile(`${postPath}/index.md`, post.body);\n    await fs.writeFile(`${postPath}/index.html`, postHtml);\n  }\n}\n\nconst templateBlogPost = ({ post }) => `<!DOCTYPE html>\n<html>\n  <head>\n    <title>Blog post<title>\n  </head>\n  <body>\n    <h1>Blog post<h1>\n    ${post.html}\n  </body>\n<html>\n`;\n\nmain().catch((err) => console.error(err));\n\n```\n\nThis is a dead simple page template using a function and a [template literal][]. There's no site navigation, not even a proper title for each post. But, it's a start. Now we're building a collection of actual web pages!\n\n[template literal]: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals\n\n## Adding metadata to blog posts\n\nSpeaking of blog post titles, there's usually more to a blog post than the body content. We usually want some metadata: a title, at least. Maybe also a date, some tags, a thumbnail image. \n\n The venerable [Jekyll][] static site generator support [YAML \"front matter\"][jekyll-front-matter] added to the top of a Markdown document as a header of structured data. A blog post following this convention looks something like this:\n\n[jekyll]: https://jekyllrb.com/\n\n```markdown\n---\ntitle:  \"Welcome to My Blog & Stuff!\"\ntags: [ \"foo<something>\", \"bar\", \"baz\" ]\n---\n\n# Welcome\n\n**Hello world**, this is my first blog post.\n\n```\n\nIt really helps that this format is flexible and not particularly tied to [Jekyll][]. So, I've found it handy to regard it as a defacto standard and keep all my blog posts in this format.\n\nIt's also convenient that there's a [front-matter][] module on NPM to process this format. So, we can easily roll support for front matter into the site generator:\n\n[jekyll-front-matter]: https://jekyllrb.com/docs/posts/\n[jekyll-gh-pages]: https://jekyllrb.com/docs/github-pages/\n[front-matter]: https://www.npmjs.com/package/front-matter\n\n```diff\n11a12\n> const frontmatter = require(\"front-matter\");\n24c25,26\n<     const body = await fs.readFile(file, \"utf8\");\n---\n>     const data = await fs.readFile(file, \"utf8\");\n>     const { attributes, body } = frontmatter(data);\n26a29,30\n>       // Copy all the front matter attributes into the post.\n>       ...attributes,\n46c50\n<     <title>Blog post<title>\n---\n>     <title>${post.title}<title>\n49c53,61\n<     <h1>Blog post<h1>\n---\n>     <h1>${post.title}<h1>\n>     ${\n>       post.tags &&\n>       `\n>       <ul>\n>         ${post.tags.map((tag) => `<li>${tag}</li>`).join(\"\\n\")}\n>       </ul>\n>     `\n>     }\n\n```\n```javascript\n#!/usr/bin/env node\nconst path = require(\"path\");\nconst globby = require(\"globby\");\nconst mkdirp = require(\"mkdirp\");\nconst util = require(\"util\");\nconst fsOrig = require(\"fs\");\nconst fs = {\n  readFile: util.promisify(fsOrig.readFile),\n  writeFile: util.promisify(fsOrig.writeFile),\n};\nconst marked = require(\"marked\");\nconst frontmatter = require(\"front-matter\");\n\nconst config = {\n  postsDir: \"../../posts\",\n  buildDir: \"/tmp/blog-build\",\n};\n\nasync function main() {\n  const posts = [];\n\n  // Load all posts into memory\n  const files = globby.stream(`${config.postsDir}/**/*.{md,markdown}`);\n  for await (const file of files) {\n    const data = await fs.readFile(file, \"utf8\");\n    const { attributes, body } = frontmatter(data);\n    const html = marked(body);\n    posts.push({\n      // Copy all the front matter attributes into the post.\n      ...attributes,\n      path: file,\n      body,\n      html,\n    });\n  }\n\n  // Write all posts to disk\n  for (const post of posts) {\n    const postPath = `${config.buildDir}/${path.basename(post.path)}`;\n    const postHtml = templateBlogPost({ post });\n    await mkdirp(postPath);\n    await fs.writeFile(`${postPath}/index.md`, post.body);\n    await fs.writeFile(`${postPath}/index.html`, postHtml);\n  }\n}\n\nconst templateBlogPost = ({ post }) => `<!DOCTYPE html>\n<html>\n  <head>\n    <title>${post.title}<title>\n  </head>\n  <body>\n    <h1>${post.title}<h1>\n    ${\n      post.tags &&\n      `\n      <ul>\n        ${post.tags.map((tag) => `<li>${tag}</li>`).join(\"\\n\")}\n      </ul>\n    `\n    }\n    ${post.html}\n  </body>\n<html>\n`;\n\nmain().catch((err) => console.error(err));\n\n```\n\nThe [front-matter][] module neatly parses the blog post YAML header into an object and separates the Markdown content body that follows. This lets us easily include metadata from the post in the page template.\n\n## Using tagged template literals to make HTML easier\n\nYou may have noticed that I introduced a problem in that last section. Take another look at that example post:\n\n```markdown\n---\ntitle:  \"Welcome to My Blog & Stuff!\"\ntags: [ \"foo<something>\", \"bar\", \"baz\" ]\n---\n\n# Welcome\n\n**Hello world**, this is my first blog post.\n\n```\n\nThe title has an ampersand - i.e. `&` - which *should* be encoded in HTML output as an `&amp;` entity. But, worse than that, look at those tags. I included a weird one - i.e. `foo<something>` - which will produce invalid markup if included as-is.\n\nThis wasn't a problem with the content body in Markdown. That's *supposed* to be treated as raw HTML. The metadata, though, needs to be encoded by escaping any characters or sequences that make trouble for HTML.\n\n### Tagged template literals in a nutshell\n\nThis is where I started having fun with [tagged template literals][tagged-literals] in JavaScript. These are multi-line string literals that support variable substitutions and can be processed through a function of your choice.\n\n[tagged-literals]: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals#Tagged_templates\n\nHere's an example of a tagged template literal function:\n\n```javascript\nconst passthrough = (strings, ...values) =>\n  strings.reduce(\n    (result, string, idx) =>\n      result\n        + string\n        // There might not be a value at this idx, \n        // if the template ends in a literal string\n        + (values[idx] ? values[idx] : \"\"),\n    \"\"\n  );\nconst msg = \"test\";\nconst str = passthrough`\n  Hello world, this is a ${msg} of a tagged template.\n`;\nconsole.log(str);\n// Hello world, this is a test of a tagged template.\n\n```\n\nFor what it's worth, I first found this example [from a site called Writing JavaScript][tagged-template-literal-sample]. Your mileage may vary, so this might be a too-terse use of [Array.reduce()][array-reduce]. But, for some reason this was the first time it really clicked for me. So, kudos to [Seth Vincent][] for putting that out there!\n\n[seth vincent]: https://sethvincent.com/\n\nAnyway, as the name `passthrough` suggests, this function just passes through the result of parsing the template literal. JavaScript splits the literal up into an array of strings, along with the result of resolving the variable substitutions as subsequent function parameters. The implementation of this `passthrough` function just glues all the strings together unchanged.\n\n[array-reduce]: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/Reduce\n[tagged-template-literal-sample]: https://writingjavascript.org/posts/creating-functions-for-tagged-template-literals#minimal-example-of-a-tag-function\n\n### Using tagged template literals for HTML encoding\n\nBut, rather than a simple passthrough, we *could* filter & transform both the strings and variable substitutions. In fact, this is what I came up with to ease\n producing HTML from template literals:\n\n```diff\n12a13\n> const escapeHtml = require(\"escape-html\");\n40c41\n<     const postHtml = templateBlogPost({ post });\n---\n>     const postHtml = templateBlogPost({ post })();\n47c48,69\n< const templateBlogPost = ({ post }) => `<!DOCTYPE html>\n---\n> const unescaped = (raw) => () => raw;\n> \n> const html = (strings, ...values) =>\n>   unescaped(\n>     strings\n>       .reduce((result, string, i) => result + string + htmlValue(values[i]), \"\")\n>       .trim()\n>   );\n> \n> const htmlValue = (value) => {\n>   if (typeof value == \"undefined\") {\n>     return \"\";\n>   } else if (typeof value === \"function\") {\n>     return value();\n>   } else if (Array.isArray(value)) {\n>     return value.map(htmlValue).join(\"\");\n>   }\n>   return escapeHtml(value);\n> };\n> \n> const templateBlogPost = ({ post }) => html`\n> <!DOCTYPE html>\n55a78,81\n>       html`\n>         <ul>\n>           ${post.tags.map((tag) => html`<li>${tag}</li>`)}\n>         </ul>\n57,60d82\n<       <ul>\n<         ${post.tags.map((tag) => `<li>${tag}</li>`).join(\"\\n\")}\n<       </ul>\n<     `\n62c84\n<     ${post.html}\n---\n>     ${unescaped(post.html)}\n\n```\n```javascript\n#!/usr/bin/env node\nconst path = require(\"path\");\nconst globby = require(\"globby\");\nconst mkdirp = require(\"mkdirp\");\nconst util = require(\"util\");\nconst fsOrig = require(\"fs\");\nconst fs = {\n  readFile: util.promisify(fsOrig.readFile),\n  writeFile: util.promisify(fsOrig.writeFile),\n};\nconst marked = require(\"marked\");\nconst frontmatter = require(\"front-matter\");\nconst escapeHtml = require(\"escape-html\");\n\nconst config = {\n  postsDir: \"../../posts\",\n  buildDir: \"/tmp/blog-build\",\n};\n\nasync function main() {\n  const posts = [];\n\n  // Load all posts into memory\n  const files = globby.stream(`${config.postsDir}/**/*.{md,markdown}`);\n  for await (const file of files) {\n    const data = await fs.readFile(file, \"utf8\");\n    const { attributes, body } = frontmatter(data);\n    const html = marked(body);\n    posts.push({\n      // Copy all the front matter attributes into the post.\n      ...attributes,\n      path: file,\n      body,\n      html,\n    });\n  }\n\n  // Write all posts to disk\n  for (const post of posts) {\n    const postPath = `${config.buildDir}/${path.basename(post.path)}`;\n    const postHtml = templateBlogPost({ post })();\n    await mkdirp(postPath);\n    await fs.writeFile(`${postPath}/index.md`, post.body);\n    await fs.writeFile(`${postPath}/index.html`, postHtml);\n  }\n}\n\nconst unescaped = (raw) => () => raw;\n\nconst html = (strings, ...values) =>\n  unescaped(\n    strings\n      .reduce((result, string, i) => result + string + htmlValue(values[i]), \"\")\n      .trim()\n  );\n\nconst htmlValue = (value) => {\n  if (typeof value == \"undefined\") {\n    return \"\";\n  } else if (typeof value === \"function\") {\n    return value();\n  } else if (Array.isArray(value)) {\n    return value.map(htmlValue).join(\"\");\n  }\n  return escapeHtml(value);\n};\n\nconst templateBlogPost = ({ post }) => html`\n<!DOCTYPE html>\n<html>\n  <head>\n    <title>${post.title}<title>\n  </head>\n  <body>\n    <h1>${post.title}<h1>\n    ${\n      post.tags &&\n      html`\n        <ul>\n          ${post.tags.map((tag) => html`<li>${tag}</li>`)}\n        </ul>\n      `\n    }\n    ${unescaped(post.html)}\n  </body>\n<html>\n`;\n\nmain().catch((err) => console.error(err));\n\n```\n\n### Weird quirks of my HTML templates\n\nThere are a few strange things going on here. (Or, at least, I thought they were strange.)\n\nFirst off, my `html` template function returns a function. *That* function returns the desired string content. \n\nThis was weird to me when I first learned about tagged template literals: *The function that processes a tagged template literal doesn't have to return a string!* It really confused in using modules like [HTM (Hyperscript Tagged Markup)][htm] to create JSX-free components for [Preact][]. But, as it turns out, a tagged template string can result in essentially *anything* - not just a string.\n\nAnd here's why I built it that way: I'm using a function as the mechanism to indicate which values *should not be encoded for HTML*. The `htmlValue` function checks for `(typeof value === \"function\")`. Any variable substitutions of type function are called & included without escaping. All others are escaped for HTML.\n\nThis might be a terrible idea, but it means my `html` template tag has two important features:\n\n1. It supports leaving selective variable substitutions raw & unencoded:\n    ```javascript\n    html`\n      This variable ${() => '<b>right here</b>`} should be unescaped markup.\n    `\n    ```\n\n1. It supports templates-within-templates, since the `html` function itself returns a function:\n    ```javascript\n    html`\n    <ul>\n      ${post.tags.map((tag) => html`<li>${tag}</li>`)}\n    </ul>\n    `\n    ```\n\nFor another way to think about it, consider that [React has a mechanism where unescaped markup is indicated][react-unescape] like so:\n\n```html\n<span dangerouslySetInnerHTML={{ __html: \"<b>right here</b>\" }} />\n```\n\nThe approach here is to just use `typeof value === 'function'` in a similar spirit.\n\n[react-unescape]: https://reactjs.org/docs/dom-elements.html#dangerouslysetinnerhtml\n\nI've been happy so far with how this template scheme has turned out. It just leaves an awkward aspect where the final consumer of the template has to call the return value to get the result:\n\n```javascript\nconst postHtml = templateBlogPost({ post })();\n```\n\nBut, this scheme has replaced a whole template engine dependency for me in [my blog's collection of templates][lmo-blog-templates]. So, that's pretty neat.\n\n### A note for VSCode users\n\nOh and there's one more benefit I found while using HTML in tagged templates: If you use VSCode as your editor, there's [the lit-html extension][lit-html-extension] to help manage & format markup within tagged templates.\n\nSure, the extension is *intended* mainly to help working with [lit-html][] templates - but it works just as well for my tagged templates too!\n\n[lit-html]: https://github.com/Polymer/lit-html\n[lit-html-extension]: https://marketplace.visualstudio.com/items?itemName=bierner.lit-html\n\n[lmo-blog-templates]: https://github.com/lmorchard/blog.lmorchard.com/tree/master/templates\n[htm]: https://www.npmjs.com/package/htm\n[preact]: https://preactjs.com/\n\n## Improving the site directory layout\n\nOkay, now we have blog posts with YAML metadata and Markdown content paired with an HTML template scheme for publishing web pages. I'll leave improving those web pages as an exercise to the reader. You can [peek at my templates][lmo-blog-templates] as an example, but you'll want your own look & feel. Also my templates are terrible.\n\nTemplates aside, the next improvement is around directory layout of the static web site. Earlier, I mentioned the \"[old web tradition][cool-uris]\" of producing clean URL paths - e.g. `/2020/05/25/diy-easy-blog-oven/`. Well, our URL paths are a mess at this point. \n\nSo, let's improve that by using dates to build directory paths:\n\n```diff\n13a14\n> const moment = require(\"moment\");\n19a21,22\n> const RE_POST_NAME = new RegExp(/(\\d{4})-(\\d{2})-(\\d{2})-(.*)/);\n> \n28a32,42\n> \n>     // Get the filename without .md or .markdown extension\n>     const postName = path.basename(file).split(\".\")[0];\n>     // Just skip any files that don't match the naming convention\n>     const dateMatch = RE_POST_NAME.exec(postName);\n>     if (!dateMatch) continue;\n> \n>     const [, year, month, day, slug] = dateMatch;\n>     const date = moment(attributes.date || `${year}-${month}-${day}T12:00:00Z`);\n>     const postPath = `${date.format(\"YYYY/MM/DD\")}/${slug}`;\n> \n32c46,51\n<       path: file,\n---\n>       path: postPath,\n>       year,\n>       month,\n>       day,\n>       date,\n>       slug,\n40c59\n<     const postPath = `${config.buildDir}/${path.basename(post.path)}`;\n---\n>     const postPath = `${config.buildDir}/${post.path}`;\n75a95\n>     <h2>${post.date.format(\"dddd, MMMM Do YYYY, h:mm:ss a\")}</h2>\n\n```\n```javascript\n#!/usr/bin/env node\nconst path = require(\"path\");\nconst globby = require(\"globby\");\nconst mkdirp = require(\"mkdirp\");\nconst util = require(\"util\");\nconst fsOrig = require(\"fs\");\nconst fs = {\n  readFile: util.promisify(fsOrig.readFile),\n  writeFile: util.promisify(fsOrig.writeFile),\n};\nconst marked = require(\"marked\");\nconst frontmatter = require(\"front-matter\");\nconst escapeHtml = require(\"escape-html\");\nconst moment = require(\"moment\");\n\nconst config = {\n  postsDir: \"../../posts\",\n  buildDir: \"/tmp/blog-build\",\n};\n\nconst RE_POST_NAME = new RegExp(/(\\d{4})-(\\d{2})-(\\d{2})-(.*)/);\n\nasync function main() {\n  const posts = [];\n\n  // Load all posts into memory\n  const files = globby.stream(`${config.postsDir}/**/*.{md,markdown}`);\n  for await (const file of files) {\n    const data = await fs.readFile(file, \"utf8\");\n    const { attributes, body } = frontmatter(data);\n    const html = marked(body);\n\n    // Get the filename without .md or .markdown extension\n    const postName = path.basename(file).split(\".\")[0];\n    // Just skip any files that don't match the naming convention\n    const dateMatch = RE_POST_NAME.exec(postName);\n    if (!dateMatch) continue;\n\n    const [, year, month, day, slug] = dateMatch;\n    const date = moment(attributes.date || `${year}-${month}-${day}T12:00:00Z`);\n    const postPath = `${date.format(\"YYYY/MM/DD\")}/${slug}`;\n\n    posts.push({\n      // Copy all the front matter attributes into the post.\n      ...attributes,\n      path: postPath,\n      year,\n      month,\n      day,\n      date,\n      slug,\n      body,\n      html,\n    });\n  }\n\n  // Write all posts to disk\n  for (const post of posts) {\n    const postPath = `${config.buildDir}/${post.path}`;\n    const postHtml = templateBlogPost({ post })();\n    await mkdirp(postPath);\n    await fs.writeFile(`${postPath}/index.md`, post.body);\n    await fs.writeFile(`${postPath}/index.html`, postHtml);\n  }\n}\n\nconst unescaped = (raw) => () => raw;\n\nconst html = (strings, ...values) =>\n  unescaped(\n    strings\n      .reduce((result, string, i) => result + string + htmlValue(values[i]), \"\")\n      .trim()\n  );\n\nconst htmlValue = (value) => {\n  if (typeof value == \"undefined\") {\n    return \"\";\n  } else if (typeof value === \"function\") {\n    return value();\n  } else if (Array.isArray(value)) {\n    return value.map(htmlValue).join(\"\");\n  }\n  return escapeHtml(value);\n};\n\nconst templateBlogPost = ({ post }) => html`\n<!DOCTYPE html>\n<html>\n  <head>\n    <title>${post.title}<title>\n  </head>\n  <body>\n    <h1>${post.title}<h1>\n    <h2>${post.date.format(\"dddd, MMMM Do YYYY, h:mm:ss a\")}</h2>\n    ${\n      post.tags &&\n      html`\n        <ul>\n          ${post.tags.map((tag) => html`<li>${tag}</li>`)}\n        </ul>\n      `\n    }\n    ${unescaped(post.html)}\n  </body>\n<html>\n`;\n\nmain().catch((err) => console.error(err));\n\n```\n\nFor my blog, I use a filename convention like this: `2020-05-25-diy-easy-blog-oven.md`\n\nThis code takes advantage of that naming convention with a regular expression to extract the date and slug for use in constructing the directory structure during the build. However, as an override, I can explicitly set a date via the `date` attribute in the post's front matter.\n\n### Dates & names & files, oh my!\n\nHere's some context & history behind that arrangement: Some file-based blogs I've used read the file modification time as the source of the date. This could be nice, insofar as the date automatically updated as I edited the post. But, things fell apart if I backed up and restored the files while forgetting to preserve the timestamps. All the posts suddenly looked like they were published *today* - oops!\n\nI can also stash the date in a post's front matter as a `date` property. I've done that in some places, occasionally as the result of an earlier database export from Movable Type or WordPress many years ago. I like to have it as an option.\n\nWhat I've found works best, though, is to follow a naming convention for blog post filenames - i.e. `YYYY-MM-DD-slug.md`. This survives lots of mistakes in backup & restore - and it gives me a natural sort order for listing files on disk.\n\n### An aside on slugs\n\nOh yeah, and [\"slug\" is a general term][slug] for the ID or name of a blog post - independent from the title or headline of the post. A slug is what shows up in the URL to uniquely identify the post from others on the same day.\n\nAlthough slugs can be random IDs or automatically derived from titles, many web publishing systems treat the slug and title as separate properties managed by the author. A fun thing to watch for on news sites is when a draft of an article is submitted with an initial slug and title. Later, the title is changed but the slug is left untouched. This can result in some fun situations where the headline of an article has been made more subtle - but the slug retains some fairly blunt language.\n\nAnyway, I'm getting punchy and I digress. In this system, the slug is derived from the filename of the blog post Markdown source file.\n\n[slug]: https://en.wikipedia.org/wiki/Slug_(publishing)\n\n## Rendering post indexes by recent, date, and tag\n\nNow that we have a decent directory structure, it would be nice to have index pages to navigate around the blog.\n\nUp to this point, I've been trying to keep the changes to the script small and relatively easy to explain. From here, though, I'm just going to go for broke and spew some code:\n\n```diff\n64a65,118\n> \n>   writeIndexPage({\n>     title: \"Recent posts\",\n>     path: \"\",\n>     posts: posts.slice(0, 15),\n>   });\n> \n>   const postsByYear = indexBy(posts, ({ year }) => year);\n>   for (const [year, posts] of Object.entries(postsByYear)) {\n>     writeIndexPage({\n>       title: `Year: ${year}`,\n>       path: year,\n>       posts,\n>     });\n>   }\n> \n>   const postsByMonth = indexBy(posts, ({ year, month }) => `${year}/${month}`);\n>   for (const [month, posts] of Object.entries(postsByMonth)) {\n>     writeIndexPage({\n>       title: `Month: ${month}`,\n>       path: month,\n>       posts,\n>     });\n>   }\n> \n>   const postsByTag = indexBy(posts, ({ tags = [] }) => tags);\n>   for (const [tag, posts] of Object.entries(postsByTag)) {\n>     writeIndexPage({\n>       title: `Tag: ${tag}`,\n>       path: `tag/${tag}`,\n>       posts,\n>     });\n>   }\n> }\n> \n> function indexBy(items, keyFn) {\n>   const index = {};\n>   for (const item of items) {\n>     const key = keyFn(item);\n>     const keys = Array.isArray(key) ? key : [key];\n>     for (const k of keys) {\n>       if (k) index[k] = [...(index[k] || []), item];\n>     }\n>   }\n>   return index;\n> }\n> \n> async function writeIndexPage(indexProps) {\n>   const indexPath = `${config.buildDir}/${indexProps.path}`;\n>   await mkdirp(indexPath);\n>   await fs.writeFile(\n>     `${indexPath}/index.html`,\n>     templateIndexPage(indexProps)()\n>   );\n85a140,162\n> \n> const templateIndexPage = ({ title, posts }) => html`\n> <!DOCTYPE html>\n> <html>\n>   <head>\n>     <title>${title}<title>\n>   </head>\n>   <body>\n>     <h1>${title}<h1>\n>     <ul>\n>       ${posts.map(\n>         (post) => html`\n>           <li>\n>             <a href=\"/${post.path}/\">\n>               ${post.date.format(\"dddd, MMMM Do YYYY\")}: ${post.title}\n>             </a>\n>           </li>\n>         `\n>       )}\n>     </ul>\n>   </body>\n> <html>\n> `;\n\n```\n```javascript\n#!/usr/bin/env node\nconst path = require(\"path\");\nconst globby = require(\"globby\");\nconst mkdirp = require(\"mkdirp\");\nconst util = require(\"util\");\nconst fsOrig = require(\"fs\");\nconst fs = {\n  readFile: util.promisify(fsOrig.readFile),\n  writeFile: util.promisify(fsOrig.writeFile),\n};\nconst marked = require(\"marked\");\nconst frontmatter = require(\"front-matter\");\nconst escapeHtml = require(\"escape-html\");\nconst moment = require(\"moment\");\n\nconst config = {\n  postsDir: \"../../posts\",\n  buildDir: \"/tmp/blog-build\",\n};\n\nconst RE_POST_NAME = new RegExp(/(\\d{4})-(\\d{2})-(\\d{2})-(.*)/);\n\nasync function main() {\n  const posts = [];\n\n  // Load all posts into memory\n  const files = globby.stream(`${config.postsDir}/**/*.{md,markdown}`);\n  for await (const file of files) {\n    const data = await fs.readFile(file, \"utf8\");\n    const { attributes, body } = frontmatter(data);\n    const html = marked(body);\n\n    // Get the filename without .md or .markdown extension\n    const postName = path.basename(file).split(\".\")[0];\n    // Just skip any files that don't match the naming convention\n    const dateMatch = RE_POST_NAME.exec(postName);\n    if (!dateMatch) continue;\n\n    const [, year, month, day, slug] = dateMatch;\n    const date = moment(attributes.date || `${year}-${month}-${day}T12:00:00Z`);\n    const postPath = `${date.format(\"YYYY/MM/DD\")}/${slug}`;\n\n    posts.push({\n      // Copy all the front matter attributes into the post.\n      ...attributes,\n      path: postPath,\n      year,\n      month,\n      day,\n      date,\n      slug,\n      body,\n      html,\n    });\n  }\n\n  // Write all posts to disk\n  for (const post of posts) {\n    const postPath = `${config.buildDir}/${post.path}`;\n    const postHtml = templateBlogPost({ post })();\n    await mkdirp(postPath);\n    await fs.writeFile(`${postPath}/index.md`, post.body);\n    await fs.writeFile(`${postPath}/index.html`, postHtml);\n  }\n\n  writeIndexPage({\n    title: \"Recent posts\",\n    path: \"\",\n    posts: posts.slice(0, 15),\n  });\n\n  const postsByYear = indexBy(posts, ({ year }) => year);\n  for (const [year, posts] of Object.entries(postsByYear)) {\n    writeIndexPage({\n      title: `Year: ${year}`,\n      path: year,\n      posts,\n    });\n  }\n\n  const postsByMonth = indexBy(posts, ({ year, month }) => `${year}/${month}`);\n  for (const [month, posts] of Object.entries(postsByMonth)) {\n    writeIndexPage({\n      title: `Month: ${month}`,\n      path: month,\n      posts,\n    });\n  }\n\n  const postsByTag = indexBy(posts, ({ tags = [] }) => tags);\n  for (const [tag, posts] of Object.entries(postsByTag)) {\n    writeIndexPage({\n      title: `Tag: ${tag}`,\n      path: `tag/${tag}`,\n      posts,\n    });\n  }\n}\n\nfunction indexBy(items, keyFn) {\n  const index = {};\n  for (const item of items) {\n    const key = keyFn(item);\n    const keys = Array.isArray(key) ? key : [key];\n    for (const k of keys) {\n      if (k) index[k] = [...(index[k] || []), item];\n    }\n  }\n  return index;\n}\n\nasync function writeIndexPage(indexProps) {\n  const indexPath = `${config.buildDir}/${indexProps.path}`;\n  await mkdirp(indexPath);\n  await fs.writeFile(\n    `${indexPath}/index.html`,\n    templateIndexPage(indexProps)()\n  );\n}\n\nconst unescaped = (raw) => () => raw;\n\nconst html = (strings, ...values) =>\n  unescaped(\n    strings\n      .reduce((result, string, i) => result + string + htmlValue(values[i]), \"\")\n      .trim()\n  );\n\nconst htmlValue = (value) => {\n  if (typeof value == \"undefined\") {\n    return \"\";\n  } else if (typeof value === \"function\") {\n    return value();\n  } else if (Array.isArray(value)) {\n    return value.map(htmlValue).join(\"\");\n  }\n  return escapeHtml(value);\n};\n\nconst templateIndexPage = ({ title, posts }) => html`\n<!DOCTYPE html>\n<html>\n  <head>\n    <title>${title}<title>\n  </head>\n  <body>\n    <h1>${title}<h1>\n    <ul>\n      ${posts.map(\n        (post) => html`\n          <li>\n            <a href=\"/${post.path}/\">\n              ${post.date.format(\"dddd, MMMM Do YYYY\")}: ${post.title}\n            </a>\n          </li>\n        `\n      )}\n    </ul>\n  </body>\n<html>\n`;\n\nconst templateBlogPost = ({ post }) => html`\n<!DOCTYPE html>\n<html>\n  <head>\n    <title>${post.title}<title>\n  </head>\n  <body>\n    <h1>${post.title}<h1>\n    <h2>${post.date.format(\"dddd, MMMM Do YYYY, h:mm:ss a\")}</h2>\n    ${\n      post.tags &&\n      html`\n        <ul>\n          ${post.tags.map((tag) => html`<li>${tag}</li>`)}\n        </ul>\n      `\n    }\n    ${unescaped(post.html)}\n  </body>\n<html>\n`;\n\nmain().catch((err) => console.error(err));\n\n```\n\nThere's a lot of repetition here, but I tried to keep it [DRY][]. \n\nThe gist is that, since we're loading all the blog posts into memory, we can easily collate posts into groupings based on attributes like year, month, and tags. The new `indexBy` utility function takes care of that.\n\n[dry]: https://en.wikipedia.org/wiki/Don%27t_repeat_yourself\n\nOnce collated into convenient groupings, we can use the `writeIndexPage` utility function to build each index page via `templateIndexPage` and then write to disk at the approriate paths in the directory structure.\n\nThis, by the way, is one of the things that surprised me: My blog has over 1000 posts, accumulated over the course of 18 years. I expected the execution time of this script to be impracticably slow.\n\nWell, the script at this point takes about 2 seconds on my computer:\n\n```shell\n$ time node listing-07.js \nreal    0m1.646s\nuser    0m2.056s\nsys     0m0.305s\n```\n\nThis was one of the big surprises I found when I started playing with this idea. I'm used to thinking about databases and indexes and threads and clusters of servers when it comes to churning through lots of content. But, even if it looks like a lot of content to me as the author, it's not much at all to a modern computer.\n\nTo be fair, I've added complications to the code that *actually* publishes this blog versus the script I've built up for this post. But, my \"production\" code still builds this whole site in under 7 seconds. And, if I feel like tinkering some more, I could probably optimize and bring that time back down again.\n\n## Publishing to GitHub Pages via Actions\n\nThis is the final stretch. We've got a script that generates a static site from blog posts - including indexes listing posts by year, month, and tag. The last thing is to get all of this content onto the web.\n\nWhen I last built a static site generator for my blog, [I hooked it up][travis-blog] to [Travis CI][] as a learning project. It was also convenient: When I pushed new content to GitHub, it eventually ended up on Amazon S3. Back in 2015, it was neat to see the Rube Goldberg machine kick into action without me having to run any code on my laptop.\n\nSince then, GitHub themselves have come up with their own offering in the workflow automation market with [GitHub Actions][]. It's worth reading the docs, but I don't want to sidetrack too far into a general tutorial. \n\nLong story short, building & publishing a static site to [GitHub Pages][] via Actions boils down to dropping a file like this as [`.github/workflows/main.yml`][main-workflow] in my GitHub repository:\n\n[main-workflow]: https://github.com/lmorchard/blog.lmorchard.com/blob/master/.github/workflows/stage.yml\n[github actions]: https://help.github.com/en/actions\n[travis-blog]: https://blog.lmorchard.com/2015/10/22/blogging-via-travis/\n[travis ci]: https://travis-ci.org/\n\n```yaml\nname: Deploy to Github Pages\non:\n  push:\n    branches: [ master ]\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Use Node.js 14.2.0\n      uses: actions/setup-node@v1\n      with:\n        node-version: 14.2.0\n    - name: Set git identity\n      run: |\n        git config --global user.email \"you@example.com\"\n        git config --global user.name \"Your Name Here\"        \n    - name: Install\n      run: yarn install\n    - name: Build\n      run: node index.js\n    - name: Deploy\n      run: npx gh-pages -t -d build -r https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git\n\n```\n\nIf you've got experience with other workflow automation tools like [Travis CI][] or [CircleCI][], this might look familiar. That is, this configuration file instructs [GitHub Actions][] to do stuff on every push to `master` branch:\n\n* Fire up a virtual machine running Ubuntu Linux.\n* Check out my repository.\n* Set up Node.js v14.2.0.\n* Configure git with my details - you'll want to customize this.\n* Installs Node packages for the blog.\n* Run the build script for the blog.\n\nFinally, in the most complicated line of the file, it runs a `gh-pages` command from NPM to push the built content into the `gh-pages` branch of the repo [using secret credentials][gh-actions-token] injected into the environment. The nice thing about this last bit is that it adapts to whatever repository in which it's used, thanks to the variables.\n\nWith a bit more research, this could probably be done even more simply. [GitHub Actions][] offers a marketplace of ready-made actions that you can drop into a workflow like this. What I've got works for now, [but there's probably a tidier option available][gh-pages-actions].\n\n[gh-pages-actions]: https://github.com/marketplace?type=actions&query=github+pages\n[gh-actions-token]: https://help.github.com/en/actions/configuring-and-managing-workflows/authenticating-with-the-github_token\n[circleci]: https://circleci.com/\n\nIn any case, the end result of all of this should be an unexpectedly fast static site generator for a blog that self-publishes to [GitHub Pages][] web hosting on pushes to a GitHub repository. As a bonus, since GitHub supports editing files directly from the web interface, you can even write blog posts in Markdown right from there and even preview your content!\n\n[github pages]: https://pages.github.com/\n\n## Next steps\n\nThe script I built up in this post looks a lot like where I started with all of this at the start of the weekend. I've since done a lot of complication, refactoring, and code golfing that probably wouldn't improve this post to explain. You can come take a peek at [my \"production\" code][github-blog-lmo], if you like. [It's all in GitHub][github-blog-lmo]!\n\n[github-blog-lmo]: https://github.com/lmorchard/blog.lmorchard.com/\n\nLeft as an exercise to the reader of this post are activities like the following:\n\n* Refactor, clean, and [DRY][] things up for yourself.\n* Improve and customize the HTML templates, add your own CSS & JS.\n* Add comments - for example, [Disqus is pretty convenient to add to a static site][disqus-install].\n* Better error handling - this script will just bail out if anything goes wrong.\n* Publish to another web host - I use Amazon S3 & CloudFront for my own domains.\n* Try indexing some different collections of posts - e.g. it wouldn't be hard to add a `featured: true` flag to front matter and build a page of featured posts!\n* Support directory-based posts - I do this to bundle the post Markdown along with associated images and other assets.\n\n[disqus-install]: https://disqus.com/admin/install/platforms/universalcode/\n\nIn any case, I hope this walkthrough was worth the time to walk through. Feel free to do whatever you want with the code, whether you start a fabulous new blog or ignore it completely. Let me know what you thought, either in the comments or wherever else you might find me!\n",
    "parentPath": "../blog.lmorchard.com/posts/2020-05-25-diy-easy-blog-oven-draft",
    "path": "2020/05/25/diy-easy-blog-oven-draft",
    "summary": "<p><strong>TL;DR</strong>: I wanted to write more about building my <a href=\"/2020/05/24/easy-blog-oven/\">Easy-Blog Oven</a>. I mainly glued together things I already knew, but I think I learned some things and had some surprises anyway.</p>\n",
    "nextPostPath": "2020/05/24/easy-blog-oven"
  },
  {
    "title": "Easy-Blog Oven",
    "tags": [
      "metablogging",
      "blogging",
      "node",
      "webdev"
    ],
    "year": "2020",
    "month": "05",
    "day": "24",
    "isDir": false,
    "slug": "easy-blog-oven",
    "date": "2020-05-24T12:00:00.000Z",
    "postName": "2020-05-24-easy-blog-oven",
    "html": "<p><strong>TL;DR</strong>: I made <a href=\"https://github.com/lmorchard/blog.lmorchard.com\">a new static site generator for my blog</a>. It&#39;s not very clever. I&#39;ve been calling it my &quot;Easy-Blog Oven&quot; and it seems to be working well so far.</p>\n<!--more-->\n\n<img class=\"fullwidth\" src=\"/uploads/2020/easy-bake-oven.jpg\" />\n\n<p>I&#39;ve tried a lot of tools for writing on the web. In fact, I&#39;ve spent more time trying tools for writing on the web than actually writing on the web. My last round was writing my own thing <a href=\"https://blog.lmorchard.com/2014/10/20/static-blog-generation-with-gulp/\">using Gulp and Amazon S3</a> as a learning project. A couple of years later, <a href=\"https://blog.lmorchard.com/2015/10/22/blogging-via-travis/\">I hooked it up to Travis CI to publish on a push to master</a>.</p>\n<p> I wrote 30 whole blog posts using that system! But, it felt slow and cumbersome. Also, I stopped using Gulp for any other projects. And, at some point, new versions of Node.js stopped running my site generator altogether. So, I&#39;ve been putting off fixing that whole mess for a while.</p>\n<p>But then, just this past week, I whipped up <a href=\"https://github.com/mozilla/fxa/blob/master/_scripts/build-storybooks-indexes.js\">a quick static site generator for a project at work</a>. All it does is this:</p>\n<ul>\n<li>Iterate through files and load them.</li>\n<li>Render HTML using <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals#Tagged_templates\">tagged template literals</a>.</li>\n</ul>\n<p>After building that, it occurred to me: What if I just wrote a stupid simple script for my blog to iterate through all my entries? So, <a href=\"https://github.com/lmorchard/easy-blog-oven/commit/13a75f91992683eb8a665b026dcf0911459872ee#diff-168726dbe96b3ce427e7fedce31bb0bcR26\">I tried it in a real quick sketch of code</a>. </p>\n<p>It was Aaron Swartz&#39; &quot;<a href=\"http://www.aaronsw.com/weblog/000404\">Bake, Don&#39;t Fry</a>&quot; blog post back in 2002 that first got me thinking about static site generators. Since this script started about as simple as a box with a light bulb in it, I started calling it my &quot;Easy-Blog Oven&quot;.</p>\n<p>I&#39;ve accumulated over 1000 posts in the 18 years since I started a blog. I expected this naive script to take an annoyingly long time to run. It took 2 seconds. Turns out computers and Node.js are fast, these days. Hell, there&#39;s probably more data dredged up from a typical <code>node_modules</code> folder than my entire blog.</p>\n<p>Thus encouraged, I tried loading everything into memory. My computer&#39;s got lots of it. Then, it&#39;s just filter, map, reduce, and sort operations on arrays to generate index pages for posts by date and tag. Turning <a href=\"https://github.com/lmorchard/easy-blog-oven/blob/553f557be22db8ca47c38559490db2b5f75c7b1d/index.js#L58\">lists of posts</a> into HTML with <a href=\"https://github.com/lmorchard/easy-blog-oven/blob/553f557be22db8ca47c38559490db2b5f75c7b1d/templates/postList.js\">tagged template literals</a> added <em>an entire second</em> to the execution time.</p>\n<p>From there, I ported over a few more elaborations &amp; complications from my old Gulp-based site generator. That added up to a whole six seconds of execution time. I&#39;d bet I could find a few single web pages out there that take about as long to load as this thing takes to generate my whole site.</p>\n<p>So anyway, I started all of this on Friday night. I spent a big chunk of Saturday continuing to tinker. And then, today, <a href=\"https://github.com/lmorchard/blog.lmorchard.com/blob/master/.github/workflows/prod.yml\">I learned enough about Github Actions get this thing building and uploading to Amazon S3</a>.</p>\n<p>The whole build and publish process now seems to take about 3 minutes. The longest part is uploading everything to Amazon S3, which could be greatly improved by just uploading what&#39;s changed. The site build itself only seems to take about 6-7 seconds. Pretty neat.</p>\n<p>Now, let&#39;s see if I start using this thing again.</p>\n",
    "body": "**TL;DR**: I made [a new static site generator for my blog](https://github.com/lmorchard/blog.lmorchard.com). It's not very clever. I've been calling it my \"Easy-Blog Oven\" and it seems to be working well so far.\n\n<!--more-->\n\n<img class=\"fullwidth\" src=\"/uploads/2020/easy-bake-oven.jpg\" />\n\nI've tried a lot of tools for writing on the web. In fact, I've spent more time trying tools for writing on the web than actually writing on the web. My last round was writing my own thing [using Gulp and Amazon S3][gulp-blog] as a learning project. A couple of years later, [I hooked it up to Travis CI to publish on a push to master][travis-ci].\n\n I wrote 30 whole blog posts using that system! But, it felt slow and cumbersome. Also, I stopped using Gulp for any other projects. And, at some point, new versions of Node.js stopped running my site generator altogether. So, I've been putting off fixing that whole mess for a while.\n\nBut then, just this past week, I whipped up [a quick static site generator for a project at work][storybook-indexes]. All it does is this:\n\n* Iterate through files and load them.\n* Render HTML using [tagged template literals][tagged-literals].\n\nAfter building that, it occurred to me: What if I just wrote a stupid simple script for my blog to iterate through all my entries? So, [I tried it in a real quick sketch of code][initial-commit]. \n\nIt was Aaron Swartz' \"[Bake, Don't Fry](http://www.aaronsw.com/weblog/000404)\" blog post back in 2002 that first got me thinking about static site generators. Since this script started about as simple as a box with a light bulb in it, I started calling it my \"Easy-Blog Oven\".\n\nI've accumulated over 1000 posts in the 18 years since I started a blog. I expected this naive script to take an annoyingly long time to run. It took 2 seconds. Turns out computers and Node.js are fast, these days. Hell, there's probably more data dredged up from a typical `node_modules` folder than my entire blog.\n\nThus encouraged, I tried loading everything into memory. My computer's got lots of it. Then, it's just filter, map, reduce, and sort operations on arrays to generate index pages for posts by date and tag. Turning [lists of posts][post-list] into HTML with [tagged template literals][post-list-template] added *an entire second* to the execution time.\n\nFrom there, I ported over a few more elaborations & complications from my old Gulp-based site generator. That added up to a whole six seconds of execution time. I'd bet I could find a few single web pages out there that take about as long to load as this thing takes to generate my whole site.\n\nSo anyway, I started all of this on Friday night. I spent a big chunk of Saturday continuing to tinker. And then, today, [I learned enough about Github Actions get this thing building and uploading to Amazon S3][gh-action-s3].\n\nThe whole build and publish process now seems to take about 3 minutes. The longest part is uploading everything to Amazon S3, which could be greatly improved by just uploading what's changed. The site build itself only seems to take about 6-7 seconds. Pretty neat.\n\nNow, let's see if I start using this thing again.\n\n[gh-action-s3]: https://github.com/lmorchard/blog.lmorchard.com/blob/master/.github/workflows/prod.yml\n[travis-ci]: https://blog.lmorchard.com/2015/10/22/blogging-via-travis/\n[post-list]: https://github.com/lmorchard/easy-blog-oven/blob/553f557be22db8ca47c38559490db2b5f75c7b1d/index.js#L58\n[post-list-template]: https://github.com/lmorchard/easy-blog-oven/blob/553f557be22db8ca47c38559490db2b5f75c7b1d/templates/postList.js\n[initial-commit]: https://github.com/lmorchard/easy-blog-oven/commit/13a75f91992683eb8a665b026dcf0911459872ee#diff-168726dbe96b3ce427e7fedce31bb0bcR26\n[tagged-literals]: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals#Tagged_templates\n[storybook-indexes]: https://github.com/mozilla/fxa/blob/master/_scripts/build-storybooks-indexes.js\n[jekyll-blog]: https://blog.lmorchard.com/2011/06/08/moved-to-jekyll/\n[wordpress-blog]: http://blog.lmorchard.com/2012/06/16/blogging-like-a-blogger/\n[gulp-blog]: https://blog.lmorchard.com/2014/10/20/static-blog-generation-with-gulp/\n[typing]: https://typing.lmorchard.com/",
    "parentPath": "../blog.lmorchard.com/posts",
    "path": "2020/05/24/easy-blog-oven",
    "thumbnail": "/blog.lmorchard.com/uploads/2020/easy-bake-oven.jpg",
    "summary": "<p><strong>TL;DR</strong>: I made <a href=\"https://github.com/lmorchard/blog.lmorchard.com\">a new static site generator for my blog</a>. It&apos;s not very clever. I&apos;ve been calling it my &quot;Easy-Blog Oven&quot; and it seems to be working well so far.</p>\n",
    "prevPostPath": "2020/05/25/diy-easy-blog-oven-draft",
    "nextPostPath": "2018/03/01/sio2pi"
  },
  {
    "title": "Fun with Themes in Firefox",
    "tags": [
      "mozilla",
      "firefox",
      "themes",
      "themer",
      "quantum",
      "addons",
      "webpack",
      "node",
      "webdev"
    ],
    "year": "2018",
    "month": "03",
    "day": "01",
    "isDir": true,
    "slug": "themesrfun",
    "date": "2018-03-01T12:00:00.000Z",
    "postName": "2018-03-01-themesrfun",
    "html": "<p><strong>TL;DR</strong>: Last year, I started work on a new Test Pilot experiment playing with themes in Firefox. </p>\n<!--more-->\n\n<nav role=\"navigation\" class=\"table-of-contents\"></nav>\n\n<h2 id=\"new-theme-apis-are-fun\">New theme APIs are fun</h2>\n<p>At the core of this experiment are <a href=\"https://developer.mozilla.org/en-US/Add-ons/WebExtensions/API/theme\">new theme APIs for add-ons</a> shipping with Firefox. </p>\n<p>These APIs take inspiration <a href=\"https://developer.chrome.com/apps/themes\">from static themes in Google Chrome</a>, building from there to enable the creation of dynamic themes. </p>\n<p>For example, <a href=\"https://addons.mozilla.org/en-US/firefox/addon/quantum-lights-dynamic/\">Quantum Lights</a> changes based on the time of day.</p>\n<p><a href=\"https://addons.mozilla.org/en-US/firefox/addon/quantum-lights-dynamic/\"><img src=\"quantum-lights.png\" alt=\"Quantum Lights dynamic theme\"></a></p>\n<p><a href=\"https://addons.mozilla.org/en-US/firefox/addon/vivaldifox/\">VivaldiFox</a> reflects the sites youre visiting.</p>\n<p><a href=\"https://addons.mozilla.org/en-US/firefox/addon/vivaldifox/\"><img src=\"image_0.png\" alt=\"VivaldiFox dynamic theme\"></a></p>\n<p>You could even build themes that use data from external HTTP services - e.g. to change based on the weather.</p>\n<p>To explore these new APIs, Firefox Themer consists of a website and a companion add-on for Firefox. The website offers a theme editor with a paper doll preview - you can click on parts of a simulated browser interface and dress it up however you like. The add-on grants special powers to the website, applying changes from the theme in the editor onto the browser itself.</p>\n<h2 id=\"editing-themes-on-the-web\">Editing themes on the web</h2>\n<p><a href=\"https://github.com/mozilla/Themer/tree/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/web\">The site</a> is built <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/webpack.web.js\">using Webpack</a>, React, and Redux. React offers a solid foundation for composing the editor. Personally, I really like working with <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/web/lib/components/SavedThemeSelector/index.js\">stateless functional components</a> - theyre kind of what tipped me over into becoming a React convert a few years ago. Im also a terrible visual designer with weak CSS-fu - but <a href=\"https://simonsmith.io/using-webpack-to-build-react-components-and-their-assets/\">using Webpack to bundle assets from per-component directories</a> makes it easier for teammates to step in where I fall short.</p>\n<img id=\"thumbnail\" title=\"An early snapshot of Themer in development\" alt=\"An early snapshot of Themer in development\" src=\"image_1.png\" />\n\n<p>Further under the hood, Redux offers a clean way to <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/lib/store.js\">manage theme data and UI state</a>. Adding <a href=\"https://github.com/mozilla/Themer/tree/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/web/lib/components/UndoRedoButtons\">undo &amp; redo buttons</a> is easy, thanks to <a href=\"https://github.com/omnidan/redux-undo/\">redux-undo</a>. And, by way of some <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/web/index.js#L52\">simple Redux middleware</a>, I was able to easily add a hook to push every theme changes into the browser via the add-on.</p>\n<p>The website is just a static page - theres no real server-side application. When you save a theme, <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/web/lib/storage.js\">it ends up in your browsers localStorage</a>. Though we plan to move to a Mozilla-owned production server on launch, Ive been <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/package.json#L29\">deploying</a> builds to <a href=\"https://mozilla.github.io/Themer/\">GitHub Pages</a> during development.</p>\n<p>Another interesting feature of the website is that we encode themes as a parameter in the URL. Rather than come up with a bespoke scheme, I use <a href=\"https://github.com/masotime/json-url\">this json-url module</a> to compress JSON and encode it as Base64, which makes for a long URL but not unreasonably so. This approach enables folks to simply copy &amp; paste a URL to share a theme theyve made. You <a href=\"https://mozilla.github.io/Themer/?theme=XQAAAAK6AAAAAAAAAABBKYhm849SCiaxqiaEGccwS-xNVABND6bPaWX82IACoyBXlMz-ogPQMZx8jZw0gi6ZqepxjZiNq3qtC6ReDugh0DJEIcc-6Ekd4BML5haoPqlXvTBKbEuN12ZBm-SJaWyB2b9GzX0tU6b_u9yjWO4ukTDkntTK440uf__ug8AA\">can</a> <a href=\"https://mozilla.github.io/Themer/?theme=XQAAAAK5AAAAAAAAAABBKYhm849SCiaxqiaEGccwS-xNVABNBRtj-x-Szc1kMeuEtwJYdDlHdJFchkY8sMP4iOzSOnr2vDVLFHcDTGfvoD2F-saWB-4Q-0HlUiMST82W8NTW8EedwTOfbOY_8T30w0e4gC9vlGFCU9f6FVIWiWSteBgU_b2G6fBR_7tUIAA\">even</a> <a href=\"https://mozilla.github.io/Themer/?theme=XQAAAAK8AAAAAAAAAABBKYhm849SCiaxqiaEGccwS-xNVABNKtQKc4Qr-u-HdLUSjaBjcrH658wB_k4I1-yfpFsfTFeutvkNHhJd47c-oR5Cmx-mMJXZ4Lq7R98D2PE8etCHIG-B5_8oTyfPCjY6DxXN-uebtBycPe1q5OYxejC4KXCppxfkfniiH__gvZgA\">link</a> <a href=\"https://mozilla.github.io/Themer/?theme=XQAAAAK7AAAAAAAAAABBKYhm849SCiaxqiaEGccwS-xNVABNC6bT6OtXpulKBw4DX1CffRksp6558s0k0DnUhq_LUMnHsWC8m0Ch34ivMZQ9sgV8nw4smjNTF6KwTBLBWoGene--BIiLoZeK7cfULCJbaoBYqyuNgz2tcB6oGDKcpyWUdMoffLb2h__-XfwA\">to</a> <a href=\"https://mozilla.github.io/Themer/?theme=XQAAAAK2AAAAAAAAAABBKYhm849SCiaxqiaEGccwS-xNVAAfaPFobPrtxqh09bZ0dFlllNZAoZN2KxC18prV-JbJ_OWRSXO_BkFys9aW3y-ZXvULv_v6dWy1x1lwnCABmI9hLlcXkVKtiPaJ2TBI4QUpuGXbvJ__-RkwAA\">themes</a> from a blog post, if you wanted to!</p>\n<p><img src=\"image_2.png\" alt=\"Copy themes as URLs\"></p>\n<p>When the page loads and sees the ?theme URL, <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/web/index.js#L201\">it unpacks the data</a> and <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/web/index.js#L204\">loads it into editors Redux store</a>. Ive also been able to work this into the location bar with the HTML5 History API and <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/web/index.js#L61\">Redux middleware</a>. The browser location represents the current theme, while back &amp; forward buttons double as undo &amp; redo.</p>\n<h2 id=\"add-ons-can-be-expansion-cartridges\">Add-ons can be expansion cartridges</h2>\n<p><a href=\"http://www.syntiac.com/chameleon.html\"><img title=\"The Turbo Chameleon 64 cartridge adds many new capabilities to a Commodore 64\" class=\"inset wide right\" src=\"chameleon_housing_small.jpg\" /></a></p>\n<p><a href=\"https://github.com/mozilla/Themer/tree/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/extension\">The companion add-on</a> is also built <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/webpack.extension.js\">using Webpack</a> and acts as an <a href=\"https://www.c64-wiki.com/wiki/Simons%27_BASIC\">expansion cartridge</a> for the theme editor on the website. (Can you tell <a href=\"https://blog.lmorchard.com/2018/03/01/sio2pi/\">Ive had retro computers on the mind</a>, lately?)</p>\n<p>Add-ons in Firefox can install <a href=\"https://developer.mozilla.org/en-US/Add-ons/WebExtensions/Content_scripts\">content scripts</a> that access content and data on web pages. Content scripts can communicate with the parent add-on <a href=\"https://developer.mozilla.org/en-US/Add-ons/WebExtensions/Content_scripts#Communicating_with_background_scripts\">by way of a message port</a>. They can also communicate with a web page <a href=\"https://developer.mozilla.org/en-US/Add-ons/WebExtensions/Content_scripts#Communicating_with_the_web_page\">by way of synthetic events</a>. Put the two together, and youve got <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/extension/contentScript.js\">a messaging channel</a> between a web page and an add-on in Firefox.</p>\n<p>Here&#39;s the heart of <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/extension/contentScript.js\">that messaging bridge</a>:</p>\n<pre><code class=\"language-javascript\">import { CHANNEL_NAME } from &quot;../lib/constants&quot;;\n\n// Relay backend port messages to content\nlet port;\n\nfunction connect() {\n  port = browser.runtime.connect({ name: CHANNEL_NAME });\n  port.onDisconnect.addListener(() =&gt; {\n    port = null;\n    reconnect();\n  });\n  port.onMessage.addListener(message =&gt; {\n    window.postMessage({ ...message, channel: `${CHANNEL_NAME}-web` }, &quot;*&quot;);\n  });\n}\n\n// Relay content messages to backend port if the channel name matches\n// (Not a security feature so much as a noise filter)\nwindow.addEventListener(&quot;message&quot;, event =&gt; {\n  if (\n    port &amp;&amp;\n    event.source === window &amp;&amp;\n    event.data &amp;&amp;\n    event.data.channel === `${CHANNEL_NAME}-extension`\n  ) {\n    port.postMessage({ ...event.data, location: window.location.href });\n  }\n});\n\nconnect();</code></pre>\n<p>With this approach, the web page doesnt actually gain access to any Firefox APIs. <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/extension/background.js#L23\">The add-on can decide what to do with with messages it receives</a>. If the page sends invalid data or asks to do something not supported - nothing happens. Here&#39;s a snippet of that logic from the extension:</p>\n<pre><code class=\"language-javascript\">const messageListener = port =&gt; message =&gt; {\n  let theme;\n  switch (message.type) {\n    case &quot;fetchTheme&quot;:\n      log(&quot;fetchTheme&quot;);\n      fetchTheme().then(({ theme: currentTheme }) =&gt;\n        port.postMessage({ type: &quot;fetchedTheme&quot;, theme: currentTheme })\n      );\n      break;\n    case &quot;setTheme&quot;:\n      theme = normalizeTheme(message.theme);\n      log(&quot;setTheme&quot;, theme);\n      storeTheme({ theme });\n      applyTheme({ theme });\n      break;\n    case &quot;ping&quot;:\n      port.postMessage({ type: &quot;pong&quot; });\n      break;\n    default:\n      log(&quot;unexpected message&quot;, message);\n  }\n};</code></pre>\n<p>And here&#39;s a peek at <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/web/index.js#L52\">that Redux middleware I mentioned earlier</a> which updates the add-on from the web:</p>\n<pre><code class=\"language-javascript\">const postMessage = (type, data = {}) =&gt;\n  window.postMessage(\n    { ...data, type, channel: `${CHANNEL_NAME}-extension` },\n    &quot;*&quot;\n  );\n\nconst updateExtensionThemeMiddleware = ({ getState }) =&gt; next =&gt; action =&gt; {\n  const returnValue = next(action);\n  const meta = action.meta || {};\n  if (!meta.skipAddon &amp;&amp; themeChangeActions.includes(action.type)) {\n    postMessage(&quot;setTheme&quot;, { theme: selectors.theme(getState()) });\n  }\n  return returnValue;\n};</code></pre>\n<p>The add-on can also restrict the set of pages from which it will accept messages: We <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/webpack.extension.js#L55\">hardcode the URL for the theme editor</a> into the add-ons content script configuration at build time, which means no other web page should be able to ask the add-on to alter the theme in Firefox.</p>\n<h2 id=\"add-on-detection-is-hard\">Add-on detection is hard</h2>\n<img class=\"inset wide right\" src=\"loader.png\" title=\"The loading overlay that appears until the editor is visually stable\" />\n\n<p>There is a wrinkle to the relationship between website and add-on, though: A normal web page cannot detect whether or not a particular add-on has been installed. All the page can do is send a message. If the add-on responds, then we know the add-on is available.</p>\n<p>Proving a negative, however, is impossible: the web page cant know for sure that the addon is *not *available. Responses to asynchronous messages take time - not necessarily a long time, but more than zero time. </p>\n<p>If the page sends a message and doesnt get a response, that doesnt mean the add-on is missing. It could just mean that the add-on is taking awhile to respond. So, we have to render the theme editor such that it starts off by assuming the add-on is not installed. If the add-on shows up, minutes or milliseconds later, the page can update itself to reflect the new state of things.</p>\n<p>Left as-is, youd see several flashes of color and elements on the page move as things settle. That seems unpleasant and possibly confusing, so we came up with a loading spinner: When the page loads, it displays the spinner and a timer starts. If that timer expires, we consider things ready and reveal the editor. But, if theres any change to the Redux store while that timer is running, we restart the clock.</p>\n<p>This is the gist of what that code does:</p>\n<pre><code class=\"language-javascript\">const unsubscribeLoader = store.subscribe(() =&gt; {\n  if (selectors.loaderDelayExpired(store.getState())) {\n    // State settled down long enough for timer to expire - stop listening.\n    unsubscribeLoader();\n  } else {\n    // Reset the timer again.\n    startLoaderDelay();\n  }\n});\n\n// Utility to (re)start up a timer to dismiss the loading indicator\nlet loaderTimer = null;\nfunction startLoaderDelay() {\n  if (loaderTimer) {\n    clearTimeout(loaderTimer);\n  }\n  loaderTimer = setTimeout(\n    () =&gt; store.dispatch(actions.ui.setLoaderDelayExpired(true)),\n    LOADER_DELAY_PERIOD\n  );\n}</code></pre>\n<p>Early changes to the store are driven by things like decoding a shared theme and responses from the add-on. Again, these are asynchronous and unpredictable. The timer duration is an arbitrary guess I made that seems to feel right. Its a dirty hack, but it seems like a good enough effort for now.</p>\n<h2 id=\"using-npm-scripts-and-multiple-webpack-configs\">Using npm scripts and multiple Webpack configs</h2>\n<p>One of the things that has worked nicely on this project is building everything in parallel with a single npm command. You can <a href=\"https://github.com/mozilla/Themer/tree/5cdcb7e15d64934f0e71521512c74337dc58fa05#get-started\">clone the repo and kick things off for development</a> with a simple <code>npm install &amp;&amp; npm start</code> dance.</p>\n<p>The add-on and the site both use Webpack. Theres <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/webpack.common.js\">a shared config</a> as a base and then specific configurations with tweaks for <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/webpack.web.js\">the site</a> and <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/webpack.extension.js\">the add-on</a>. So, we want to run two separate instances of Webpack to build everything, watch files, and host the dev server.</p>\n<p>This is where <a href=\"https://www.npmjs.com/package/npm-run-all\">npm-run-all</a> comes in: Its a CLI tool that lets you run multiple npm scripts. I used to use gulp to orchestrate this sort of thing, but <a href=\"https://www.npmjs.com/package/npm-run-all\">npm-run-all</a> lets me arrange it all <a href=\"https://docs.npmjs.com/misc/scripts\">in <code>package.json</code></a>. It would be fine if this just enabled running scripts in series. But, npm-run-all also lets you run scripts* in parallel<em>. The cherry on top is that [this parallelization works on Linux, OS X, *and Windows</em>](<a href=\"https://www.npmjs.com/package/npm-run-all#%EF%B8%8F-motivation\">https://www.npmjs.com/package/npm-run-all#%EF%B8%8F-motivation</a>).</p>\n<pre><code class=\"language-json\">&quot;scripts&quot;: {\n  &quot;start&quot;: &quot;npm-run-all --parallel server watch:extension watch:lint&quot;,\n  &quot;server&quot;: &quot;cross-env NODE_ENV=development webpack-dev-server --config webpack.web.js&quot;,\n  &quot;watch&quot;: &quot;npm-run-all --parallel watch:*&quot;,\n  &quot;watch:web&quot;: &quot;cross-env NODE_ENV=development webpack --watch --progress --colors --config webpack.web.js&quot;,\n  &quot;watch:extension&quot;: &quot;cross-env NODE_ENV=development webpack --watch --progress --colors --config webpack.extension.js&quot;,\n  &quot;watch:lint&quot;: &quot;onchange -p -v \\&quot;src/**/*.js\\&quot; -- npm run lint&quot;,\n  &quot;lint&quot;: &quot;eslint --color .&quot;,\n},</code></pre>\n<p>In past years, Windows support might have been an abstract novelty for me. But, in recent months, Ive switched from Apple hardware to a PC laptop. Ive found the new <a href=\"https://docs.microsoft.com/en-us/windows/wsl/install-win10\">Windows Subsystem for Linux</a> to be essential to that switch. But, sometimes its nice to just fire up a Node.js dev environment directly in PowerShell - <a href=\"https://www.npmjs.com/package/npm-run-all\">npm-run-all</a> lets me (and you) do that!</p>\n<p>So, <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/package.json#L12\">the start script in our package.json</a> is able to fire up both Webpack processes for the site and add-on. It can also <a href=\"https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/package.json#L17\">start a file watcher to run linting</a> and tests (when we have them) alongside. That simplifies using everything in a single shell window across platforms. <a href=\"https://decafbad.com/2011/06/os-webdev-vm/slides.html#1\">I used to lean on Vagrant or Docker to offer something &quot;simple&quot; to folks interested in contributing to a project</a>. But, though virtual machines and containers can hide apparent complexity in development, its hard to beat just running things in node on the native OS.</p>\n<h2 id=\"help-us-make-themes-more-fun\">Help us make themes more fun!</h2>\n<p>Were launching this experiment soon. And, though it only makes limited use of the new theme APIs for now, were hoping that the web-based editor and ease of sharing makes it fun &amp; worth playing with. Weve got some ideas on what to add over the course of the experiment and hope to get more from the community. </p>\n<p>Whether you can offer code, give feedback, participate in discussions, or just let us watch how you use something - everyone has something valuable to offer. In fact, one of <a href=\"https://wiki.mozilla.org/Test_Pilot/mission\">the overarching goals of Test Pilot</a> is to expand channels of contribution for folks interested in helping us build Firefox.</p>\n<p>As with all Test Pilot experiments, well be watching how folks use this stuff as input for what happens next. We also encourage participation in our <a href=\"https://discourse.mozilla.org/c/test-pilot\">Discourse forums</a>. And finally, the project itself is <a href=\"https://github.com/mozilla/Themer\">open source on Github</a> and open to pull requests. </p>\n<p>In the meantime, start collecting color swatches for your own theme. Personally, I might try my hand at <a href=\"https://draculatheme.com/\">a Dracula theme</a> or maybe raid my Vim config directory for some inspiration.</p>\n",
    "body": "**TL;DR**: Last year, I started work on a new Test Pilot experiment playing with themes in Firefox. \n\n<!--more-->\n\n<nav role=\"navigation\" class=\"table-of-contents\"></nav>\n\n## New theme APIs are fun\n\nAt the core of this experiment are [new theme APIs for add-ons](https://developer.mozilla.org/en-US/Add-ons/WebExtensions/API/theme) shipping with Firefox. \n\nThese APIs take inspiration [from static themes in Google Chrome](https://developer.chrome.com/apps/themes), building from there to enable the creation of dynamic themes. \n\nFor example, [Quantum Lights](https://addons.mozilla.org/en-US/firefox/addon/quantum-lights-dynamic/) changes based on the time of day.\n\n[![Quantum Lights dynamic theme](quantum-lights.png)](https://addons.mozilla.org/en-US/firefox/addon/quantum-lights-dynamic/)\n\n[VivaldiFox](https://addons.mozilla.org/en-US/firefox/addon/vivaldifox/) reflects the sites youre visiting.\n\n[![VivaldiFox dynamic theme](image_0.png)](https://addons.mozilla.org/en-US/firefox/addon/vivaldifox/)\n\nYou could even build themes that use data from external HTTP services - e.g. to change based on the weather.\n\nTo explore these new APIs, Firefox Themer consists of a website and a companion add-on for Firefox. The website offers a theme editor with a paper doll preview - you can click on parts of a simulated browser interface and dress it up however you like. The add-on grants special powers to the website, applying changes from the theme in the editor onto the browser itself.\n\n## Editing themes on the web\n\n[The site](https://github.com/mozilla/Themer/tree/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/web) is built [using Webpack](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/webpack.web.js), React, and Redux. React offers a solid foundation for composing the editor. Personally, I really like working with [stateless functional components](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/web/lib/components/SavedThemeSelector/index.js) - theyre kind of what tipped me over into becoming a React convert a few years ago. Im also a terrible visual designer with weak CSS-fu - but [using Webpack to bundle assets from per-component directories](https://simonsmith.io/using-webpack-to-build-react-components-and-their-assets/) makes it easier for teammates to step in where I fall short.\n\n<img id=\"thumbnail\" title=\"An early snapshot of Themer in development\" alt=\"An early snapshot of Themer in development\" src=\"image_1.png\" />\n\nFurther under the hood, Redux offers a clean way to [manage theme data and UI state](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/lib/store.js). Adding [undo & redo buttons](https://github.com/mozilla/Themer/tree/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/web/lib/components/UndoRedoButtons) is easy, thanks to [redux-undo](https://github.com/omnidan/redux-undo/). And, by way of some [simple Redux middleware](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/web/index.js#L52), I was able to easily add a hook to push every theme changes into the browser via the add-on.\n\nThe website is just a static page - theres no real server-side application. When you save a theme, [it ends up in your browsers localStorage](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/web/lib/storage.js). Though we plan to move to a Mozilla-owned production server on launch, Ive been [deploying](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/package.json#L29) builds to [GitHub Pages](https://mozilla.github.io/Themer/) during development.\n\nAnother interesting feature of the website is that we encode themes as a parameter in the URL. Rather than come up with a bespoke scheme, I use [this json-url module](https://github.com/masotime/json-url) to compress JSON and encode it as Base64, which makes for a long URL but not unreasonably so. This approach enables folks to simply copy & paste a URL to share a theme theyve made. You [can](https://mozilla.github.io/Themer/?theme=XQAAAAK6AAAAAAAAAABBKYhm849SCiaxqiaEGccwS-xNVABND6bPaWX82IACoyBXlMz-ogPQMZx8jZw0gi6ZqepxjZiNq3qtC6ReDugh0DJEIcc-6Ekd4BML5haoPqlXvTBKbEuN12ZBm-SJaWyB2b9GzX0tU6b_u9yjWO4ukTDkntTK440uf__ug8AA) [even](https://mozilla.github.io/Themer/?theme=XQAAAAK5AAAAAAAAAABBKYhm849SCiaxqiaEGccwS-xNVABNBRtj-x-Szc1kMeuEtwJYdDlHdJFchkY8sMP4iOzSOnr2vDVLFHcDTGfvoD2F-saWB-4Q-0HlUiMST82W8NTW8EedwTOfbOY_8T30w0e4gC9vlGFCU9f6FVIWiWSteBgU_b2G6fBR_7tUIAA) [link](https://mozilla.github.io/Themer/?theme=XQAAAAK8AAAAAAAAAABBKYhm849SCiaxqiaEGccwS-xNVABNKtQKc4Qr-u-HdLUSjaBjcrH658wB_k4I1-yfpFsfTFeutvkNHhJd47c-oR5Cmx-mMJXZ4Lq7R98D2PE8etCHIG-B5_8oTyfPCjY6DxXN-uebtBycPe1q5OYxejC4KXCppxfkfniiH__gvZgA) [to](https://mozilla.github.io/Themer/?theme=XQAAAAK7AAAAAAAAAABBKYhm849SCiaxqiaEGccwS-xNVABNC6bT6OtXpulKBw4DX1CffRksp6558s0k0DnUhq_LUMnHsWC8m0Ch34ivMZQ9sgV8nw4smjNTF6KwTBLBWoGene--BIiLoZeK7cfULCJbaoBYqyuNgz2tcB6oGDKcpyWUdMoffLb2h__-XfwA) [themes](https://mozilla.github.io/Themer/?theme=XQAAAAK2AAAAAAAAAABBKYhm849SCiaxqiaEGccwS-xNVAAfaPFobPrtxqh09bZ0dFlllNZAoZN2KxC18prV-JbJ_OWRSXO_BkFys9aW3y-ZXvULv_v6dWy1x1lwnCABmI9hLlcXkVKtiPaJ2TBI4QUpuGXbvJ__-RkwAA) from a blog post, if you wanted to!\n\n![Copy themes as URLs](image_2.png)\n\nWhen the page loads and sees the ?theme URL, [it unpacks the data](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/web/index.js#L201) and [loads it into editors Redux store](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/web/index.js#L204). Ive also been able to work this into the location bar with the HTML5 History API and [Redux middleware](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/web/index.js#L61). The browser location represents the current theme, while back & forward buttons double as undo & redo.\n\n## Add-ons can be expansion cartridges\n\n[<img title=\"The Turbo Chameleon 64 cartridge adds many new capabilities to a Commodore 64\" class=\"inset wide right\" src=\"chameleon_housing_small.jpg\" />](http://www.syntiac.com/chameleon.html)\n\n[The companion add-on](https://github.com/mozilla/Themer/tree/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/extension) is also built [using Webpack](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/webpack.extension.js) and acts as an [expansion cartridge](https://www.c64-wiki.com/wiki/Simons%27_BASIC) for the theme editor on the website. (Can you tell [Ive had retro computers on the mind](https://blog.lmorchard.com/2018/03/01/sio2pi/), lately?)\n\nAdd-ons in Firefox can install [content scripts](https://developer.mozilla.org/en-US/Add-ons/WebExtensions/Content_scripts) that access content and data on web pages. Content scripts can communicate with the parent add-on [by way of a message port](https://developer.mozilla.org/en-US/Add-ons/WebExtensions/Content_scripts#Communicating_with_background_scripts). They can also communicate with a web page [by way of synthetic events](https://developer.mozilla.org/en-US/Add-ons/WebExtensions/Content_scripts#Communicating_with_the_web_page). Put the two together, and youve got [a messaging channel](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/extension/contentScript.js) between a web page and an add-on in Firefox.\n\nHere's the heart of [that messaging bridge](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/extension/contentScript.js):\n\n```javascript\nimport { CHANNEL_NAME } from \"../lib/constants\";\n\n// Relay backend port messages to content\nlet port;\n\nfunction connect() {\n  port = browser.runtime.connect({ name: CHANNEL_NAME });\n  port.onDisconnect.addListener(() => {\n    port = null;\n    reconnect();\n  });\n  port.onMessage.addListener(message => {\n    window.postMessage({ ...message, channel: `${CHANNEL_NAME}-web` }, \"*\");\n  });\n}\n\n// Relay content messages to backend port if the channel name matches\n// (Not a security feature so much as a noise filter)\nwindow.addEventListener(\"message\", event => {\n  if (\n    port &&\n    event.source === window &&\n    event.data &&\n    event.data.channel === `${CHANNEL_NAME}-extension`\n  ) {\n    port.postMessage({ ...event.data, location: window.location.href });\n  }\n});\n\nconnect();\n```\n\nWith this approach, the web page doesnt actually gain access to any Firefox APIs. [The add-on can decide what to do with with messages it receives](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/extension/background.js#L23). If the page sends invalid data or asks to do something not supported - nothing happens. Here's a snippet of that logic from the extension:\n\n```javascript\nconst messageListener = port => message => {\n  let theme;\n  switch (message.type) {\n    case \"fetchTheme\":\n      log(\"fetchTheme\");\n      fetchTheme().then(({ theme: currentTheme }) =>\n        port.postMessage({ type: \"fetchedTheme\", theme: currentTheme })\n      );\n      break;\n    case \"setTheme\":\n      theme = normalizeTheme(message.theme);\n      log(\"setTheme\", theme);\n      storeTheme({ theme });\n      applyTheme({ theme });\n      break;\n    case \"ping\":\n      port.postMessage({ type: \"pong\" });\n      break;\n    default:\n      log(\"unexpected message\", message);\n  }\n};\n```\n\nAnd here's a peek at [that Redux middleware I mentioned earlier](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/src/web/index.js#L52) which updates the add-on from the web:\n\n```javascript\nconst postMessage = (type, data = {}) =>\n  window.postMessage(\n    { ...data, type, channel: `${CHANNEL_NAME}-extension` },\n    \"*\"\n  );\n\nconst updateExtensionThemeMiddleware = ({ getState }) => next => action => {\n  const returnValue = next(action);\n  const meta = action.meta || {};\n  if (!meta.skipAddon && themeChangeActions.includes(action.type)) {\n    postMessage(\"setTheme\", { theme: selectors.theme(getState()) });\n  }\n  return returnValue;\n};\n```\n\nThe add-on can also restrict the set of pages from which it will accept messages: We [hardcode the URL for the theme editor](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/webpack.extension.js#L55) into the add-ons content script configuration at build time, which means no other web page should be able to ask the add-on to alter the theme in Firefox.\n\n## Add-on detection is hard\n\n<img class=\"inset wide right\" src=\"loader.png\" title=\"The loading overlay that appears until the editor is visually stable\" />\n\nThere is a wrinkle to the relationship between website and add-on, though: A normal web page cannot detect whether or not a particular add-on has been installed. All the page can do is send a message. If the add-on responds, then we know the add-on is available.\n\nProving a negative, however, is impossible: the web page cant know for sure that the addon is *not *available. Responses to asynchronous messages take time - not necessarily a long time, but more than zero time. \n\nIf the page sends a message and doesnt get a response, that doesnt mean the add-on is missing. It could just mean that the add-on is taking awhile to respond. So, we have to render the theme editor such that it starts off by assuming the add-on is not installed. If the add-on shows up, minutes or milliseconds later, the page can update itself to reflect the new state of things.\n\nLeft as-is, youd see several flashes of color and elements on the page move as things settle. That seems unpleasant and possibly confusing, so we came up with a loading spinner: When the page loads, it displays the spinner and a timer starts. If that timer expires, we consider things ready and reveal the editor. But, if theres any change to the Redux store while that timer is running, we restart the clock.\n\nThis is the gist of what that code does:\n\n```javascript\nconst unsubscribeLoader = store.subscribe(() => {\n  if (selectors.loaderDelayExpired(store.getState())) {\n    // State settled down long enough for timer to expire - stop listening.\n    unsubscribeLoader();\n  } else {\n    // Reset the timer again.\n    startLoaderDelay();\n  }\n});\n\n// Utility to (re)start up a timer to dismiss the loading indicator\nlet loaderTimer = null;\nfunction startLoaderDelay() {\n  if (loaderTimer) {\n    clearTimeout(loaderTimer);\n  }\n  loaderTimer = setTimeout(\n    () => store.dispatch(actions.ui.setLoaderDelayExpired(true)),\n    LOADER_DELAY_PERIOD\n  );\n}\n```\n\nEarly changes to the store are driven by things like decoding a shared theme and responses from the add-on. Again, these are asynchronous and unpredictable. The timer duration is an arbitrary guess I made that seems to feel right. Its a dirty hack, but it seems like a good enough effort for now.\n\n## Using npm scripts and multiple Webpack configs\n\nOne of the things that has worked nicely on this project is building everything in parallel with a single npm command. You can [clone the repo and kick things off for development](https://github.com/mozilla/Themer/tree/5cdcb7e15d64934f0e71521512c74337dc58fa05#get-started) with a simple `npm install && npm start` dance.\n\nThe add-on and the site both use Webpack. Theres [a shared config](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/webpack.common.js) as a base and then specific configurations with tweaks for [the site](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/webpack.web.js) and [the add-on](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/webpack.extension.js). So, we want to run two separate instances of Webpack to build everything, watch files, and host the dev server.\n\nThis is where [npm-run-all](https://www.npmjs.com/package/npm-run-all) comes in: Its a CLI tool that lets you run multiple npm scripts. I used to use gulp to orchestrate this sort of thing, but [npm-run-all](https://www.npmjs.com/package/npm-run-all) lets me arrange it all [in `package.json`](https://docs.npmjs.com/misc/scripts). It would be fine if this just enabled running scripts in series. But, npm-run-all also lets you run scripts* in parallel*. The cherry on top is that [this parallelization works on Linux, OS X, *and Windows*](https://www.npmjs.com/package/npm-run-all#%EF%B8%8F-motivation).\n\n```json\n\"scripts\": {\n  \"start\": \"npm-run-all --parallel server watch:extension watch:lint\",\n  \"server\": \"cross-env NODE_ENV=development webpack-dev-server --config webpack.web.js\",\n  \"watch\": \"npm-run-all --parallel watch:*\",\n  \"watch:web\": \"cross-env NODE_ENV=development webpack --watch --progress --colors --config webpack.web.js\",\n  \"watch:extension\": \"cross-env NODE_ENV=development webpack --watch --progress --colors --config webpack.extension.js\",\n  \"watch:lint\": \"onchange -p -v \\\"src/**/*.js\\\" -- npm run lint\",\n  \"lint\": \"eslint --color .\",\n},\n```\n\nIn past years, Windows support might have been an abstract novelty for me. But, in recent months, Ive switched from Apple hardware to a PC laptop. Ive found the new [Windows Subsystem for Linux](https://docs.microsoft.com/en-us/windows/wsl/install-win10) to be essential to that switch. But, sometimes its nice to just fire up a Node.js dev environment directly in PowerShell - [npm-run-all](https://www.npmjs.com/package/npm-run-all) lets me (and you) do that!\n\nSo, [the start script in our package.json](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/package.json#L12) is able to fire up both Webpack processes for the site and add-on. It can also [start a file watcher to run linting](https://github.com/mozilla/Themer/blob/5cdcb7e15d64934f0e71521512c74337dc58fa05/package.json#L17) and tests (when we have them) alongside. That simplifies using everything in a single shell window across platforms. [I used to lean on Vagrant or Docker to offer something \"simple\" to folks interested in contributing to a project](https://decafbad.com/2011/06/os-webdev-vm/slides.html#1). But, though virtual machines and containers can hide apparent complexity in development, its hard to beat just running things in node on the native OS.\n\n## Help us make themes more fun!\n\nWere launching this experiment soon. And, though it only makes limited use of the new theme APIs for now, were hoping that the web-based editor and ease of sharing makes it fun & worth playing with. Weve got some ideas on what to add over the course of the experiment and hope to get more from the community. \n\nWhether you can offer code, give feedback, participate in discussions, or just let us watch how you use something - everyone has something valuable to offer. In fact, one of [the overarching goals of Test Pilot](https://wiki.mozilla.org/Test_Pilot/mission) is to expand channels of contribution for folks interested in helping us build Firefox.\n\nAs with all Test Pilot experiments, well be watching how folks use this stuff as input for what happens next. We also encourage participation in our [Discourse forums](https://discourse.mozilla.org/c/test-pilot). And finally, the project itself is [open source on Github](https://github.com/mozilla/Themer) and open to pull requests. \n\nIn the meantime, start collecting color swatches for your own theme. Personally, I might try my hand at [a Dracula theme](https://draculatheme.com/) or maybe raid my Vim config directory for some inspiration.\n\n[modeline]: # ( vim: set wrap linebreak nolist wrapmargin=5 syntax=markdown textwidth=78 formatoptions-=t: )\n",
    "parentPath": "../blog.lmorchard.com/posts/2018-03-01-themesrfun",
    "path": "2018/03/01/themesrfun",
    "thumbnail": "/blog.lmorchard.com/2018/03/01/themesrfun/image_1.png",
    "summary": "<p><strong>TL;DR</strong>: Last year, I started work on a new Test Pilot experiment playing with themes in Firefox. </p>\n",
    "prevPostPath": "2018/03/01/sio2pi",
    "nextPostPath": "2018/02/08/pumpkin"
  },
  {
    "title": "How I learned to love spreadsheets in space",
    "tags": [
      "gaming",
      "node",
      "apis",
      "eveonline",
      "eve"
    ],
    "thumbnail": "/blog.lmorchard.com/uploads/2016/spreadsheets-in-space/wallet.PNG",
    "year": "2016",
    "month": "04",
    "day": "17",
    "isDir": false,
    "slug": "spreadsheets-in-space",
    "date": "2016-04-17T12:00:00.000Z",
    "postName": "2016-04-17-spreadsheets-in-space",
    "html": "<p><strong>TL;DR</strong>: I thought it would be fun to fly internet space ships. Instead,\nit&#39;s proven more satisfying to write software and make internet space money.</p>\n<!--more-->\n\n<nav role=\"navigation\" class=\"table-of-contents\"></nav>\n\n<h2 id=\"looking-for-a-space-job\">Looking for a space job</h2>\n<p>I&#39;ve had an on-again, off-again relationship with EVE Online over the years.\nI was initially attracted by the opportunities to fly space ships, explore the\nuniverse, and occasionally shoot at things in the company of feral internet\nrandos. </p>\n<p>But, when you shoot at things, they often shoot back. Sometimes, you explode.\nSince space ships cost space money, you&#39;re going to need a steady space income.</p>\n<p>Unless you&#39;ve got disposable money IRL to blow on <a href=\"https://secure.eveonline.com/PLEX/howToUsePlex.aspx\">PLEX</a>, this\nmeans you need to <a href=\"http://wiki.eveuniversity.org/EVE_Careers_101\">find a space job</a>.</p>\n<p><a href=\"http://swiftandbitter.com/eve/wtd/\"><img class=\"fullwidth\" title=\"What to do in EVE Online\" src=\"/uploads/2016/spreadsheets-in-space/eve-wtd.jpg\"></a></p>\n<p>For the most part, I&#39;ve found that space jobs in EVE Online are machines\ndesigned to convert tolerance for tedium into small amounts of space money,\nwith scattered moments of panic to keep you paying attention. In fact, it\nreally seems like space jobs are a clever mechanism to position you as\ncontent for other players:</p>\n<ul>\n<li>Miners are stationary targets for long hours in asteroid fields.</li>\n<li>Mission runners hang out in dangerous space for long periods.</li>\n<li>Haulers travel predictable paths between markets.</li>\n<li>Explorers offer roaming targets in otherwise mostly empty space.</li>\n<li>Traders provide inputs into a lively market simulation.</li>\n</ul>\n<p>Much of EVE Online seems to be in discovering ways to generate fun from space\njobs despite the tedium, and players have been astonishingly creative in doing\nso.</p>\n<h2 id=\"wherein-i-found-the-spreadsheets-in-space\">Wherein I found the spreadsheets in space</h2>\n<p>But, I digress. There are reasons why EVE Online is synonymous with\n&quot;<a href=\"google\">spreadsheets in space</a>&quot; - every space station in EVE has a market.\nMost space jobs lead there: Loot, minerals, salvage, and stolen goods all get\nsold on the market. And, nearly everything you&#39;d want to buy with the proceeds\nof your space job come from the market.</p>\n<img class=\"fullwidth\" src=\"/uploads/2016/spreadsheets-in-space/transactions-1.PNG\">\n\n<p>This is where I discovered <a href=\"https://wiki.braveineve.com/public/dojo/wiki/station_trading_complete_guide\">station trading</a>: The price for\nbuying from the market is always higher than selling to the market. It&#39;s like\nretail vs wholesale pricing, but weirder. And, for various reasons, the spread\nbetween these prices can be quite large. So, without ever leaving the station,\nyou can perform <a href=\"https://en.wikipedia.org/wiki/Arbitrage\">arbitrage</a> - i.e. buy low, sell high, pocket the\ndifference.</p>\n<img class=\"fullwidth\" src=\"/uploads/2016/spreadsheets-in-space/history-3.PNG\">\n\n<p>One evening, I tried getting into station trading entirely off-the-cuff:</p>\n<ol>\n<li>Click through every item in the market.</li>\n<li>Eyeball the price spread and history.</li>\n<li>Assemble a list of all the items with a decent, stable margin.</li>\n<li>Put up buy orders, babysit them to ensure they&#39;re always slightly higher\nthan competitors. </li>\n<li>Put items up for sale as buy orders are fulfilled.</li>\n<li>Babysit sell orders to ensure they&#39;re always slightly lower than competitors. </li>\n<li>Profit!</li>\n</ol>\n<h2 id=\"this-looks-like-a-job-for-a-machine\">This looks like a job for a machine</h2>\n<p>As with most space jobs, there is a generous helping of tedium in trading.  It\nimmediately occurred to me that this would be better done by a computer. Why\nclick through all these items one-by-one, when an algorithm could zip through\nand serve up a list of high-margin items in seconds?</p>\n<img class=\"fullwidth\" src=\"/uploads/2016/spreadsheets-in-space/shell.PNG\" style=\"width: 100%\">\n\n<p>Of course, in many games, this would be considered cheating. I remember the\ncontroversy back in the 80s &amp; 90s when &quot;<a href=\"https://www.google.com/search?q=%22tradewars+2002%22+helpers\">helpers</a>&quot; first started appearing for\n<a href=\"http://www.tradewars.com/default.html\">TradeWars 2002</a>, a game that many cite as an early inspiration for EVE\nOnline. And, indeed, fully automated market bots are a bannable offense in EVE\nOnline - that is, CCP want a human to manually enter all those buy &amp; sell\norders and keep on top of them. </p>\n<p>However, CCP only seem to consider the last mile of automation as\noff limits.  <a href=\"https://eve-central.com/home/develop.html\">Enterprising players</a> and <a href=\"https://eveonline-third-party-documentation.readthedocs.org/en/latest/\">even CCP themselves</a> have\nlong offered web service APIs for things like character and market data.  This\nmeans you can use Excel or Google Spreadsheets or even your own original\nsoftware to pull in this data, run calculations, scan for trade\nopportunities, etc. </p>\n<p>As I read up about all of this, it dawned on me: <strong>This is one of the first\nvideo games I&#39;ve played where software development and algorithms are\nintentionally supported ways to play</strong>!</p>\n<p>Holy crap.</p>\n<h2 id=\"sharpening-the-saw\">Sharpening the saw</h2>\n<p>I&#39;ve always loved writing software to solve problems. And, you can\ndescribe games as problem generators. So, it&#39;s been satisfying to play a\ngame through software development. And, it&#39;s been rewarding to measure that\nsoftware&#39;s effectiveness through my profits in space money.  It feels demented\nto say it, but most days I get more out of my wallet balance in station than\nfrom actually flying a ship.</p>\n<img class=\"fullwidth\" src=\"/uploads/2016/spreadsheets-in-space/code-3.PNG\">\n\n<p>It&#39;s had all the nerdy fun of working through puzzles, while also helping\nsharpen the saw on my tech skills. I wasn&#39;t all that familiar with node.js\nbeforehand, but now I&#39;m pretty sharp on it after having applied it to\npractical challenges. I learned a bit of MongoDB and Postgresql to get things\ndone. I&#39;ve played with some JS frameworks to build visualizations for\nmyself, and will probably poke at building some UI for myself in React at some\npoint.</p>\n<p>In the past, my &quot;Hello World&quot; for a new technology stack might have been\ningesting RSS &amp; Atom news feeds to build a River of News. I even used that\nhabit as fodder to write <a href=\"http://amzn.to/1T0lk0p\">my first book</a>. But, these days, I&#39;m finding\nmyself reaching for EVE Online data to provide the test bed for things I want\nto learn. Maybe I&#39;ll find some way to channel this enthusiasm into something\nlike another book or some conference talks. Who knows?</p>\n<!-- vim: set wrap wm=5 syntax=markdown textwidth=78: -->\n",
    "body": "**TL;DR**: I thought it would be fun to fly internet space ships. Instead,\nit's proven more satisfying to write software and make internet space money.\n\n<!--more-->\n\n<nav role=\"navigation\" class=\"table-of-contents\"></nav>\n\n## Looking for a space job\n\nI've had an on-again, off-again relationship with EVE Online over the years.\nI was initially attracted by the opportunities to fly space ships, explore the\nuniverse, and occasionally shoot at things in the company of feral internet\nrandos. \n\nBut, when you shoot at things, they often shoot back. Sometimes, you explode.\nSince space ships cost space money, you're going to need a steady space income.\n\nUnless you've got disposable money IRL to blow on [PLEX][howplex], this\nmeans you need to [find a space job][spacejob].\n\n[spacejob]: http://wiki.eveuniversity.org/EVE_Careers_101\n[howplex]: https://secure.eveonline.com/PLEX/howToUsePlex.aspx\n\n[<img class=\"fullwidth\" title=\"What to do in EVE Online\" src=\"/uploads/2016/spreadsheets-in-space/eve-wtd.jpg\">](http://swiftandbitter.com/eve/wtd/)\n\nFor the most part, I've found that space jobs in EVE Online are machines\ndesigned to convert tolerance for tedium into small amounts of space money,\nwith scattered moments of panic to keep you paying attention. In fact, it\nreally seems like space jobs are a clever mechanism to position you as\ncontent for other players:\n\n* Miners are stationary targets for long hours in asteroid fields.\n* Mission runners hang out in dangerous space for long periods.\n* Haulers travel predictable paths between markets.\n* Explorers offer roaming targets in otherwise mostly empty space.\n* Traders provide inputs into a lively market simulation.\n\nMuch of EVE Online seems to be in discovering ways to generate fun from space\njobs despite the tedium, and players have been astonishingly creative in doing\nso.\n\n## Wherein I found the spreadsheets in space\n\nBut, I digress. There are reasons why EVE Online is synonymous with\n\"[spreadsheets in space](google)\" - every space station in EVE has a market.\nMost space jobs lead there: Loot, minerals, salvage, and stolen goods all get\nsold on the market. And, nearly everything you'd want to buy with the proceeds\nof your space job come from the market.\n\n[google]: https://www.google.com/search?q=spreadsheets+in+space\n\n<img class=\"fullwidth\" src=\"/uploads/2016/spreadsheets-in-space/transactions-1.PNG\">\n\nThis is where I discovered [station trading][stationtrading]: The price for\nbuying from the market is always higher than selling to the market. It's like\nretail vs wholesale pricing, but weirder. And, for various reasons, the spread\nbetween these prices can be quite large. So, without ever leaving the station,\nyou can perform [arbitrage][] - i.e. buy low, sell high, pocket the\ndifference.\n\n<img class=\"fullwidth\" src=\"/uploads/2016/spreadsheets-in-space/history-3.PNG\">\n\nOne evening, I tried getting into station trading entirely off-the-cuff:\n\n1. Click through every item in the market.\n2. Eyeball the price spread and history.\n3. Assemble a list of all the items with a decent, stable margin.\n4. Put up buy orders, babysit them to ensure they're always slightly higher\n   than competitors. \n5. Put items up for sale as buy orders are fulfilled.\n6. Babysit sell orders to ensure they're always slightly lower than competitors. \n7. Profit!\n\n## This looks like a job for a machine\n\nAs with most space jobs, there is a generous helping of tedium in trading.  It\nimmediately occurred to me that this would be better done by a computer. Why\nclick through all these items one-by-one, when an algorithm could zip through\nand serve up a list of high-margin items in seconds?\n\n<img class=\"fullwidth\" src=\"/uploads/2016/spreadsheets-in-space/shell.PNG\" style=\"width: 100%\">\n\nOf course, in many games, this would be considered cheating. I remember the\ncontroversy back in the 80s & 90s when \"[helpers][]\" first started appearing for\n[TradeWars 2002][], a game that many cite as an early inspiration for EVE\nOnline. And, indeed, fully automated market bots are a bannable offense in EVE\nOnline - that is, CCP want a human to manually enter all those buy & sell\norders and keep on top of them. \n\n[helpers]: https://www.google.com/search?q=\"tradewars+2002\"+helpers\n[TradeWars 2002]: http://www.tradewars.com/default.html\n\nHowever, CCP only seem to consider the last mile of automation as\noff limits.  [Enterprising players][evecentral] and [even CCP themselves][eveapi] have\nlong offered web service APIs for things like character and market data.  This\nmeans you can use Excel or Google Spreadsheets or even your own original\nsoftware to pull in this data, run calculations, scan for trade\nopportunities, etc. \n\nAs I read up about all of this, it dawned on me: **This is one of the first\nvideo games I've played where software development and algorithms are\nintentionally supported ways to play**!\n\nHoly crap.\n\n## Sharpening the saw\n\nI've always loved writing software to solve problems. And, you can\ndescribe games as problem generators. So, it's been satisfying to play a\ngame through software development. And, it's been rewarding to measure that\nsoftware's effectiveness through my profits in space money.  It feels demented\nto say it, but most days I get more out of my wallet balance in station than\nfrom actually flying a ship.\n\n<img class=\"fullwidth\" src=\"/uploads/2016/spreadsheets-in-space/code-3.PNG\">\n\nIt's had all the nerdy fun of working through puzzles, while also helping\nsharpen the saw on my tech skills. I wasn't all that familiar with node.js\nbeforehand, but now I'm pretty sharp on it after having applied it to\npractical challenges. I learned a bit of MongoDB and Postgresql to get things\ndone. I've played with some JS frameworks to build visualizations for\nmyself, and will probably poke at building some UI for myself in React at some\npoint.\n\nIn the past, my \"Hello World\" for a new technology stack might have been\ningesting RSS & Atom news feeds to build a River of News. I even used that\nhabit as fodder to write [my first book][book]. But, these days, I'm finding\nmyself reaching for EVE Online data to provide the test bed for things I want\nto learn. Maybe I'll find some way to channel this enthusiasm into something\nlike another book or some conference talks. Who knows?\n\n[book]: http://amzn.to/1T0lk0p\n\n[evecentral]: https://eve-central.com/home/develop.html\n[eveapi]: https://eveonline-third-party-documentation.readthedocs.org/en/latest/\n[arbitrage]: https://en.wikipedia.org/wiki/Arbitrage\n[stationtrading]: https://wiki.braveineve.com/public/dojo/wiki/station_trading_complete_guide\n\n<!-- vim: set wrap wm=5 syntax=markdown textwidth=78: -->\n",
    "parentPath": "../blog.lmorchard.com/posts",
    "path": "2016/04/17/spreadsheets-in-space",
    "summary": "<p><strong>TL;DR</strong>: I thought it would be fun to fly internet space ships. Instead,\nit&apos;s proven more satisfying to write software and make internet space money.</p>\n",
    "prevPostPath": "2016/08/29/gamechord",
    "nextPostPath": "2016/02/21/modelm-controller"
  }
]