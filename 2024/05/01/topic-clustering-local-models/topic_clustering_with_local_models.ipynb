{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f667fd54-3828-4b8f-84c4-8c549aa1f70d",
   "metadata": {
    "id": "f667fd54-3828-4b8f-84c4-8c549aa1f70d"
   },
   "source": [
    "Let's brainstorm a list of miscellaneous things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e91a7c1-ee10-4b71-b7cc-5ee3ff5f38f1",
   "metadata": {
    "id": "6e91a7c1-ee10-4b71-b7cc-5ee3ff5f38f1"
   },
   "outputs": [],
   "source": [
    "items_text = \"\"\"\n",
    "- pasta\n",
    "- thomas dolby\n",
    "- alpha\n",
    "- apples\n",
    "- cats\n",
    "- pears\n",
    "- meters\n",
    "- brick\n",
    "- dogs\n",
    "- beta\n",
    "- howard jones\n",
    "- concrete\n",
    "- asphalt\n",
    "- milk\n",
    "- rebar\n",
    "- gillian gilbert\n",
    "- hamsters\n",
    "- bread\n",
    "- butter\n",
    "- wendy carlos\n",
    "- gamma\n",
    "- birds\n",
    "- bananas\n",
    "- rick wakeman\n",
    "- inches\n",
    "- glass\n",
    "- feet\n",
    "- gary numan\n",
    "- miles\n",
    "- lumber\n",
    "- kilometers\n",
    "- geoff downes\n",
    "\"\"\"\n",
    "\n",
    "# Split the text into non-empty lines...\n",
    "items = [x for x in items_text.split(\"\\n\") if x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L9iFm_f9lXRn",
   "metadata": {
    "id": "L9iFm_f9lXRn"
   },
   "source": [
    "Let's install some needful modules..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "NV9kLwjeiKgh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NV9kLwjeiKgh",
    "outputId": "2544a622-1da3-464a-9b68-2a344659ceb2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: torch in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (2.3.0)\n",
      "Requirement already satisfied: sentence_transformers in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: accelerate in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: filelock in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from sentence_transformers) (4.39.1)\n",
      "Requirement already satisfied: tqdm in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from sentence_transformers) (4.66.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from sentence_transformers) (0.22.2)\n",
      "Requirement already satisfied: Pillow in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from sentence_transformers) (10.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: requests in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2024.4.16)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lorchard/devel/pubpulse/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn torch sentence_transformers accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be31fc26-fba7-43e1-9609-8f2138ac5090",
   "metadata": {
    "id": "be31fc26-fba7-43e1-9609-8f2138ac5090"
   },
   "source": [
    "Next, let's pick an embedding model and generate semantic vector representations for all our list items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "qa6Z5_E1kBKR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qa6Z5_E1kBKR",
    "outputId": "61cc0b2c-ff84-4c6c-e6cf-17fa1aaeaebf",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02736097,  0.00340217, -0.01076854, ..., -0.02489066,\n",
       "         0.01647391, -0.02072625],\n",
       "       [-0.03888908,  0.02349574,  0.0143796 , ..., -0.01913134,\n",
       "        -0.03127009, -0.0304915 ],\n",
       "       [ 0.01443943,  0.02336113,  0.00634783, ...,  0.00120864,\n",
       "        -0.01801292, -0.02678853],\n",
       "       ...,\n",
       "       [ 0.00835066,  0.00595316, -0.01179765, ..., -0.01259451,\n",
       "        -0.0165759 , -0.0056388 ],\n",
       "       [ 0.0005869 ,  0.01886297, -0.0079366 , ..., -0.04092352,\n",
       "        -0.01162215, -0.01117233],\n",
       "       [-0.00889315, -0.00544541, -0.02917784, ..., -0.01641204,\n",
       "        -0.01544971, -0.01567657]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 384 dimensions - https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "# embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# 384 dimensions - https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2\n",
    "# embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2')\n",
    "\n",
    "# 768 dimensions - https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n",
    "# embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# 768 dimensions - https://huggingface.co/thenlper/gte-base\n",
    "# embedding_model = SentenceTransformer('thenlper/gte-base')\n",
    "\n",
    "# 1024 dimensions - https://huggingface.co/thenlper/gte-large\n",
    "embedding_model = SentenceTransformer('thenlper/gte-large')\n",
    "\n",
    "embeddings = embedding_model.encode(items)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca1f979-c48e-4abf-9234-ea18e5dc9279",
   "metadata": {
    "id": "0ca1f979-c48e-4abf-9234-ea18e5dc9279"
   },
   "source": [
    "Now that we have vectors, let's try clustering them within the semantic space of the model. This should be roughly analogous to grouping them by meaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a01789e5-0257-4227-a71a-666cc1160e98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a01789e5-0257-4227-a71a-666cc1160e98",
    "outputId": "bb3086e7-a6e7-43f8-f239-be205f1d373f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['- meters', '- inches', '- feet', '- miles', '- kilometers'],\n",
       " ['- alpha', '- beta', '- gamma'],\n",
       " ['- brick', '- concrete', '- asphalt', '- rebar', '- glass', '- lumber'],\n",
       " ['- howard jones', '- gillian gilbert', '- wendy carlos'],\n",
       " ['- apples', '- pears', '- bananas'],\n",
       " ['- cats', '- dogs', '- hamsters', '- birds'],\n",
       " ['- pasta', '- bread'],\n",
       " ['- thomas dolby', '- rick wakeman', '- gary numan', '- geoff downes'],\n",
       " ['- milk', '- butter']]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from itertools import groupby\n",
    "\n",
    "# Let's say we want to organize the list into this many clusters\n",
    "n_clusters = 9\n",
    "\n",
    "# Use the k-means algorithm to come up with a cluster ID for each embedding\n",
    "cluster_ids = KMeans(n_clusters=n_clusters, n_init='auto').fit_predict(embeddings)\n",
    "\n",
    "# Associate each cluster ID with the corresponding item\n",
    "cluster_ids_with_items = zip(cluster_ids, items)\n",
    "\n",
    "# Group the pairs of (cluster_id, item) into lists based on cluster ID\n",
    "grouped_cluster_ids_with_items = groupby(\n",
    "    sorted(cluster_ids_with_items, key=lambda x: x[0]),\n",
    "    key=lambda x: x[0]\n",
    ")\n",
    "\n",
    "# Simplify that whole mess so we just have a list of clustered items\n",
    "clustered_items = [\n",
    "    [item for cluster_id, item in item_group]\n",
    "    for cluster_id, item_group\n",
    "    in grouped_cluster_ids_with_items\n",
    "]\n",
    "\n",
    "clustered_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f44e1d2-7179-4bce-8d0a-e716eecfcfb4",
   "metadata": {
    "id": "8f44e1d2-7179-4bce-8d0a-e716eecfcfb4"
   },
   "source": [
    "It's not perfect, but we've got our list roughly organized. \n",
    "Next, let's load up an LLM to use very shortly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6ad70058-0eab-4f73-89a9-5e90a9ea55a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0/tree/main\n",
    "\n",
    "This model is about 2.2GB.\n",
    "My 2021 MacPook Pro with an Apple M1 Pro and 32GB of RAM seems to have no problem with this model.\n",
    "\"\"\"\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0de560-71f6-495d-884d-aba9d17e0c79",
   "metadata": {},
   "source": [
    "Loading the LLM is separate from using it, so we can iterate faster on the prompt in this next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "9449ca3f-fe7b-49a2-8d71-729b8da12207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# \"Essential Measurement Tools for Everyday Life\"\n",
      "\n",
      "- meters\n",
      "- inches\n",
      "- feet\n",
      "- miles\n",
      "- kilometers\n",
      "\n",
      "# \"Key Components for Successful Project Management\"\n",
      "\n",
      "- alpha\n",
      "- beta\n",
      "- gamma\n",
      "\n",
      "# \"Materials for Construction and Repair\"\n",
      "\n",
      "- brick\n",
      "- concrete\n",
      "- asphalt\n",
      "- rebar\n",
      "- glass\n",
      "- lumber\n",
      "\n",
      "# \"Essential Artists: Howard Jones, Gillian Gillespie, and Wendy Carlos\"\n",
      "\n",
      "- howard jones\n",
      "- gillian gilbert\n",
      "- wendy carlos\n",
      "\n",
      "# \"Fresh Fruits\"\n",
      "\n",
      "- apples\n",
      "- pears\n",
      "- bananas\n",
      "\n",
      "# \"Animals\"\n",
      "\n",
      "- cats\n",
      "- dogs\n",
      "- hamsters\n",
      "- birds\n",
      "\n",
      "# \"Essential Ingredients for a Comforting Meal\"\n",
      "\n",
      "- pasta\n",
      "- bread\n",
      "\n",
      "# \"Top 5 Legendary Musicians of the 1980s\"\n",
      "\n",
      "- thomas dolby\n",
      "- rick wakeman\n",
      "- gary numan\n",
      "- geoff downes\n",
      "\n",
      "# \"Food Essentials\"\n",
      "\n",
      "- milk\n",
      "- butter\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are a helpful but terse assistant.\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Given the following list of items, I need a succinct label that effectively encapsulates the overall theme or purpose.\n",
    "\n",
    "This is the list of items:\n",
    "\n",
    "%s\n",
    "\n",
    "Can you generate a concise, descriptive label for this list? Thanks in advance!\n",
    "\"\"\"\n",
    "\n",
    "def generate_topic(items):\n",
    "    text = \"\\n\".join(items)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt % text},\n",
    "    ]\n",
    "    prompt = pipe.tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    results = pipe(\n",
    "        prompt,\n",
    "        max_new_tokens=32,\n",
    "        do_sample=True,\n",
    "        # this tells the LLM how much of a rando to be while selecting tokens during generation\n",
    "        temperature=0.1,\n",
    "        # this tells the LLM how many different tokens to decide between at each step of generation\n",
    "        top_k=3,\n",
    "        # this tells the LLM how picky to be about the most likely tokens to select while generating\n",
    "        top_p=0.8,\n",
    "    )\n",
    "    # HACK: trim the prompt off the start of the generated text\n",
    "    generated_text = results[0]['generated_text'][len(prompt):].strip()    \n",
    "    return generated_text\n",
    "    \n",
    "for cluster in clustered_items:\n",
    "    topic = generate_topic(cluster)\n",
    "\n",
    "    print(f\"# {topic}\")\n",
    "    print()\n",
    "    for item in cluster:\n",
    "        print(f\"{item}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
